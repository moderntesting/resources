1
00:00:00,000 --> 00:00:01,440
Brent, can you beat box?

2
00:00:02,080 --> 00:00:02,580
No.

3
00:00:06,210 --> 00:00:10,370
Welcome to AB testing podcast, your modern testing podcast.

4
00:00:10,690 --> 00:00:16,090
Your hosts, Alan and Brent will be here to guide you through topics on testing

5
00:00:16,310 --> 00:00:19,290
leadership, agile, and anything else that comes to mind.

6
00:00:19,570 --> 00:00:21,130
Now on with the show.

7
00:00:21,770 --> 00:00:24,970
Welcome to two guys drinking beer, talking bullshit.

8
00:00:24,970 --> 00:00:27,370
This is your modern testing podcast.

9
00:00:27,370 --> 00:00:28,050
I'm Alan.

10
00:00:28,170 --> 00:00:28,970
Hi, Brent.

11
00:00:29,170 --> 00:00:32,570
And here we are yet again to drink beer.

12
00:00:32,690 --> 00:00:33,690
I didn't make a drink.

13
00:00:33,930 --> 00:00:35,330
I was chatting with Molly.

14
00:00:35,370 --> 00:00:37,170
This is like the second podcast in a row.

15
00:00:37,690 --> 00:00:43,370
Call out to Molly where I thought about drinking ahead of or during the podcast.

16
00:00:43,370 --> 00:00:48,290
There's, um, I'll say I'm going to, I'm going to say this job's great.

17
00:00:48,330 --> 00:00:48,650
I'm fine.

18
00:00:48,690 --> 00:00:49,570
I'm at the stage now.

19
00:00:49,570 --> 00:00:51,290
I'm actually getting stuff done, which is fun.

20
00:00:51,290 --> 00:00:52,030
I haven't done that yet.

21
00:00:52,030 --> 00:00:52,570
So that's good.

22
00:00:52,610 --> 00:00:53,110
Good.

23
00:00:53,530 --> 00:00:58,810
Not a lot of stuff, a little stuff, but you know how it is when you got a

24
00:00:58,810 --> 00:01:01,610
drag people from one belief system to another.

25
00:01:02,330 --> 00:01:03,170
Uh, yeah.

26
00:01:03,410 --> 00:01:03,810
Yeah.

27
00:01:03,810 --> 00:01:06,170
So I'm doing some of that and it's essential.

28
00:01:06,330 --> 00:01:09,250
Welcome to the, if it was easy, it wouldn't be fun.

29
00:01:09,330 --> 00:01:10,050
Exactly.

30
00:01:10,290 --> 00:01:13,090
And I was going to say, welcome to the AB testing podcast.

31
00:01:13,090 --> 00:01:13,730
Oh, yeah.

32
00:01:14,610 --> 00:01:14,970
Yeah.

33
00:01:15,010 --> 00:01:16,090
This is what we do here.

34
00:01:16,170 --> 00:01:16,410
Right.

35
00:01:16,410 --> 00:01:16,610
Yeah.

36
00:01:17,370 --> 00:01:18,450
So anyway, how are you doing?

37
00:01:18,450 --> 00:01:19,770
What's, what's new in your world?

38
00:01:20,610 --> 00:01:22,530
Uh, review season.

39
00:01:22,570 --> 00:01:23,170
That's,

40
00:01:23,650 --> 00:01:24,650
I got so lucky.

41
00:01:24,650 --> 00:01:28,850
I joined NBCU right after their review season.

42
00:01:28,850 --> 00:01:31,410
So I don't have to do it for like 10 months.

43
00:01:31,610 --> 00:01:32,210
Oh yeah.

44
00:01:32,210 --> 00:01:35,970
That's you did get lucky and even better.

45
00:01:36,720 --> 00:01:41,560
You almost got really unlucky because, Oh, and by the way, it's review season.

46
00:01:41,560 --> 00:01:45,120
And you got to get all your feedback in by Friday.

47
00:01:45,400 --> 00:01:49,800
You know, I did a review season right before I left unity, not right

48
00:01:49,800 --> 00:01:51,000
before, but recently.

49
00:01:51,320 --> 00:01:56,370
And I was working with my HR business partner who had just come to unity

50
00:01:56,370 --> 00:02:01,450
from a different company and unfortunately due to cycles, he had, cause this is

51
00:02:01,450 --> 00:02:06,490
the painful, it's just a painful process for HR and, and managers it's essential.

52
00:02:06,490 --> 00:02:11,730
And if you do it right, it's essential because it puts a framework around having

53
00:02:11,730 --> 00:02:13,370
some good career discussions for folks.

54
00:02:13,370 --> 00:02:17,450
All that's great, but it's a lot of work and it's a lot of work for HR.

55
00:02:17,490 --> 00:02:20,290
Anyway, the story, I probably shouldn't have bothered telling when I've

56
00:02:20,290 --> 00:02:24,570
already started, I suppose, we'll finish it is he ended up doing back to back

57
00:02:25,090 --> 00:02:28,850
reviews, re seasons, because he did one of his old company, changed jobs,

58
00:02:28,890 --> 00:02:30,290
immediately had to do another one at unity.

59
00:02:32,740 --> 00:02:36,060
So, uh, and that's from the HR side, a little bit different, but still,

60
00:02:36,060 --> 00:02:40,060
it's a lot of coordination they do to get every stuff, everything together.

61
00:02:40,060 --> 00:02:45,100
But it would be equally as bad, if not worse for like a manager to do a review

62
00:02:45,100 --> 00:02:47,460
season, get a new job and then go right back into it again.

63
00:02:48,220 --> 00:02:50,380
Also, it would be hard to do as a new manager.

64
00:02:50,500 --> 00:02:53,180
Anyway, review season at the big M.

65
00:02:54,000 --> 00:02:54,720
Yes.

66
00:02:54,800 --> 00:02:55,440
Yes.

67
00:02:55,520 --> 00:02:59,760
You may have heard that there are some changes to cycle around.

68
00:02:59,760 --> 00:03:01,080
It was public news.

69
00:03:01,400 --> 00:03:03,840
Oh, there, there are no merit increases, correct?

70
00:03:03,960 --> 00:03:04,480
Right.

71
00:03:05,040 --> 00:03:06,240
I did hear that.

72
00:03:06,440 --> 00:03:09,560
And honestly, I think that's a smart move.

73
00:03:10,120 --> 00:03:13,870
I wish, I think it's a reasonable move.

74
00:03:14,070 --> 00:03:16,150
If you're not doing any more layoffs.

75
00:03:17,330 --> 00:03:17,570
Yes.

76
00:03:17,570 --> 00:03:21,610
I think, I think it sends a pretty mixed message on the negative side.

77
00:03:21,650 --> 00:03:25,370
If you continue to do layoffs while doing that.

78
00:03:25,890 --> 00:03:32,450
Well, so the thing is, is that hopefully it constructs some form of

79
00:03:32,450 --> 00:03:38,500
insulation layoffs are going to be very tightly bound to whether or not we get

80
00:03:38,500 --> 00:03:41,940
out of the recession or, you know, anytime soon or not.

81
00:03:42,730 --> 00:03:44,010
You're already overpaid anyway.

82
00:03:44,010 --> 00:03:44,490
Give it up.

83
00:03:45,210 --> 00:03:46,530
Uh, wait, we all are.

84
00:03:47,170 --> 00:03:49,090
Uh, and yes, definitely.

85
00:03:49,410 --> 00:03:55,650
And no, I worked hard to get, to get it, but there's several other things that are

86
00:03:55,890 --> 00:03:59,410
potentially interesting around what they're doing there.

87
00:04:00,970 --> 00:04:04,970
We can talk about it later in the, in the, in the show if necessary, but

88
00:04:05,170 --> 00:04:10,730
yeah, like, like that'll just tell right into our seamless agenda a little bit later.

89
00:04:10,850 --> 00:04:11,170
Yeah.

90
00:04:11,450 --> 00:04:17,450
The, well, it will actually, but like a great salary normalization.

91
00:04:18,130 --> 00:04:24,080
It is probably on its way, whether it be through things like AI, whether it

92
00:04:24,080 --> 00:04:30,800
be through things like, uh, inflation, there's big things, big things of foot

93
00:04:30,840 --> 00:04:31,920
in my humble of view.

94
00:04:32,400 --> 00:04:40,800
And I think, I think the more we make things simpler than the more you can

95
00:04:40,800 --> 00:04:46,600
get things done with less qualified people, less qualified people required

96
00:04:47,040 --> 00:04:53,600
less salary, which then might do to market forces changes the demand for that salary.

97
00:04:53,840 --> 00:04:54,400
Potentially.

98
00:04:54,400 --> 00:04:59,800
And we talked about this last time in that while that is true, you can

99
00:04:59,800 --> 00:05:01,480
look at it, that as being absolutely true.

100
00:05:01,480 --> 00:05:03,920
And that's one possible outcome or timeline.

101
00:05:04,360 --> 00:05:11,560
Another one is, is that we use AI smart people who should be compensated.

102
00:05:11,560 --> 00:05:16,760
Well, can use AI to enhance what they get done.

103
00:05:16,760 --> 00:05:18,480
So they actually are getting more done.

104
00:05:19,360 --> 00:05:21,960
So there's a couple of different ways this plays out, but

105
00:05:23,480 --> 00:05:27,920
really it's like, it's, there's a lot of forces all competing at the same

106
00:05:27,920 --> 00:05:34,000
time with the recession, the economy with AI and the advances that are put

107
00:05:34,000 --> 00:05:38,120
us into the adjacent possible, Steven Johnson called us plus world

108
00:05:38,120 --> 00:05:43,320
situations and American shit show of politics, all sorts of things

109
00:05:43,360 --> 00:05:50,270
are playing off each other, affecting all affecting everything else.

110
00:05:50,590 --> 00:05:50,870
Yeah.

111
00:05:50,870 --> 00:05:51,070
Yeah.

112
00:05:51,070 --> 00:05:53,270
And they're all fighting everything else.

113
00:05:53,750 --> 00:05:56,030
Uh, and it's like, it's a system.

114
00:05:56,710 --> 00:06:03,300
It is a system, but all the different, it's like a system and they've taken

115
00:06:03,300 --> 00:06:08,060
out too many parts and replaced them with two new with different parts that

116
00:06:08,060 --> 00:06:13,220
look fundamentally different and do different things and right.

117
00:06:13,220 --> 00:06:18,260
I, I wonder how long it's going to take for this, for this system to sort

118
00:06:18,260 --> 00:06:20,700
of restabilize so that we understand it.

119
00:06:21,620 --> 00:06:22,580
That's number one.

120
00:06:22,580 --> 00:06:27,620
And number two, I guess, will it, will it ever stabilize?

121
00:06:27,620 --> 00:06:34,500
Cause certainly on the pace of AI, that's accelerating faster

122
00:06:34,500 --> 00:06:36,380
and faster and faster.

123
00:06:36,940 --> 00:06:42,220
By the way, by the way, um, because we have a, we have a AI packed show today.

124
00:06:42,220 --> 00:06:46,340
I believe, although again, long time listeners will know we used to have

125
00:06:46,340 --> 00:06:48,780
agendas, but now we don't, but we do.

126
00:06:48,820 --> 00:06:50,060
We just don't write them down.

127
00:06:50,060 --> 00:06:51,260
We're that much in sync.

128
00:06:51,660 --> 00:06:58,490
Is your middle name, Ian, or anything is more than I, uh, my, my, could you change

129
00:06:58,490 --> 00:06:58,610
it?

130
00:06:58,650 --> 00:07:01,530
Cause I think maybe we can be the AI testing podcast.

131
00:07:02,740 --> 00:07:06,010
Oh, I'll consider it.

132
00:07:06,250 --> 00:07:06,650
All right.

133
00:07:06,690 --> 00:07:06,970
All right.

134
00:07:06,970 --> 00:07:07,650
I'm not going to go.

135
00:07:07,850 --> 00:07:11,530
I'm not going to go with you have to take advantage of what's popular.

136
00:07:12,170 --> 00:07:15,090
There is, I put this on my five for Friday, which you didn't read,

137
00:07:15,090 --> 00:07:16,410
but some of the listeners have.

138
00:07:16,730 --> 00:07:19,930
I religiously, wait, wait, wait, wait.

139
00:07:19,930 --> 00:07:24,810
F F U I religiously read your five for today.

140
00:07:25,370 --> 00:07:27,450
No, I, I read it when I get home.

141
00:07:27,450 --> 00:07:29,930
So you're, you're just, you're not really okay.

142
00:07:29,930 --> 00:07:30,410
We need home.

143
00:07:30,530 --> 00:07:30,770
You know what?

144
00:07:30,770 --> 00:07:32,090
I'm going to give you a number five.

145
00:07:32,450 --> 00:07:35,690
It's this tea shop in India called chai GPT.

146
00:07:36,550 --> 00:07:37,230
Oh, that's funny.

147
00:07:37,390 --> 00:07:37,750
That's right.

148
00:07:37,750 --> 00:07:39,630
I thought it was really, really funny.

149
00:07:39,710 --> 00:07:40,510
Really funny.

150
00:07:40,830 --> 00:07:41,590
It's funny.

151
00:07:41,710 --> 00:07:43,870
I mean, except for the fact chai is gross.

152
00:07:44,350 --> 00:07:46,030
Well, I actually, I do like chai.

153
00:07:46,190 --> 00:07:51,190
I drink chai tea without any of the milk, just the tea, you know, chai,

154
00:07:51,550 --> 00:07:55,150
chai tea with milk, but without the chai is pretty good.

155
00:07:56,790 --> 00:08:00,790
Actually worth calling out here in our random bit from two guys drinking

156
00:08:00,790 --> 00:08:03,030
beer without any beer is that I.

157
00:08:03,750 --> 00:08:05,990
During the pandemic, I went through fate.

158
00:08:06,030 --> 00:08:09,230
Well, they can't call it the pandemic because I work from home all the time.

159
00:08:09,230 --> 00:08:13,710
Now this is my office, but somewhere like when it first started, my first

160
00:08:13,710 --> 00:08:19,030
all went home because my good, like work has crappy coffee at home has good

161
00:08:19,030 --> 00:08:22,990
coffee, my coffee consumption initially skyrocketed.

162
00:08:23,790 --> 00:08:27,550
I was drinking so much coffee, like so much.

163
00:08:27,630 --> 00:08:30,510
So I stopped, I've tapered, I didn't cold turkey.

164
00:08:30,510 --> 00:08:31,030
I stopped.

165
00:08:31,030 --> 00:08:31,790
I tapered off.

166
00:08:31,990 --> 00:08:33,870
I never stopped drinking coffee.

167
00:08:33,870 --> 00:08:35,270
I stopped drinking as much coffee.

168
00:08:35,550 --> 00:08:37,270
I stopped having coffee every morning.

169
00:08:37,470 --> 00:08:41,630
I kind of got into tea for a while and now I drink tea probably as

170
00:08:41,630 --> 00:08:42,950
often as I drink coffee.

171
00:08:42,950 --> 00:08:46,710
I've become, I went from all the way coffee backed off, went all the way

172
00:08:46,710 --> 00:08:50,310
tea, and now I just do either whatever feels right.

173
00:08:50,310 --> 00:08:52,430
It's kind of like what am I drinking tonight?

174
00:08:52,430 --> 00:08:53,830
Is it gin?

175
00:08:53,870 --> 00:08:54,870
Is it wine?

176
00:08:54,870 --> 00:08:55,790
Is it beer?

177
00:08:56,230 --> 00:09:00,910
It could be anything I can, I'm, I can do it all.

178
00:09:01,230 --> 00:09:09,430
I too have had a, a bio rhythm of sorts on my preferred caffeine beverage.

179
00:09:10,030 --> 00:09:17,670
Uh, I am definitely at coffee right now, but like 10 years ago, uh, you

180
00:09:17,670 --> 00:09:19,190
would never see me with coffee.

181
00:09:19,190 --> 00:09:24,390
You would see me walking around with a cup of Earl gray, which was my, my go-to tea.

182
00:09:24,430 --> 00:09:26,390
That's just because of, of TNG, right?

183
00:09:27,210 --> 00:09:27,770
Of what?

184
00:09:28,740 --> 00:09:29,580
TNG?

185
00:09:29,740 --> 00:09:30,460
TNG.

186
00:09:30,620 --> 00:09:37,400
Next generation, Captain Picard always drink Earl gray, hot dude, hand in your

187
00:09:37,400 --> 00:09:39,080
geek card, hand it in.

188
00:09:39,720 --> 00:09:42,160
Uh, you know, no, I was trying to answer your question.

189
00:09:42,160 --> 00:09:45,080
I'm like, you know, I, it might've been.

190
00:09:47,880 --> 00:09:51,600
I don't, you are a geek, but you're too old and forgetful to remember it.

191
00:09:52,040 --> 00:09:52,520
Yeah.

192
00:09:52,600 --> 00:09:53,320
That's correct.

193
00:09:54,120 --> 00:09:55,200
Well, that's for sure.

194
00:09:55,600 --> 00:09:55,960
All right.

195
00:09:56,280 --> 00:09:58,960
Hey, do we have any topics to talk about that you had something you

196
00:09:58,960 --> 00:10:02,000
wanted to talk about and I riffed on that and that gave me some stuff.

197
00:10:02,120 --> 00:10:06,000
We have not discussed these in advance, but I thought, you know, 10 minutes in.

198
00:10:06,790 --> 00:10:08,430
We should almost do it.

199
00:10:08,470 --> 00:10:11,750
But the great thing is we started a little bit late and we're going to end

200
00:10:12,190 --> 00:10:13,310
just before the top of the hour.

201
00:10:13,310 --> 00:10:15,350
Like we usually do listeners.

202
00:10:15,350 --> 00:10:21,200
I want to hear from you because I listened to a lot, a lot of podcasts.

203
00:10:21,880 --> 00:10:24,680
And my favorite ones actually are the half hour ones.

204
00:10:24,680 --> 00:10:26,600
I don't know if we could do a half hour podcast because

205
00:10:26,600 --> 00:10:27,600
we'd be closing right now.

206
00:10:27,800 --> 00:10:31,480
Uh, but lately because we've been starting a little bit after the hour

207
00:10:31,480 --> 00:10:35,000
and then I edit out all, believe it or not, out of all the boring

208
00:10:35,000 --> 00:10:39,400
parts in our podcast, there is a chunk more that ends up on the

209
00:10:39,800 --> 00:10:41,240
virtual cutting room floor.

210
00:10:41,360 --> 00:10:44,880
So this will end up being about 40, 45 minutes, which I think is a pretty

211
00:10:44,880 --> 00:10:46,520
good length for an ABI testing podcast.

212
00:10:46,800 --> 00:10:48,600
You play that at 1.25 speed.

213
00:10:48,600 --> 00:10:50,760
You can still understand me when I'm hopped up on caffeine.

214
00:10:51,000 --> 00:10:53,940
And later when I rap, you want to slow that down.

215
00:10:53,940 --> 00:10:55,380
It sounds, but it'll sound better sped up.

216
00:10:55,380 --> 00:10:56,020
Don't slow it down.

217
00:10:56,340 --> 00:10:59,380
Shorter podcast, rewind the stack stuff.

218
00:10:59,380 --> 00:11:01,220
We're going to talk about Brent Europe.

219
00:11:01,940 --> 00:11:02,420
All right.

220
00:11:02,860 --> 00:11:06,900
On the one of the, bring some energy, Brent, come on in on the one

221
00:11:06,900 --> 00:11:08,420
of the three slack channel.

222
00:11:08,580 --> 00:11:09,260
Yeah.

223
00:11:09,300 --> 00:11:09,540
Yeah.

224
00:11:09,540 --> 00:11:09,980
Yeah.

225
00:11:10,100 --> 00:11:15,210
Um, there was a thought that, that came by recently.

226
00:11:15,650 --> 00:11:15,890
Right.

227
00:11:15,890 --> 00:11:21,290
And I was thinking about, I'll share the, the thought shortly.

228
00:11:21,730 --> 00:11:25,780
I was thinking about what started us down this podcast.

229
00:11:25,820 --> 00:11:26,140
Right.

230
00:11:26,140 --> 00:11:30,790
It was, it was, um, agile.

231
00:11:31,630 --> 00:11:35,410
Agile is, is not so much agile.

232
00:11:35,410 --> 00:11:39,250
I was buzzword term used far too often wrong in the industry.

233
00:11:39,330 --> 00:11:40,050
That would agile is.

234
00:11:40,410 --> 00:11:43,730
Uh, that is, uh, one of the many definitions.

235
00:11:43,770 --> 00:11:44,210
Yes.

236
00:11:44,490 --> 00:11:52,730
The invention and rollout eventually of agile and eventually people started to observe

237
00:11:52,730 --> 00:11:55,090
successful deployments, right.

238
00:11:55,090 --> 00:12:00,410
And as well as, as service, uh, services coming on where, where agile really

239
00:12:00,410 --> 00:12:01,410
makes sense, right?

240
00:12:01,450 --> 00:12:06,930
The ability to quickly adapt, which really couldn't do in the ship product world.

241
00:12:07,530 --> 00:12:07,890
Right.

242
00:12:08,520 --> 00:12:15,530
That in my view is what started the domino chain where not only do we see

243
00:12:15,730 --> 00:12:21,970
testing becoming less relevant, uh, but becoming.

244
00:12:22,810 --> 00:12:29,290
Under threat and eventually causing you and I to start going through doing some

245
00:12:29,290 --> 00:12:36,040
studies, I did some experimentation and going, Oh, if we view testing as

246
00:12:36,080 --> 00:12:38,760
his job is to reduce risk.

247
00:12:39,680 --> 00:12:40,760
Um, yeah.

248
00:12:40,880 --> 00:12:45,200
Uh, actually agile succeeds way better than anything I've ever done.

249
00:12:45,800 --> 00:12:46,360
It does.

250
00:12:46,440 --> 00:12:50,960
And this is a little bit of a riff on the agile being the buzzword thing,

251
00:12:51,440 --> 00:12:53,000
you don't see agile.

252
00:12:53,360 --> 00:12:59,580
What we really started seeing was a massive reduction in cycle time,

253
00:13:00,180 --> 00:13:03,580
even from teams doing poor cycle time and feedback time.

254
00:13:04,020 --> 00:13:04,260
Yes.

255
00:13:04,260 --> 00:13:04,580
Yes.

256
00:13:04,700 --> 00:13:11,150
Feedback feedback loops massively improved to the point where it was obvious to you

257
00:13:11,150 --> 00:13:18,990
and I that a traditional testing role or traditional testing process would just get

258
00:13:18,990 --> 00:13:22,710
in the way of the goodness that came from that feedback cycle.

259
00:13:23,490 --> 00:13:23,890
Correct.

260
00:13:23,970 --> 00:13:28,320
And then we wondered, well, crud, what do we do next?

261
00:13:28,360 --> 00:13:31,480
And we like, what does that mean for us?

262
00:13:32,040 --> 00:13:32,840
What does that mean?

263
00:13:32,840 --> 00:13:33,880
What do we do next?

264
00:13:33,880 --> 00:13:35,600
And what does everybody else do next?

265
00:13:35,600 --> 00:13:41,060
So the podcast started because we wanted to explore that along with everybody else

266
00:13:41,060 --> 00:13:44,280
experiencing that so they could have an idea what does come next.

267
00:13:44,320 --> 00:13:45,960
And man, we have seen it.

268
00:13:47,620 --> 00:13:56,040
I, to continue on, what I'm beginning to see, and I did a quick search, but the

269
00:13:56,040 --> 00:14:01,600
comment we saw on the stock channel was essentially doing a comparison and I'll

270
00:14:02,440 --> 00:14:10,360
call it the traditional test methods, which is there's several bodies of knowledge

271
00:14:10,360 --> 00:14:13,960
around traditional test methods that are still active today.

272
00:14:14,720 --> 00:14:23,340
Um, and, and certain consultant firms that are referred to quite often, um, on this

273
00:14:23,340 --> 00:14:29,700
topic, uh, and I'm getting the sense that they're feeling under threat by AI

274
00:14:29,700 --> 00:14:34,140
now and things like GPT, uh, even further.

275
00:14:34,620 --> 00:14:36,820
And I did a test this morning.

276
00:14:37,380 --> 00:14:43,740
I wrote a little piece of code and then I gave it to GPT and I said, write me

277
00:14:43,740 --> 00:14:45,100
a unit test suite for this.

278
00:14:45,900 --> 00:14:46,100
Yeah.

279
00:14:46,140 --> 00:14:47,100
It's actually pretty good at that.

280
00:14:47,740 --> 00:14:48,980
Uh, it's fantastic.

281
00:14:48,980 --> 00:14:53,180
It went through and automatically did, did all of the obvious ones.

282
00:14:53,180 --> 00:14:54,820
And I said, ah, okay.

283
00:14:55,420 --> 00:15:03,490
Then I start started, you know, as, as, um, let's just say the, the proponents

284
00:15:03,530 --> 00:15:09,410
of, of traditional test methods will say testing is a thinking thing, not a

285
00:15:09,450 --> 00:15:10,810
checking thing, right?

286
00:15:11,330 --> 00:15:12,970
So I said, okay, great.

287
00:15:13,050 --> 00:15:14,610
I got those, those done.

288
00:15:14,930 --> 00:15:16,290
Now let's think up another one.

289
00:15:17,100 --> 00:15:18,020
Oh, you know what?

290
00:15:18,580 --> 00:15:24,540
You didn't cover the case where this was null add that boom.

291
00:15:24,580 --> 00:15:25,220
There it is.

292
00:15:25,340 --> 00:15:26,220
Well, you're thinking.

293
00:15:26,660 --> 00:15:26,860
Yeah.

294
00:15:26,860 --> 00:15:27,260
Yeah.

295
00:15:27,620 --> 00:15:28,980
So I've done the same thing.

296
00:15:28,980 --> 00:15:33,340
I I've been writing, you know, my son's been in computer science class and I've

297
00:15:33,340 --> 00:15:36,140
been just for fun, I've been doing his homework alongside of him.

298
00:15:36,740 --> 00:15:40,380
And then when he asked questions, I can say, Oh, you probably, you probably did

299
00:15:40,380 --> 00:15:43,900
this, or I could say, have you thought of this, but I would write the code for

300
00:15:43,900 --> 00:15:47,980
these assignments and then I would use chat GPT to help me write the unit

301
00:15:47,980 --> 00:15:50,940
test because I'm lazy and I knew, I knew it would do a good job.

302
00:15:51,140 --> 00:15:52,340
So I would give it the code.

303
00:15:52,540 --> 00:15:54,500
I say, give me a set of basic unit tests for this.

304
00:15:54,780 --> 00:15:56,820
Then I would ask, what risks do you see here?

305
00:15:57,060 --> 00:16:00,860
And it would identify some, I'd say, okay, of those write the unit tests for one,

306
00:16:00,860 --> 00:16:01,580
two, and four.

307
00:16:02,140 --> 00:16:04,380
And I would say, what about the case where this happens?

308
00:16:04,580 --> 00:16:05,700
Can you write a test for that?

309
00:16:06,060 --> 00:16:06,780
And it would do that.

310
00:16:06,780 --> 00:16:11,780
And it was, it, I think my experience with chat GPT is it's okay at writing

311
00:16:11,780 --> 00:16:17,340
implementation code, but writing unit tests has been very, very, very good.

312
00:16:17,580 --> 00:16:19,580
So there's two kinds of code.

313
00:16:19,580 --> 00:16:20,700
I have it right.

314
00:16:21,340 --> 00:16:28,340
One that's in Python and another one in an internal Microsoft's language.

315
00:16:28,900 --> 00:16:29,820
Actually, it's not internal.

316
00:16:29,820 --> 00:16:30,260
It's shipped.

317
00:16:30,260 --> 00:16:32,220
It's Azure data Explorer.

318
00:16:32,220 --> 00:16:34,620
Internally it's called Cousteau, right?

319
00:16:34,620 --> 00:16:36,260
It's sort of a query language.

320
00:16:37,140 --> 00:16:39,940
It almost never screws up on Python.

321
00:16:39,980 --> 00:16:46,100
Even I've gotten, I've, I've gotten clear on what I ask it for, but it

322
00:16:46,100 --> 00:16:47,300
almost never screws up.

323
00:16:47,340 --> 00:16:51,740
Well, I told you, I tried to have it write a Python program that needed to

324
00:16:51,740 --> 00:16:55,180
do some math and it failed because it's just bad at math even when coding.

325
00:16:55,580 --> 00:16:56,940
Yeah, I suppose it could do all right.

326
00:16:56,940 --> 00:17:02,580
But this is really related to our initial conversation earlier on the podcast is

327
00:17:02,580 --> 00:17:09,700
you can either look to AI to replace you or look to AI to enhance what you do.

328
00:17:10,100 --> 00:17:14,020
And you're saying as a tester, putting your, putting your tester hat on, as

329
00:17:14,020 --> 00:17:19,580
they say, you can apply, be the thinking tester, use your brain.

330
00:17:19,820 --> 00:17:21,660
And I want to put a pin in that and talk about that.

331
00:17:21,660 --> 00:17:24,620
Cause it's going to be my, my article tomorrow for my sub stack.

332
00:17:25,220 --> 00:17:34,140
You are using your brain for the creative part and using AI to accelerate

333
00:17:34,180 --> 00:17:35,580
what you're doing with your brain.

334
00:17:35,820 --> 00:17:37,020
So, right.

335
00:17:37,180 --> 00:17:38,900
So now I have two questions for you.

336
00:17:39,660 --> 00:17:40,420
First question.

337
00:17:41,370 --> 00:17:49,850
Are we at a phase in software development, the current place we are in the world?

338
00:17:49,890 --> 00:17:51,730
So not a phase, but a timeline.

339
00:17:52,290 --> 00:17:59,880
Are we at a place right now where the manual tester versus automated tester

340
00:18:00,700 --> 00:18:02,300
no longer makes sense?

341
00:18:02,660 --> 00:18:07,380
Well, I believe that for, I mean, look, we live in a bubble where

342
00:18:07,380 --> 00:18:12,300
people do things in sensible ways, but there are many, many organizations

343
00:18:12,300 --> 00:18:16,580
that have a dedicated manual testing team and a dedicated automation team.

344
00:18:17,220 --> 00:18:20,060
And not, not, and, and, and dedicated development team.

345
00:18:20,380 --> 00:18:22,740
It's, it's a horrible way to make software.

346
00:18:22,740 --> 00:18:25,940
It's extremely inefficient yet it exists.

347
00:18:25,940 --> 00:18:28,860
So that is, it still exists in plenty of places, but I,

348
00:18:29,380 --> 00:18:35,340
No, but I'm actually thinking it's a non we're very rapidly heading to a place

349
00:18:35,340 --> 00:18:37,980
where that's a nonsensical distinction.

350
00:18:38,890 --> 00:18:39,130
Right.

351
00:18:39,170 --> 00:18:45,630
And doesn't matter if I'm, if I'm an S dead or an STE, if I can communicate

352
00:18:45,630 --> 00:18:49,630
a concept to something like GPT and get it the right information.

353
00:18:50,350 --> 00:18:51,910
Tell it what I'm looking for.

354
00:18:51,910 --> 00:18:52,190
Right.

355
00:18:52,190 --> 00:18:55,630
I own the thinking and it generates the output.

356
00:18:56,190 --> 00:18:57,630
Why wouldn't I do that?

357
00:18:58,270 --> 00:18:58,470
Right.

358
00:18:58,470 --> 00:19:03,190
That's you should, you should double that more than doubles my value proposition

359
00:19:03,190 --> 00:19:04,110
as an STE.

360
00:19:04,230 --> 00:19:08,270
Let me, let me come back to my pin and get on my soapbox for it.

361
00:19:08,270 --> 00:19:09,630
I've been on this soapbox before.

362
00:19:09,630 --> 00:19:13,070
Like I said, I'm going to write about this tomorrow, but I saw on LinkedIn,

363
00:19:13,070 --> 00:19:16,190
these kind of ball the time again, I go to LinkedIn to try and help out my

364
00:19:16,190 --> 00:19:19,270
friends who have are all getting laid off from their jobs.

365
00:19:19,790 --> 00:19:27,790
And someone posts something about how testers need to use their brain and like

366
00:19:27,790 --> 00:19:31,750
using your brain, like using your brain and being creative and curious is

367
00:19:31,750 --> 00:19:35,910
something unique to software testing, which blows my mind.

368
00:19:36,110 --> 00:19:36,390
Yeah.

369
00:19:36,390 --> 00:19:40,270
So it's knowledge work, the knowledge work that you and I do the knowledge

370
00:19:40,270 --> 00:19:43,630
work that isn't just putting widgets, you know, buttons onto a jacket and a

371
00:19:43,630 --> 00:19:46,070
factory, it requires those things.

372
00:19:46,070 --> 00:19:47,510
It requires critical thinking.

373
00:19:47,510 --> 00:19:49,150
It requires curiosity.

374
00:19:49,550 --> 00:19:53,110
It's just true for all knowledge work testing isn't special there.

375
00:19:53,310 --> 00:19:59,430
So I think any knowledge worker, I put it this way, every knowledge worker or

376
00:19:59,430 --> 00:20:05,510
every kind of knowledge worker could have some fear that AI was going to take

377
00:20:05,510 --> 00:20:11,030
their job at the same time, every knowledge worker can enhance and

378
00:20:11,030 --> 00:20:14,670
accelerate what they do by using AI effectively.

379
00:20:15,270 --> 00:20:15,870
Also.

380
00:20:15,950 --> 00:20:16,630
Yes.

381
00:20:16,790 --> 00:20:17,030
Yeah.

382
00:20:17,030 --> 00:20:17,470
Of course.

383
00:20:17,470 --> 00:20:18,870
Cause I'm absolutely right.

384
00:20:18,870 --> 00:20:21,350
And my, I'm, my arguments are infallible.

385
00:20:21,670 --> 00:20:28,270
And, and even further, it allows you to enter into an arena.

386
00:20:28,830 --> 00:20:31,870
We've already talked about like recorded scripts in the past.

387
00:20:32,110 --> 00:20:37,390
Previously, what we would do in the old days with STEs, right?

388
00:20:37,390 --> 00:20:40,670
We had them run through scripts as they thought through their tests.

389
00:20:40,990 --> 00:20:41,230
Right.

390
00:20:41,230 --> 00:20:43,190
So we could preserve that and check it in.

391
00:20:43,390 --> 00:20:43,630
Okay.

392
00:20:43,990 --> 00:20:51,670
But the quality of the test cases out of GPT is much better, just much better.

393
00:20:52,440 --> 00:20:59,770
And I'm like, Oh, so I was just thinking around, I see evidence right now.

394
00:21:00,050 --> 00:21:07,380
Again, the traditional crowd is acting defensive as if, ah, hell, like we, we

395
00:21:07,620 --> 00:21:12,900
survived the agile phase, which in my view, they didn't because you can see

396
00:21:12,900 --> 00:21:17,950
that the momentum against anything other than the dev owning their own

397
00:21:17,950 --> 00:21:21,310
tests is dramatically slipping.

398
00:21:21,350 --> 00:21:27,750
So, and I think we've talked about this before and, and I am just about, I

399
00:21:27,750 --> 00:21:33,190
think, if not done, almost not almost done completely done talking about the

400
00:21:33,190 --> 00:21:37,630
other bubble, when we first started this podcast, we talked about how teams

401
00:21:37,630 --> 00:21:41,990
could adapt to agile and faster feedback cycles, et cetera, because they were

402
00:21:41,990 --> 00:21:43,670
afraid it was going to screw up their job.

403
00:21:44,230 --> 00:21:44,430
Right.

404
00:21:44,430 --> 00:21:49,550
And as you were getting at earlier lately and today, especially we're doing

405
00:21:49,550 --> 00:21:53,310
the same thing, talking about like everybody's thinking, Oh, is AI going to

406
00:21:53,310 --> 00:21:54,110
take my job?

407
00:21:54,430 --> 00:22:00,140
And the answer is only if you let it know, you're right.

408
00:22:00,180 --> 00:22:01,940
I'd actually, you're right that I'm wrong there.

409
00:22:01,980 --> 00:22:03,860
That, that part was definitely fallible.

410
00:22:04,020 --> 00:22:08,090
So it is, what do I mean to say?

411
00:22:08,530 --> 00:22:09,810
So here, let me try.

412
00:22:10,010 --> 00:22:10,210
All right.

413
00:22:10,210 --> 00:22:11,890
AI will take your job.

414
00:22:12,450 --> 00:22:15,730
You will only be unemployed if you let it.

415
00:22:16,330 --> 00:22:18,650
That, that, that's a better version.

416
00:22:18,690 --> 00:22:24,260
AI is a motivator to, for you to start thinking around.

417
00:22:24,500 --> 00:22:26,100
It's a creative partner.

418
00:22:26,100 --> 00:22:28,940
And I don't get why people like, and I know what you're talking about.

419
00:22:28,940 --> 00:22:32,540
People are either, they're, they're trying to be dismissive of it saying,

420
00:22:32,540 --> 00:22:35,740
Oh, it can't do this, but you can't do a, but you know what?

421
00:22:35,740 --> 00:22:37,140
It can do B C D E and F.

422
00:22:37,140 --> 00:22:38,540
So don't use it for a idiot.

423
00:22:39,140 --> 00:22:39,380
Yeah.

424
00:22:39,700 --> 00:22:41,820
So here's the thing.

425
00:22:42,680 --> 00:22:46,280
With the way it's accelerating, do you know what an AGI is?

426
00:22:47,240 --> 00:22:49,680
I, isn't that like the emeritus?

427
00:22:49,720 --> 00:22:51,040
Um, I don't know what it is.

428
00:22:51,040 --> 00:22:53,440
I had a joke answer, but I can't remember what it was.

429
00:22:53,680 --> 00:22:56,720
Adjusted gross income is your, your poor joke.

430
00:22:56,760 --> 00:22:57,800
That's what I was trying to think of.

431
00:22:58,320 --> 00:23:01,360
AGI stands for artificial general intelligence.

432
00:23:01,640 --> 00:23:01,960
Okay.

433
00:23:02,680 --> 00:23:04,080
What that means.

434
00:23:04,440 --> 00:23:07,120
So an AI is nothing more than a simulator.

435
00:23:07,120 --> 00:23:09,080
Can't think, can't do anything.

436
00:23:09,640 --> 00:23:14,040
And AGI has the ability to independently rationalize.

437
00:23:14,920 --> 00:23:19,880
So it can make the decision to go and train itself on something new.

438
00:23:20,730 --> 00:23:22,610
It can learn by itself.

439
00:23:22,650 --> 00:23:23,330
Cool.

440
00:23:23,770 --> 00:23:23,970
Okay.

441
00:23:25,270 --> 00:23:26,670
Uh, no, that's not Skynet.

442
00:23:26,670 --> 00:23:28,910
Skynet is an ASI.

443
00:23:29,840 --> 00:23:31,600
That's a, now you're just making shit up.

444
00:23:31,680 --> 00:23:32,400
No, I'm not.

445
00:23:32,400 --> 00:23:33,120
You can look these up.

446
00:23:34,400 --> 00:23:36,960
That is an artificial super intelligence.

447
00:23:37,360 --> 00:23:42,360
And I will absolutely tell you if, if human society ever creates an ASI, it's over.

448
00:23:43,140 --> 00:23:48,900
Uh, just straight up over, but they predict that an AGI will exist, uh, within

449
00:23:48,900 --> 00:23:49,740
three to five years.

450
00:23:50,560 --> 00:23:51,360
Very cool.

451
00:23:51,560 --> 00:23:52,280
Very cool.

452
00:23:52,440 --> 00:23:52,800
All right.

453
00:23:52,800 --> 00:23:56,560
So I think that the, I don't know if there's more for this part because of

454
00:23:56,560 --> 00:23:58,520
other stuff I want to cover, but we can stay here if you want to.

455
00:23:58,640 --> 00:24:05,230
But the moral is the AI testing podcast, which we now may be called that we

456
00:24:05,230 --> 00:24:11,030
are, we're once again here to help teams navigate this, to help people

457
00:24:11,030 --> 00:24:13,510
navigate this change and understand what it means.

458
00:24:14,520 --> 00:24:15,880
We made new principles.

459
00:24:16,160 --> 00:24:19,680
Now, every time there's no, I think the principles are fine.

460
00:24:20,720 --> 00:24:24,960
Honestly, the, I was joking, but I do want to talk about the principles.

461
00:24:24,960 --> 00:24:27,360
So anyway, go on this one up for me.

462
00:24:27,640 --> 00:24:28,000
Okay.

463
00:24:28,000 --> 00:24:29,640
So that was an unannounced segue.

464
00:24:29,680 --> 00:24:30,120
Sorry.

465
00:24:30,480 --> 00:24:31,320
You're absolutely right.

466
00:24:31,360 --> 00:24:34,320
Like we're at a, we're at an interesting change.

467
00:24:34,720 --> 00:24:34,960
Okay.

468
00:24:34,960 --> 00:24:41,890
And it is in my experience, those who freak out about the potential of the change are

469
00:24:41,890 --> 00:24:42,810
the ones that are doomed.

470
00:24:43,130 --> 00:24:43,730
Well, yeah.

471
00:24:43,730 --> 00:24:48,730
Those, those who look around and say, anytime there's change, there is always

472
00:24:48,730 --> 00:24:52,650
an opportunity that, that no one's looking at cause they're too busy freaking out.

473
00:24:53,050 --> 00:24:54,570
Agile was a disruptor.

474
00:24:54,650 --> 00:24:55,850
AI is a disruptor.

475
00:24:55,850 --> 00:24:57,730
It's probably other things in between I've missed.

476
00:24:57,970 --> 00:24:58,290
Yep.

477
00:24:58,650 --> 00:25:01,130
When these disruptors happen, it's a pattern.

478
00:25:01,130 --> 00:25:04,530
Some people try and dismiss it, say it'll go away.

479
00:25:05,130 --> 00:25:10,090
Some people let it freak them out and some people embrace it and ride the wave.

480
00:25:10,650 --> 00:25:11,130
Yes.

481
00:25:11,370 --> 00:25:13,090
There's going to be more of these, man.

482
00:25:13,090 --> 00:25:18,790
This is what I love about work about knowledge work in general is I get to

483
00:25:18,790 --> 00:25:22,110
ride the wave, these disruptors and see where they take them.

484
00:25:22,150 --> 00:25:24,230
They keep me from being bored.

485
00:25:25,940 --> 00:25:26,220
All right.

486
00:25:26,220 --> 00:25:29,140
You want to talk more AI, you want to talk more chat GPT.

487
00:25:29,300 --> 00:25:31,660
No, I was just, I was just thinking around.

488
00:25:31,820 --> 00:25:32,940
I got to talk about it.

489
00:25:32,940 --> 00:25:33,620
Keep on going though.

490
00:25:33,620 --> 00:25:33,980
All right.

491
00:25:34,060 --> 00:25:35,260
I'll get to my stuff later.

492
00:25:35,340 --> 00:25:41,080
I'm summing up you son of a person.

493
00:25:41,720 --> 00:25:42,960
I thought we already summed up.

494
00:25:43,000 --> 00:25:43,320
All right.

495
00:25:43,320 --> 00:25:43,640
Fine.

496
00:25:43,640 --> 00:25:43,960
Go.

497
00:25:44,360 --> 00:25:45,280
No, do you want to sum up again?

498
00:25:45,320 --> 00:25:46,000
No, I'm done.

499
00:25:46,320 --> 00:25:46,840
I'm done.

500
00:25:47,080 --> 00:25:47,640
I'm done.

501
00:25:47,920 --> 00:25:48,480
You're done.

502
00:25:48,760 --> 00:25:49,000
Yeah.

503
00:25:49,000 --> 00:25:54,510
So, um, I got a couple of things I want to do from my friend chat GPT for you.

504
00:25:54,830 --> 00:25:55,230
Okay.

505
00:25:55,750 --> 00:25:57,350
And this is a play along at home.

506
00:25:57,910 --> 00:26:01,500
I want everybody to get out your pens and papers and break.

507
00:26:01,500 --> 00:26:02,260
You don't have to.

508
00:26:02,980 --> 00:26:07,300
And this is technically a multiple choice quiz, but I'm going to see if you can get

509
00:26:07,300 --> 00:26:10,860
it, uh, without the choices, because with the choices, I think you'll do really well

510
00:26:10,860 --> 00:26:15,300
because I would regard you as an expert in the area.

511
00:26:15,940 --> 00:26:16,420
Okay.

512
00:26:16,460 --> 00:26:20,060
So you know, I had that conversation with chat GPT.

513
00:26:20,060 --> 00:26:22,780
We talked about a couple episodes ago where we talked all about the

514
00:26:22,780 --> 00:26:25,300
modern testing principles, got some ideas.

515
00:26:25,500 --> 00:26:29,380
So that's all in the buffer of this chat session I have with chat GPT.

516
00:26:29,620 --> 00:26:30,100
Okay.

517
00:26:30,860 --> 00:26:35,180
And I had a little, little more conversation with it today.

518
00:26:35,260 --> 00:26:37,540
I keep that, that chat handy.

519
00:26:37,940 --> 00:26:43,020
I hope you, I hope you didn't ask GPT to create a modern testing certification.

520
00:26:43,140 --> 00:26:46,960
Ladies and gentlemen, it's the modern testing certification quiz.

521
00:26:46,960 --> 00:26:47,940
10 questions.

522
00:26:50,390 --> 00:26:51,710
I hope you're still joking.

523
00:26:51,710 --> 00:26:52,350
Oh my God.

524
00:26:52,350 --> 00:26:55,070
Brent can be certified in modern testing.

525
00:26:55,070 --> 00:26:55,850
Are you ready?

526
00:26:55,850 --> 00:26:57,270
And please play at home.

527
00:26:57,550 --> 00:26:58,630
10 questions.

528
00:26:58,990 --> 00:27:04,110
I probably won't read all the choices unless they're funny, but are you ready?

529
00:27:04,790 --> 00:27:05,710
Probably not.

530
00:27:05,750 --> 00:27:09,950
What is the primary, if you need all four choices, by the way, just ask

531
00:27:09,950 --> 00:27:12,150
for them all given to you, but I want to give you a chance to

532
00:27:12,150 --> 00:27:13,270
answer without them first.

533
00:27:13,470 --> 00:27:13,910
All right.

534
00:27:14,070 --> 00:27:17,310
What is the primary focus of the modern testing principles?

535
00:27:18,260 --> 00:27:21,140
To accelerate the achievement of sip of equality.

536
00:27:21,420 --> 00:27:23,060
Let me give you the choices here.

537
00:27:23,260 --> 00:27:23,980
Oh, fine.

538
00:27:24,020 --> 00:27:26,140
A maximizing profits.

539
00:27:27,280 --> 00:27:29,880
B enhancing customer satisfaction.

540
00:27:30,820 --> 00:27:36,180
C increasing test coverage or D minimizing development time.

541
00:27:37,460 --> 00:27:41,380
Oh, uh, except for C they're all pretty good.

542
00:27:42,060 --> 00:27:45,220
I don't like maximizing profits, but that's what I'm going to go with.

543
00:27:45,380 --> 00:27:45,660
No.

544
00:27:48,940 --> 00:27:50,220
It's increasing test coverage.

545
00:27:50,220 --> 00:27:52,580
No, it's enhancing customer satisfaction.

546
00:27:53,260 --> 00:27:53,540
All right.

547
00:27:53,540 --> 00:27:54,460
You have nine left.

548
00:27:54,500 --> 00:27:54,940
No.

549
00:27:54,980 --> 00:27:55,300
Yeah.

550
00:27:55,300 --> 00:27:55,540
Yeah.

551
00:27:55,540 --> 00:27:55,700
Yeah.

552
00:27:55,700 --> 00:27:55,860
Yeah.

553
00:27:55,860 --> 00:27:55,940
Yeah.

554
00:27:55,940 --> 00:27:56,060
Yeah.

555
00:27:56,060 --> 00:27:56,300
Yeah.

556
00:27:56,300 --> 00:27:57,340
You can still get 90%.

557
00:27:57,660 --> 00:27:57,900
All right.

558
00:27:57,900 --> 00:27:59,100
I feel horrible.

559
00:27:59,260 --> 00:27:59,820
You can do this.

560
00:28:00,300 --> 00:28:00,940
This one's easy.

561
00:28:00,940 --> 00:28:04,900
Which models can be used to identify and mitigate bottlenecks in the

562
00:28:04,900 --> 00:28:08,060
software development process, according to the modern testing principles,

563
00:28:08,180 --> 00:28:10,020
which models it's multiple choice.

564
00:28:10,540 --> 00:28:10,980
Sure.

565
00:28:11,220 --> 00:28:13,900
A waterfall and agile.

566
00:28:14,460 --> 00:28:17,260
Wait, waterfall and agile is one option.

567
00:28:17,380 --> 00:28:17,700
Yeah.

568
00:28:18,220 --> 00:28:23,780
For redo read the question again, what models can be used to identify and

569
00:28:23,780 --> 00:28:27,940
mitigate bottlenecks in the software development process, according to the MTP.

570
00:28:28,720 --> 00:28:29,360
It's agile.

571
00:28:29,840 --> 00:28:34,640
A waterfall and agile B lean thinking and theory of constraints.

572
00:28:35,240 --> 00:28:35,880
Okay.

573
00:28:35,960 --> 00:28:39,200
Scrum and Kanban D spiral and rad.

574
00:28:41,520 --> 00:28:44,320
There's a couple of models I haven't heard of it a long time.

575
00:28:44,680 --> 00:28:45,080
Yeah.

576
00:28:45,320 --> 00:28:50,360
So it's interesting because I still view lean as a superset.

577
00:28:50,720 --> 00:28:51,240
I know.

578
00:28:51,280 --> 00:28:53,800
Look, it's it's, these are from AI.

579
00:28:54,320 --> 00:28:54,840
I get it.

580
00:28:54,840 --> 00:28:55,600
It's B.

581
00:28:56,600 --> 00:28:57,840
Here's one maybe you can do.

582
00:28:58,080 --> 00:29:05,480
But, but waterfall and agile as, as, as, as a top answer, I'm like, uh, that hurts my head.

583
00:29:05,600 --> 00:29:05,880
Yeah.

584
00:29:06,360 --> 00:29:06,560
Yeah.

585
00:29:06,600 --> 00:29:06,840
Okay.

586
00:29:06,840 --> 00:29:12,040
According to the modern testing principles, who is the ultimate judge of software quality?

587
00:29:12,680 --> 00:29:13,280
The customer.

588
00:29:13,640 --> 00:29:15,370
Yeah, that's correct.

589
00:29:15,570 --> 00:29:16,490
What were the choices?

590
00:29:16,530 --> 00:29:19,610
The developers, the project manager or the testers.

591
00:29:20,250 --> 00:29:20,810
Oh, okay.

592
00:29:21,250 --> 00:29:22,650
Those are all reasonable answers.

593
00:29:22,970 --> 00:29:27,610
Which I mean, if you gave this to someone who thought we were full of crap, which

594
00:29:27,610 --> 00:29:30,050
are there are many out there, they would give different answers.

595
00:29:30,450 --> 00:29:30,570
Yeah.

596
00:29:30,570 --> 00:29:32,570
Number four, how should teams approach?

597
00:29:32,570 --> 00:29:34,090
Can I'll give you a close to this one.

598
00:29:34,410 --> 00:29:37,330
How should teams approach continuous improvement?

599
00:29:37,970 --> 00:29:41,370
A by relying on safety nets to catch failures.

600
00:29:42,090 --> 00:29:46,210
B by prioritizing process compliance over adaptability.

601
00:29:46,570 --> 00:29:53,530
C by actively seeking ways to optimize practices and succeed or D by relying

602
00:29:53,530 --> 00:29:55,570
on predefined best practices.

603
00:29:58,130 --> 00:30:01,610
That was a pretty good list, but the obvious it's doing, it does a pretty

604
00:30:01,610 --> 00:30:04,210
good job on the other answers.

605
00:30:04,770 --> 00:30:05,050
Yeah.

606
00:30:05,050 --> 00:30:10,810
The problem is they're all kind of synonyms, but C on that one.

607
00:30:11,530 --> 00:30:13,610
Is it C all the way down the path?

608
00:30:13,730 --> 00:30:14,130
No.

609
00:30:14,370 --> 00:30:14,890
Okay.

610
00:30:15,450 --> 00:30:15,850
No.

611
00:30:16,330 --> 00:30:16,690
All right.

612
00:30:16,770 --> 00:30:20,130
Um, what is the role of testers in modern testing principles?

613
00:30:20,450 --> 00:30:26,810
A to write code and develop software B to advocate for the customer and

614
00:30:26,810 --> 00:30:34,260
ensure functional correctness C to, uh, manage project timelines and budgets

615
00:30:34,460 --> 00:30:37,500
or D to document requirement specifications.

616
00:30:38,830 --> 00:30:43,070
And the answer is none of the above because chat GPT said B to advocate

617
00:30:43,070 --> 00:30:45,030
for the customer and ensure functional.

618
00:30:45,030 --> 00:30:45,310
Correct.

619
00:30:45,350 --> 00:30:49,070
I'm like, um, tell me answer again.

620
00:30:49,110 --> 00:30:49,590
What was it?

621
00:30:49,590 --> 00:30:52,270
It's AA to write code and develop software.

622
00:30:52,630 --> 00:30:53,910
That one's actually closer.

623
00:30:53,910 --> 00:30:56,030
That was a say that was closer.

624
00:30:57,890 --> 00:30:59,490
Uh, halfway done.

625
00:30:59,650 --> 00:31:01,770
It was a weird way, but I agree with that.

626
00:31:01,770 --> 00:31:02,410
It does.

627
00:31:02,770 --> 00:31:06,530
Um, how should teams gather insights about customer usage and bridge the

628
00:31:06,530 --> 00:31:09,810
gap between product hypothesis and business impact data?

629
00:31:10,290 --> 00:31:14,130
Uh, yeah, whatever, whatever answer data is by using data extensively.

630
00:31:14,130 --> 00:31:15,170
There was, that's a dumb one.

631
00:31:15,770 --> 00:31:19,570
What is the benefit of expanding abilities and know-how across the team?

632
00:31:20,010 --> 00:31:26,320
A to increase team specialization and efficiency B to reduce the need

633
00:31:26,320 --> 00:31:32,620
for dedicated specialists C to create silos and minimize cross team collaboration

634
00:31:33,180 --> 00:31:37,580
or D to delegate testing activities to non-technical team members.

635
00:31:38,410 --> 00:31:43,260
Actually say those again, cause none of them feel right to me.

636
00:31:43,620 --> 00:31:46,900
B to reduce the need for dedicated specialists.

637
00:31:47,380 --> 00:31:48,460
That's what it says.

638
00:31:48,580 --> 00:31:48,820
Yeah.

639
00:31:49,500 --> 00:31:50,340
No, no, no.

640
00:31:50,340 --> 00:31:51,380
I mean, that's horrible.

641
00:31:52,380 --> 00:31:55,420
That's that's not the goal of increasing it.

642
00:31:56,060 --> 00:31:58,860
It may, it may result in that, but it's not the goal.

643
00:31:58,900 --> 00:31:59,300
Right.

644
00:31:59,540 --> 00:32:02,540
And we've always said that the goal isn't to get rid of testers.

645
00:32:02,540 --> 00:32:08,380
The goal is to improve enough and go fast enough where you end up where there's

646
00:32:08,380 --> 00:32:10,460
enough quality culture on the team, we end up not needing them.

647
00:32:10,900 --> 00:32:11,740
It's a side effect.

648
00:32:12,300 --> 00:32:15,140
Again, AI, according to the modern testing principles, what is the

649
00:32:15,140 --> 00:32:17,060
responsibility of software developers?

650
00:32:17,620 --> 00:32:18,140
Everything.

651
00:32:18,500 --> 00:32:19,060
Everything.

652
00:32:19,260 --> 00:32:19,620
Yep.

653
00:32:20,460 --> 00:32:21,780
Uh, is that an option?

654
00:32:22,180 --> 00:32:26,780
Well, no, they're all because it's all of the above chat.

655
00:32:26,780 --> 00:32:27,780
GPT just blows it.

656
00:32:28,590 --> 00:32:28,950
What is it?

657
00:32:28,950 --> 00:32:32,750
The choices are ensure customer satisfaction.

658
00:32:33,500 --> 00:32:34,020
Yes.

659
00:32:34,100 --> 00:32:35,780
Write code and develop software.

660
00:32:35,980 --> 00:32:36,580
Yes.

661
00:32:37,180 --> 00:32:38,940
Conduct thorough testing activities.

662
00:32:39,020 --> 00:32:39,660
Yes.

663
00:32:40,260 --> 00:32:42,260
Document test cases and scenarios.

664
00:32:42,700 --> 00:32:46,580
Maybe man, but a through C are all absolutely.

665
00:32:46,620 --> 00:32:47,940
Yeah, absolutely.

666
00:32:48,180 --> 00:32:54,300
Like what roles do telemetry and fast feedback loops play in the MTP?

667
00:32:54,460 --> 00:32:57,500
A they help in monitoring project timelines and budgets.

668
00:32:57,940 --> 00:33:00,580
They assist in regulatory compliance and audits.

669
00:33:01,140 --> 00:33:02,380
Both of these are true.

670
00:33:02,660 --> 00:33:05,020
They well, we don't talk about them ever.

671
00:33:05,220 --> 00:33:09,060
They provide real time insights into customer usage and satisfaction.

672
00:33:09,380 --> 00:33:10,700
That's the primary reason.

673
00:33:10,740 --> 00:33:10,980
Yep.

674
00:33:11,220 --> 00:33:16,540
They automate the entire testing process and well, no, but entire no.

675
00:33:16,980 --> 00:33:17,820
No, to limit.

676
00:33:17,820 --> 00:33:21,060
I mean, there's a lot more work than we've talked about using on this

677
00:33:21,060 --> 00:33:23,940
podcast before many telemetry for testing.

678
00:33:24,060 --> 00:33:27,740
You absolutely can use it, but the way the phrases, no, that's.

679
00:33:27,740 --> 00:33:28,820
Yeah, it's not great.

680
00:33:28,820 --> 00:33:29,700
It needs a massaging.

681
00:33:29,700 --> 00:33:33,540
I did not touch these at all, but a number 10, before I give you your certificate.

682
00:33:33,980 --> 00:33:36,020
Oh, which it cause it's free.

683
00:33:36,020 --> 00:33:39,260
Just like the modern testing principles, just like joining our Slack group,

684
00:33:39,260 --> 00:33:42,300
just like this in this podcast, just like reading my blog posts.

685
00:33:42,300 --> 00:33:42,900
It's all free.

686
00:33:42,900 --> 00:33:44,100
We don't care about the money.

687
00:33:44,620 --> 00:33:47,940
No, if we cared about the money, we'd take a whole different tact.

688
00:33:47,940 --> 00:33:52,620
We'd be into sensationalism and hyperbole and puppies and all those things.

689
00:33:52,700 --> 00:33:54,220
Which of the following statements.

690
00:33:54,300 --> 00:33:55,740
I am into puppies.

691
00:33:55,980 --> 00:33:56,500
Yeah, me too.

692
00:33:56,940 --> 00:34:00,580
Uh, which of the following statements aligns with the modern testing principles?

693
00:34:01,420 --> 00:34:05,940
Hey, testers are responsible for achieving maximum test coverage.

694
00:34:06,760 --> 00:34:08,600
No, I think we can eliminate that one.

695
00:34:08,880 --> 00:34:09,080
Yeah.

696
00:34:09,240 --> 00:34:14,200
B quality is determined by adherence to predefined standards.

697
00:34:14,680 --> 00:34:15,360
Oh my God.

698
00:34:15,440 --> 00:34:15,840
No.

699
00:34:15,920 --> 00:34:16,360
We're going to go.

700
00:34:16,360 --> 00:34:16,640
No.

701
00:34:17,500 --> 00:34:17,940
Oh my God.

702
00:34:17,940 --> 00:34:18,700
It's all the above.

703
00:34:19,100 --> 00:34:24,460
It's like this one feels like it's echoing back that previous question.

704
00:34:24,460 --> 00:34:24,660
Yeah.

705
00:34:24,860 --> 00:34:29,060
See development team should adapt and optimize practices to succeed.

706
00:34:29,980 --> 00:34:30,940
I agree with that.

707
00:34:31,890 --> 00:34:36,850
D safety nets and catch all error handling are the key to quality insurance.

708
00:34:37,670 --> 00:34:38,430
Uh, no.

709
00:34:38,870 --> 00:34:42,150
Well, actually, actually they are.

710
00:34:42,190 --> 00:34:46,230
If you want to keep quality assurance teams around, they're absolutely key.

711
00:34:46,270 --> 00:34:47,870
Completely agree with that statement.

712
00:34:48,270 --> 00:34:52,390
It's kind of, it's contradictory to modern testing, but yeah.

713
00:34:52,790 --> 00:34:53,630
One more thing.

714
00:34:53,630 --> 00:34:55,710
I may have to just read this without trying.

715
00:34:55,990 --> 00:34:59,390
It is not rehearsed, not rehearsed at all.

716
00:34:59,510 --> 00:35:01,150
Not even read yet.

717
00:35:01,750 --> 00:35:02,030
All right.

718
00:35:02,030 --> 00:35:07,630
But, uh, we're too old white dudes, but saw, I feel weird asking this question,

719
00:35:07,630 --> 00:35:09,190
but Brent, can you beat box?

720
00:35:09,830 --> 00:35:10,270
No.

721
00:35:10,830 --> 00:35:11,350
Fine.

722
00:35:11,830 --> 00:35:12,270
Fine.

723
00:35:12,710 --> 00:35:16,790
There will be no AI generated modern testing rap today.

724
00:35:17,310 --> 00:35:19,830
Why don't we go ahead and end it there and we'll see you next

725
00:35:19,830 --> 00:35:21,910
time on the AB testing podcast.

726
00:35:43,050 --> 00:35:46,690
Yo, let me drop some knowledge about the empty principles of rap.

727
00:35:46,690 --> 00:35:50,810
You make your thinking challenge your residual, enhancing customer satisfaction.

728
00:35:50,810 --> 00:35:51,690
That's the goal.

729
00:35:51,810 --> 00:35:54,290
Put their needs first and let the quality unfold.

730
00:35:56,090 --> 00:35:58,450
Modern testing breaks the mold.

731
00:35:58,450 --> 00:35:59,810
Customer satisfaction.

732
00:35:59,810 --> 00:36:00,970
Let it be told.

733
00:36:01,170 --> 00:36:04,690
Lean thinking, theory of constraints, continuous improvement.

734
00:36:04,690 --> 00:36:05,890
No time to relent.

735
00:36:06,330 --> 00:36:07,490
No safety nets.

736
00:36:07,490 --> 00:36:08,890
No catching all the flaws.

737
00:36:09,050 --> 00:36:10,450
Adapt and optimize.

738
00:36:10,490 --> 00:36:11,730
Find the root cause.

739
00:36:11,890 --> 00:36:14,370
Testers advocate for customers with pride.

740
00:36:14,610 --> 00:36:15,850
Functional correctness.

741
00:36:15,850 --> 00:36:17,050
That's the stride.

742
00:36:17,250 --> 00:36:19,250
Modern tests to break the mold.

743
00:36:19,810 --> 00:36:20,850
Customer satisfaction.

744
00:36:20,850 --> 00:36:22,130
Let it be told.

745
00:36:22,410 --> 00:36:26,010
Lean thinking, theory of constraints, continuous improvement.

746
00:36:26,010 --> 00:36:26,810
No time to relent.

747
00:36:26,810 --> 00:36:27,690
One more time.

748
00:36:27,930 --> 00:36:29,250
Data driven insights.

749
00:36:29,250 --> 00:36:30,330
The key to success.

750
00:36:30,530 --> 00:36:31,890
Telemetry and feedback.

751
00:36:31,890 --> 00:36:33,170
We're never second guess.

752
00:36:33,250 --> 00:36:34,650
Expand abilities.

753
00:36:34,650 --> 00:36:35,810
Don't need to special roles.

754
00:36:36,050 --> 00:36:37,090
Bridge the gaps.

755
00:36:37,090 --> 00:36:38,410
Let's reach our goals.

756
00:36:38,410 --> 00:36:38,850
Yeah.

