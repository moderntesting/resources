1
00:00:00,000 --> 00:00:05,440
Maybe the tooling we need around this is the tooling that stops people from being fucking idiots

2
00:00:09,150 --> 00:00:13,190
Welcome to a be testing podcast your modern testing podcast

3
00:00:13,430 --> 00:00:18,950
Your hosts Alan and Brent will be here to guide you through topics on testing

4
00:00:19,390 --> 00:00:26,510
Leadership agile and anything else that comes to mind now on with the show. We're back for another a be testing

5
00:00:26,510 --> 00:00:28,030
It's just me

6
00:00:28,030 --> 00:00:35,410
Alan wait what just you sorry. I just mean Alan comma Alan. Sorry try that again. It's me Alan and me

7
00:00:35,410 --> 00:00:41,670
Brit and we're here together. Nobody no guess nobody else. My dog is asleep on the floor. Yeah my cat

8
00:00:42,350 --> 00:00:43,390
empty

9
00:00:43,390 --> 00:00:50,910
Your cat's empty. What no, so I I get it. Did I get I get it? Okay, I the cat bed. No cat did I

10
00:00:51,470 --> 00:00:54,710
Already show you I did I did last episode. Yeah, yeah

11
00:00:55,230 --> 00:00:59,470
It's been fantastic. She no longer jumps tries to jump on my keyboard

12
00:01:00,190 --> 00:01:02,670
She's just happy being within arms reach

13
00:01:03,310 --> 00:01:07,970
I am getting over a cold. I am going to edit out all of the

14
00:01:08,790 --> 00:01:10,590
coughing that I may do

15
00:01:10,590 --> 00:01:14,710
but I'm hoping that for the listeners it gives my voice a

16
00:01:16,790 --> 00:01:18,260
Texture

17
00:01:18,260 --> 00:01:22,980
That will draw you in to the important things I have to talk about

18
00:01:23,620 --> 00:01:28,950
Or not or fast-forward you're actually I already sound higher pitched

19
00:01:29,670 --> 00:01:36,870
Than I do normally because you are listening to this at 1.5 speed. I'm doing swell

20
00:01:36,870 --> 00:01:40,510
I'm eager for the weekend within minutes

21
00:01:41,590 --> 00:01:43,590
my of this

22
00:01:43,870 --> 00:01:46,550
Podcasts being done my daughter and I

23
00:01:47,470 --> 00:01:49,470
despite the damn

24
00:01:49,830 --> 00:01:51,710
liquid sunshine today

25
00:01:51,710 --> 00:01:57,190
We're gonna go out geocaching and we oh cool. You're both excited about it

26
00:01:57,190 --> 00:02:00,430
I did that with my kids a long time ago. It's kind of fun

27
00:02:00,430 --> 00:02:03,950
Yeah, hey, but speaking of going out have you seen Dune new Dune?

28
00:02:04,510 --> 00:02:09,510
Dune 2 no Dune 2 you got to go see Dune 2 in IMAX. I have not seen doing one yet

29
00:02:10,030 --> 00:02:12,030
So much better than the Dune we grew up with

30
00:02:12,830 --> 00:02:14,190
Yeah

31
00:02:14,190 --> 00:02:16,710
That probably won't take much. I

32
00:02:17,550 --> 00:02:23,450
Am going to play Xbox this weekend for the first time literally in months. I got to tell you about

33
00:02:24,630 --> 00:02:25,670
my

34
00:02:25,670 --> 00:02:27,150
Struggle with starfield

35
00:02:27,150 --> 00:02:33,630
Okay is I am in a place now where I do not have enough health nor ammo

36
00:02:33,710 --> 00:02:37,910
To get out alive of this building. I'm in but I have to kind of walk my way out of

37
00:02:38,430 --> 00:02:44,430
So I think I'm gonna have to go back to a save point well before the building is kind of start a whole big

38
00:02:44,430 --> 00:02:47,030
Quest over because there's just no way out

39
00:02:47,030 --> 00:02:52,390
I have scoured the building and all I find are more bad guys and no ammo and it's been kind of frustrating

40
00:02:52,390 --> 00:02:59,210
I think if I'm a game designer, I would not put myself in that but put my players in that position

41
00:02:59,210 --> 00:03:01,210
So I'm gonna give it a shot again

42
00:03:01,310 --> 00:03:04,830
It's been long enough now that if I have to go do the whole quest again

43
00:03:04,830 --> 00:03:10,790
I won't be mad because I'll forgotten most of it. It's kind of not a great experience. So I'm gonna go fix I

44
00:03:11,790 --> 00:03:15,430
In starfield got myself into that situation I

45
00:03:16,430 --> 00:03:22,510
Refused to do what you did and I just you know died reload died reload

46
00:03:23,230 --> 00:03:29,710
Have already done done that 300 times and I did it enough to manage to squeak through

47
00:03:30,190 --> 00:03:36,990
Okay, I will probably try another 50 times before I give up just for the record, but I probably I don't feel confident

48
00:03:36,990 --> 00:03:38,990
I am now roughly

49
00:03:39,070 --> 00:03:46,340
I haven't played it in a couple of months. I am I think around level 35 the last time I checked in

50
00:03:46,340 --> 00:03:50,060
I was I'm at 12. I think it was around 7 but my

51
00:03:51,260 --> 00:03:56,650
My birthday was last week in my Oh Happy Birthday Brett Brett's 25 now

52
00:03:57,370 --> 00:03:59,810
25 going on 12 and

53
00:04:00,970 --> 00:04:03,290
My eldest gave me

54
00:04:04,090 --> 00:04:08,770
Baldur's Gate. Oh, I've been playing that too. That's a fun game, too

55
00:04:08,850 --> 00:04:12,570
And that's the other I play three games on my Xbox. I play

56
00:04:13,730 --> 00:04:15,730
Starfield Baldur's Gate and FIFA

57
00:04:16,360 --> 00:04:22,520
Okay, I thought I felt I was I only am doing to matter of fact

58
00:04:22,520 --> 00:04:26,320
I think I told you I went out and bought a whole new Xbox

59
00:04:27,880 --> 00:04:30,400
Just to be able to play starfield and

60
00:04:31,400 --> 00:04:36,200
Currently that Xbox has exactly two games installed upon it. I

61
00:04:37,510 --> 00:04:39,670
Picked up an X. I think last summer

62
00:04:40,470 --> 00:04:44,230
It has my whole library on it because why not? I don't have my other one plugged in anywhere

63
00:04:44,230 --> 00:04:50,390
I I thought about plugging one of them. I have so many of them now. Anyway, lots of Xboxes. I'm gonna do that this weekend. Oh

64
00:04:51,030 --> 00:04:54,650
Oh, I want to talk about how forgetful I am

65
00:04:55,090 --> 00:04:56,130
Okay

66
00:04:56,130 --> 00:05:01,340
So I had an idea for a podcast topic and Brent has a better one. Thankfully

67
00:05:01,740 --> 00:05:05,380
But longtime listeners will know that I often

68
00:05:05,980 --> 00:05:07,180
vet

69
00:05:07,180 --> 00:05:08,820
articles or

70
00:05:08,820 --> 00:05:10,300
our

71
00:05:10,300 --> 00:05:15,860
Presentations on the podcast is talking about something that I'm thinking about for a presentation but kind of work through it

72
00:05:15,860 --> 00:05:20,080
I'm giving a presentation at another company in May

73
00:05:20,600 --> 00:05:27,100
Which is coming rather quickly and it's a it's a company that invited me up to give them a talk

74
00:05:28,180 --> 00:05:31,460
pre-pandemic I supposed to give the talk in April or May of

75
00:05:32,140 --> 00:05:33,900
2020

76
00:05:34,100 --> 00:05:40,380
Bad time to travel around the world. I'm finally gonna go back and give some talks and I was gonna talk through them

77
00:05:40,380 --> 00:05:42,380
But I heard back from them today

78
00:05:42,980 --> 00:05:47,540
asking me for some information about my talk and blah blah blah and blah blah blah and

79
00:05:47,970 --> 00:05:52,570
I realized I do not have a copy of the abstract. I sent them anywhere

80
00:05:52,570 --> 00:05:59,250
I don't know exactly what my talk is about. So I'm not gonna vet that here on the podcast because

81
00:06:00,050 --> 00:06:08,890
Because I'm frankly old and dumb. Well, it feels like a good a good hour or two on the

82
00:06:09,210 --> 00:06:13,130
Podcast you and I could just chat GPT it out. Yeah. Oh

83
00:06:14,010 --> 00:06:18,570
And we're gonna get to chat GPT in a minute. But speaking of old and dumb

84
00:06:19,340 --> 00:06:23,140
This is episode 197 of the AB testing podcast

85
00:06:24,020 --> 00:06:24,940
197

86
00:06:24,980 --> 00:06:29,500
So we are coming up on not only the 200th episode

87
00:06:30,320 --> 00:06:37,880
Not all but more but more we're coming up on the 10th anniversary of the very first AB testing podcast

88
00:06:37,880 --> 00:06:39,040
Do not listen to it

89
00:06:39,040 --> 00:06:40,840
if we were

90
00:06:40,840 --> 00:06:45,440
now I have been thinking hard about how we get to

91
00:06:46,720 --> 00:06:52,100
200 to be released on that day and what it means is we got to get

92
00:06:53,060 --> 00:06:55,060
197 198 and

93
00:06:55,180 --> 00:07:00,940
199 out quickly. I think we decided this is 187, right? This is 197

94
00:07:00,940 --> 00:07:06,740
Okay, and I'm Alan and that's Brent and this has been episode 197 of the AB testing podcast. All right

95
00:07:08,460 --> 00:07:10,500
Now now let's do 198, okay

96
00:07:15,300 --> 00:07:19,700
We're gonna figure it out, I don't know I got time let me know let me know if you want to do we could release

97
00:07:20,500 --> 00:07:23,940
Episode one as a recap. Oh

98
00:07:24,740 --> 00:07:29,780
No, we could do episode one with like director commentary. Oh

99
00:07:30,580 --> 00:07:32,420
for 198

100
00:07:32,420 --> 00:07:38,960
Okay, and and by the way like who invented this rule that episode

101
00:07:39,460 --> 00:07:41,740
200 has to be done after

102
00:07:42,860 --> 00:07:44,620
198 199

103
00:07:44,620 --> 00:07:48,180
Right, right. We could just we could just skip some you're right

104
00:07:48,420 --> 00:07:54,580
But I like the idea of MST 3k in our first episode that actually would be fun

105
00:07:54,580 --> 00:08:01,460
I haven't listened to it in a long I gotta figure out I am pretty sure I can figure out how to just pipe that in

106
00:08:02,180 --> 00:08:07,370
To us and we can listen and pause as we go along. That would be fun

107
00:08:07,450 --> 00:08:11,290
Let's actually let's do that. Let's figure out how to make that 199

108
00:08:12,480 --> 00:08:18,360
Okay, actually we'll do that. We get your calendar out figure out how we're gonna shove those in I will make it work

109
00:08:18,760 --> 00:08:21,980
If you want to just pick a night, I got nothing going on. Let me know

110
00:08:23,820 --> 00:08:28,710
So listeners don't know that Brent tonight we don't talk in between we got it we don't plan

111
00:08:28,710 --> 00:08:31,030
We don't have a good things to do

112
00:08:31,750 --> 00:08:37,790
Yeah, we should get a we should get an assistant assistant producer that would figure all this out. Just tell us what to do

113
00:08:37,990 --> 00:08:41,850
Okay, we don't pay I think we can make this happen

114
00:08:42,530 --> 00:08:45,980
All right, the hard part will be

115
00:08:47,230 --> 00:08:49,230
We will have to do

116
00:08:49,790 --> 00:08:51,790
episode 200

117
00:08:52,110 --> 00:08:54,670
Morning our time if we want to do it on that day

118
00:08:55,390 --> 00:08:56,510
Okay

119
00:08:56,510 --> 00:08:57,950
We should

120
00:08:57,950 --> 00:09:00,990
You know what because that one I probably won't edit so we could

121
00:09:01,790 --> 00:09:05,310
If we're going to do it live with guests, I probably won't edit it

122
00:09:06,060 --> 00:09:08,540
Uh, i'm going to talk to alan about this

123
00:09:09,100 --> 00:09:11,100
Outside of the cast so

124
00:09:12,540 --> 00:09:15,100
And if you all want to offer input

125
00:09:15,660 --> 00:09:18,940
One of the three slack calm is our slack channel

126
00:09:18,940 --> 00:09:22,540
But the way if you're not already there you can go to modern testing org

127
00:09:22,940 --> 00:09:26,060
And click the link and joiny joiny joiny and get in there

128
00:09:26,910 --> 00:09:30,590
And we're going to do our best to make it all happen and we want lots of guests

129
00:09:30,670 --> 00:09:35,150
We're going to have for episode 200 whenever that is we're going to have people join

130
00:09:35,870 --> 00:09:40,830
And there's going to be a chat gallery. We can have people just i'll figure it out. We can have lots of people on

131
00:09:41,070 --> 00:09:44,590
It's going to be a big party without all the fear of covid and that stuff

132
00:09:52,500 --> 00:09:53,540
All right

133
00:09:53,540 --> 00:09:55,540
We have done some planning some

134
00:09:56,100 --> 00:10:00,420
Gnashing of teeth and fingers and and things and we're going to do the best to make it work

135
00:10:00,420 --> 00:10:03,140
But we have more to figure out but our assistant will step in and help out there

136
00:10:03,860 --> 00:10:05,860
and let's talk about

137
00:10:06,820 --> 00:10:14,820
Something brant you had an idea for a topic and it was five minutes ago. So I forgot what it was. So yeah, so go ahead alan

138
00:10:15,920 --> 00:10:18,960
You and I have stop sharing your screen

139
00:10:19,600 --> 00:10:23,120
Yeah, all right. I'm gonna try pushing this stop button and see what happens

140
00:10:24,260 --> 00:10:28,740
It worked. Okay, great. Yeah, it didn't kill the recording. We're good. Yeah. I'm like, why is it called stop?

141
00:10:28,820 --> 00:10:32,580
It should be called unshare. What's gonna happen if I push this button?

142
00:10:33,760 --> 00:10:36,020
Whitaker

143
00:10:36,020 --> 00:10:38,020
recently wrote a post

144
00:10:38,830 --> 00:10:39,870
uh

145
00:10:39,870 --> 00:10:43,150
Alan if he remembers will link to it

146
00:10:44,510 --> 00:10:48,750
And it is called the resurrection of software testing

147
00:10:49,780 --> 00:10:52,420
And I thought it might be fun

148
00:10:53,760 --> 00:10:56,000
for us to review slash

149
00:10:57,060 --> 00:10:58,500
Comment on it

150
00:10:58,500 --> 00:11:02,500
What this is this the same james whitaker who said test is dead?

151
00:11:03,140 --> 00:11:04,500
He did

152
00:11:04,500 --> 00:11:09,780
He's claiming he's giving credit to his colleague at the time alberto

153
00:11:10,420 --> 00:11:13,060
Um, but I heard it for the first time from him

154
00:11:14,460 --> 00:11:17,260
Yeah, and a lot of people misinterpreted this

155
00:11:17,820 --> 00:11:21,580
Merritt had a great post this week that I mentioned in five for friday talks about people

156
00:11:22,220 --> 00:11:23,710
who

157
00:11:23,710 --> 00:11:30,350
Reference things in their talk that they have not fact checked it on the full research on so test conferences in my experience are famous for this

158
00:11:30,430 --> 00:11:32,430
People telling stories about things that are half true

159
00:11:33,150 --> 00:11:35,150
And a lot of the stories about test is dead

160
00:11:36,030 --> 00:11:37,550
Missed the point

161
00:11:37,550 --> 00:11:43,310
A lot of the test is dead about the same things brent and I have been talking about because your data is there to help us

162
00:11:43,950 --> 00:11:45,950
Uh testing as it's been known

163
00:11:45,950 --> 00:11:47,950
This is I think that was 10 years ago, right?

164
00:11:48,510 --> 00:11:51,870
15 years ago 14 and 2011 so 13 years ago

165
00:11:52,590 --> 00:11:54,590
First gave the test is dead talk

166
00:11:55,300 --> 00:11:56,900
Stuff was changing

167
00:11:56,900 --> 00:12:01,940
So it was a fair talk to give I think a lot of people lose a lot of the context or haven't looked into why

168
00:12:02,500 --> 00:12:04,820
and again as we talked about with um

169
00:12:05,380 --> 00:12:08,020
with cat a few episodes ago, it is

170
00:12:09,280 --> 00:12:11,140
surprising to me

171
00:12:11,140 --> 00:12:20,180
How many testers who tout themselves on critical thinking fail to apply critical thinking when evaluating things they don't agree with but anyway

172
00:12:20,900 --> 00:12:26,900
So that all happened. There was some reaction a lot of it misconstrued and then james who is

173
00:12:27,780 --> 00:12:30,980
Trying to remain relevant in the world. Sorry james

174
00:12:31,540 --> 00:12:36,980
Comes out with an article called the resurrection of software testing where he says, you know what?

175
00:12:38,270 --> 00:12:40,270
Maybe it's not quite so dead

176
00:12:41,090 --> 00:12:43,090
All right. Yeah

177
00:12:43,090 --> 00:12:47,730
The ending of it is software testing may well have died in 2011

178
00:12:47,810 --> 00:12:51,890
But its mindset needs to be resurrected in 2024

179
00:12:52,450 --> 00:12:58,050
The world needs the skills of testers more than ever and researchers need to step up

180
00:12:58,530 --> 00:13:05,090
To create similar tools processes and training they did for software so long ago

181
00:13:05,970 --> 00:13:10,770
And what's interesting that we're going to actually spend a half hour talking about this post but

182
00:13:11,490 --> 00:13:17,810
The first it's not a very long post and the first three quarters of it. All they do is recap albert's test is dead talk

183
00:13:18,450 --> 00:13:22,610
And then he says oh ai and then gives uh brent's

184
00:13:23,630 --> 00:13:26,270
Paragraph and I think there's a lot of truth to that

185
00:13:27,100 --> 00:13:30,620
No, I think there's some truth to what james is saying

186
00:13:31,660 --> 00:13:32,860
because

187
00:13:32,860 --> 00:13:34,620
ai is

188
00:13:34,680 --> 00:13:38,700
Changing the way software development can work

189
00:13:39,940 --> 00:13:42,020
A lot of people think of ai as magic

190
00:13:42,420 --> 00:13:43,460
Yeah

191
00:13:43,460 --> 00:13:48,980
A lot of people blindly use the suggestions from ai without reading them remember my prediction show I talked about

192
00:13:49,540 --> 00:13:51,540
As mentioned in the sense then at least twice

193
00:13:52,300 --> 00:13:57,980
The ability to read code critically is going to become very important because you have to figure out

194
00:13:58,620 --> 00:14:00,780
What's actually happening with this generated code?

195
00:14:01,420 --> 00:14:04,540
And if that's and maybe that's a tester mindset

196
00:14:05,470 --> 00:14:11,150
In a sense like brent's making a face like he's about to go to town on this really this one paragraph article

197
00:14:12,110 --> 00:14:13,790
No, you just said

198
00:14:13,790 --> 00:14:16,430
When the way you said the tester mindset

199
00:14:17,150 --> 00:14:18,510
triggered

200
00:14:18,510 --> 00:14:21,790
Negative thoughts from old podcasts. I get it right

201
00:14:23,630 --> 00:14:25,470
When I read this

202
00:14:25,470 --> 00:14:31,630
That didn't trigger. So so you you bring in loading that into the brain at the same time. I'm like, oh

203
00:14:32,110 --> 00:14:33,150
I'm gonna

204
00:14:33,150 --> 00:14:35,220
Cute a little now. Um

205
00:14:35,460 --> 00:14:38,900
And I as an aside i'm like, hey, do you have arvin's?

206
00:14:39,060 --> 00:14:45,620
Uh phone number on on speed dial like maybe we should pause and call him into this right now because I'd love

207
00:14:46,020 --> 00:14:51,060
I think this would be a topic of interest to you. I'll go grab me living in my basement. Oh second living

208
00:14:51,780 --> 00:14:54,340
He did something very hand wavy like

209
00:14:55,140 --> 00:14:58,980
James super hand wavy. It's canonical with james

210
00:14:59,940 --> 00:15:01,940
like he's the master at

211
00:15:02,850 --> 00:15:06,610
What's a nice way of saying authoring clickbait titles rhetoric

212
00:15:07,010 --> 00:15:11,090
No, like the resurrection of software testing like oh, yeah. Yeah

213
00:15:11,650 --> 00:15:18,050
Yeah, and and to be clear we both love james a great friend. He's a funny guy and he's and it's obvious to me what he's

214
00:15:18,130 --> 00:15:22,850
Doing here, but he's actually in his and he will tell you

215
00:15:23,490 --> 00:15:28,130
That he is not being, you know facetious or clickbaity. He really means it but

216
00:15:28,850 --> 00:15:32,290
On the other and he is actually correct. I want to go into why he's correct

217
00:15:33,330 --> 00:15:36,370
But there's not enough there there

218
00:15:37,170 --> 00:15:40,050
To actually get a full opinion. I think hopefully there's more coming

219
00:15:40,610 --> 00:15:44,770
I thought it was funny james posted like this is right from three weeks ago two weeks ago. He posted

220
00:15:45,570 --> 00:15:48,050
Any testers on the east side want to get together and chat?

221
00:15:48,690 --> 00:15:51,650
And of course, he's going to invite them to his bar where they can buy his beer, right?

222
00:15:51,810 --> 00:15:55,650
But he's like get together and I I just replied hey, dude test is dead

223
00:15:56,370 --> 00:16:01,730
Did you I did I did I think you replied i'm talking about testers not test

224
00:16:02,530 --> 00:16:04,290
words are important

225
00:16:04,290 --> 00:16:07,170
so yeah, well, no, it's interesting because I

226
00:16:08,660 --> 00:16:10,660
I think we would argue

227
00:16:10,740 --> 00:16:13,860
That tester is more dead than test

228
00:16:14,580 --> 00:16:16,260
Yeah, I would

229
00:16:16,260 --> 00:16:18,820
I'm not going to write the article with that headline but

230
00:16:19,680 --> 00:16:25,280
I'm like, you know because I read this line the world needs the skills of testers more than ever

231
00:16:25,360 --> 00:16:29,920
So he never he says the resurrection of software testing

232
00:16:30,880 --> 00:16:35,920
And I don't know I I don't think he's what what evokes for me

233
00:16:36,560 --> 00:16:37,840
is

234
00:16:37,840 --> 00:16:41,840
Bringing back right the the singular discipline

235
00:16:42,560 --> 00:16:44,240
Bringing I hope not

236
00:16:44,240 --> 00:16:48,480
And I want to talk about what what my interpretation of that is and it's kind of riff on that for a second

237
00:16:48,480 --> 00:16:51,600
But I do want to bring up a tangent. Oh, no a tangent never

238
00:16:51,680 --> 00:16:57,680
Tangent tangent. I happen to be we needed a theme song for tangent except we just I'd run out of copyright money

239
00:16:58,240 --> 00:17:03,280
I uh was talking to a internet colleague today

240
00:17:03,680 --> 00:17:09,920
Just talking about job searches and giving some generic advice knowing nothing about the person but super nice guy. I think he'll do well

241
00:17:09,920 --> 00:17:10,960
I think

242
00:17:10,960 --> 00:17:12,960
None of that's important if you're listening

243
00:17:13,360 --> 00:17:17,600
And we talk today friday. I actually really think you're gonna do well, but

244
00:17:18,560 --> 00:17:21,760
The thing we talked about is something i've noticed because I just

245
00:17:22,400 --> 00:17:26,720
I do a lot of free consulting not as an employee of my company just because people say hey

246
00:17:26,720 --> 00:17:28,880
Do you got 10 minutes or 15 minutes talk about a thing?

247
00:17:29,280 --> 00:17:33,040
And I say as long as you're not trying to sell me something i'd be happy to talk to you

248
00:17:33,520 --> 00:17:37,200
The industry has been very nice to me. The best thing I can do is talk to folks who asked for it

249
00:17:37,840 --> 00:17:38,960
so

250
00:17:38,960 --> 00:17:44,720
What I've noticed and I told him this what i've noticed in having these conversations over the past few months is actually

251
00:17:45,280 --> 00:17:47,280
The bubble is moving

252
00:17:48,020 --> 00:17:55,460
The bubble is moving on what testing is doing. We'll even put our conversation with brian finster from the podcast into this bucket

253
00:17:56,180 --> 00:18:00,500
People are beginning to see that testers on good teams

254
00:18:01,220 --> 00:18:04,980
When they exist exist to help developers do their job better

255
00:18:05,780 --> 00:18:09,860
And that can be coaching or frameworks things are not there to do the vast majority of testing

256
00:18:09,860 --> 00:18:12,580
They may do a little bit of testing because they're really good at it

257
00:18:12,580 --> 00:18:15,060
But they're doing it in a way that makes people around them better

258
00:18:15,540 --> 00:18:18,660
And I want to come back to that put a pin in that for a conversation on ai

259
00:18:19,140 --> 00:18:21,140
And I also talked to a company

260
00:18:21,380 --> 00:18:26,580
Uh, a test leader at a large company brent wrote a tangent song and chat gpt. This is great

261
00:18:27,300 --> 00:18:31,700
I talked to a manager at a large company who has a test team

262
00:18:32,740 --> 00:18:37,620
And my little alarm bells went off. Oh, you have a qa team. Mike also the qa team

263
00:18:38,180 --> 00:18:40,180
I said, what do they do?

264
00:18:40,180 --> 00:18:43,540
And what he basically he described that I won't use the words

265
00:18:43,860 --> 00:18:50,820
But basically they accelerate the achievement of quality. They exist to help make to help with feedback loops

266
00:18:51,540 --> 00:18:54,180
Help with the testing part of feedback loops. They can go faster

267
00:18:54,660 --> 00:18:56,900
They there was a few cases where they did a little bit of

268
00:18:57,620 --> 00:19:03,220
A little bit more than I thought they would but they are actively working on removing that from what they do

269
00:19:03,300 --> 00:19:11,460
Okay, so this is a large company's probably had testers for 20 30 years. I am seeing the changes happening

270
00:19:12,180 --> 00:19:14,980
I think these changes apply

271
00:19:15,700 --> 00:19:21,860
To ai we do not need dedicated ai testers testing ai now. It's funny because

272
00:19:22,660 --> 00:19:27,540
Arbin said you and I would one or both of us would both be in qa roles by the end of the year

273
00:19:27,780 --> 00:19:30,660
But I have not been interested at all in any of these folks

274
00:19:31,700 --> 00:19:35,300
Jobs or positions what i'm interested in learning kind of their journey so I can

275
00:19:35,860 --> 00:19:37,860
Try and get stuff a stick in my head

276
00:19:38,100 --> 00:19:41,460
I think we need people like and go back to the ai problem

277
00:19:42,180 --> 00:19:48,820
It is a parrot as we discussed. It is not magic. I watch self-proclaimed test experts

278
00:19:49,460 --> 00:19:51,620
use chat gpt for things or

279
00:19:52,610 --> 00:19:57,250
Test chat gpt on things that an llm and generative ai would never be able to do

280
00:19:57,650 --> 00:20:01,810
And they point their fingers and say you can't trust this stuff. It's broke and it doesn't work

281
00:20:02,210 --> 00:20:07,490
We need people we need critical thinkers who understand how this stuff works

282
00:20:07,810 --> 00:20:10,130
So they can one stop those people in their tracks

283
00:20:10,130 --> 00:20:15,490
So when somebody it wants to use generative ai to manage their nuclear power plant

284
00:20:16,370 --> 00:20:21,090
That's someone steps in so that's not a great application here the right things is good for

285
00:20:21,410 --> 00:20:24,930
That's kind of what's been missing and we can go on the little ethics and ai thing

286
00:20:25,970 --> 00:20:29,330
We don't necessarily need ai tested

287
00:20:30,350 --> 00:20:34,190
We need people who really understand how it works

288
00:20:34,670 --> 00:20:39,550
To explain to the rest of us one last thing i'm gonna get off my soapbox because I went to a talk

289
00:20:40,190 --> 00:20:41,630
from someone

290
00:20:41,630 --> 00:20:44,350
Virtually, of course, I don't leave my house because when I do I get sick

291
00:20:45,070 --> 00:20:47,070
I went to a talk

292
00:20:47,150 --> 00:20:54,670
Virtually from someone giving a talk on ai or llms or both people don't get the difference and yet neither to this person

293
00:20:55,310 --> 00:20:57,310
They were on one hand

294
00:20:57,470 --> 00:21:05,390
Ranting about how much they knew and how deep their talk was and while I was watching thinking oh my god, this is all wrong

295
00:21:06,180 --> 00:21:12,020
So it's really missing from the industry today to sum up my ted talk what's really missing from the industry today?

296
00:21:12,500 --> 00:21:15,940
Is people who understand how llms work?

297
00:21:16,880 --> 00:21:22,660
Explaining and hand holding the people who are using them so they use it in the way that's most effective

298
00:21:22,820 --> 00:21:26,740
And they don't use it for the things that it's not designed for and complaining

299
00:21:27,380 --> 00:21:31,300
You're not going to get me to disagree with that i'm more curious around

300
00:21:32,100 --> 00:21:35,380
Like the synops of of the one talk that you talked about

301
00:21:36,380 --> 00:21:42,620
Like what was a key thing that this person was wrong on? I can look I probably have notes somewhere. I can look it up

302
00:21:43,180 --> 00:21:45,500
They were actually wrong in a couple things

303
00:21:46,200 --> 00:21:49,260
Partially right, but also in some places very wrong. No, it was it was

304
00:21:50,780 --> 00:21:52,780
So high level that it didn't matter

305
00:21:53,020 --> 00:21:59,500
And the low level stuff, but no it went deep because the speaker was very adamant about saying how deep they went

306
00:22:00,060 --> 00:22:03,260
But the stuff they went on deep on it was obvious. They did not understand

307
00:22:04,510 --> 00:22:06,160
Okay

308
00:22:06,160 --> 00:22:10,560
They had no idea what a rag model was but they talked about it like they did but then they described it

309
00:22:10,560 --> 00:22:12,560
It was obvious. They did not know what it was

310
00:22:13,390 --> 00:22:15,060
for example

311
00:22:15,060 --> 00:22:19,700
Anyway, I don't I'm I'm not here to throw internet people under the bus

312
00:22:20,420 --> 00:22:26,420
What i'm here to do is say this is an example of where we need i don't even want to call it testing

313
00:22:26,740 --> 00:22:28,740
It's an example of where we need

314
00:22:29,620 --> 00:22:31,860
critical thinking applied to how

315
00:22:32,480 --> 00:22:34,480
AI is used

316
00:22:35,060 --> 00:22:40,740
Brent showing me a paper on his desk about how to filter content for retrieval augmented. Yeah

317
00:22:41,780 --> 00:22:46,020
I literally just printed it out and just pulled it out of my paper my printer

318
00:22:46,820 --> 00:22:51,220
The issue that we're battling is the same thing we've been battling

319
00:22:51,940 --> 00:22:53,940
for a long time, you know

320
00:22:54,320 --> 00:22:59,700
Ignorance the intellectually lazy is what i'm gonna call them. Yeah. Yeah

321
00:23:00,340 --> 00:23:01,900
That's it

322
00:23:01,900 --> 00:23:09,180
I don't know how we fix that like honestly lom quite honestly is probably going the other direction

323
00:23:10,720 --> 00:23:12,880
Correct, right? It's like oh

324
00:23:14,400 --> 00:23:16,240
Oh, we need a jingle

325
00:23:16,240 --> 00:23:22,160
We need a little theme song for when we go to the start up the tangent segment. Oh chat gpt

326
00:23:23,040 --> 00:23:26,400
Hey, it rhymes cool. Let me show it to allen, right? I spent

327
00:23:27,940 --> 00:23:31,220
No time reading it most of my time going what's the prompt?

328
00:23:32,020 --> 00:23:33,220
right, uh it

329
00:23:33,220 --> 00:23:34,370
theme

330
00:23:34,370 --> 00:23:36,510
That's the other thing

331
00:23:36,510 --> 00:23:38,910
At work. I play the role that you

332
00:23:39,550 --> 00:23:40,780
just

333
00:23:40,780 --> 00:23:43,100
Talk through. Oh, maybe you're gonna be a

334
00:23:43,900 --> 00:23:46,000
Uh, uh, ai qa

335
00:23:46,080 --> 00:23:47,520
Uh, no

336
00:23:47,520 --> 00:23:49,520
Yeah, exactly. Yeah, no

337
00:23:49,840 --> 00:23:55,120
No, because number one that would make arban correct, uh, and I refuse to let that happen

338
00:23:55,680 --> 00:23:56,960
I

339
00:23:56,960 --> 00:23:58,960
On a daily basis the last

340
00:23:59,760 --> 00:24:01,760
I have had random

341
00:24:02,000 --> 00:24:04,160
ICs come to me and they're like hey

342
00:24:04,720 --> 00:24:10,240
I have this awesome idea for how to use llm great sit down walk me through it

343
00:24:11,650 --> 00:24:14,290
And they're like, oh, yes perfect except for

344
00:24:15,330 --> 00:24:20,210
You know the parts where I actually use llm it keeps coming back with weird stuff

345
00:24:21,410 --> 00:24:23,650
And then I sit down and I tell them

346
00:24:24,690 --> 00:24:25,650
how

347
00:24:25,650 --> 00:24:26,850
to use

348
00:24:26,850 --> 00:24:28,290
the system

349
00:24:28,290 --> 00:24:30,290
With with the endeavors that you do

350
00:24:30,770 --> 00:24:32,930
You actually do it

351
00:24:33,010 --> 00:24:37,090
Nearly optimal for what is what it excels at right? It's

352
00:24:37,970 --> 00:24:40,450
If it's something that's a creative endeavor

353
00:24:41,010 --> 00:24:44,770
Oh, yeah, I mean it's it's gonna knock things out like

354
00:24:45,330 --> 00:24:47,490
Just as an example today. I have

355
00:24:48,530 --> 00:24:50,530
my team has a

356
00:24:51,090 --> 00:24:58,050
python package that we had built on top of llm to make our lives easier on a lot of aspects and

357
00:24:58,930 --> 00:25:00,380
I

358
00:25:00,380 --> 00:25:05,820
One of my ICs had created a unit test that had dependencies

359
00:25:06,780 --> 00:25:11,020
And I don't like unit tests having dependencies. So I nor should you

360
00:25:11,980 --> 00:25:14,220
So I did depend as sized it

361
00:25:15,140 --> 00:25:20,420
And I had some sample content that I use in other things where it's it's quotes

362
00:25:21,300 --> 00:25:24,180
quotes from yoda and quotes from mark twain

363
00:25:25,620 --> 00:25:27,620
And I just I just said hey

364
00:25:28,820 --> 00:25:32,500
Create three new quotes from a fictitious author

365
00:25:33,300 --> 00:25:36,020
That simultaneously speaks like twain

366
00:25:37,200 --> 00:25:39,200
and like yoda

367
00:25:39,940 --> 00:25:42,580
And then write a story that includes those quotes

368
00:25:43,460 --> 00:25:44,660
and

369
00:25:44,660 --> 00:25:48,420
I better did all right. It did fantastic. Like the the quotes were

370
00:25:49,140 --> 00:25:54,580
I'm like, yeah, that's like that's literally mark twain and yoda

371
00:25:56,060 --> 00:25:58,300
the story was a little chintzy because

372
00:25:59,250 --> 00:26:04,930
It invented a story about a little girl that lived in the village and she found a quote book

373
00:26:05,890 --> 00:26:12,050
And she opened the first page and read the first quote and are they cheated? Yeah, i'm like, okay

374
00:26:12,130 --> 00:26:17,170
Well, you did what I asked for but that's a boring story. That's what they do. That's what they do

375
00:26:17,170 --> 00:26:19,890
But some tester now, here's the here's the difference

376
00:26:20,370 --> 00:26:26,850
Some tester will ask you to write that story but write exactly five paragraphs and each paragraph should have 27 words

377
00:26:27,790 --> 00:26:29,790
And it's not going to be able to do that

378
00:26:30,030 --> 00:26:33,710
It doesn't get that it's not going to do that and they're going to say it's broken

379
00:26:35,020 --> 00:26:39,180
We need people because they don't understand how llms and gen ai work, right?

380
00:26:39,900 --> 00:26:42,700
So what i'm saying we need in testing is and you like I said llms

381
00:26:43,180 --> 00:26:48,060
They are here for now gone for later. We're going to have something else something different with agis or whatever

382
00:26:48,780 --> 00:26:55,020
now each different thing that we call ai and even even gen ai is

383
00:26:55,980 --> 00:26:59,180
Is it really ai is it really intelligent? Maybe not

384
00:26:59,980 --> 00:27:02,380
Right. Absolutely not

385
00:27:03,380 --> 00:27:10,900
So what we need for every single iteration of ai I was given our listeners the benefit of the dot to jump in there

386
00:27:11,140 --> 00:27:13,700
We need somebody who understands how it works

387
00:27:14,930 --> 00:27:21,570
To help figure out how it should be used what we've lost with chat gpt is nobody ever did that

388
00:27:22,050 --> 00:27:27,330
Here's a thing you could ask these questions and then 90 of the people use it in a way

389
00:27:27,330 --> 00:27:33,090
It wasn't designed and are frustrated with it. I don't understand because it's not hard to go figure out

390
00:27:33,090 --> 00:27:37,410
It's it's intellectual laziness as you've called it and it's going to happen because

391
00:27:37,970 --> 00:27:41,250
The speed of innovation this area is going to crank like hell

392
00:27:41,970 --> 00:27:47,410
And people are not going to be able to keep up if they do not take some time to learn how these things

393
00:27:47,730 --> 00:27:50,610
Work before deciding they know how they work

394
00:27:51,250 --> 00:27:55,170
There is a couple of things when I when I think about this like

395
00:27:55,810 --> 00:27:56,850
I

396
00:27:56,850 --> 00:28:02,850
Right as you and I talked about james and james wrote this very hand wavy in my view your view as well

397
00:28:03,410 --> 00:28:06,390
And he left it with the final paragraph

398
00:28:06,930 --> 00:28:12,130
And and we both know him well enough. He did this on purpose. He left it. We do. Yeah

399
00:28:12,690 --> 00:28:17,090
And and what he's going to do is we know james and actually I like the way james does research

400
00:28:17,090 --> 00:28:20,530
He's going to pull people in on this. They're going to give him a bunch of feedback

401
00:28:20,770 --> 00:28:25,810
He's going to get a bunch of ideas and then he's going to con one of them into writing a book with his name on it

402
00:28:28,430 --> 00:28:30,140
Or

403
00:28:30,140 --> 00:28:32,460
Yeah, and you get and you'll get to write the forward

404
00:28:33,180 --> 00:28:35,760
right, you know

405
00:28:35,760 --> 00:28:41,920
He's got an equation that works and i'm not going to fault him for it. I just quite no, no me neither me neither

406
00:28:43,040 --> 00:28:48,160
Nothing, but respect because he does he does know his shit and he knows what he's doing

407
00:28:48,800 --> 00:28:53,840
100 unlike some other folks in the industry who just whatever anyway, yeah

408
00:28:54,560 --> 00:28:56,880
unicorns and rainbows unicorns and rainbows

409
00:28:57,040 --> 00:29:03,840
He says the skills of testers. Okay, i'm not certain what the skills of testers he's talking about here

410
00:29:04,400 --> 00:29:06,400
What are what are skills of testers brent?

411
00:29:07,170 --> 00:29:09,020
um

412
00:29:09,020 --> 00:29:15,900
I guess it would be in this like the ones I would say are are the ability to critically understand what's going on

413
00:29:15,900 --> 00:29:17,820
It's not fine bugs

414
00:29:17,820 --> 00:29:20,320
okay, it's

415
00:29:20,320 --> 00:29:23,600
Tie and connect the dots between the customer's needs

416
00:29:24,320 --> 00:29:26,560
And the product I definitely

417
00:29:27,360 --> 00:29:29,230
Oh, wow

418
00:29:29,230 --> 00:29:31,230
There was a day a day

419
00:29:32,180 --> 00:29:36,420
Decades ago where I would have cited. Oh, it's matching to the

420
00:29:37,040 --> 00:29:39,940
Requirements spec like you know, i'm long past that

421
00:29:40,500 --> 00:29:45,380
It's around connecting to the needs of the customer to this now. I will tell you

422
00:29:46,700 --> 00:29:47,660
one

423
00:29:47,720 --> 00:29:50,060
Really big I was I was

424
00:29:51,120 --> 00:29:53,520
I was in a very high level

425
00:29:54,380 --> 00:29:56,480
llm meeting within my company

426
00:29:57,870 --> 00:29:59,150
just

427
00:29:59,150 --> 00:30:00,850
yesterday

428
00:30:00,850 --> 00:30:02,370
um

429
00:30:02,370 --> 00:30:03,730
Not yesterday

430
00:30:03,730 --> 00:30:06,610
Tuesday, whatever this week. I raised the question

431
00:30:07,250 --> 00:30:08,620
Hey

432
00:30:08,620 --> 00:30:10,700
Has anyone found a way to?

433
00:30:11,700 --> 00:30:13,700
to quantify

434
00:30:14,420 --> 00:30:16,420
the number of times

435
00:30:16,820 --> 00:30:18,660
a particular

436
00:30:18,720 --> 00:30:20,020
qualities

437
00:30:20,020 --> 00:30:23,140
uh situation that occurs in llm has occurred

438
00:30:24,130 --> 00:30:27,330
And like no, but if you find something I need it

439
00:30:27,970 --> 00:30:34,210
And then it went down the line every data science. No, if you find something I need it the biggest challenge

440
00:30:35,230 --> 00:30:38,110
Are you familiar with the book? Uh, what is it? Systematics?

441
00:30:38,990 --> 00:30:43,550
No, okay. It's it's like one of the primers on systems theory. Okay

442
00:30:44,350 --> 00:30:45,660
and

443
00:30:45,740 --> 00:30:48,960
In there he has something he calls the law of systematics

444
00:30:49,500 --> 00:30:52,940
And that law is the number of problems in the universe

445
00:30:54,770 --> 00:31:00,770
Is constant right and you've mentioned this before I didn't I forgot I didn't know what book it was from. So yeah

446
00:31:01,010 --> 00:31:06,770
Yeah, and so the problem with llm when you're trying to do it in a non-creative space

447
00:31:07,810 --> 00:31:10,690
You have to figure out. Okay. What does it do? Well, i'll tell you

448
00:31:11,410 --> 00:31:12,610
It does

449
00:31:12,610 --> 00:31:14,210
conformance well

450
00:31:14,210 --> 00:31:18,850
Like let's say you have five different help docs written by different people

451
00:31:19,860 --> 00:31:26,900
And there's a format a language choices that you like from from on one. Yeah, you just say hey

452
00:31:27,620 --> 00:31:29,620
Take this style rewrite these ones

453
00:31:30,180 --> 00:31:32,180
It'll do that just fine

454
00:31:32,180 --> 00:31:36,420
Well, actually that's a again. It goes back to my I think we need

455
00:31:37,140 --> 00:31:39,140
AI

456
00:31:39,380 --> 00:31:41,780
Guides what's a fancy word for a guide?

457
00:31:42,610 --> 00:31:43,890
guide

458
00:31:43,890 --> 00:31:45,390
Okay

459
00:31:45,390 --> 00:31:51,470
What a docent near an AI docent to kind of walk organizations through how to use it because

460
00:31:52,270 --> 00:31:54,170
time and time again

461
00:31:54,170 --> 00:31:56,350
Organizations think that AI is magic

462
00:31:57,070 --> 00:32:03,790
And people go. Oh, this is a really hard problem. Let's use let's use magic to solve it and someone needs to say

463
00:32:04,670 --> 00:32:06,270
Not only stop them

464
00:32:06,270 --> 00:32:11,470
But I actually look at the org and say here are some areas where we really could use AI

465
00:32:11,870 --> 00:32:14,190
And make sure it's happening someone who understands

466
00:32:14,830 --> 00:32:19,150
You know some companies may call it an AI architect. That's the wrong word too, but somebody

467
00:32:19,870 --> 00:32:22,590
It would be more effective if someone made it work correctly. I want to go back to james

468
00:32:22,590 --> 00:32:26,270
Arden. I want to hold on. I want to go back to that because I don't actually uh

469
00:32:27,150 --> 00:32:35,490
I think the principles of testing that we have been talking about that testers need to serve as a guide

470
00:32:36,370 --> 00:32:41,010
Is the way to do it? It's not AI coach. It's an AI. There's the words. It's an AI

471
00:32:41,090 --> 00:32:43,890
That's what i'm looking for. AI coach an LLM coach

472
00:32:44,930 --> 00:32:50,850
Like someone who can pass on and sprit and spread like seeds to the wind

473
00:32:51,650 --> 00:32:53,650
What works what doesn't work?

474
00:32:54,340 --> 00:32:58,180
I was gonna say I fully agree and when james says

475
00:32:58,740 --> 00:33:03,400
While testing may well have died in 2011. It's the mindset needs to be resurrected in 2024

476
00:33:04,750 --> 00:33:09,550
Testing may well have died in 2011. We need a different kind of person

477
00:33:10,270 --> 00:33:12,270
to be doing

478
00:33:12,330 --> 00:33:16,830
evaluation coaching testing on AI in 2024 and beyond

479
00:33:17,310 --> 00:33:18,510
When the might

480
00:33:18,510 --> 00:33:22,910
No, here's the thing and actually this is one of the things with this statement that I I will

481
00:33:23,450 --> 00:33:27,870
Adjectly like if you were here, I would look him in the eyes and say james. This is bullshit

482
00:33:28,430 --> 00:33:31,070
Because while software testing may have died in 2011

483
00:33:31,790 --> 00:33:38,110
The mindset that was necessary to build software did not still exists

484
00:33:38,670 --> 00:33:40,780
And is thriving

485
00:33:40,780 --> 00:33:44,300
It's just now we spent the last 13 years

486
00:33:45,020 --> 00:33:47,340
Getting devs to understand it better

487
00:33:48,400 --> 00:33:50,160
right, it's

488
00:33:50,160 --> 00:33:52,000
to me i'm like

489
00:33:52,000 --> 00:33:54,000
No, I don't think this

490
00:33:54,480 --> 00:34:03,040
I wish I could disentangle with skills attesters when he says researchers need to step up and create similar tools and process and training

491
00:34:03,680 --> 00:34:09,440
That part I probably agree with and I think we're probably talking about that. I don't know if it's researchers, but it's

492
00:34:10,480 --> 00:34:11,520
there

493
00:34:11,520 --> 00:34:13,040
It's not only

494
00:34:13,040 --> 00:34:17,280
The guides like you talk about the docent or like coach

495
00:34:18,000 --> 00:34:21,200
What this says say is people like me

496
00:34:22,350 --> 00:34:26,430
Who who do understand a lot of things about this and by no means do I?

497
00:34:27,070 --> 00:34:32,270
I understand more than the common people and I understand that there's a lot more people who understand way more than me

498
00:34:33,020 --> 00:34:39,980
What the world needs is a set of in this space a set of tools that make the sticky harder problem

499
00:34:41,210 --> 00:34:42,510
clearer

500
00:34:42,510 --> 00:34:44,610
Make it avoidable

501
00:34:44,610 --> 00:34:46,340
like don't

502
00:34:46,340 --> 00:34:48,340
You know what? Here's a tool

503
00:34:48,930 --> 00:34:52,610
It's a front end that sits on top of chat gpt

504
00:34:53,330 --> 00:34:57,330
And does some nlp on your input prompt

505
00:34:57,970 --> 00:34:59,970
To let you to give you a score

506
00:35:00,290 --> 00:35:07,330
On the shittiness i'm sorry the quality of your prompt like I could write this I could figure out if this is a question that I think

507
00:35:07,890 --> 00:35:09,410
chat gpt

508
00:35:09,410 --> 00:35:11,250
will answer

509
00:35:11,250 --> 00:35:16,050
Really well or answer like you're asking it something stupid that you'll never get a good answer on

510
00:35:17,710 --> 00:35:21,550
You and I use critical thinking to figure that out, but I can quantify that

511
00:35:22,110 --> 00:35:24,110
How how would you quantify it?

512
00:35:24,590 --> 00:35:30,110
I'm going to use a language model that looks like there. So I know what chat gpt is good at it's good at

513
00:35:30,670 --> 00:35:34,590
parroting text and finding similarities and the style of somebody

514
00:35:35,230 --> 00:35:39,870
All those things but that's it's not but all those things is a big

515
00:35:40,750 --> 00:35:45,230
No, I want to flag the things. I know it's bad at so maybe i'm just going to do it simply

516
00:35:45,790 --> 00:35:46,990
from

517
00:35:46,990 --> 00:35:52,990
A keyword input file of things like similar it's going to look for words like count or rhyme

518
00:35:53,390 --> 00:36:00,190
Or any of the multiplication symbols or all of those things. I know it's bad at and I know it's probably a quantifiable list

519
00:36:00,750 --> 00:36:05,630
Uh and use those to help maybe it's harder than I think it is but it's possible

520
00:36:06,270 --> 00:36:09,950
It is absolutely harder than you think it is. It's just software

521
00:36:10,350 --> 00:36:14,590
Uh, but but here's one of the things that I don't know if you've ever done this

522
00:36:15,150 --> 00:36:16,670
um

523
00:36:16,670 --> 00:36:19,230
I I told you i've been talking to

524
00:36:20,110 --> 00:36:24,910
Employees just about every day for the last two weeks. Okay, one of them is

525
00:36:25,710 --> 00:36:31,150
Is is actually a rock star who reports to me, but he's still kind of unfamiliar with llm

526
00:36:31,150 --> 00:36:37,790
He's familiar with with neural net. So the other day I was walking him through and I generated a prompt

527
00:36:38,510 --> 00:36:42,270
And it gave me an answer and literally what I was asking it to do

528
00:36:43,070 --> 00:36:45,070
Is I asked it to write code

529
00:36:45,820 --> 00:36:51,100
And I said I want a comment that describes the purpose of this code

530
00:36:51,900 --> 00:36:53,900
after the curly brace

531
00:36:54,900 --> 00:36:57,460
It kept on putting it before the curly brace

532
00:36:58,100 --> 00:37:02,820
And I wanted it after so then I chided it and I said no

533
00:37:03,780 --> 00:37:06,340
You put the comment before I want it after

534
00:37:06,900 --> 00:37:09,220
And then it says oh, okay, and then it

535
00:37:09,860 --> 00:37:11,060
fixes it

536
00:37:11,060 --> 00:37:15,300
Then I went back and I did the thing that blew my employees mind and I said

537
00:37:16,180 --> 00:37:17,380
Okay

538
00:37:17,380 --> 00:37:19,620
Now tell me how I should have

539
00:37:20,540 --> 00:37:26,140
Prompted you such that you had gotten it right the first time. I just asked it

540
00:37:26,980 --> 00:37:30,180
Tell me what the prompt should have been so that you would not have made this mistake

541
00:37:30,980 --> 00:37:33,380
Now oftentimes it gives you advice. It's wrong

542
00:37:34,220 --> 00:37:37,820
But nine times out of ten, maybe not nine times seven times out of ten

543
00:37:38,460 --> 00:37:39,580
It works

544
00:37:39,580 --> 00:37:44,540
Yeah, I wonder if there's a way to use chat gpt maybe because you can modify the prompt

545
00:37:45,100 --> 00:37:47,900
Yeah, not in the commercial, but if you just like to open ai

546
00:37:48,700 --> 00:37:51,420
Maybe you can work that into the prompt like you can actually

547
00:37:52,220 --> 00:37:54,700
If you've worked on the back end of it, you know that you can

548
00:37:55,500 --> 00:37:58,380
Change the prompt to make sure it does not give it does not

549
00:37:59,340 --> 00:38:01,100
chat gpt as

550
00:38:01,100 --> 00:38:06,380
It exists on the web for most people it will always give you an answer even if it doesn't know

551
00:38:07,340 --> 00:38:10,460
So it could be confidently wrong, right? You can prompt it to not do that

552
00:38:11,020 --> 00:38:14,540
If you don't know tell you don't know no, but that's changing the answer

553
00:38:15,330 --> 00:38:18,290
But that you're exactly right though, right? It's essentially

554
00:38:19,740 --> 00:38:21,980
So you talked about it's a parrot and i'm glad that that

555
00:38:22,380 --> 00:38:26,860
I wonder if because I haven't played with this what I want to know is can I use that same prompt?

556
00:38:26,860 --> 00:38:30,700
Can I use some prompt engineering on the sort of in the middle layer like you can do with?

557
00:38:30,700 --> 00:38:35,900
Oh, you know if like azure openai can I muck with the prompt there give additional prompts?

558
00:38:36,460 --> 00:38:38,460
That would have it

559
00:38:38,940 --> 00:38:43,420
Great like rather than confidently give an answer to some math that it can't do

560
00:38:44,220 --> 00:38:47,660
If it could reply back and say this isn't something i'm good at

561
00:38:48,430 --> 00:38:51,710
Or I don't have a cop my or my confidence level on my answer

562
00:38:52,350 --> 00:38:57,470
I don't know now. It's so in my but these are the these are the research tools

563
00:38:57,470 --> 00:39:00,110
I want these fancy researchers wittaker speaks of to write

564
00:39:00,750 --> 00:39:02,880
yeah, my

565
00:39:02,880 --> 00:39:07,520
That for me that one would be a difficult one to do

566
00:39:08,320 --> 00:39:12,720
Because and I love difficult because oh it's fine, but the the thing is

567
00:39:13,820 --> 00:39:15,870
llm

568
00:39:15,870 --> 00:39:22,990
Like I know all it is and I know you know this but i'm gonna remind everyone on in the audience, right?

569
00:39:23,630 --> 00:39:26,910
All it does is it given a string of text?

570
00:39:27,970 --> 00:39:30,290
It produces the next character

571
00:39:31,410 --> 00:39:36,130
Right and then given that new string of text. What's the next character?

572
00:39:36,850 --> 00:39:44,530
Repeat until bored. Okay, but I I realized what i'm doing is something I get mad at companies for doing all the time

573
00:39:45,440 --> 00:39:47,040
remember when uh

574
00:39:47,040 --> 00:39:53,760
One of the iphones like the seven or something it didn't work and steve job said it's because you're holding it wrong

575
00:39:53,840 --> 00:39:56,480
Because the antenna was in a weird place, right? I remember that

576
00:39:57,360 --> 00:40:02,560
So in a way, I am telling people they're holding their phone wrong. People are using chat gpt

577
00:40:02,560 --> 00:40:04,560
They're getting asked. They don't like it's broken

578
00:40:04,640 --> 00:40:08,560
And here I am saying it's because you're holding your phone wrong. You're doing it wrong

579
00:40:08,880 --> 00:40:15,600
So what I want the tool to do if you're doing it wrong is to tell you you're doing it wrong because maybe that's easier

580
00:40:15,840 --> 00:40:20,080
Than have every company having an ai coach to help them from stop being stupid

581
00:40:20,560 --> 00:40:24,720
Maybe the tooling we need around this is the tooling that stops people from being

582
00:40:25,340 --> 00:40:26,160
idiots

583
00:40:26,160 --> 00:40:27,440
gpt

584
00:40:27,440 --> 00:40:29,840
And now we're aboard. I just want to be super clear

585
00:40:30,240 --> 00:40:37,040
Gpt will never ever ever ever ever do what you just want. However, that doesn't mean

586
00:40:37,920 --> 00:40:43,140
That just means no one should be using gpt directly. It should be going through a different endpoint

587
00:40:44,560 --> 00:40:46,880
Gpt is just a front end on top of a

588
00:40:47,920 --> 00:40:52,240
Really really big llm. Yes, exactly aboard happiness

589
00:40:52,800 --> 00:40:55,180
But I look at this and i'm like

590
00:40:55,420 --> 00:40:56,850
Yeah

591
00:40:56,850 --> 00:41:00,930
To me it it's the same thing if you are building

592
00:41:02,030 --> 00:41:07,010
software or a solution that relies on llm

593
00:41:08,300 --> 00:41:09,790
then

594
00:41:09,790 --> 00:41:11,790
the the developers of it

595
00:41:12,430 --> 00:41:14,590
They need to be thinking about

596
00:41:15,470 --> 00:41:19,630
What is the quality of this solution? How will will it solve the problems?

597
00:41:20,350 --> 00:41:22,350
It'd be interesting to bring

598
00:41:23,040 --> 00:41:24,140
Nicole

599
00:41:24,140 --> 00:41:26,140
Forsgren on and say

600
00:41:26,240 --> 00:41:29,120
Hey, did the principles of your thing? Do you have any opinion?

601
00:41:29,520 --> 00:41:33,360
To me, it seems like the very same principles that you're talking about for code

602
00:41:34,000 --> 00:41:40,400
Would also apply to prompt engineering. I know you may or may not have studied that but what's your intuition?

603
00:41:40,720 --> 00:41:42,720
I'd love to hear her answer to that

604
00:41:43,090 --> 00:41:45,810
Because i'm just I have a question for you. Yeah

605
00:41:46,450 --> 00:41:50,530
So we've been doing we've been doing a little book club on accelerate at work

606
00:41:50,690 --> 00:41:54,450
Have you and we just did chapter three and four today and three is the one on culture

607
00:41:55,250 --> 00:41:57,890
And talk about westerum's model, which is super cool

608
00:41:58,770 --> 00:42:00,770
I wonder if

609
00:42:00,850 --> 00:42:03,570
And you can talk we can both talk about this from a microsoft

610
00:42:04,590 --> 00:42:08,430
I wonder if the advent of chat gpt is

611
00:42:09,450 --> 00:42:11,550
Re-encouraging the hero mindset

612
00:42:12,190 --> 00:42:18,350
Because somebody wants to go solve everyone's problem with the magic of gpt. I haven't seen that

613
00:42:19,150 --> 00:42:24,750
I haven't seen that but there is something there is something very relevant that I have seen

614
00:42:25,630 --> 00:42:27,310
in that timeline

615
00:42:27,310 --> 00:42:29,310
okay, and that is the

616
00:42:31,170 --> 00:42:32,290
the

617
00:42:32,290 --> 00:42:36,770
proactive claim of duplication of effort in order to

618
00:42:38,190 --> 00:42:43,550
Make sure everyone is aware that I have licked the cookie. This is mine

619
00:42:44,460 --> 00:42:45,980
right in the the

620
00:42:45,980 --> 00:42:49,820
Alan i'm concerned that you're duplicating my team's effort

621
00:42:50,700 --> 00:42:52,700
Right. That's just a political ploy

622
00:42:53,180 --> 00:42:55,180
Oh sure. Yeah

623
00:42:55,240 --> 00:43:02,380
Particularly like i've been getting it a lot lately because I run a data science team that specializes in the nlp

624
00:43:03,020 --> 00:43:06,860
And the other team that quote unquote is competing with me is a dev team

625
00:43:07,580 --> 00:43:10,380
Right from a knowledge point of view. They're not going to beat my team

626
00:43:11,100 --> 00:43:16,060
The only way they win is from a if it turns into an api problem, which

627
00:43:16,620 --> 00:43:18,620
Right gpt is an api

628
00:43:19,340 --> 00:43:25,260
But it's the quality output of it that matters. So here's my thought so, you know remember back in the day I work with

629
00:43:25,980 --> 00:43:31,020
Folks on the microsoft research team on a lot of software engineering studies, but here's the study I want to see

630
00:43:31,660 --> 00:43:38,060
It's almost too early to do it. It's way too hard for me to do but I want to find something around the

631
00:43:39,020 --> 00:43:42,700
The effect of generative AI on organizational culture

632
00:43:43,260 --> 00:43:50,460
Or organizational health either one of those i'll call it organizational health like how is chat we talk a lot because we're adjacent to it

633
00:43:50,940 --> 00:43:54,380
About chat gpt helping programmers and helping make software

634
00:43:55,100 --> 00:44:00,780
As you know when we've discussed chat gpt and generative AI isn't just for developers

635
00:44:00,860 --> 00:44:06,300
That's some pretty good pluses for us and I talk about how I use it in writing and thinking through things

636
00:44:07,460 --> 00:44:13,220
But what is that's the thing ai is for everyone gen ii is for everyone

637
00:44:13,940 --> 00:44:18,420
What is the effect of that? What what is happening to organizations who embrace?

638
00:44:18,660 --> 00:44:23,700
Gen ai who play with gen ai like what is happening there? Are they getting healthier?

639
00:44:23,940 --> 00:44:28,660
Are they getting less healthy? There can't be no impact. Oh, there's gonna be impact

640
00:44:29,460 --> 00:44:35,300
But I want I don't I actually don't have an opinion of what that's gonna be but it's worth measuring i'll i'll give you

641
00:44:36,260 --> 00:44:39,380
I'll give you some thoughts. I have enough thoughts already

642
00:44:40,020 --> 00:44:42,020
Here's a few more

643
00:44:42,100 --> 00:44:47,140
Okay, i'll squeeze them in number one. Remember what I just said about systematics. Okay. Yes

644
00:44:47,620 --> 00:44:51,540
The key thing is that the number of problems in the universe is constant

645
00:44:52,500 --> 00:44:55,140
Okay, and when I talk about

646
00:44:56,130 --> 00:44:58,130
This this law

647
00:44:58,130 --> 00:45:01,010
I talk about like okay when email happened

648
00:45:02,210 --> 00:45:05,330
Right when I remember I remember when email was invented

649
00:45:06,210 --> 00:45:09,140
Why was it cool?

650
00:45:09,140 --> 00:45:11,940
Because we could talk to our friends anywhere in the world

651
00:45:12,940 --> 00:45:16,220
And not have to pay for stamps and not have to wait

652
00:45:17,100 --> 00:45:19,100
For free, right?

653
00:45:19,260 --> 00:45:21,340
As long as we paid our computer lab fee and

654
00:45:22,530 --> 00:45:30,370
Then what negative what problem was constructed because we created email a couple problems, okay

655
00:45:31,550 --> 00:45:37,150
One big one is you couldn't infer tone or or anything from the email

656
00:45:38,350 --> 00:45:40,830
We also created spam emails

657
00:45:41,470 --> 00:45:47,470
We also created and again, maybe it goes with the first one with we created internet anonymity where

658
00:45:48,110 --> 00:45:53,550
You could be a dick to someone because you're more likely to be a dick to someone because you were you had never met them

659
00:45:53,630 --> 00:45:56,270
You'd have a relationship with them. You're talking to people

660
00:45:56,270 --> 00:46:01,470
You don't know as much now over email because it's free right and and actually even

661
00:46:02,270 --> 00:46:04,030
even

662
00:46:04,030 --> 00:46:11,310
More and some may view this as a positive or negative but even if you just talk of you know, limit it to friends and family

663
00:46:11,950 --> 00:46:13,870
Right. What did you do?

664
00:46:13,870 --> 00:46:17,070
You increase the friction or decrease the friction

665
00:46:18,320 --> 00:46:23,840
For you know grandma to send you you know the chain letter that will save

666
00:46:26,270 --> 00:46:30,270
Even allies would still will send you crap now

667
00:46:31,070 --> 00:46:32,290
right

668
00:46:32,290 --> 00:46:36,210
My uncle I have an uncle that every time his pc dies

669
00:46:37,490 --> 00:46:39,490
And you've encountered this i'm sure

670
00:46:40,050 --> 00:46:44,850
Right. Oh call brent. He works for microsoft. He can be your oh god. Yes

671
00:46:45,810 --> 00:46:51,570
Well before email there's no way he would ever have like sent me a letter asking me for that right?

672
00:46:55,090 --> 00:46:56,690
Automation

673
00:46:56,690 --> 00:46:58,370
reduces friction

674
00:46:58,370 --> 00:47:02,530
It doesn't just reduce friction on the bad things it reduces friction

675
00:47:03,540 --> 00:47:09,620
So the good things become a lot easier to do but the bad things do too

676
00:47:10,180 --> 00:47:15,460
like junk junk mail spam the ability at scale for

677
00:47:16,500 --> 00:47:18,500
the nigerian prince to

678
00:47:19,220 --> 00:47:21,540
Ask you for help, right? Yep

679
00:47:22,260 --> 00:47:27,540
The same thing's gonna happen here and the intellectual lazy are gonna get caught by it

680
00:47:28,020 --> 00:47:31,620
They're gonna get creamed one of the issues is

681
00:47:32,740 --> 00:47:35,540
Okay, so ai can at scale

682
00:47:36,990 --> 00:47:38,990
review let's say

683
00:47:39,470 --> 00:47:41,470
Bug reports, right?

684
00:47:41,470 --> 00:47:43,470
AI can at scale review it

685
00:47:43,970 --> 00:47:46,530
But now you have to review what it reviewed

686
00:47:47,490 --> 00:47:49,410
Right. How do you how do you know?

687
00:47:50,450 --> 00:47:53,650
Because you know enough that it's a generative AI

688
00:47:54,450 --> 00:47:58,050
How do you how do you know it's doing the right thing?

689
00:47:58,530 --> 00:48:02,210
And here's the well, isn't that similar to who tests the tests?

690
00:48:03,170 --> 00:48:04,990
Yeah

691
00:48:04,990 --> 00:48:06,990
Except when it's who tests the tests

692
00:48:08,380 --> 00:48:13,260
Uh in the past it's been a human being that you can kind of go. All right. Well

693
00:48:13,980 --> 00:48:18,780
Karma will eventually hit the tester who wrote a billion bogus test cases

694
00:48:19,500 --> 00:48:21,500
Right. No, I I get what you're saying

695
00:48:22,140 --> 00:48:26,140
AI is skynet happens when we begin trusting the AI for everything

696
00:48:26,620 --> 00:48:33,260
Well, yeah, and if we if we are about to get even more flooded with AI generated content

697
00:48:34,400 --> 00:48:39,600
Right. It's that flood that's going to lead to trust because I just don't have the time to read it. Otherwise

698
00:48:40,860 --> 00:48:44,540
100 million percent. Yep. All right. We should we should cut it there. Yep

699
00:48:45,260 --> 00:48:50,140
That was actually a fun conversation. I got a little bit more passionate about it than I thought I would so super exciting

700
00:48:50,140 --> 00:48:52,540
Thank you. James Whitaker for your contributions today

701
00:48:54,300 --> 00:48:59,580
What was it 197 197? All right. We'll see you next time. I'm Alan. I'm brain

702
00:49:00,750 --> 00:49:01,870
order of law

703
00:49:01,870 --> 00:49:04,220
I'll peter say

