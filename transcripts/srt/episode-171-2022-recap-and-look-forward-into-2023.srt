1
00:00:00,000 --> 00:00:07,600
You and I do not have the mental capacity to combine the number of ideas that this

2
00:00:08,160 --> 00:00:10,640
freaking bot already has done.

3
00:00:14,400 --> 00:00:21,200
Welcome to AV testing podcast, your modern testing podcast. Your hosts, Alan and Brent,

4
00:00:21,200 --> 00:00:26,720
will be here to guide you through topics on testing, leadership, Agile, and anything else

5
00:00:26,720 --> 00:00:32,240
that comes to mind. Now on with the show. Hey, everyone. I am Alan Page and I am here with

6
00:00:32,320 --> 00:00:39,440
my colleague, Jensen. That's right. I don't know what I'm doing. I wasn't expecting the

7
00:00:40,320 --> 00:00:45,920
I wasn't either, but through miracles and miracles, we got Zencaster to work and gets you that three,

8
00:00:45,920 --> 00:00:51,870
two, one. As a risk repeating myself, I'm not going to do on the whole rant I did last time,

9
00:00:51,870 --> 00:00:59,070
but I want to like Zencaster. And I feel like this is what's frustrating is if I start off with

10
00:00:59,070 --> 00:01:05,070
buggy software and it gets better and better, I fall in love with it more. But when you have

11
00:01:05,070 --> 00:01:13,870
software that works and then stops working, it's really annoying, really not or the experience gets

12
00:01:13,870 --> 00:01:19,230
worse. It is frustrating. But anyway, I think we're working. We have a backup going in place.

13
00:01:20,030 --> 00:01:25,230
I have the sounds coming in the right holes and out the right holes. I figure like it's a

14
00:01:25,230 --> 00:01:33,790
good place to do our last A.B. testing podcast of the year 2022 2022. That's the year. Yeah, good job.

15
00:01:33,790 --> 00:01:38,750
Not so do you remember a year ago, like what we're going to do today, the usual end of year,

16
00:01:38,750 --> 00:01:42,750
we're going to reflect on the year a little bit and we're going to look ahead a little bit into

17
00:01:42,750 --> 00:01:48,110
the year. And that's going to take about 40 minutes. I'm sorry to say. So if you don't care

18
00:01:48,110 --> 00:01:54,590
about that, then you can just wait till January for 172. Yes. But, you know, listen on.

19
00:01:55,310 --> 00:02:03,950
Yeah. You do never, never know what you're going to find out. So did you go back and listen to

20
00:02:04,990 --> 00:02:07,070
whatever episode it was, the last one from last year?

21
00:02:08,590 --> 00:02:15,310
No, I do recall that I did a shit job on predictions.

22
00:02:16,370 --> 00:02:24,050
Here's what I did. I did not go back and listen to it. It's like 159 or something.

23
00:02:24,050 --> 00:02:27,650
But here's what I did do. I got to tell you, and you know this, I'm going to repeat it for our

24
00:02:27,650 --> 00:02:35,970
listeners who may have forgotten. So since I left Microsoft, the only Microsoft software I use is

25
00:02:35,970 --> 00:02:44,370
my Xbox and Visual Studio Code. And I think that's it, except for one exception, which I do

26
00:02:44,370 --> 00:02:50,930
once a year. And that is to load. I don't want to bother installing all of Office, but I load up

27
00:02:51,650 --> 00:02:59,810
Word for web, whatever it's called, into my browser. And then I go to the dictation thing and import

28
00:02:59,810 --> 00:03:06,530
and I import the MP3 of the podcast from a year ago, our predictions episode. And I let the

29
00:03:06,530 --> 00:03:13,730
translate function auto translate it from the MP3. Oh, does that do a good job? You're saying we

30
00:03:14,130 --> 00:03:18,770
not a really very good job at all, but close enough. I can give you some context.

31
00:03:19,410 --> 00:03:23,970
You're saying we could have been doing crappy transcriptions forever then, huh?

32
00:03:23,970 --> 00:03:32,690
Yeah, it would just take so much editing to get it right. So I know, and I get there's a,

33
00:03:32,690 --> 00:03:35,730
I didn't highlight, there's a couple of really funny ones in there.

34
00:03:36,610 --> 00:03:40,050
But you can kind of get the gist of it scrolling through pretty quickly. I get much

35
00:03:40,050 --> 00:03:46,770
faster than listening. I can just scroll, blah, blah, blah. But some stuff is surprisingly accurate.

36
00:03:46,770 --> 00:03:50,610
Do you want to, let's, maybe before we go into our predictions from last year,

37
00:03:51,330 --> 00:03:56,930
like how was your 2022? What was it like? What did you get done? Can you remember back to January?

38
00:03:57,490 --> 00:04:00,930
Do, is it all a blur to you like it is for me?

39
00:04:00,930 --> 00:04:08,930
This year was mostly a blur. There's, there's nothing I can look back on.

40
00:04:10,430 --> 00:04:23,230
And go, you had 2022. I guess the only thing would be, would be the D, the partial D COVID occasion

41
00:04:23,230 --> 00:04:32,110
of society. I mean, that was great. I mean, a lot of the news reports coming out now kind of

42
00:04:32,110 --> 00:04:39,630
ticked me off, but the fact that things kind of going back to normal ish ish.

43
00:04:40,510 --> 00:04:47,070
We just had a discussion with some of the leadership for our local office to talk about. We've,

44
00:04:47,070 --> 00:04:50,110
I'm not going to rehash this because we've talked about this a few episodes ago.

45
00:04:50,910 --> 00:04:55,710
How do we get more people to go back to the office? So my, my view on that is changing.

46
00:04:55,710 --> 00:05:00,670
My view on how do we get more people to go back is changing a little bit. It's more of,

47
00:05:01,790 --> 00:05:08,370
why don't we just give up? Why don't we just have a smaller office? I think for a lot of

48
00:05:08,370 --> 00:05:13,330
tech companies, especially in places like here in San Francisco, where, uh, here in a lot of

49
00:05:13,330 --> 00:05:17,970
your breathing there, especially places like here in San Francisco, where people are commuting from

50
00:05:17,970 --> 00:05:22,690
a lot farther away, even for you. How long is your commute from where you live to the Microsoft

51
00:05:22,690 --> 00:05:27,330
office? It'll be between 15 minutes and 30 minutes. Okay. Your system, I thought you're a

52
00:05:27,330 --> 00:05:32,450
little farther north there by make a difference, but you come in pretty early. So mine's about 25

53
00:05:32,450 --> 00:05:36,610
from where I live to downtown Bellevue. I'm good with that. But a lot of people,

54
00:05:37,250 --> 00:05:41,890
especially folks that haven't lived here as long and they just live an hour away.

55
00:05:41,890 --> 00:05:45,490
Cause that's where they can afford to get a house. And it takes a big chunk of commuting time.

56
00:05:45,490 --> 00:05:51,410
I'm kind of wondering at this stage of the pandemic, it's not over by any means,

57
00:05:52,420 --> 00:05:57,300
but we're at a stage where we're just learning and we're getting towards where it's endemic,

58
00:05:57,300 --> 00:06:03,940
I guess, where we're learning to live with it. I never anymore have a time when I don't know

59
00:06:03,940 --> 00:06:08,500
anybody that has COVID like any day of the week, you could ask me, Alan, do you know anybody that

60
00:06:08,500 --> 00:06:12,900
has COVID right now? And I can tell you names of people. That's what it's like. And I don't,

61
00:06:12,900 --> 00:06:18,100
I'm not that social. I don't know a lot of people. I always seem to know people who have COVID.

62
00:06:18,100 --> 00:06:24,980
Yeah. I don't know anyone right now. I mean, I guess we're not taking a poll there.

63
00:06:24,980 --> 00:06:30,420
Well, so anyway, the, the, the point I was going to get to is I think a lot of companies,

64
00:06:30,500 --> 00:06:35,540
I'm not saying my company or Microsoft or any other companies. We should just make co,

65
00:06:35,540 --> 00:06:40,660
like our co-working places, like, which is kind of what our offices are now, just make some smaller

66
00:06:40,660 --> 00:06:48,060
offices. Like my office typically has 30 to 50 people there a day. The office holds 200 to 250.

67
00:06:48,700 --> 00:06:54,060
If we had an office that held 75 or a hundred, it would at least feel like an office. It would

68
00:06:54,060 --> 00:06:58,380
feel like there would be some of that buzz and, and some conversations happening that weren't just

69
00:06:58,380 --> 00:07:07,420
about work. But anyway, uh, 2022 I can share. So on that, on that front, for example, I can share.

70
00:07:08,380 --> 00:07:16,460
So we're here at Microsoft and I don't know if I've shared this, but I am often involved in like

71
00:07:16,460 --> 00:07:24,220
office moves. I'm, I'm particularly good at figuring out who goes where type of thing. I even,

72
00:07:24,700 --> 00:07:30,540
uh, this year I did something I've been doing. I've been wanting to do forever. I actually wrote an AI

73
00:07:31,180 --> 00:07:35,180
to, to do it and figure it out. You had mentioned that before. That's cool.

74
00:07:35,820 --> 00:07:42,560
Now, the thing that is interesting right now is we're, we're in this,

75
00:07:43,200 --> 00:07:53,520
Microsoft officially is in this weird place. We, we are simultaneously do not have enough offices

76
00:07:53,520 --> 00:08:02,080
and have too, too many offices. I can't wait to, I can't wait to hear you explain this. Well, um,

77
00:08:02,080 --> 00:08:10,320
so when you were here, if, if you recall there, there were rules on like space and moves,

78
00:08:11,200 --> 00:08:18,720
right? Seniority rules, for example, if you've been here 80,000 years, you get, you get the

79
00:08:18,720 --> 00:08:25,920
corner office. Exactly. And over years things have changed. Uh, for example, every move that

80
00:08:26,560 --> 00:08:33,440
I've done in the last, I don't know, 10 years, uh, if you're doubled, you get a window office.

81
00:08:33,440 --> 00:08:40,560
If you are a single or a manager or for whatever reason you get your own office, usually that'll

82
00:08:40,560 --> 00:08:45,840
be an inside office, right? They kind of, kind of appeals to a little bit of a balance to make

83
00:08:45,840 --> 00:08:50,480
it work. Gotcha. Right. Right. And of course, Microsoft being one of the only companies where

84
00:08:50,480 --> 00:08:58,100
employees have offices, but go on. And even that's changing. Right. But even in the open space,

85
00:08:58,100 --> 00:09:03,540
right? If you have seniority, then you get, you get the one desk where your back's against the

86
00:09:03,540 --> 00:09:10,500
wall and in a, in a corner next to the window, whatever. Right. So what's going to be right now

87
00:09:11,220 --> 00:09:18,420
is a lot of those rules are still in place. And so there's a lot of people taking up

88
00:09:19,220 --> 00:09:28,340
space because they have seniority who are then not coming in. Aha. And I have a story about that.

89
00:09:28,340 --> 00:09:34,580
Like w w there's a break. Right. And then new hires are automatically being told, sorry,

90
00:09:34,580 --> 00:09:41,620
you will be working from home because there's no space here. Now, weird. I can't imagine that. Okay.

91
00:09:41,620 --> 00:09:48,660
This is weird. That it's a, it's a weird thing. And lastly, someone did some bad scan. Um, you

92
00:09:48,660 --> 00:09:55,620
know, we, you have a, you have to scan a badge and approximately 11% of our populace are coming in

93
00:09:56,500 --> 00:10:04,820
into the actual office. It's all weird. And Microsoft leases a bunch of buildings and,

94
00:10:04,820 --> 00:10:09,700
and found out that we're going to give up the lease on one of the buildings and everyone's

95
00:10:09,700 --> 00:10:15,300
all freaking out where are we going to fit all the people? I'm just like, yeah, you got rules from

96
00:10:15,300 --> 00:10:21,780
1998 that are making it difficult for you to figure out this problem. So for example, one of the,

97
00:10:21,780 --> 00:10:30,420
the things that I did for my manager's recent move, I went to, I, I did a data science way. I said,

98
00:10:30,420 --> 00:10:38,500
okay, based off, I did a poll has bunch of people. Okay. Seriously though, you know, in the next

99
00:10:38,500 --> 00:10:43,460
hundred days, how many times do you think you're going to come in? And they answered honestly,

100
00:10:43,460 --> 00:10:49,860
and I guaranteed that they'll have a desk. And then I rearranged people based off of the

101
00:10:49,860 --> 00:10:54,180
probability that they're going to be in. And so then you could say, all right,

102
00:10:55,230 --> 00:11:01,630
the, the probability this office is going to have at least one person in, in a particular day is

103
00:11:01,630 --> 00:11:10,590
going to be 0.8. Right. Anyway, you take that, you rebalance it and you end up with everybody

104
00:11:10,590 --> 00:11:18,750
being able to be guaranteed a desk, not, not, not having to turn it away. Like if I were to show you

105
00:11:18,750 --> 00:11:28,540
right now, you'll see that even I am, I am currently doubled up with a desk. This is a coworker,

106
00:11:28,540 --> 00:11:34,380
a coworker of mine who comes in maybe once a month. Okay. You know, there's a couple of things I want

107
00:11:34,380 --> 00:11:39,900
to share here. One is just sort of in the regular world, the non-Microsoft world and more open

108
00:11:39,900 --> 00:11:46,100
spaces, the idea of hot desking is just a lot easier. And you know, you were telling me a while

109
00:11:46,180 --> 00:11:51,620
back, maybe even a year ago that Microsoft was moving towards away from desktop workstations

110
00:11:51,620 --> 00:11:55,860
and more towards high-end laptops to work from. Did that ever become a thing?

111
00:11:56,420 --> 00:11:59,220
Hasn't become a thing yet. It hasn't become a thing.

112
00:11:59,220 --> 00:12:03,380
We're, you know, we have of course some parts of our, go ahead, Brent.

113
00:12:03,940 --> 00:12:15,700
It is still so, not only high-end laptops, but an AVD instance, an Azure virtual desktop

114
00:12:15,700 --> 00:12:23,740
instance for everyone as well. So we would all have pretty beefy VMs in the cloud. And that to

115
00:12:23,740 --> 00:12:29,340
me all makes perfect sense. And they announced this, God, nearly a year ago.

116
00:12:29,340 --> 00:12:29,980
Yeah.

117
00:12:29,980 --> 00:12:32,060
I probably should dive in.

118
00:12:32,060 --> 00:12:40,300
The way it works for us is we just have a desk reservation system and all the desks are reservable,

119
00:12:40,300 --> 00:12:46,140
either ongoing permanently or for a one-off. And it's just first come, first serve for the most

120
00:12:46,140 --> 00:12:52,060
case, the few exceptions. And you just reserve your desk, you show up, you plug, there's monitors

121
00:12:52,060 --> 00:12:59,180
there. You plug your laptop in. We have lockers there where I keep my portable Bluetooth

122
00:12:59,180 --> 00:13:06,560
mechanical keyboard and mouse. And yeah, I just sit wherever. But I've been sitting in one seat

123
00:13:07,200 --> 00:13:14,720
regularly now, which is non-reservable because we have, I won't even name any names,

124
00:13:15,360 --> 00:13:23,040
but we have one person who's a senior vice president reports to our CEO who has a permanent desk

125
00:13:23,040 --> 00:13:29,520
in a very nice spot. And I know he never comes to work. So I moved all of his stuff into a file

126
00:13:29,520 --> 00:13:31,120
cabinet. I've been sitting at that desk.

127
00:13:31,120 --> 00:13:31,680
Because I like that.

128
00:13:37,980 --> 00:13:42,380
So I always have a desk that I just work there. And then a lot of times I go in and I'm in,

129
00:13:42,380 --> 00:13:46,220
you know, Zoom meetings all day. But anyway, the laptop works well.

130
00:13:47,740 --> 00:13:52,460
Just as an aside, does the senior VP know you're homesteading his desk?

131
00:13:55,060 --> 00:13:59,860
Maybe. I told him that I may just take his desk over. He didn't say anything

132
00:13:59,860 --> 00:14:05,460
once on a call. He's one of these folks who splits his time between Seattle and California.

133
00:14:05,460 --> 00:14:10,340
And I think he's been mostly on the California side in a while. So yeah, that's where we're at.

134
00:14:10,340 --> 00:14:18,660
So anyway, we talked last year a little about the pandemic and COVID. Do you remember a conversation?

135
00:14:19,300 --> 00:14:21,780
We've had multiple of those conversations.

136
00:14:21,780 --> 00:14:27,060
I'm going to go back to the specific episode 151 and talk about some of our predictions last

137
00:14:27,140 --> 00:14:34,020
year before we begin looking forward to the next year. So one of the things was that I said that

138
00:14:34,020 --> 00:14:39,300
I wasn't planning to go to the office at all in 2022. That ended up changing. I got bored of

139
00:14:39,300 --> 00:14:43,940
working here probably the last three months I've been going to the office two to three times a

140
00:14:43,940 --> 00:14:52,140
week. So I was wrong. You also mentioned that Bill Gates had mentioned that the pandemic would be

141
00:14:52,140 --> 00:14:59,820
over in 2022. And I don't think we dove enough into the definition of air quote over. Like I,

142
00:14:59,820 --> 00:15:05,660
it's not over unless you could say it's a standemic. I don't think we're quite too endemic yet. So

143
00:15:06,220 --> 00:15:13,900
I think it's not over. I think there still is a COVID pandemic. So Bill Gates was wrong.

144
00:15:14,700 --> 00:15:19,420
He was wrong to hire me too. You know, even though it's several levels of indirection, but whatever.

145
00:15:19,420 --> 00:15:28,690
I don't know who has the authority to declare it over, but our president stated it was over

146
00:15:28,690 --> 00:15:37,250
on September 21st of this year. Well, he was wrong. He was wrong. Just, you know, yeah,

147
00:15:37,250 --> 00:15:42,210
he was wrong, but at least he didn't come out with his own line of trading card NFTs

148
00:15:42,850 --> 00:15:49,790
of him dressed as a superhero. Yeah. Who knows what his son's doing.

149
00:15:50,590 --> 00:15:54,910
Yeah. So a year ago, we were talking a little bit about your art. Are you still painting?

150
00:15:55,790 --> 00:16:01,660
No, I haven't. I haven't. So what happened? What happened? Usually you're showing me stuff. Like

151
00:16:01,660 --> 00:16:07,740
what happened to your up and coming painting career? So I'm going to restart it. Actually,

152
00:16:07,740 --> 00:16:12,620
I had a conversation with my daughter when I dropped her off today. There is this cool

153
00:16:14,220 --> 00:16:24,060
online class that costs, I guess, like $400 that I can make Microsoft pay for with that

154
00:16:25,260 --> 00:16:29,260
random benefit that I think came into play when you were still here.

155
00:16:29,260 --> 00:16:33,260
Yeah. Some sort of education benefit. That what it is. Might've happened after I left. It's all

156
00:16:33,260 --> 00:16:44,380
right. No, they took when they changed it such that you had options other than the pro club.

157
00:16:46,080 --> 00:16:51,120
You could sign up for a pro club or you could get X amount of dollars back for whatever the

158
00:16:51,120 --> 00:16:54,320
hell you want. Right. That's what I did. I did that for the last couple of years. So yeah.

159
00:16:54,880 --> 00:17:00,160
Yeah. And at that point in time, the whatever hell you wanted had to be something fitness

160
00:17:00,160 --> 00:17:06,080
related, but they've since changed that and it can kind of be whatever the hell you want.

161
00:17:06,080 --> 00:17:12,000
Oh, that's cool. But yeah, I asked my daughter if that would be something she would want to do

162
00:17:12,800 --> 00:17:17,280
with me. She's like, as long as we're doing it together. And I'm like,

163
00:17:17,280 --> 00:17:23,120
oh, wow. She's about to turn 13 and she still wants to do things with dad.

164
00:17:23,120 --> 00:17:24,720
Yeah. That's nice.

165
00:17:24,720 --> 00:17:33,120
I'm in. He's like, who knows how long that's going to last? So yeah. No, I painted. I painted one thing

166
00:17:34,830 --> 00:17:41,070
this year and I hated how it came out. I never actually finished it and shredded it.

167
00:17:42,030 --> 00:17:48,270
It is one of those things where the nice thing about painting, particularly like oil paints,

168
00:17:49,230 --> 00:17:55,470
you screw something up. It's very like anyone who's watched Bob Ross, right? Happy little

169
00:17:55,470 --> 00:18:05,230
accidents. You could easily fix it. Watercolor, it soaks into the paper and it's a lot

170
00:18:06,300 --> 00:18:12,960
harder to do that. And then when you stare at something and you go, oh, I see mistakes

171
00:18:12,960 --> 00:18:19,440
everywhere as part of my QA training, right? It still sticks with you. You see negativity

172
00:18:19,440 --> 00:18:26,000
everywhere. And then I go, and it's beyond my capability of fixing it. So I can either keep

173
00:18:26,000 --> 00:18:34,720
it here until I find a way to fix it or I'm going to shred it, which is what I did because I'm like,

174
00:18:34,720 --> 00:18:39,920
I can't stand looking at it because it frustrates me. It's broken and I can't fix it.

175
00:18:39,920 --> 00:18:47,220
I'm glad you're getting back into it. Actually, I want to look forward yet. So I want to look back

176
00:18:47,220 --> 00:18:52,740
on our predictions from last year and add some few notes in there. One thing I did in 2020, so

177
00:18:52,740 --> 00:18:57,780
here's weird, something I've done the last six months that everybody else did at the beginning

178
00:18:57,780 --> 00:19:04,500
of the pandemic is I grew my own sourdough starter and have been making sourdough bread.

179
00:19:04,500 --> 00:19:10,180
It's been coming out better every time. Are you still using the, you're using the same

180
00:19:11,620 --> 00:19:18,900
refrigerator? I made my own mother. That's so cool. So it's just, you get the whole wheat flour and

181
00:19:18,900 --> 00:19:23,860
get the pulling yeast from the air, which is generally including at least some yeast from my

182
00:19:23,860 --> 00:19:33,540
body. So it is literally out. It's like made from me. Made with love. So I did that. So we spent

183
00:19:33,540 --> 00:19:40,020
some time last year talking about streaming services and what we've been watching. And

184
00:19:40,580 --> 00:19:46,580
we just, my wife and I just wrapped up watching Wednesday last night and this is where it gets

185
00:19:46,580 --> 00:19:51,300
blur. I can't remember what I watched this year versus last year. I did two years ago. You

186
00:19:51,300 --> 00:19:56,260
recommended what was it with the masked singer, which I still don't like. And I told you that last

187
00:19:56,260 --> 00:20:02,420
year and you said you liked it, but whatever. So I watched the Reacher series on Amazon was

188
00:20:02,420 --> 00:20:09,300
really good this year. I've read all the books and or is, is, I think the best start in my

189
00:20:09,300 --> 00:20:15,700
discussion to have here and, or I think maybe the best star Wars series on Disney.

190
00:20:16,260 --> 00:20:25,620
Now, interesting. I just finished and or I, this week, like I think Tuesday and I was surprised with

191
00:20:25,620 --> 00:20:31,870
the end of the episode, right? I'm like, what? What that or it's season, whether that's the end

192
00:20:31,870 --> 00:20:39,150
of the season, but what's he going to pick? We kind of know. Spoiler. We kind of know by the smile.

193
00:20:41,230 --> 00:20:48,990
What's going to be chosen? I thought I don't know. I don't like I felt that like a good deal of the

194
00:20:50,030 --> 00:21:01,310
Star Wars mythos was, I don't know, neglected. I don't it felt it felt like a like they had taken

195
00:21:01,870 --> 00:21:08,030
a template of some form of similar script and just mapped it to the Star Wars.

196
00:21:09,570 --> 00:21:15,490
I mean, it is kind of maybe that's why I liked it. It was definitely a more mature show.

197
00:21:15,490 --> 00:21:19,090
There's no baby Yoda in this thing. It was dark and serious all the way through.

198
00:21:19,810 --> 00:21:25,010
Maybe Mandalorian Mandalorian. I like Mandalorian. I guess that was last year,

199
00:21:25,010 --> 00:21:33,490
but I like Mandalorian so much more. I mean, the Roku character could get me. Who cares? But

200
00:21:33,490 --> 00:21:40,050
the Mandalorian character, that character was awesome. I know, but it's lighter. And maybe

201
00:21:40,050 --> 00:21:45,330
it's just me and I like the darker stuff. But what else? What else was good this year?

202
00:21:45,330 --> 00:21:51,980
What did you see on the Oh, did you watch the one on Hulu? Do you have Hulu? The one where

203
00:21:52,780 --> 00:21:59,340
I really like it. It's the chef in Chicago, who's like a decorated chef who goes back and it's a

204
00:21:59,340 --> 00:22:07,710
drama, not a reality show restaurant. I the bear, the bear, the bear. That's it. That was really good.

205
00:22:07,710 --> 00:22:18,670
The bear, the bear as in growly thing. Yes. OK. I love cooking themed things of all sorts. I

206
00:22:19,470 --> 00:22:24,030
have not. You should check that out. But you know what? I've been watching this

207
00:22:24,030 --> 00:22:27,870
a show on Netflix called Drink Masters. It's like a food cooking show,

208
00:22:27,870 --> 00:22:36,190
but they're making mixed drinks and it's delicious to watch. I no longer have Netflix and it took

209
00:22:36,190 --> 00:22:43,710
forever. It took forever to finally let go of it. It's not coming back. It's not coming back.

210
00:22:44,270 --> 00:22:48,510
It can stay gone. So did what did Netflix do to hurt you?

211
00:22:49,230 --> 00:22:58,830
It it had it essentially cancelled Iron Fist. That's what finally pissed me off. I'm like, OK.

212
00:22:59,950 --> 00:23:04,510
Well, that wasn't that good of a show. And I had I was a big big Marvel fan.

213
00:23:04,510 --> 00:23:11,230
I had the entire 15 issues of the Iron Fist run. But it's a big Iron Fist fan. That wasn't

214
00:23:11,230 --> 00:23:16,430
a great show. They didn't do a great job with it. They ended it horribly. But I think because

215
00:23:16,430 --> 00:23:21,630
they got cut. Yeah, they said, could we please finish it badly with ten dollars in a piece of

216
00:23:21,630 --> 00:23:29,630
guy. And then with with the main hero having cheap powered guns. What the hell is this?

217
00:23:29,630 --> 00:23:36,270
It got weird. Yeah. So anything else could you be watching? I have watched

218
00:23:37,360 --> 00:23:44,880
everything Marvel on Disney Plus now, like literally everything you go, even like the stupid

219
00:23:44,880 --> 00:23:53,920
like five minute clips about I've watched those two. Yep. I finished about three weeks ago.

220
00:23:54,560 --> 00:24:00,720
I finished. I hadn't watched all of Agents of S.H.I.E.L.D. That is now over.

221
00:24:00,800 --> 00:24:03,760
Yeah, I watched I watched those when they were on network TV.

222
00:24:04,400 --> 00:24:09,440
All right. Like I said, literally everything on Disney Plus Marvel I have seen.

223
00:24:10,480 --> 00:24:13,440
That's a very good series from beginning to end. Lots of fun.

224
00:24:14,160 --> 00:24:20,880
Yeah. Although the agents of S.H.I.E.L.D. series, the last season, this is so weird,

225
00:24:20,880 --> 00:24:24,910
but it was clear they were just trying to tie things up 100 percent.

226
00:24:25,550 --> 00:24:33,950
Similarly, I have H.B.L. Maxx, so I'm similarly almost through the D.C. stuff.

227
00:24:34,750 --> 00:24:41,070
I have tried to get into like the Teen Titans in those series on there and I just can't.

228
00:24:41,920 --> 00:24:48,500
Oh, Titans, I've gotten through. Oh, oh, and the episode one of series four,

229
00:24:49,620 --> 00:24:53,780
a season four of Doom Patrol came out this week.

230
00:24:54,500 --> 00:24:56,420
I haven't tried watching Doom Patrol yet.

231
00:24:57,460 --> 00:25:00,740
If you haven't watched Doom Patrol, oh, my God, it is.

232
00:25:01,380 --> 00:25:06,260
It is in my view, it is absolutely the best thing D.C. has made ever.

233
00:25:06,900 --> 00:25:07,940
Well, it's not a high bar.

234
00:25:08,740 --> 00:25:11,220
Flash is pretty good. The C.W. Flash.

235
00:25:11,940 --> 00:25:14,740
Yeah, that was good. I did watch a season of that.

236
00:25:15,380 --> 00:25:21,540
It's kind of like I don't know if because my childhood was 98 percent Marvel and two percent D.C.,

237
00:25:21,540 --> 00:25:28,350
that's kind of what my it's hard for me to get into the D.C. shows, but I'll give it a shot.

238
00:25:28,350 --> 00:25:30,350
I'm going to put Doom Patrol on my list.

239
00:25:30,350 --> 00:25:34,990
Doom Patrol is way better than Masked Singer.

240
00:25:36,190 --> 00:25:37,550
I got it again.

241
00:25:37,550 --> 00:25:38,110
Low bar.

242
00:25:38,510 --> 00:25:47,550
And then the other one I am up to date on is The Boys on Amazon.

243
00:25:47,550 --> 00:25:50,030
Yeah, I couldn't I did not like that at all.

244
00:25:50,030 --> 00:25:53,710
I and actually I was just going to get mad at you for recommending it,

245
00:25:53,710 --> 00:25:59,070
but I see other people say they think it's awesome, but I just it didn't click for me at all.

246
00:25:59,630 --> 00:26:02,830
Uh, maybe maybe you just didn't get through enough of it.

247
00:26:03,390 --> 00:26:06,270
All right. Well, maybe I'll try it again.

248
00:26:06,270 --> 00:26:07,790
I'm going to put it here.

249
00:26:07,790 --> 00:26:09,550
I may give it a shot again sometime.

250
00:26:09,550 --> 00:26:12,670
I have a whole crap ton of work to do, but I have those weeks off.

251
00:26:12,670 --> 00:26:13,710
Maybe I'll do some streaming.

252
00:26:13,710 --> 00:26:14,350
Check those out.

253
00:26:15,230 --> 00:26:20,190
So anything else from the streaming world worth mentioning for our fans who want to get that?

254
00:26:20,190 --> 00:26:22,190
We don't have fans, people that tolerate us.

255
00:26:22,990 --> 00:26:27,710
Speaking of people that tolerate us without looking, I would like you to guess

256
00:26:28,270 --> 00:26:33,390
how many people were in our Slack group a year ago versus today.

257
00:26:34,190 --> 00:26:36,110
This is one of the three dot slack dot com.

258
00:26:36,190 --> 00:26:39,710
You can go to modern testing dot org, click on the link and join.

259
00:26:39,710 --> 00:26:42,270
Sometimes it comes back and says the link is invalid.

260
00:26:42,270 --> 00:26:44,350
Just try it again because it just does that.

261
00:26:44,350 --> 00:26:45,230
It's a slack thing.

262
00:26:46,060 --> 00:26:55,660
I am going to guess last year around 500 and this year around the thousand.

263
00:26:56,900 --> 00:27:00,720
Well, you're wrong on both sides.

264
00:27:00,720 --> 00:27:02,560
So we didn't grow a lot this year.

265
00:27:02,640 --> 00:27:09,920
Last year we had 742 members of our wonderful Slack community, which is it's vibrant.

266
00:27:09,920 --> 00:27:12,480
People ask questions about modern tests.

267
00:27:12,480 --> 00:27:14,560
It's not like Brent and I have to go answering.

268
00:27:14,560 --> 00:27:19,840
People just talk about stuff and some great conversations, some simulations of chat,

269
00:27:19,840 --> 00:27:22,640
GPT, having an ABI testing podcast, which are kind of hilarious.

270
00:27:22,880 --> 00:27:24,800
Yeah, we added.

271
00:27:24,800 --> 00:27:33,200
We added 122 members to our Slack over the last year, which is all right.

272
00:27:33,200 --> 00:27:36,160
So it was from 742 to 864.

273
00:27:36,720 --> 00:27:42,720
If we do another hundred and I mean, we're on that pace, ramped up a little bit.

274
00:27:42,720 --> 00:27:47,410
We should finally get to a thousand next year, which is a peer vanity metric.

275
00:27:47,410 --> 00:27:51,570
But well, it means nothing on our way to a million.

276
00:27:51,570 --> 00:27:53,090
It's not like we don't have hypothesis.

277
00:27:53,090 --> 00:27:58,450
Brent, I think if we talk about the boys on the podcast, we'll add 10 more people to our Slack

278
00:27:58,450 --> 00:28:02,770
community. We should have a channel because channels are free in Slack.

279
00:28:02,770 --> 00:28:07,410
Why don't we have a channel in our Slack to discuss what is good on streaming television?

280
00:28:08,300 --> 00:28:09,340
Why does that not exist?

281
00:28:09,980 --> 00:28:11,660
That's a very good point.

282
00:28:11,660 --> 00:28:12,620
Somebody will do it now.

283
00:28:12,620 --> 00:28:13,020
Thank you.

284
00:28:13,020 --> 00:28:14,380
Thank you. Whoever created that channel.

285
00:28:15,020 --> 00:28:18,460
Please invite me and I will put links to everything I've watched.

286
00:28:19,100 --> 00:28:22,860
Why doesn't Netflix give me a year interview recap like Spotify?

287
00:28:23,660 --> 00:28:33,500
Why can it not tell me where I binged my time or same thing for Peacock or Hulu or Paramount Plus or

288
00:28:33,500 --> 00:28:34,780
oh, Ted Lasso.

289
00:28:34,780 --> 00:28:37,420
Ted Lasso also very good if you have Apple TV Plus.

290
00:28:37,420 --> 00:28:42,140
Oh, you probably don't have Apple TV because Microsoft ignores the existence of a company

291
00:28:42,140 --> 00:28:47,580
called Apple. Apple TV has a show called Severance, which is utterly fantastic.

292
00:28:47,580 --> 00:28:49,100
Maybe the best thing I watched this year.

293
00:28:49,660 --> 00:28:52,540
It's a show. Let me give you the premise of this show just for you.

294
00:28:52,540 --> 00:28:57,900
Everybody else has seen it, Brent, but I will tell you literally everyone else has seen it

295
00:28:57,900 --> 00:29:01,500
except for Microsoft employees because they don't believe in Apple because ever since

296
00:29:01,500 --> 00:29:05,500
bomber smashed that phone, it's like it's like it's erased from the brain.

297
00:29:05,500 --> 00:29:13,470
Anyway, the premise of the show is this idea that your work life and your home life are

298
00:29:13,470 --> 00:29:19,470
severed, meaning when you're at work, you have no recollection of who you are in the real world.

299
00:29:19,470 --> 00:29:23,230
And then when you leave work, you have no idea what you do for a living.

300
00:29:23,230 --> 00:29:24,830
Just just just know where you work.

301
00:29:25,390 --> 00:29:27,870
Oh, that would be so.

302
00:29:27,870 --> 00:29:32,670
And the moral implications of such an arrangement and ethical.

303
00:29:32,670 --> 00:29:37,710
And then what happened to someone decides they let me give you one little gist of a thing.

304
00:29:37,710 --> 00:29:39,230
Doesn't give anything away. No spoilers.

305
00:29:39,230 --> 00:29:43,230
What would happen if someone at work decided, you know what?

306
00:29:43,230 --> 00:29:45,230
I don't like this anymore. I don't want to do it.

307
00:29:46,110 --> 00:29:49,630
And then they tell their boss that in their bosses, okay, let's talk about it tomorrow.

308
00:29:49,630 --> 00:29:50,910
And they come talk about it tomorrow.

309
00:29:50,910 --> 00:29:57,230
And there's a recording of the home person of that home version of that person,

310
00:29:57,230 --> 00:30:01,630
meaning themselves and they left work saying, no matter what, I do not want to quit.

311
00:30:01,630 --> 00:30:05,150
I'm staying in this position. So you're arguing with yourself.

312
00:30:05,150 --> 00:30:06,990
Yeah, no, I was from two different lives.

313
00:30:07,630 --> 00:30:10,110
I was seeing all sorts of.

314
00:30:11,070 --> 00:30:17,710
Right. You could be a PI in your job and be hired to investigate yourself.

315
00:30:18,620 --> 00:30:20,940
I know it really good. Really good. You should watch it.

316
00:30:21,710 --> 00:30:27,150
You just get like, I'm sure it may be pirated somewhere or yourself like a trial of Apple TV

317
00:30:27,150 --> 00:30:30,670
to watch that. You could like binge that and Ted Lasso and have a wonderful week.

318
00:30:31,710 --> 00:30:35,470
Okay. The last thing you said that I recalled from the translated notes,

319
00:30:36,510 --> 00:30:41,470
which I would like you to expand on, then we can look forward to 2023 a bit is you said,

320
00:30:42,030 --> 00:30:45,470
which I think is true, but I want you to talk about it.

321
00:30:46,270 --> 00:30:49,950
Modern testing principles will safely die to some degree.

322
00:30:50,670 --> 00:30:54,030
Well, safely. Wow. That was generic.

323
00:30:55,550 --> 00:30:57,950
That's how you get the I said it was right. It didn't say it was good.

324
00:30:59,470 --> 00:31:05,090
Yeah, it's. That's weird, because in some angles,

325
00:31:05,090 --> 00:31:13,700
it's it's it's hotter. Well, it's no longer a fad topic, I would say, like when when we came out

326
00:31:13,700 --> 00:31:21,060
with it, right, it was a bunch of people. I don't get a lot of people arguing against it with

327
00:31:21,060 --> 00:31:27,060
white knuckles like we used to. Yeah. And also the point to bring up was again to talk about

328
00:31:27,060 --> 00:31:33,780
what's the next evolution of those that isn't just tester focused. So that way they empty

329
00:31:33,780 --> 00:31:39,540
principles are dead. Long live empty. And we got to a point where said modern testing is about testing

330
00:31:39,540 --> 00:31:47,870
and it is modern. Right. Right. In terms of like the A.B. testing, which is interesting because we've

331
00:31:47,870 --> 00:31:54,830
had a few of our if we had a few of our listeners go, please, please don't go down that route around

332
00:31:56,110 --> 00:32:03,390
user studies and A.B. testing. I did a I just like the rest of human society.

333
00:32:03,470 --> 00:32:15,150
I I am been fascinated with chat GPT as as a knowledge, a knowledge graph, a knowledge mining tool

334
00:32:15,870 --> 00:32:23,520
along these lines. I asked it. I asked it two questions today, and I didn't save the other one,

335
00:32:24,540 --> 00:32:29,580
which was more relevant. You know who Christopher Alexander is? Of course you do.

336
00:32:29,580 --> 00:32:37,490
Of course I do. Yeah. And I asked chat B.T. to describe software quality in the spirit

337
00:32:37,490 --> 00:32:45,490
of Christopher Alexander. I also asked it in the spirit of James Bach. Oh, God.

338
00:32:46,050 --> 00:32:52,930
Does it know who James Bach is? It does. That's cool. And I didn't pace the James Bach one,

339
00:32:52,930 --> 00:32:58,690
but obviously you would read it and go, yeah, it did an excellent job doing that. Right.

340
00:32:59,650 --> 00:33:05,570
What I find fascinating, though, is combining Christopher Alexander did not talk about software

341
00:33:05,570 --> 00:33:13,920
quality at all. Right. Right. He talked about quality directly. Not directly. He talked about

342
00:33:13,920 --> 00:33:23,920
quality and design patterns invented by him were for the express purpose of delivering quality.

343
00:33:23,920 --> 00:33:30,000
And and I thought it did a very good job at this as well. Right. The very first concept,

344
00:33:30,720 --> 00:33:37,040
it is a holistic concept that considers the overall functionality, usability and value of

345
00:33:37,040 --> 00:33:44,580
the software, as well as how it fits into the larger system. That phrase or something like

346
00:33:44,580 --> 00:33:52,260
that wasn't in the chat GPT's expression around James. And if I've read Christopher Alexander,

347
00:33:52,340 --> 00:33:57,940
I'm like, yeah, that's totally him. Right. And then it continued on talking about

348
00:33:58,770 --> 00:34:05,570
the user and the well-being and satisfaction of the person using it. Right. And I'm just like, okay,

349
00:34:06,370 --> 00:34:12,850
this right. Clearly, I go back, winding it back to modern testing principles. I go back and I think

350
00:34:12,850 --> 00:34:22,450
about what was in my mind. And it's it's more of that that point of view that Christopher Alexander

351
00:34:23,250 --> 00:34:32,050
or Weinberg or a myriad of people that that we have talked to and talked about on the show.

352
00:34:32,050 --> 00:34:41,330
And it's it's around the human and how the human is going to to use the thing to bring

353
00:34:42,450 --> 00:34:49,090
to make their life better, easier, stronger, faster, whatever. I completely forgot why,

354
00:34:49,090 --> 00:34:54,450
how I got on this tangent. Nobody knows. Yeah.

355
00:34:55,090 --> 00:35:02,370
So we were going to talk about modern testing principles dying or not dying. Oh, we got here.

356
00:35:02,370 --> 00:35:08,050
So wrap this up. So we have to start making predictions. Yeah. Yeah. I think in some regards,

357
00:35:08,930 --> 00:35:17,250
I'm going to say it is in its it's in its midlife. It's no longer bored and exciting, but it's it's

358
00:35:17,250 --> 00:35:23,410
not dead yet. It kind of, you know, kind of like you and me. It just is around. Yeah. So speaking

359
00:35:23,410 --> 00:35:28,290
of not dead before we go on to predictions. And this is kind of again, another snapshot of the

360
00:35:28,290 --> 00:35:34,850
world. I was thumbing through my RSS feeds. There was a time when I caught up on my RSS feeds

361
00:35:34,850 --> 00:35:38,850
every day. Now it's every couple of weeks I go see what do people write about? So I quickly go

362
00:35:38,850 --> 00:35:43,840
through and I saw someone somewhere say something around. What do I it was one of these like Cora

363
00:35:43,840 --> 00:35:50,880
type posts. What do I do as a tester? What do I do when a manager asked me why I didn't find a bug?

364
00:35:51,440 --> 00:35:56,960
So today I tweeted, what do I do when management asks a tester? Why didn't you find this bug?

365
00:35:57,790 --> 00:36:01,950
And my answer, of course, is first thing is that I get back in my time machine and get the fuck

366
00:36:02,030 --> 00:36:08,510
out of 1997. And then of course, there's going to be a few people who say things like,

367
00:36:09,230 --> 00:36:17,070
this seems like a legitimate question for management to ask. No, it's just this idea of, I mean, it's

368
00:36:17,070 --> 00:36:23,870
a good, it's a, to me, it's a straw man argument that I mean, I, I think largely it's a straw man,

369
00:36:23,870 --> 00:36:29,870
because most companies don't function like that. How can that be largely a straw man?

370
00:36:29,870 --> 00:36:35,070
And it's blatantly a strong man. I, well, I would say blatantly a straw man, except for,

371
00:36:35,070 --> 00:36:41,070
I'm guessing that some places blaming testers for bugs in the wild is still the way they operate.

372
00:36:41,710 --> 00:36:48,820
I think it's completely idiotic. I think it's the fact that someone, anyway, I'm just, oh, Lord.

373
00:36:49,460 --> 00:36:54,100
So anyway, there's a little bit of a reference to the future. Let's talk about the future

374
00:36:54,100 --> 00:36:58,420
where I already talked about the fact we're going to get to a thousand people in our slack

375
00:36:58,420 --> 00:37:02,960
group. At some point it's going to snowball. No more in trouble. The other thing you almost got

376
00:37:02,960 --> 00:37:11,520
right was I asked you what would be the last episode of 2023, 2022. And you said 170 and this

377
00:37:11,520 --> 00:37:20,240
is one, two, three, four, five, 171. So you're off by one. Sorry, man. And we'll probably get to some,

378
00:37:21,120 --> 00:37:27,040
we'll probably get to one 90, one 90, one 91 next year, one 92 somewhere in there.

379
00:37:27,520 --> 00:37:34,240
I'm predicting one 92. Okay. I say one 91 and I have control over that. So I'm probably going to

380
00:37:34,240 --> 00:37:39,920
win, which means here's the good news is that we're going to get to 200 in 2024.

381
00:37:40,960 --> 00:37:47,920
If we both live that long, but we predicted that. And we did, we did. Okay. So what else is going

382
00:37:47,920 --> 00:37:57,150
to happen in 2023? I wrote down two things in 2023 for sure. Do you want to share those things?

383
00:37:57,790 --> 00:38:03,870
Oh, and we didn't, we didn't talk. Uh, what was your favorite episode this last year?

384
00:38:04,750 --> 00:38:17,330
Oh, I don't know. According to Spotify, uh, 155. The, when we had, uh, Anne Marie on for.

385
00:38:17,330 --> 00:38:21,490
Oh yeah. That was fun. And she's popular. She's more popular than us. So

386
00:38:21,490 --> 00:38:28,450
she brought in some listeners for us. Gotcha. Mine was, uh, was, was the one with Al. Um,

387
00:38:28,450 --> 00:38:32,690
cause you like Al. Well, it's so weird to think that was this year.

388
00:38:33,570 --> 00:38:41,170
It was, it was January 10th. So it was barely this year. And we have, I'm not gonna, I'm not

389
00:38:41,170 --> 00:38:47,170
gonna, just gonna hint at it. Our first recording of 2023, we have a guest who is going to be

390
00:38:47,250 --> 00:38:55,120
fantastic. Awesome. That's my prediction. All right. My prediction. Number one,

391
00:38:55,120 --> 00:39:01,280
hybrid will finally actually work. They're about hybrid work or hybrid cars. Hybrid work.

392
00:39:02,400 --> 00:39:10,610
Hybrid cars. I don't know. Okay. Hybrid work. Um, again, can you, do you want to define

393
00:39:10,610 --> 00:39:15,250
work a little bit? I think like anything works with the right air quotes around it.

394
00:39:15,650 --> 00:39:20,690
Ah, yeah, that's true. Cause you're going to hold this against me next year. So I better be more

395
00:39:20,690 --> 00:39:32,450
specific. I think the, the, the creativity of humanity and or the knowledge of, of chat GPT

396
00:39:32,450 --> 00:39:43,710
will work together to come up with a solution for dealing with individual as well as corporate

397
00:39:44,590 --> 00:39:56,050
preferences, right? The, hopefully with, well, we'll see. Never. I will never underestimate the

398
00:39:56,050 --> 00:40:03,890
power of short sighted thinking. Um, so that will certainly throw a wrench in it. Uh, the,

399
00:40:03,970 --> 00:40:16,750
the prediction I am absolutely the most confident in is GPT three, which is the AI basis for things

400
00:40:16,750 --> 00:40:32,620
like chat GPT will be the fastest service online ever in humanity to bring in 1 billion revenue.

401
00:40:33,340 --> 00:40:36,940
What's the revenue model? Uh, I don't even think they have one right now.

402
00:40:38,030 --> 00:40:45,330
I want to ask chat GPT, what is the revenue model for GPT three? Okay. Well, that'll be that,

403
00:40:45,330 --> 00:40:52,690
that one is good. I dig that one. Oh, I think, I think they'll go from zero to a billion next

404
00:40:52,690 --> 00:41:00,050
year and it'll be the fastest service ever in humanity's lifetime to do that. And once that is

405
00:41:00,050 --> 00:41:07,730
done, uh, bets are off. All predictions are off because that is a massive accelerant.

406
00:41:07,730 --> 00:41:10,290
So do you think it's through, I want to talk about this a little bit. Is it just,

407
00:41:10,930 --> 00:41:17,220
you know, microtransactions on API calls to use that to solve all the myriad of problems?

408
00:41:17,220 --> 00:41:21,380
Cause I would, that would be useful. Yeah. Yeah. That's exactly what I think it'll be.

409
00:41:21,380 --> 00:41:25,620
Yep. Okay. That's what I would do if I was them, I would, again, for the hobbyist,

410
00:41:25,620 --> 00:41:31,730
it would be nothing pennies to play with it. And for a corporation wanting to, like,

411
00:41:31,730 --> 00:41:38,690
we can go back and look at this whole thing of 15 years ago, target using data science,

412
00:41:38,690 --> 00:41:44,370
air quotes to predict, uh, to know based on what somebody was buying if they were pregnant.

413
00:41:45,420 --> 00:41:49,580
Now this is accelerating that this is accelerating things like that,

414
00:41:50,380 --> 00:41:55,820
even for companies, cause it's natural language based NLP as Brett likes to put it.

415
00:41:56,540 --> 00:42:03,340
This makes data science like that accessible for any company. There's some API calls and your prediction

416
00:42:03,340 --> 00:42:09,900
from three years ago, where you're saying that data science as a role or discipline is going away

417
00:42:09,900 --> 00:42:18,620
become accelerated potentially by GPT three. Oh, uh, yeah. Yeah. Like my, my team focuses on

418
00:42:18,620 --> 00:42:25,660
natural language processing. And I'm like, okay, maybe I need to lead the way here and guide my

419
00:42:25,660 --> 00:42:32,380
team away from that and start being one of the first to actually, you know, make the calls into

420
00:42:33,420 --> 00:42:40,620
GPT three. Matter of fact, just before our podcast started, um, uh, one of my peers set up a,

421
00:42:41,660 --> 00:42:49,340
a meeting in the new year to, to, to discuss GPT three and, uh, a system my team owns

422
00:42:49,340 --> 00:42:55,500
code named wayfinder. So I'm just thinking through this. And I think if you, you are

423
00:42:55,500 --> 00:43:05,340
hauntingly going to be correct on this because you, as it is today, uh, GPT has its learning model

424
00:43:05,340 --> 00:43:15,040
is based on your login and what you've entered. So if you could have a learning model in a service,

425
00:43:15,040 --> 00:43:22,720
you say based on the data, these thousand transactions, what is the next step for block?

426
00:43:22,720 --> 00:43:27,920
I mean, it could fricking do that. It could, it could be decision. There's the creativity involved,

427
00:43:27,920 --> 00:43:32,880
which talk about last time, but the decision matrix is yeah, I'm, I'm on board with that.

428
00:43:32,880 --> 00:43:41,280
I support that prediction. So I have taken GPT three or chat GPT, like one of our threads on,

429
00:43:41,280 --> 00:43:48,640
on our Slack channel where you talk about the modern testing principles version two and

430
00:43:49,280 --> 00:43:58,480
a whole bunch of the three came in and commented. Yep. They did. They did. I, uh, did not read all

431
00:43:58,480 --> 00:44:06,510
of those comments. It was a very long reply chain, but I did copy and paste it into chat B,

432
00:44:06,510 --> 00:44:15,070
GPT three and said, generate rewrite the modern testing principles in a way that makes everyone happy.

433
00:44:19,310 --> 00:44:22,670
Would you like to hear them? One million percent? Yes.

434
00:44:24,500 --> 00:44:30,020
Number one, our priority is improving the business. It did not change that one. Nobody's mad.

435
00:44:30,020 --> 00:44:37,540
Number two, we identify, prioritize and mitigate bottlenecks in the system to accelerate the team.

436
00:44:38,640 --> 00:44:43,310
Okay. All right. One of the, that took the feedback. It took the feedback for those

437
00:44:43,310 --> 00:44:46,590
you're not in the Slack channel. Some people did not like, thought it was too

438
00:44:47,150 --> 00:44:50,750
prescriptive to mention theory of constraints and things like that. So,

439
00:44:51,230 --> 00:44:57,390
well, and the other thing too was someone also said they didn't like that accelerate was removed

440
00:44:57,390 --> 00:45:03,870
in V2. Number three, we are a force for continuous improvement and adapt and optimize

441
00:45:03,870 --> 00:45:11,100
our practices to succeed. To me, that feels kind of vague and hand wavy, but it's still got the,

442
00:45:11,740 --> 00:45:19,180
the right thing across. Number four, we care about the skills and professionalism of our team

443
00:45:19,180 --> 00:45:24,140
and work to foster a culture of excellence. That's better than what we wrote.

444
00:45:28,510 --> 00:45:35,550
Number five, I kind of don't know the controversial, but not controversial. Number five.

445
00:45:35,550 --> 00:45:41,310
Well, and, but it did exactly what I asked. Number five, the customer five deleted.

446
00:45:42,030 --> 00:45:47,810
Nope. The customer is the ultimate judge of the quality of our product.

447
00:45:48,930 --> 00:45:52,210
That's actually not horrible, not a horrible reinterpretation.

448
00:45:52,210 --> 00:45:58,370
It's correct, but, and it's written in a way that no one would disagree, but it did so.

449
00:45:58,370 --> 00:46:03,010
No, but you're right. It softened it where we see the only one capable,

450
00:46:03,890 --> 00:46:07,490
meaning stop pretending like you're the customer. And I told you,

451
00:46:07,490 --> 00:46:12,210
I read Melissa Perry's book on, which is freaking excellent called the build trap on

452
00:46:12,770 --> 00:46:17,490
outcome driven software development. And she talks about product manager,

453
00:46:17,490 --> 00:46:21,090
product management saying some product managers say they are the voice of quality,

454
00:46:21,860 --> 00:46:26,260
which is, which is kind of funny from the, because testers always say we're the voice of quality,

455
00:46:26,260 --> 00:46:30,580
but she follows it up and says that, but we're not used to use the fricking data.

456
00:46:31,300 --> 00:46:36,770
All right. Number six. It did not change. Number six at all. Okay.

457
00:46:36,850 --> 00:46:41,090
I guess data extensively to deeply understand customer usage, then close the gap between

458
00:46:41,090 --> 00:46:45,730
product hypothesis and business impact. Apparently I wrote that one like a robot.

459
00:46:46,370 --> 00:46:50,690
Now it did change. Number seven. It's still expected. It was because that one,

460
00:46:50,690 --> 00:46:59,010
that one makes people mad too. Okay. We strive to expand abilities and knowledge across the team,

461
00:46:59,010 --> 00:47:07,650
aiming to eliminate dependency on specialists and consciously choosing specialties that the team

462
00:47:07,650 --> 00:47:14,450
can consume as a service when necessary. Oh, cause that was in the discussion. I forget. I don't

463
00:47:14,450 --> 00:47:21,250
know about that, but I mean, I get it. I get the, I get the origin story of these updated things

464
00:47:21,250 --> 00:47:24,210
and probably the ones that didn't change because nobody argued about them.

465
00:47:24,770 --> 00:47:29,970
If I would have put in that thread, but nobody mentioned lemon pie, lemon pie would show up in

466
00:47:29,970 --> 00:47:37,730
one of these things. We should, but now, now think of, this is a, I mean, it was a lot of comments,

467
00:47:37,730 --> 00:47:44,700
but, but think of applying this across a much larger sample set. Boy, it's like I said last

468
00:47:44,700 --> 00:47:49,260
week, there are creative things I do. And I don't think very much of my job can be automated,

469
00:47:49,340 --> 00:47:56,220
automated away by chat GPT, but also maybe it can, maybe there are some things like leadership

470
00:47:56,220 --> 00:48:00,540
principles and things I think about around alignment that I could get written better as

471
00:48:00,540 --> 00:48:08,140
a result of some, some discussion. No, it's so here is the thing, right? Where do ideas come from?

472
00:48:08,140 --> 00:48:16,700
It come from old ideas getting together, right? You and I do not have the mental capacity

473
00:48:16,700 --> 00:48:24,780
to combine the number of ideas that this freaking bot already has done. There are some very common

474
00:48:24,780 --> 00:48:29,580
detractors of modern testing principles. I'm wondering if I could, if I could get,

475
00:48:29,580 --> 00:48:33,260
if I could get this thing to rewrite it in the style of our detractors.

476
00:48:34,940 --> 00:48:40,380
And I think my prediction also is we will eventually have an episode of AB testing in

477
00:48:40,380 --> 00:48:46,220
2023 where chat GPT or GPT three do not, but worth it for today.

478
00:48:46,220 --> 00:48:47,660
Maybe towards the end of next year.

479
00:48:48,300 --> 00:48:51,900
My predictions are not for 2023. I do have a prediction for this weekend.

480
00:48:52,540 --> 00:48:59,040
I believe that Argentina will beat France on Sunday in the World Cup final.

481
00:49:00,080 --> 00:49:04,800
That's what I got. I don't think I had time to think of very many other ones.

482
00:49:05,600 --> 00:49:10,320
We will see. I'll see if I can write some into the show notes of it. They can be before

483
00:49:10,320 --> 00:49:14,000
the weekend, but it was fun to look back. Fun to look forward a little bit.

484
00:49:15,040 --> 00:49:18,960
We will see what happens. I'm looking forward to, we're both kind of in that

485
00:49:19,600 --> 00:49:23,840
20 ish episodes for 2023. That seems like a good pace. That means we go every other week,

486
00:49:23,840 --> 00:49:29,760
skip a few, make it all work out. Every year I predict all get the guts to act,

487
00:49:29,760 --> 00:49:34,400
get Nicole forage going to come onto the podcast. So maybe I'll just throw that one out there again.

488
00:49:34,400 --> 00:49:39,200
That may happen, may not. We will continue to do guests from time to time.

489
00:49:39,920 --> 00:49:43,760
That's all I got. I'm excited about the GPT three stuff. We'll make that happen.

490
00:49:43,760 --> 00:49:46,720
So anything else from you, Brent Meister?

491
00:49:46,720 --> 00:49:49,600
No. Happy holidays, everyone.

492
00:49:49,600 --> 00:49:53,600
Yeah. Happy holidays. Have a good new year. We'll see you in January 2023 with a new

493
00:49:53,600 --> 00:49:56,000
episode sometime. I'm Alan. I'm Brett.

494
00:49:56,640 --> 00:49:59,600
And we'll see you next time on the AB testing podcast.

