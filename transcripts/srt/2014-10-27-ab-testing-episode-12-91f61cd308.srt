1
00:00:15,280 --> 00:00:21,280
Hey everyone. Hello. Hey, I'm Alan. I'm Brent and we're back for episode 12 of AB testing.

2
00:00:21,280 --> 00:00:25,520
We're almost getting to the point where I'm going to be or not be able to keep track.

3
00:00:25,520 --> 00:00:29,600
All right, Brent, stop pounding on the table and get your face in the microphone. That's all I ask.

4
00:00:29,600 --> 00:00:36,340
Testing. All right, great. Yeah. Hey, I think we, we get a lot of flack, but I'm getting some flack

5
00:00:36,340 --> 00:00:39,540
about us talking about our three listeners. Apparently we have more. We don't know how

6
00:00:39,540 --> 00:00:43,620
many more, but you know, we have listeners in Australia. Somebody said, Hey, you have listeners

7
00:00:43,700 --> 00:00:51,540
here. So I think we may have more than we think for, including your God. Okay. The indirect advice

8
00:00:51,540 --> 00:00:58,100
I got was to stop making references to our, our low listener count. Maybe someone might feel like,

9
00:00:58,100 --> 00:01:02,500
well, if there's only three, maybe I'm too many and maybe there's something wrong. I'm not noticing

10
00:01:02,500 --> 00:01:08,020
with what the, I've been thinking through like marketing plans for us and to get t-shirts.

11
00:01:08,020 --> 00:01:12,500
I'm one of the three and things like that. I don't know if I approve of that advice.

12
00:01:12,500 --> 00:01:22,240
All right. Whatever. Okay. Hey. Caps, mugs, watches. Yeah. Great. Doggy vests.

13
00:01:23,040 --> 00:01:28,240
Sure. Absolutely. We can branch out. So last week talked about interviews and some

14
00:01:28,240 --> 00:01:33,280
junk going on there and then, kablamo, we get mail this week saying, Hey, we're changing the

15
00:01:33,280 --> 00:01:38,880
way we're moving jobs at Microsoft. We're not going to make it. I'm not going to totally

16
00:01:38,880 --> 00:01:43,600
leak the mail, which I'm sure is already posted on several news sites, but basically it said that

17
00:01:43,600 --> 00:01:49,760
moving between jobs at Microsoft is a lot easier. You don't have to be in job as long as let's

18
00:01:49,760 --> 00:01:54,080
let people find out, you know, figure out where they can have the biggest impact,

19
00:01:54,080 --> 00:02:00,900
which I think is great. The thing missing from the mail I thought was we still, I mentioned

20
00:02:00,900 --> 00:02:05,060
this last week, we still at Microsoft, the one flaw we have in our internal interviews left is

21
00:02:05,140 --> 00:02:10,420
that we still put people through basically the same interview they had to go through to get hired

22
00:02:10,420 --> 00:02:15,780
at Microsoft. And my assumption is we've hired them once. If we want to bring them to their team,

23
00:02:15,780 --> 00:02:20,740
they've done pretty well. I want to primarily interview them for, I want to know how they're

24
00:02:20,740 --> 00:02:26,350
going to work with others, how they're going to fit on the team. And to do that, I can talk to

25
00:02:26,350 --> 00:02:32,910
them, but, and I'll get some good information there. So I can, I can get some good behavioral

26
00:02:32,910 --> 00:02:39,150
ideas, but I really, really want to heavily rely on peer feedback and we don't have a great system

27
00:02:39,150 --> 00:02:45,180
for peer feedback. There was, so you mentioned there, I'm going to, I'm going to rewind just a

28
00:02:45,180 --> 00:02:49,420
second. Cause you mentioned that there was just one thing that you saw missing and that's actually

29
00:02:49,420 --> 00:02:54,380
the logistics around the interview process. There was one other thing missing. We'll see if it's

30
00:02:54,380 --> 00:03:02,670
as big as mine, but yeah, another one, um, that I saw missing is it didn't seem to address.

31
00:03:02,670 --> 00:03:10,670
So let's say you, you, it significantly reduced the friction around, uh, finding and getting a new job.

32
00:03:10,670 --> 00:03:17,470
That was fantastic or exploring it. Um, there were other restrictions that used to be in place,

33
00:03:18,350 --> 00:03:26,510
that made it, um, really hard short of, of staying in your team for two years. It made

34
00:03:26,510 --> 00:03:31,950
it really hard for you to transfer out of that. Uh, and as we've talked about in the past,

35
00:03:32,590 --> 00:03:37,550
right? Team fit is really important. Sometimes you don't detect that in, in the interview. And when

36
00:03:37,550 --> 00:03:43,790
you get in there and four months later you realize, holy crap, I may not actually be the fit for the

37
00:03:43,790 --> 00:03:49,230
culture for this team. You're kind of stuck there for another couple of years until, until you can,

38
00:03:50,670 --> 00:03:56,350
go either fix it in that org or go and find another org that has a fit. But the one thing

39
00:03:56,350 --> 00:04:02,190
that I didn't see, let's say you go through this new process and you get accepted. I didn't

40
00:04:02,270 --> 00:04:07,550
see any limitation on how long your existing team can hold on to you before you transferred.

41
00:04:07,550 --> 00:04:14,260
The current process today, you pass an interview, uh, your existing team can only hold on to you

42
00:04:14,260 --> 00:04:20,050
for a minimum of a month. I didn't see any discussion of that minimum. Cause so now what

43
00:04:20,050 --> 00:04:25,330
I'm worried about, great. Yes, Alan, you can go to this new team. How's 2017 work for you?

44
00:04:25,330 --> 00:04:30,850
Oh, I see the, uh, yeah, you pass the interview. I think that may be in the fine print that

45
00:04:31,650 --> 00:04:37,490
goes to managers or cause that that's bad as well. All right. That's not, um, I sort of implied that

46
00:04:37,490 --> 00:04:42,560
wouldn't be, uh, that wouldn't be an issue, but we'll, we'll see what happens. I don't think that's

47
00:04:42,560 --> 00:04:47,760
a huge issue fast forwarding. And first of all, uh, one of the great things to tell people about

48
00:04:47,760 --> 00:04:51,920
working at a big company like Microsoft, I guess big strong word, huge, massive,

49
00:04:52,560 --> 00:04:58,800
gigantuous, um, is that you can change jobs without leaving the company, which is, I think

50
00:04:58,800 --> 00:05:04,560
sort of a good advantage. You can try new things, new products, even new roles at the company.

51
00:05:05,280 --> 00:05:08,880
I've always, I guess that's both good and bad because there's a lot of people who are,

52
00:05:09,440 --> 00:05:13,760
uh, they're learning has been stunted, uh, working only at Microsoft because they haven't

53
00:05:13,760 --> 00:05:17,680
paid attention to anything going on outside the walls of Microsoft. It's a pro and con like

54
00:05:17,680 --> 00:05:22,880
you, if you go to a smaller company, let's say you went to Netflix or something like that,

55
00:05:23,440 --> 00:05:32,820
um, right. If, if you get to a point in your career where you've, you feel like you've done

56
00:05:32,820 --> 00:05:37,860
learning what you wanted to learn there, you really have to leave that company right here.

57
00:05:39,220 --> 00:05:44,420
We have people who really enjoy their jobs and stay in that position for, I know people

58
00:05:44,420 --> 00:05:49,460
who have stayed in their job for 15 years. I know, I know. And I, there are pros and cons

59
00:05:49,460 --> 00:05:56,580
to that too. Cons for me mostly. I couldn't stand that. I can't either. My resume is filled with,

60
00:05:56,580 --> 00:06:02,580
um, I'm actually, it's a very proud point for me. I've done just about everything you can. I've

61
00:06:02,580 --> 00:06:09,140
done API, I've done UI, I've done service, I've done consumer, I've done, uh, enterprise, uh,

62
00:06:09,140 --> 00:06:18,050
servers. It's for me, that aspect of Microsoft is fantastic. I can just, um, whenever I decide to

63
00:06:18,370 --> 00:06:24,290
leave a team, I go, what do I want to learn next? Uh, and who's got a position opening that?

64
00:06:25,460 --> 00:06:31,700
Very cool. Yes. Uh, so what the, there was a point I was getting to and it was around peer feedback

65
00:06:31,700 --> 00:06:36,740
and I want to really, uh, I was brainstorming this with a friend of ours the other day and

66
00:06:37,380 --> 00:06:41,460
you know, we've tried the, let me tell you about the peer feedback system we have right now at

67
00:06:41,460 --> 00:06:47,300
Microsoft. It's completely ineffective because the way it works is the way it works today is I say,

68
00:06:48,450 --> 00:06:55,520
hey, Bob, Joe and Fred, can you please provide feedback to me knowing that Bob, Joe and Fred

69
00:06:55,520 --> 00:06:59,200
really liked me and they will say great things about me and my manager has to take that with

70
00:06:59,200 --> 00:07:06,340
a grain of salt. Uh, and a good manager may reach out to some other people and ask them for

71
00:07:06,340 --> 00:07:12,740
feedback and it's if they feel like it and it's not a great system for getting objective feedback.

72
00:07:12,740 --> 00:07:16,580
So the idea that came out of this brainstorm, which I, I've had several

73
00:07:16,660 --> 00:07:20,820
brainstorm on this in the past and one was for those who had been around the internet for a long,

74
00:07:20,820 --> 00:07:27,700
long time in the nineties or mid mid to late nineties, there was a site called Am I hot or not?

75
00:07:28,620 --> 00:07:33,660
And, um, the idea was you see pictures of people, you'd rate them and then you'd

76
00:07:33,660 --> 00:07:37,500
seen an appropriate picture and close web browser and hope you never came back to the site again.

77
00:07:37,500 --> 00:07:43,170
But the idea was over, it was crowdsourcing whether you were hot or not moving forward,

78
00:07:43,170 --> 00:07:47,490
not what we're doing here, but the, my joking proposition that started from was

79
00:07:47,490 --> 00:07:52,130
am I a good employee or not? Where people see me a little bio about me and the people I've

80
00:07:52,130 --> 00:07:56,450
worked with and they go, yeah, I like working with him or no, I don't. Um, not the plan I'm

81
00:07:56,450 --> 00:08:01,970
suggesting someone is coding that right now in their office. Yes, it's the miracle. Uh,

82
00:08:02,850 --> 00:08:10,380
but what if, and I'll throw this out to you Brent, uh, what if you were required

83
00:08:10,380 --> 00:08:16,780
to submit, not just solicit feedback to submit feedback, you're required. You need to give

84
00:08:16,780 --> 00:08:23,340
feedback on five people a quarter or 10 people a year, some, some number that could increase as

85
00:08:23,340 --> 00:08:28,860
your level band increases or could stay flat, but you have to, you're required to give feedback

86
00:08:28,860 --> 00:08:39,740
to a minimum of N number of people, uh, per year. And even better, you know, how, um, uh, in any

87
00:08:39,740 --> 00:08:45,020
social networking site, review site, you can, or Amazon reviews, you can like someone's comment or

88
00:08:45,020 --> 00:08:51,100
give a thumbs up or thumbs down as a manager reading the feedback. Uh, I want to rate you

89
00:08:51,100 --> 00:08:56,740
as a person who gives feedback by saying this feedback was useful. This feedback was not useful.

90
00:08:57,860 --> 00:09:05,700
So the one aspect, I'm trying to encourage, uh, the goal here is to get people to submit feedback,

91
00:09:06,420 --> 00:09:14,900
uh, that, and not just for quantity, but for give valuable feedback that evaluates their peers,

92
00:09:14,900 --> 00:09:22,100
people they work with, and also, um, want to be viewed as a good feedback giver. Uh, so that's the

93
00:09:22,100 --> 00:09:26,500
idea I'm floating around in my head now, not that I'm in charge of HR. Any of this will happen, but

94
00:09:27,380 --> 00:09:33,460
I, but, but the last thing I'll say is I have a good track record of throwing out random ideas,

95
00:09:33,780 --> 00:09:40,900
which aren't really that random and, uh, seeing some of them adopted, it's probably pure

96
00:09:40,900 --> 00:09:45,700
serendipity. In fact, it's entirely pure serendipity, but there's my, there's my plan. Brent,

97
00:09:45,700 --> 00:09:52,660
throw in your ideas. So the, your idea is we have some sort of peer feedback site someplace.

98
00:09:54,260 --> 00:10:00,580
Everyone has to contribute to it. So instead of me requesting from others, I have to pick,

99
00:10:01,380 --> 00:10:09,390
uh, and number of people and provide them feedback. Correct. And I assume this end would not be in my

100
00:10:09,390 --> 00:10:19,580
directs. Correct. Okay. Um, and then other people, let's say for me, other people who have chosen me

101
00:10:19,580 --> 00:10:29,010
to, to give me feedback, um, they, they can come in and they can see other people's feedback.

102
00:10:29,010 --> 00:10:33,840
I don't know if they can or not. I don't think so. You mentioned this sort of plus one or no,

103
00:10:33,840 --> 00:10:38,080
that's, that's for the manager. That's for the, so your manager sees your feedback and they go

104
00:10:38,080 --> 00:10:42,880
through it and this person says, Brent's great. He's got a nice smile. And, and the manager has

105
00:10:42,880 --> 00:10:47,340
to fill out this. Was this feedback helpful? And he says, heck no. Then someone gives a lot of more,

106
00:10:47,340 --> 00:10:50,700
a lot of better constructive feedback or positive feedback. It's like, this gives me a good idea

107
00:10:50,700 --> 00:10:56,430
of how Brent works. That's, you know, that's thumbs up. That helps the manager, but more

108
00:10:56,430 --> 00:11:02,430
importantly, my idea is once you get a collection of feedback, that's ongoing about somebody, I,

109
00:11:02,430 --> 00:11:08,270
my hunch is if I can read that, I have an idea of how they work and a little bit more inside of them

110
00:11:08,270 --> 00:11:15,090
than a review and rewards and those things. Yeah. It reminds me a lot of the, the college

111
00:11:15,090 --> 00:11:22,530
interview process we used to have here where we would send out interviewers and then, uh,

112
00:11:23,170 --> 00:11:28,690
I, I haven't done Cal campus recruiting in quite a while, but the recruiters themselves

113
00:11:29,330 --> 00:11:35,330
get rated on their ability, uh, to get, to pick flybacks that actually get accepted.

114
00:11:37,170 --> 00:11:43,390
That could work. The, there's a lot of subjective bias in that system though.

115
00:11:44,720 --> 00:11:52,860
The first off, like the, the, the manager, let's say you come in and you say something that's

116
00:11:52,860 --> 00:11:59,890
totally viable, but I could care less about your principles since they contradict mine.

117
00:12:00,690 --> 00:12:06,290
That's totally fine. The manager, I still want that feedback and the value in that more value.

118
00:12:06,290 --> 00:12:10,370
Look managers, we have bad managers discarding feedback all over the place,

119
00:12:10,370 --> 00:12:17,090
but the value in that feedback in aggregate is that, uh, over time I can get a better picture

120
00:12:17,090 --> 00:12:22,370
of how this person works for future managers. So I'm also thinking of this in sort of the

121
00:12:22,370 --> 00:12:30,660
data-driven engineering culture, right? Cause we'd also have you presumably sending feedback

122
00:12:31,300 --> 00:12:37,700
to multiple different, uh, employees under different managers. Sure. And then we'd

123
00:12:37,700 --> 00:12:46,130
have the manager's ability to rate feedback and be able to compare, um, hey, Allen's feedback

124
00:12:46,130 --> 00:12:53,650
turns out this one guy consistently hates feedback of this sort. Uh, this other, I think

125
00:12:53,650 --> 00:12:59,090
there's some valuable data mining you can give. I think you can look at, again, in, in aggregate

126
00:12:59,090 --> 00:13:04,620
in big data, once you've done this for awhile and you can start to get some really interesting

127
00:13:05,580 --> 00:13:10,700
insights. And again, it's not everything and your fit and value to the team and your value

128
00:13:10,700 --> 00:13:15,820
to Microsoft at reward time is worth a lot more. I mean, pure feedback. I want to be more of that.

129
00:13:16,220 --> 00:13:20,540
But it still has to be about output and technical contribution and product impact and, and those

130
00:13:20,540 --> 00:13:26,060
things as well. The thing is, but we do a really bad job figuring out if someone people, if someone

131
00:13:26,060 --> 00:13:32,670
is collaborative, someone can work with other people. The, we did a, we did a similar, uh, we

132
00:13:32,670 --> 00:13:41,550
did a process when me, one of my peers at the last review where we basically, um, evaluated each

133
00:13:41,630 --> 00:13:47,950
of the new three topics, like how well you do results and how well you basically leverage others

134
00:13:47,950 --> 00:13:53,780
and proactively contribute to others. And we kind of went very deep in all three of those topics for

135
00:13:53,780 --> 00:14:03,980
each of our guys. And we found it using period feedback. We found it very hard. Um, the one

136
00:14:03,980 --> 00:14:11,870
challenge is if, if I'm able to select five people or no. So actually I think it's actually

137
00:14:11,870 --> 00:14:18,750
to brainstorm further. I think it needs to be both ice. I select five people because, uh, and

138
00:14:19,710 --> 00:14:25,310
five people are individuals also have to select five people in which they review.

139
00:14:26,530 --> 00:14:32,210
Perhaps. And the primary reason why I would suggest that is, uh, we do have people who

140
00:14:32,210 --> 00:14:37,330
like to spend their time in their office. Uh, we also have, like, you don't know what you

141
00:14:37,330 --> 00:14:42,130
don't know. You're right. So you do need to, there's a chance with that program that there'll

142
00:14:42,130 --> 00:14:47,900
be people who don't get feedback at all. And this is a case where, especially in the short term,

143
00:14:47,900 --> 00:14:53,580
not going to be overwhelmed by too much data. I think if you gather those and, and, oh, more

144
00:14:53,580 --> 00:14:59,820
work to do, like, look, it doesn't take it's, it's minimal, but over time, as we get more of

145
00:14:59,820 --> 00:15:03,740
this data, we can figure out, Oh, this, this one of these doesn't work. We're going to stop

146
00:15:03,740 --> 00:15:07,980
doing it. Or one of these works. Well, it could be that you can use the data to help tweak the

147
00:15:07,980 --> 00:15:12,780
system. I have an improvement suggestion. I have, I already have 10 in my head from this

148
00:15:12,780 --> 00:15:22,370
conversation so far. So go ahead. The, the, so an individual, let's say it's n right. The,

149
00:15:22,370 --> 00:15:28,260
the number of feedback that they have to fill out, it could be ladder level. It can be whatever

150
00:15:29,060 --> 00:15:35,700
at some point in time where the, that poor soul doesn't end up with a feedback burnout.

151
00:15:36,510 --> 00:15:40,320
Right. We don't want to, we don't want to get it to the point where they're like,

152
00:15:41,520 --> 00:15:45,760
I think you build a code. I'm just going to copy and paste what I said for Alan for this guy.

153
00:15:45,760 --> 00:15:52,000
No. And let me, let me pause there because that's a definite trap to fall into because we do feedback

154
00:15:52,000 --> 00:15:56,000
one time a year when I get this pile of requests and, and you know, I let mine pile up

155
00:15:56,000 --> 00:16:01,730
and I do them and then I put them in there. The idea of my original idea of, you know,

156
00:16:01,730 --> 00:16:08,880
me choosing to give feedback is a sentence in, in the moment, sort of in the moment, like,

157
00:16:08,880 --> 00:16:13,920
well, Scott really helped me figure this thing out and I couldn't have done it without him.

158
00:16:13,920 --> 00:16:17,440
And it was outside the scope of his job. I'm going to give that feedback. I'm going to just

159
00:16:17,440 --> 00:16:21,840
chuck that in there somewhere, whatever, whatever the mechanism is, but I'd rather do

160
00:16:21,840 --> 00:16:26,880
it in the moment than one time a year when I've completely forgotten about that event.

161
00:16:26,880 --> 00:16:34,670
So now I have two ideas. The idea on this one is let them select a few of those folks,

162
00:16:35,870 --> 00:16:44,560
but the rest is selected for them via, you know, could scratch your email, it could email the

163
00:16:44,560 --> 00:16:49,360
good hierarchy. Yeah, whatever. Right. And then it's, and then it's sort of a random sampling.

164
00:16:49,920 --> 00:16:57,520
The second thing, this is my favorite feedback trick. I use this quite often. I don't know

165
00:16:57,520 --> 00:17:05,120
if I've ever walked you through it before. This was taught to me by a peer years and years ago.

166
00:17:05,900 --> 00:17:12,740
So I'll just run you through it if you don't mind. I don't mind. Okay. Alan. Brett.

167
00:17:12,740 --> 00:17:19,900
Step one, what I would like you to do is rate during our last podcast, not this one,

168
00:17:19,900 --> 00:17:27,340
but our last podcast, rate your expectations of me from one to 10 of rate how well I achieved

169
00:17:27,340 --> 00:17:33,260
your expectations of me from one to 10 in our last podcast. All right. 10 is the most awesome. Yep.

170
00:17:34,020 --> 00:17:40,180
What's your rating? Oh, you want me out loud? Yeah. One to 10. Uh, eight. Eight. Awesome.

171
00:17:41,600 --> 00:17:44,400
Because I have low expectations of you and you nailed almost all of them.

172
00:17:45,040 --> 00:17:51,840
That was sweet. Now that this is the important question, what could I have done differently

173
00:17:51,840 --> 00:17:56,560
in our last podcast such that your answer to the prior question would have been a 10.

174
00:17:57,200 --> 00:17:59,600
You could have put your damn face closer to the microphone.

175
00:18:00,740 --> 00:18:06,350
Okay. If I had, if I had done everything in the podcast and I had put my face close to the

176
00:18:06,350 --> 00:18:10,270
microphone, would that have make it a 10? Uh, that would bring it to it. That would bring it

177
00:18:10,270 --> 00:18:13,630
to a nine. I've changed it. My first score cause you did a lot. That's a seven. That'd bring you

178
00:18:13,630 --> 00:18:20,270
to a nine. Okay. What else could I have done? So when I edit, uh, the less I have to edit

179
00:18:20,270 --> 00:18:25,620
of you making weird sounds out of your mouth, weird sounds. Yeah. I'll send you an outtake.

180
00:18:29,810 --> 00:18:37,070
That might be why I'm staying far away from the measure book. All right. Anyway, so the,

181
00:18:37,070 --> 00:18:44,590
that very quick feedback loop, something like that, I would love to have peer feedback. And in,

182
00:18:44,590 --> 00:18:51,500
in addition to that, uh, the, the random selection, you can time box it and say

183
00:18:51,500 --> 00:18:56,780
your expectations of this individual in the last three months, what we captured there was

184
00:18:56,780 --> 00:19:03,840
an evaluation of and translated to a work situation. It's an evaluation to how perception

185
00:19:03,840 --> 00:19:11,340
of accomplishing a task expectations. What's missing. And that's not what I'm worried about.

186
00:19:11,340 --> 00:19:17,900
We'll get that. Maybe, maybe I should be, but what I'm more worried about is we don't seem to

187
00:19:17,900 --> 00:19:25,330
care enough, careful, let's use my words here about actual collaboration and working with others.

188
00:19:26,290 --> 00:19:31,010
And you didn't that, that, that, that, that evaluation didn't capture that. I want to be able

189
00:19:31,010 --> 00:19:37,090
to change the, so if you, if you saw what I did first off is I said, give me a reading

190
00:19:37,650 --> 00:19:41,970
due to some expectation. Now you can change that expectation. You could say,

191
00:19:41,970 --> 00:19:47,410
give me a reading from one to 10 of how well you, you felt I collaborated in the last three

192
00:19:47,410 --> 00:19:53,010
months or how well you feel I am as a manager or how well you feel I am as a developer or

193
00:19:53,010 --> 00:19:57,490
whatever. Now the brilliant thing about that is it actually doesn't matter.

194
00:19:57,490 --> 00:20:02,530
You're going to go all the way to brilliant. Yes, all the way. There are better things than

195
00:20:02,530 --> 00:20:06,450
brilliant, but the brilliant thing about that is it doesn't matter what your rating is.

196
00:20:06,450 --> 00:20:12,960
What that rating does is it forces you to sort of make your own relative.

197
00:20:13,840 --> 00:20:21,630
I think it's a good system, but a different system. Sure. And, and maybe with different

198
00:20:22,350 --> 00:20:26,750
input and different results. But the great thing is another great thing about a big company before

199
00:20:26,750 --> 00:20:35,550
we move on is, uh, we could AB test not in the, in the Alan Brent testing podcast, but in traditional

200
00:20:35,550 --> 00:20:39,710
AB testing where we could run experiments in this division, we're going to do this in this

201
00:20:39,710 --> 00:20:43,710
division or this part of this division. We're going to do this. Um, it would be great if we,

202
00:20:43,710 --> 00:20:50,860
I want to do data driven HR. That would be awesome. And I don't know why.

203
00:20:50,860 --> 00:20:55,580
I don't know that I could get my boss to buy into that. Bet you, your boss would buy into that.

204
00:20:55,580 --> 00:21:02,850
There come my boss's boss. Wouldn't yeah. Yeah. But no boss to shield you from your boss's boss.

205
00:21:02,850 --> 00:21:06,450
Hey, my, my boss is fully supportive of am I a good employee or not?

206
00:21:07,950 --> 00:21:14,030
Alan, do it. Do it. Uh, the other thing, the other thing that you may not have noticed that

207
00:21:14,030 --> 00:21:21,070
is something of a huge passion for me, I truly believe that everybody is awesome.

208
00:21:22,420 --> 00:21:29,380
But everybody has behaviors that suck, particularly in the environment or in the expectations.

209
00:21:29,940 --> 00:21:36,900
And so trying to use peer feedback to tug out what are those behaviors that may not fit well

210
00:21:36,900 --> 00:21:41,860
in, in, we talk about systems thinking in the, in the new system that this person is trying to

211
00:21:41,860 --> 00:21:48,720
join. Um, I've had people who back in the days, I remember with this one guy who was a tester

212
00:21:48,720 --> 00:21:53,680
who hated testing and I sat him down and I'm like, look, you don't like to do any of the

213
00:21:54,400 --> 00:21:58,320
things around testing. It wasn't about the activity, but his behaviors show

214
00:21:58,960 --> 00:22:07,600
you don't like this. You like PM, go get a PM job. And, and he was a repeat, uh,

215
00:22:07,600 --> 00:22:14,830
three Oh, back in those days, three Oh was hugely bad. Uh, with that encouragement,

216
00:22:14,830 --> 00:22:21,070
he went on and he, um, ended up being a repeat four Oh four or five employee in that new role.

217
00:22:21,070 --> 00:22:26,350
Yeah. There's, uh, I made that invention in the podcast for, but a big fan of the grid that

218
00:22:26,350 --> 00:22:30,990
Michael Lott talks about in his fantastic management book called managing humans and

219
00:22:30,990 --> 00:22:36,030
the skill in the will quadrant and you have high skill, you have basically can bucket

220
00:22:36,030 --> 00:22:40,990
your employees into four groups, high skill, high will high, high skill, low will low skill,

221
00:22:40,990 --> 00:22:46,110
high will and low skill, low will. And the idea is that each of those is a different sort of

222
00:22:46,110 --> 00:22:50,610
management challenge or different management approach. When you have your high skill, high

223
00:22:50,610 --> 00:22:54,850
will employees, the ones that just there, the awesome people, you can't just leave them alone.

224
00:22:54,850 --> 00:23:00,290
You got to make sure they maintain challenge and keep them there. You have low skill, high will,

225
00:23:00,290 --> 00:23:04,530
like this is like your typical like college hire. I want to do, I want to do a little puppy dog,

226
00:23:04,530 --> 00:23:09,170
but get them to make sure they get the right training or, or coaching or mentoring so they can

227
00:23:09,170 --> 00:23:14,050
get the skills they need to get up into that high skill, high will. Same thing with the low

228
00:23:14,770 --> 00:23:19,330
will high skill. A lot of times like your guy, they're just in the wrong job. Like I'm really

229
00:23:19,330 --> 00:23:23,890
capable. I'm really smart, but I don't like what I'm doing or I don't like the product I'm working

230
00:23:23,890 --> 00:23:29,170
on. You need to, as a manager, it's your job to get your whole team to try and juggle your

231
00:23:29,170 --> 00:23:33,970
whole team into that high skill, high will bucket. Or if they're just low skill, low will,

232
00:23:33,970 --> 00:23:38,290
and it's not the wrong job, you just hired a putz, you know, find a way to deal with them in

233
00:23:38,290 --> 00:23:43,410
the appropriate way as well. There's another tool that I'm, I'm familiar with. I've talked with

234
00:23:43,410 --> 00:23:49,490
Alan in the past, the influencer series. They talk about a similar thing, which is motivation and

235
00:23:49,490 --> 00:23:57,100
ability. Right. Motivation. You can get people to change both of these, but a lot of the times

236
00:23:58,340 --> 00:24:02,580
it's not worth the ROI. It's important for, and we're off the topic here, but it's important for

237
00:24:02,580 --> 00:24:09,060
managers to recognize that you're, you have an employee who just may not be, it may be a great

238
00:24:09,060 --> 00:24:13,300
employee, but not the best employee for your team. And if your job is a manager, if they're not cutting

239
00:24:13,300 --> 00:24:18,820
it on your team, but you see potential there, it's your job to find them the right fit on the team,

240
00:24:18,820 --> 00:24:24,820
on your org or somewhere else at Microsoft. And people, people forget that too often.

241
00:24:24,820 --> 00:24:28,980
So what are we concluding on the, uh, I don't know. I'm, I'm, a couple of things came out of

242
00:24:28,980 --> 00:24:35,060
that. I'm curious if there are any examples in the industry of data driven HR. So if anybody knows of

243
00:24:35,060 --> 00:24:40,420
any of those, I think you brought up an example last time around, uh, no, it was, no, that wasn't

244
00:24:40,420 --> 00:24:47,380
data driven. That was data analysis on HR. Google look at, let's look at the feedback we've done

245
00:24:47,380 --> 00:24:52,420
over the last 10 years and do some analysis on that. And they said all the KPIs we've been using

246
00:24:53,140 --> 00:25:00,580
suck. Well, again, and you can, I'm not going to rehash the last podcast. Uh, I think that

247
00:25:01,620 --> 00:25:07,140
we're, I love the, again, I like the direction I was about to say love, but I like the direction

248
00:25:07,140 --> 00:25:14,620
we're making some changes. Uh, like with me, I always like to see more, a little more extreme.

249
00:25:14,620 --> 00:25:20,220
So I want to see if, and I think peer feedback is one getting that right will help us the system

250
00:25:20,220 --> 00:25:25,660
we have now. We may as well not do it. That's, that's, that's my closing. Yeah. It's, it's

251
00:25:27,660 --> 00:25:32,540
Pointly. We talked about Google and one of the things, uh, Google does on peer feedback

252
00:25:33,340 --> 00:25:39,500
is you can select, um, six people. I don't know. It's a budget. They, they change it

253
00:25:39,500 --> 00:25:43,820
frequently, but the peer bonus system. No, no, I'm talking about peer feedback. So this is what

254
00:25:43,820 --> 00:25:48,860
I last heard is, is that you as an individual can select, uh, six people very similar to

255
00:25:49,820 --> 00:25:55,740
what we have here, but anybody who wants to, this is different from here.

256
00:25:56,540 --> 00:26:01,460
Anybody who wants to can proactively add feedback. Yeah. I don't know about that.

257
00:26:02,180 --> 00:26:07,540
I haven't paid attention. It just, that one change would be a huge value out here.

258
00:26:07,540 --> 00:26:12,420
Let's experiment. Try some things out. Stephen Johnson, one of my authoring heroes was at

259
00:26:12,420 --> 00:26:16,420
Microsoft yesterday. I got a chance to meet him and, and get a second copy of his books. I

260
00:26:16,500 --> 00:26:22,000
can have one autographed. That's pretty cool. His, uh, sounds like a public service announcement,

261
00:26:22,000 --> 00:26:27,680
which it probably is because he did his last book called how we get to now, um, which is

262
00:26:27,680 --> 00:26:32,560
based on a nugget from his last book, which I, which I have read like three times now where

263
00:26:32,560 --> 00:26:36,800
good ideas come from, which if you've heard me talk at all about testing, I steal liberally from

264
00:26:36,800 --> 00:26:43,470
him. I told him that he was cool. He didn't punch me, but how we get to now, he filmed as

265
00:26:43,470 --> 00:26:49,170
a PBS series at the same time he wrote it. So he would go out and get the ideas and do

266
00:26:49,170 --> 00:26:52,770
the research and they'd film for like 10 hours. Then he'd go back and do a bunch of writing

267
00:26:52,770 --> 00:26:56,930
or vice versa. He'd write about something and then they go film it. But there's a PBS series.

268
00:26:56,930 --> 00:27:02,530
It's the third episode is maybe fourth. Anyway, it's six episodes, six parts of the book

269
00:27:03,170 --> 00:27:11,120
on these great, uh, connections of ideas and innovation through history. Uh, quick story from

270
00:27:11,120 --> 00:27:15,360
yesterday. He has a great example of, you know, there was a, I'm going to paraphrase this horribly.

271
00:27:15,360 --> 00:27:20,320
That's what I do. There was a printing plant and the ink was running. So they

272
00:27:22,000 --> 00:27:26,640
that guy there is trying to figure out how to dehumidify the air and he figured it out.

273
00:27:26,640 --> 00:27:30,080
And the machine he made had the side effect of cooling off the room as well.

274
00:27:30,800 --> 00:27:34,000
People liked that. I started eating lunch in the printing room because it was nice and cool in

275
00:27:34,000 --> 00:27:38,320
there. They maybe were onto something and out of the end, a couple of years later or several

276
00:27:38,320 --> 00:27:42,880
years later, they were able to build, um, air conditioning units that would work in a house.

277
00:27:43,440 --> 00:27:49,200
And that drove air conditioning. The invention of that, which came out of a dehumidifier for

278
00:27:49,200 --> 00:27:55,440
a printing plant actually drove large scale migration of people to areas like, uh, Phoenix,

279
00:27:56,000 --> 00:28:00,880
South Florida, Las Vegas, you know, turn of the century, just turn of last century,

280
00:28:00,880 --> 00:28:05,440
a hundred years ago, there were like 150 people leave living in Las Vegas. And now it's the

281
00:28:05,440 --> 00:28:10,720
fastest growing city in the, like in the country. Uh, and all that's due to the, to dehumidifying.

282
00:28:10,720 --> 00:28:14,400
And then he talks about how that goes into how it actually has affected the political

283
00:28:14,400 --> 00:28:18,400
climate of political races and, and all kinds of great connections. He's great at drawing

284
00:28:18,400 --> 00:28:23,200
these connections. And which makes sense. Cause he's the guy that learned where

285
00:28:23,200 --> 00:28:25,680
ideas come from and where do ideas come from, Brent?

286
00:28:26,770 --> 00:28:29,650
Uh, unicorn rainbow land.

287
00:28:29,650 --> 00:28:35,170
They come from other ideas. And, uh, anyway, uh, I'm a huge fan of his, uh,

288
00:28:36,050 --> 00:28:41,570
I think anyone, anyone interested in coming up with new ideas, if you're, if you're fine,

289
00:28:41,570 --> 00:28:45,420
have you read Shapiro yet? Stephen Shapiro.

290
00:28:45,420 --> 00:28:52,540
Yes. Yeah. He's he's, I have not read Stephen Johnson, but I, I'm all in on Shapiro and

291
00:28:52,540 --> 00:28:56,860
it's very much along those same lines. And what I would say with Stephen Johnson,

292
00:28:56,860 --> 00:29:01,900
with, um, I have, and to be fair, I've only read like the first half a chapter of the new book.

293
00:29:02,460 --> 00:29:08,270
Uh, but where ideas come from, where good ideas come from, if you actually don't care

294
00:29:08,270 --> 00:29:10,990
about coming up with new ideas and you're fine, just doing it, you're told,

295
00:29:10,990 --> 00:29:15,950
probably don't need to read it. But if you actually want to, uh, figure out where ideas

296
00:29:15,950 --> 00:29:19,550
come from and how to come up with good ideas of your own and how to think about that,

297
00:29:19,550 --> 00:29:24,030
you gotta go read where good ideas come from. And I've read, uh, he's written nine books.

298
00:29:24,030 --> 00:29:30,030
I've written, I've read, I've written, I've read about half. I read everything bad is good

299
00:29:30,030 --> 00:29:35,790
for you and the ghost map and, um, and where good ideas come from, which math,

300
00:29:37,310 --> 00:29:42,030
I read a third of his book. I'll, I'll, I'll increase that to just under half when I finish,

301
00:29:42,030 --> 00:29:48,110
uh, where, um, so, so you guys, you guys in podcast lane can't, can't see Allen when he's

302
00:29:48,110 --> 00:29:53,710
thinking about Stephen Johnson, but it is clear. He has a major bromance for this guy.

303
00:29:53,710 --> 00:29:58,220
Yeah. Yeah. I'm getting a little embarrassed and little flustered.

304
00:29:58,220 --> 00:30:06,140
All right. Hey, um, one last thing before we get going is, uh, maybe one next to last thing,

305
00:30:06,140 --> 00:30:10,300
but right. You wanted to talk a little bit about sort of the not invented to hear syndrome,

306
00:30:10,300 --> 00:30:15,740
what that means for business. Yeah. So we've talked about this quite a bit.

307
00:30:17,040 --> 00:30:27,090
And there's a situation currently happening in my org. Uh, it, it, it frustrates me quite a bit.

308
00:30:27,170 --> 00:30:32,770
I'm not gonna, I'm not gonna share it on the podcast, but I'm wondering, maybe Alan, you could,

309
00:30:32,770 --> 00:30:38,980
you could brainstorm with me in the time we have remaining today around, how can we accelerate

310
00:30:40,110 --> 00:30:51,390
learning in the organization in a nutshell? What we have is we have a well-known bad decision

311
00:30:51,390 --> 00:30:59,440
that has occurred in, in business. Okay. Well-known bad decision, a bunch of teams.

312
00:30:59,440 --> 00:31:08,400
I would say somewhere around 50 people working hard to replace, uh, the, the assets built as a

313
00:31:08,400 --> 00:31:18,800
result of that bad decision. And we're, we're in a phase, uh, where multiple teams in, in a specific

314
00:31:18,800 --> 00:31:26,240
context, this is around a data pipeline, which, which I argue is the, the test harness. No,

315
00:31:27,200 --> 00:31:32,480
I was thinking the same thing. Yeah. It was, it was the test harness for a long time. And now,

316
00:31:32,480 --> 00:31:36,560
now that every team wrote, we have, oh, we have a test harness harness. It's great.

317
00:31:36,560 --> 00:31:42,320
Now it's the data pipeline. Yeah. The, the, the difference though, is back in the old

318
00:31:42,320 --> 00:31:49,500
school days, if you didn't build a test harness, you still could ship, right? You work 40 hour

319
00:31:49,500 --> 00:31:55,580
days. Everyone's bug bashing in the last month. Fun. Yeah. I mean, it's not efficient. It's

320
00:31:55,580 --> 00:32:00,700
quite painful, but you could still ship. But in these days, if you don't have a good data pipeline,

321
00:32:01,820 --> 00:32:12,290
um, your business is hurt. Period. And so what we're seeing is, is a lot of NIH around data pipes.

322
00:32:12,370 --> 00:32:20,340
NIH is not invented here for the acronym, uh, weary. Yes. And, and, uh, there's a human condition

323
00:32:20,900 --> 00:32:29,940
where we're prebuilt to, to believe that other people's ideas are stupid and mine is awesome.

324
00:32:30,860 --> 00:32:35,260
And I battle that. I, there's a phrase that you'll hear in my hallway quite often that

325
00:32:35,340 --> 00:32:43,020
NIH is awesome. Not invented here is bonus. Let's go. Um, anyway,

326
00:32:45,390 --> 00:32:51,390
there was a decision that looks like it's in flight. It was made, uh, in isolation. Uh,

327
00:32:51,390 --> 00:32:55,870
it hasn't been vetted with all the other executives, but one executive basically very

328
00:32:55,870 --> 00:33:02,690
recently has made a decision that it's going to lead us down a path that's remarkably similar

329
00:33:03,330 --> 00:33:11,540
to the one we just, um, got ourselves unburied. And not only that, this is much bigger. And,

330
00:33:11,540 --> 00:33:18,850
and so what I find myself puzzling is how do we prevent this going forward? Why is this

331
00:33:18,850 --> 00:33:26,260
learning at this level so hard? I don't think it's that hard. I, I, I do think about this a lot

332
00:33:26,260 --> 00:33:30,260
and I have a great story I'll share in a moment, which will make yours seem mellow in comparison.

333
00:33:31,140 --> 00:33:39,460
I think ego tends to Trump invention in non-learning organizations. And what I mean by that

334
00:33:39,460 --> 00:33:44,740
is I commonly see, you know, I think non-invented here comes from ego comes from,

335
00:33:44,740 --> 00:33:49,380
I, nobody else could come up with a better idea than me. This must be the best idea.

336
00:33:49,380 --> 00:33:55,620
I have been here for 20 years and I know. And I also believe that, like I mentioned a few

337
00:33:55,620 --> 00:34:01,940
minutes ago from Steven Johnson, good ideas come from other ideas and learning orgs, uh, and

338
00:34:02,660 --> 00:34:08,100
another book recommendation, one always knew that the outside edge of my bookshelf is, uh,

339
00:34:08,100 --> 00:34:11,700
Peter Zingay's, uh, the fifth discipline, which is a learning organization.

340
00:34:12,580 --> 00:34:18,900
I think a learning organization in tech comes a lot from small experiments that fail. Like

341
00:34:18,900 --> 00:34:22,660
if I want to have a new data pipeline, I want to think, I want to brainstorm every little bit

342
00:34:22,660 --> 00:34:29,140
of it and come up with at least a few, one or two or sorry, not one, at least two or three

343
00:34:29,140 --> 00:34:35,380
different options for each part and give, let some people go investigate, not two to three

344
00:34:35,380 --> 00:34:41,790
week investigations. I want, I want little short investigations that include an investigation could

345
00:34:41,790 --> 00:34:45,230
be, here's an idea how to do it. Let me understand more why this didn't work,

346
00:34:45,870 --> 00:34:51,940
why something still didn't work in the past. I think, and that's where those ideas coming

347
00:34:51,940 --> 00:34:55,700
together, have those teams get together and do a little brainstorm, a little, little,

348
00:34:57,010 --> 00:34:59,970
probably different than a scrum meeting, but a little half hour, like here's what I thought of

349
00:34:59,970 --> 00:35:04,050
and let those ideas bounce off each other. And then you're going to come up with something

350
00:35:04,050 --> 00:35:10,900
that's a lot better. Uh, I think when you just think this is the right way, I really

351
00:35:10,900 --> 00:35:17,140
can't think of another way. In fact, I think this is from Weinberg. I can't remember a bit

352
00:35:17,140 --> 00:35:23,060
when I'm thinking for a solution for a really difficult problem. I want to come up with three

353
00:35:23,060 --> 00:35:27,810
ideas for it. Cause I don't know, you know, I might think of one and well, this one's the best one

354
00:35:27,810 --> 00:35:31,970
for sure. And then I'll force myself. Well, let me think of two other ways I could do this.

355
00:35:31,970 --> 00:35:37,570
And often, not always, but often I find something in that second or third solution and,

356
00:35:38,210 --> 00:35:41,490
and not just me, but myself, but working with others, because that's how I believe these

357
00:35:41,490 --> 00:35:46,850
things need to happen. I got something in my eye. Um, but when you think from the beginning

358
00:35:46,850 --> 00:35:51,810
that you have a solution and there isn't, there won't be another way to do it, uh, regardless of

359
00:35:51,810 --> 00:35:57,890
whether it's repeats a bad decision you made before, it's probably a bad decision. There's a,

360
00:35:57,890 --> 00:36:03,570
there's a couple of things. First off, um, I do the same thing in terms of coming up with three

361
00:36:03,570 --> 00:36:11,010
solutions and, and it's very interesting because I, I've actually been teaching people this. I've

362
00:36:11,010 --> 00:36:15,410
now taught it four times in the last week and the last time I've taught it to someone who was

363
00:36:15,570 --> 00:36:21,970
five years ago. So there's this weird sort of coincidence thing. Basically what I do is when

364
00:36:21,970 --> 00:36:29,120
you need to come up with alternatives for brainstorming, solution number one, what is the

365
00:36:29,120 --> 00:36:37,820
high cost but low risk solution? Solution number three is what is the low cost but high risk

366
00:36:37,820 --> 00:36:46,220
solution? And then solution number two is the one that's medium cost, medium risk. And starting

367
00:36:46,300 --> 00:36:54,300
with those things, you, you end up getting the two scales and then, uh, you're able to converge on

368
00:36:54,300 --> 00:36:59,580
what would be a good in between that allows us to be flexible. Perhaps one, one technique I use a lot

369
00:36:59,580 --> 00:37:04,620
is the, um, look at these extremes for any, any technical problem or any adaptive problem. Look at

370
00:37:04,620 --> 00:37:09,660
what one extreme versus the other, whether it's those criteria and others, and then take the

371
00:37:09,660 --> 00:37:15,100
best from both sides and figure it out. The other thing that, that I picked up from your,

372
00:37:15,100 --> 00:37:23,410
your guidance is it implies that if we could somehow come up with a way to measure the

373
00:37:23,410 --> 00:37:31,360
maturity model of an organization around how they are, are a learning organization. Right.

374
00:37:32,460 --> 00:37:35,500
There's a heuristic that as you were talking, it reminds me of,

375
00:37:36,220 --> 00:37:42,300
they're still very dominant. This philosophy within our company around betting the farm.

376
00:37:43,740 --> 00:37:50,620
And I'm like, I've, I've now after seen this for, for several months in the last two years played out,

377
00:37:51,260 --> 00:37:57,820
I actually think that that's a heuristic for someone who's low on that maturity model. The,

378
00:37:57,820 --> 00:38:04,880
what you're talking about, uh, with the, the, the printer ink not drawing, right? I, I thought of

379
00:38:04,880 --> 00:38:11,040
it in terms of Reese's concepts of pivot and persevere. The guys invented something that

380
00:38:11,040 --> 00:38:17,920
solved this problem, but they then very quickly understood the behavior of human beings given

381
00:38:17,920 --> 00:38:24,480
this new environment. And they recognized, Hey, wait a minute. There's likely a significantly

382
00:38:24,480 --> 00:38:29,520
more valuable idea in terms of the usage of this asset we just built.

383
00:38:29,520 --> 00:38:34,240
Steven Johnson calls those when you fail to do that, those blind spots. And they're very common.

384
00:38:34,240 --> 00:38:41,360
There was a guy ahead of Edison who invented a way to record music on a, on a cylinder.

385
00:38:42,240 --> 00:38:46,800
He thought that was fantastic. And it was kind of developed out of his idea that people take

386
00:38:46,800 --> 00:38:52,240
shorthand. I'll make this thing that records and then they'll learn how to read the waves in this

387
00:38:52,240 --> 00:38:59,440
recording and be able to transcribe it. Uh, he, it didn't even occur to him that people might want

388
00:38:59,440 --> 00:39:05,780
to listen to what had been recorded. He could record, but it couldn't, and the fact that it

389
00:39:05,780 --> 00:39:11,440
couldn't play back, not even on his radar. And, but I was, I was, wait, wait, what problem was

390
00:39:11,440 --> 00:39:15,280
he solving? He wanted to be able to record something so that, and his idea was that well,

391
00:39:15,280 --> 00:39:20,480
once it's recorded, people can look at the wave. You can do a little, a little, look at the

392
00:39:20,480 --> 00:39:25,280
waves and the wax and transcribe that into words. He thought it would be a new, new,

393
00:39:25,920 --> 00:39:30,720
new form of shorthand. Oh, he was trying to, he was trying to automate transcription. Yeah.

394
00:39:30,720 --> 00:39:36,320
So he missed and we see that happen. I heard that. I go, I've seen that happen about a hundred

395
00:39:36,320 --> 00:39:40,240
times, at least in software engineering where I have this and I see it actually come out of

396
00:39:40,240 --> 00:39:44,480
research a lot where the great thing we have super smart people in Microsoft research. And I

397
00:39:44,480 --> 00:39:47,840
come up with great ideas. It goes, I developed this thing that does this. And you go, well,

398
00:39:47,840 --> 00:39:53,040
that's not interesting at all. But if I take it and then do this with it, now it's super

399
00:39:53,120 --> 00:39:58,640
valuable. Thanks. Yeah. Yeah. I've been kind of situations where I've done, I was trying to do

400
00:39:58,640 --> 00:40:04,930
this and it completely failed, but I'm sharing and I look at it. I'm like, do you not see what

401
00:40:04,930 --> 00:40:11,970
you have? All right. We're almost at a time. Hey, I want to tell my story. So years ago,

402
00:40:13,250 --> 00:40:18,690
I was involved. I was actually the principal, the key person involved in trying to acquire some

403
00:40:19,490 --> 00:40:27,120
really cool technology from Microsoft. I had talked to the owners of the program. People,

404
00:40:27,760 --> 00:40:35,360
excitement at Microsoft was high. Cost was relatively cheap. It's like, oh my gosh,

405
00:40:35,360 --> 00:40:39,760
this is going to happen. We're like, it was very exciting time. Started floating it around,

406
00:40:39,760 --> 00:40:45,040
you know, and trying to figure out an idea of how much scale we need. And the VP of one

407
00:40:45,980 --> 00:40:55,380
major product at Microsoft said he vetoed it. He said, this program, this platform offers features

408
00:40:55,380 --> 00:41:00,100
that we may implement sometime in the future. So we don't want it to compete. So I don't want it

409
00:41:00,100 --> 00:41:07,580
here at Microsoft. And I said, the deal was done. The deal is off. What? And I have to leave it.

410
00:41:07,580 --> 00:41:12,540
I'll leave it at that for now, but it's funny that we may want to implement the features in

411
00:41:12,620 --> 00:41:18,460
the company we're trying to acquire. So he said, our product may implement many of these features

412
00:41:18,460 --> 00:41:22,540
sometime. So we don't want to have that here because it'll take away from our future growth.

413
00:41:23,840 --> 00:41:29,520
Yeah, that was the line. Is that VP still here? I don't know. I don't know. I can tell you though,

414
00:41:29,520 --> 00:41:34,000
recently, there's been a resurgence of a huge number of people saying,

415
00:41:34,880 --> 00:41:38,240
saying, hey, we should get this product here. And they searched the internal web and they found

416
00:41:38,800 --> 00:41:44,960
these documents I wrote six, seven years ago. Say, hey, whatever happened with this? And I sadly tell

417
00:41:44,960 --> 00:41:51,040
them probably even a less interesting version of that story. But I think we really missed out big

418
00:41:51,040 --> 00:41:58,400
time on a chance to become a learning organization. So that line just blows me away. Our product's

419
00:41:58,400 --> 00:42:04,160
going to have this stuff someday. So maybe. So we don't want to spend this minimal amount

420
00:42:04,160 --> 00:42:10,620
of money to have it here. Does that product have it? No, absolutely not. Nothing even close.

421
00:42:10,620 --> 00:42:16,380
And have you recently done any sort of update check in terms of the status of that company?

422
00:42:16,380 --> 00:42:21,100
Yeah. Here's the funny part. Yeah, they're still around. They're more popular than ever.

423
00:42:21,900 --> 00:42:27,340
Much harder for us to get it on site than it was then. I still have the contacts. It's funny. I

424
00:42:27,340 --> 00:42:32,460
still have the contacts who tell me behind the curtain that, sure, we'll help you get it set up.

425
00:42:33,340 --> 00:42:39,100
But there's still NIH around that from the interested parties now. And so even though

426
00:42:39,970 --> 00:42:43,810
I honestly could get them here for a price that Microsoft could afford and be economical,

427
00:42:44,370 --> 00:42:51,250
given the value. Maybe I missed it. This is a company we're trying to acquire or a service

428
00:42:51,250 --> 00:42:56,590
we wanted to bring in-house. A service we wanted to bring in-house. Oh, I hate this.

429
00:42:56,590 --> 00:43:02,350
Yes. Anyway, when I think of not invented here, this is a story that grinds me more than any.

430
00:43:02,430 --> 00:43:08,030
And I think it's a loss of opportunity. So last time, the time before, I was talking about the

431
00:43:08,030 --> 00:43:11,550
third party that we were going with. And we hit some of that when we were

432
00:43:12,990 --> 00:43:20,820
flooding the proposal. Because there is another team who's trying to build those services. And I said,

433
00:43:20,820 --> 00:43:27,710
that's fantastic. We're going to go with this because we need it now. And here's our design. And

434
00:43:27,710 --> 00:43:34,910
we're going to design it such that we can flip the switch. I hope that approach becomes a prototype

435
00:43:34,910 --> 00:43:42,110
and a practice we can see more of at Microsoft. But I think you're still in the rare bucket.

436
00:43:43,300 --> 00:43:51,620
Yeah, for me, it's just time is of essence. We don't have the time to wait for you to light

437
00:43:51,620 --> 00:43:57,540
up this feature. We need it now. And it's cheaper than putting- We don't have to serialize.

438
00:43:58,100 --> 00:44:02,980
Right. Right. And we'd- Yeah. All right. We're out of time. So, hey, fun podcast today,

439
00:44:02,980 --> 00:44:06,980
Brett. Yeah. Thank you. How do you do today? I'll let you know after you turn the mic off.

440
00:44:08,340 --> 00:44:13,220
Hey, everybody. Thanks again for listening. Yep. I'm Alan. I'm Brett. And we'll see you next time.

