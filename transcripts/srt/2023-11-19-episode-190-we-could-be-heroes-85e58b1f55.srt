1
00:00:00,000 --> 00:00:04,440
And, and Brent has no idea what I said because he was typing furiously.

2
00:00:04,760 --> 00:00:05,480
But what did you ask it?

3
00:00:05,480 --> 00:00:06,080
What did you ask?

4
00:00:06,080 --> 00:00:10,400
I actually did have what it is, but the second you challenged me on that, it did

5
00:00:10,400 --> 00:00:11,120
flush. Yes.

6
00:00:14,770 --> 00:00:18,930
Welcome to AB testing podcast, your modern testing podcast.

7
00:00:19,250 --> 00:00:24,650
Your hosts, Alan and Brent will be here to guide you through topics on testing,

8
00:00:24,890 --> 00:00:27,850
leadership, agile, and anything else that comes to mind.

9
00:00:28,130 --> 00:00:29,730
Now on with the show.

10
00:00:29,890 --> 00:00:30,770
Hello, everyone.

11
00:00:30,970 --> 00:00:31,730
It's Alan.

12
00:00:32,210 --> 00:00:33,260
And Brent.

13
00:00:33,460 --> 00:00:38,930
And we're here today to bring light to your life, like rays of sunshine sparkling

14
00:00:38,930 --> 00:00:44,010
into your living room or your car or wherever you listen to our wonderful podcast.

15
00:00:44,410 --> 00:00:47,790
Calm, motion, gently crash.

16
00:00:47,830 --> 00:00:51,910
This is the Pretty Little Things podcast where we talk about things that make us

17
00:00:51,910 --> 00:00:54,950
happy. No, we talk about things that make us mad and piss us off.

18
00:00:55,270 --> 00:00:57,030
This is AB testing, damn it.

19
00:00:57,550 --> 00:00:58,110
Yes.

20
00:00:59,340 --> 00:01:01,900
Who wants to listen to what makes us happy?

21
00:01:02,060 --> 00:01:04,380
So I think I may get the recording right the first time here.

22
00:01:04,380 --> 00:01:06,060
We will see what happens.

23
00:01:06,380 --> 00:01:07,860
I'm learning new stuff.

24
00:01:08,300 --> 00:01:09,500
Just had another problem.

25
00:01:09,540 --> 00:01:11,580
I accidentally unplugged my recording device.

26
00:01:11,580 --> 00:01:13,140
Hopefully I won't do that again.

27
00:01:13,620 --> 00:01:14,860
But how you been doing, Brent?

28
00:01:15,980 --> 00:01:17,500
Uh, it's review season.

29
00:01:17,780 --> 00:01:19,840
So yay.

30
00:01:19,880 --> 00:01:21,320
You didn't use that like a month ago.

31
00:01:21,320 --> 00:01:23,280
Is it, how long does review season last?

32
00:01:23,920 --> 00:01:28,260
Uh, this time it was three, three weeks.

33
00:01:28,300 --> 00:01:29,060
It's not too bad.

34
00:01:29,220 --> 00:01:30,020
That's not too bad.

35
00:01:30,420 --> 00:01:31,620
We have that coming up.

36
00:01:32,020 --> 00:01:36,820
We should probably talk about not specifics of that, but I have a lot of

37
00:01:36,820 --> 00:01:41,220
thoughts that are thought were ubiquitous, but are not around how to do fair

38
00:01:41,220 --> 00:01:45,100
employee reviews, but that is not on my bullet list for today.

39
00:01:45,380 --> 00:01:45,940
What a pain.

40
00:01:45,940 --> 00:01:48,940
And at Microsoft too, it's, it's, it's weird.

41
00:01:49,380 --> 00:01:50,980
Flip a coin, right?

42
00:01:50,980 --> 00:01:51,500
It's fair.

43
00:01:51,500 --> 00:01:52,340
50 50.

44
00:01:52,380 --> 00:01:53,220
Just flip a coin.

45
00:01:54,100 --> 00:01:54,700
Throw darts.

46
00:01:55,300 --> 00:01:56,820
Nine boxes and darts.

47
00:01:57,140 --> 00:01:57,860
That's all we need.

48
00:01:58,260 --> 00:02:01,380
Have you gone through a review season at the current place?

49
00:02:01,380 --> 00:02:01,780
No.

50
00:02:02,500 --> 00:02:03,020
Okay.

51
00:02:03,220 --> 00:02:11,140
That should be a topic because I'm very curious as to, as to how much Microsoft

52
00:02:11,180 --> 00:02:14,460
and unity have influenced your style at the new place.

53
00:02:14,460 --> 00:02:18,140
Well, it's also, you have to do your style as much as you can within a

54
00:02:18,140 --> 00:02:21,060
confine of rules given to you by your context.

55
00:02:21,700 --> 00:02:22,620
Yes.

56
00:02:23,020 --> 00:02:24,580
So I will do what I can.

57
00:02:24,620 --> 00:02:26,700
My big value with me is fairness.

58
00:02:26,700 --> 00:02:31,140
I'll try and be fair, but sometimes the fair thing to do is to give one

59
00:02:31,260 --> 00:02:34,300
if someone's 0% merit, it's fair.

60
00:02:34,460 --> 00:02:36,540
What's critical is that we're fair all the time.

61
00:02:36,540 --> 00:02:38,180
Anyway, that is another topic.

62
00:02:38,460 --> 00:02:42,580
We're probably not going to get there in 2023.

63
00:02:43,340 --> 00:02:47,460
If we record in two weeks, we may get two more episodes in before the end of the

64
00:02:47,460 --> 00:02:51,100
year, we've got to coordinate calendars and figure that out to make sure we get

65
00:02:51,100 --> 00:02:56,860
the 2023 predictions and recap episode recorded properly.

66
00:02:57,460 --> 00:03:00,940
So let's spend a little bit of calendar time offline here, but that's coming

67
00:03:00,940 --> 00:03:02,100
up as a little preview.

68
00:03:02,100 --> 00:03:05,580
So one ninety one or one ninety two will be that the year end recap and

69
00:03:05,580 --> 00:03:09,940
predictions episode, it'll be fun to look back and look forward like we always do

70
00:03:09,940 --> 00:03:12,540
for the last million years we've been doing this podcast.

71
00:03:13,060 --> 00:03:15,460
So speak at a podcast.

72
00:03:16,510 --> 00:03:19,790
I've been slowly catching up on my backlog of podcasts.

73
00:03:20,390 --> 00:03:21,030
Do you listen?

74
00:03:21,070 --> 00:03:25,870
You listen to I know 99% invisible used to be on your radar.

75
00:03:26,270 --> 00:03:28,030
Do you listen to podcasts much anymore?

76
00:03:28,430 --> 00:03:29,950
Not as much.

77
00:03:29,950 --> 00:03:34,030
I still do like podcasts are still my favorite thing to do.

78
00:03:34,030 --> 00:03:38,930
Like when I'm mowing the lawn or chores, chore casts.

79
00:03:39,610 --> 00:03:44,610
Right. 99% visible is is still top.

80
00:03:45,170 --> 00:03:49,330
It's still it's listened to enough that it's still top in my little

81
00:03:49,610 --> 00:03:51,450
M.R.U. list on Spotify.

82
00:03:51,850 --> 00:03:52,850
Cool.

83
00:03:53,730 --> 00:03:57,210
The 60 songs I talked to you about this a while ago, the 60 songs.

84
00:03:57,250 --> 00:03:59,050
Yeah, I got to check that one out.

85
00:03:59,050 --> 00:04:04,180
60 songs that explain the 90s episode.

86
00:04:04,900 --> 00:04:06,180
What episode are they on?

87
00:04:06,220 --> 00:04:09,900
Oh, dude, by the way, like he's gone way more than 60.

88
00:04:10,140 --> 00:04:13,540
No, I got to check that one out because I forgot I'm slowly getting caught up.

89
00:04:13,540 --> 00:04:20,280
I was literally a hundred podcasts behind a while back between the move and

90
00:04:20,280 --> 00:04:25,160
everything and I've been walking to the gym every day and I walk a lot living

91
00:04:25,160 --> 00:04:29,240
where I live, so slowly catching up and I want to add some new podcasts.

92
00:04:29,240 --> 00:04:33,150
I'm going to get to the end and there are I want to check this one out and my

93
00:04:33,150 --> 00:04:38,470
quick tangent there is speaking of the 90s and currently to today, even.

94
00:04:39,190 --> 00:04:43,550
Are you going to you don't do you leave your house much because the food fighters

95
00:04:43,550 --> 00:04:44,910
are playing next summer.

96
00:04:45,310 --> 00:04:48,710
Yeah, no, the are you inviting me to the food fighters?

97
00:04:48,750 --> 00:04:49,710
I only have one ticket.

98
00:04:49,710 --> 00:04:50,710
I'm asking for your.

99
00:04:52,510 --> 00:04:55,870
I'm not that guy that buys one ticket to a concert goes by himself.

100
00:04:56,150 --> 00:04:56,670
I'm that guy.

101
00:04:57,270 --> 00:04:57,830
Oh, are you?

102
00:04:57,990 --> 00:04:58,190
Yeah.

103
00:04:58,510 --> 00:05:04,990
Oh, my, my daughter would be upset as well as well.

104
00:05:05,070 --> 00:05:10,110
Actually my middle son who, who, I don't know if I talked about it, but he just got

105
00:05:10,110 --> 00:05:15,070
married and congratulations, but he's in Florida, so he's not going to make that

106
00:05:15,070 --> 00:05:15,310
trip.

107
00:05:15,630 --> 00:05:20,150
Well, I'm in Florida, so the food fighters.

108
00:05:20,230 --> 00:05:25,910
Yeah, that's, that's a, that's a good van and I really enjoyed the YouTube of

109
00:05:25,910 --> 00:05:26,630
the food fighters.

110
00:05:26,710 --> 00:05:28,030
Have you done much of that?

111
00:05:28,430 --> 00:05:33,830
Like Dave Grohl does a whole lot of like random songs and bringing people from

112
00:05:33,830 --> 00:05:35,670
it is just a good person.

113
00:05:36,150 --> 00:05:37,550
He's a good man.

114
00:05:37,550 --> 00:05:38,870
Fantastic person.

115
00:05:38,870 --> 00:05:39,750
He's a good guy.

116
00:05:39,790 --> 00:05:40,830
That's why I like the band.

117
00:05:41,030 --> 00:05:44,070
Their songs are kind of okay, but Dave Grohl's I'm a, I'm a Dave Grohl fan.

118
00:05:44,550 --> 00:05:45,070
I'm kidding.

119
00:05:45,110 --> 00:05:45,910
The songs are good too.

120
00:05:47,910 --> 00:05:52,270
So anyway, I wanted to mention that, but the real topic I wanted to mention is as

121
00:05:52,310 --> 00:05:54,710
I add new podcasts, there are two things.

122
00:05:55,530 --> 00:06:00,730
There's a quality of podcast as brand types, while I'm talking again, but I'll go

123
00:06:00,730 --> 00:06:02,970
ahead and tell my story anyway, cause I can edit that shit out.

124
00:06:03,450 --> 00:06:05,290
I looked for a couple of things in a podcast.

125
00:06:05,490 --> 00:06:13,210
One, of course, a topic I'm remotely interested in, but that's almost sub

126
00:06:13,290 --> 00:06:14,610
to two things are there.

127
00:06:14,970 --> 00:06:19,890
I don't know how to describe this, but I listened to a podcast where I

128
00:06:20,010 --> 00:06:26,380
loved the content, but the recording was so awful that I could not continue

129
00:06:26,380 --> 00:06:27,020
listening to it.

130
00:06:27,540 --> 00:06:28,900
It was recorded low.

131
00:06:29,020 --> 00:06:30,220
There was echo.

132
00:06:30,540 --> 00:06:32,260
It was just, I could not listen to it.

133
00:06:32,580 --> 00:06:33,460
That's on one end.

134
00:06:33,460 --> 00:06:35,980
Was that, was that our podcast last episode?

135
00:06:35,980 --> 00:06:36,860
No, shut up.

136
00:06:36,860 --> 00:06:41,740
Oh, we have top notch video and audio editors working on our

137
00:06:41,740 --> 00:06:43,100
podcast around the clock.

138
00:06:43,540 --> 00:06:47,900
And then, so that one was hard, but also I tried listening to, like I'm a big

139
00:06:47,900 --> 00:06:52,080
fan of, ah, crap, I'm forgetting names cause it's Friday.

140
00:06:52,080 --> 00:06:53,320
Who's the Netflix guy?

141
00:06:53,320 --> 00:06:54,360
Read what?

142
00:06:54,360 --> 00:07:00,280
Not the, not the Netflix guy, the, um, LinkedIn guy read, which one's Hoffman?

143
00:07:00,720 --> 00:07:01,760
Hastings Hoffman.

144
00:07:01,760 --> 00:07:02,920
I get him confused sometimes.

145
00:07:03,040 --> 00:07:04,040
Former LinkedIn guy.

146
00:07:04,040 --> 00:07:08,480
He wrote this great book called, um, the Alliance, which I love.

147
00:07:09,200 --> 00:07:13,200
I align well with the Alliance to book on, on managing people in the 21st

148
00:07:13,200 --> 00:07:16,480
century, but his podcast, good material.

149
00:07:16,680 --> 00:07:20,360
I can't listen to it because it's so overproduced.

150
00:07:20,800 --> 00:07:24,880
It has sound effects all over the place and weird music and weird places.

151
00:07:24,880 --> 00:07:26,920
It just, it's, it's too cheesy.

152
00:07:27,040 --> 00:07:28,480
It's too, too cheesy.

153
00:07:28,760 --> 00:07:31,040
It's like, it's like a podcast for an amusement park.

154
00:07:31,120 --> 00:07:35,160
I just need a subject that's remotely interesting, which is nothing

155
00:07:35,160 --> 00:07:36,520
you'll find on this podcast.

156
00:07:37,080 --> 00:07:41,080
And then a reasonably good recording, which you'll sometimes find on this podcast.

157
00:07:41,900 --> 00:07:44,740
This is not the podcast to compare against other ones.

158
00:07:44,740 --> 00:07:48,460
This is just your guilty pleasure to do while you're cleaning the bathroom.

159
00:07:48,660 --> 00:07:50,740
You've listened to 99% of visible.

160
00:07:50,780 --> 00:07:51,340
I have.

161
00:07:51,860 --> 00:07:52,260
Okay.

162
00:07:52,620 --> 00:07:54,020
Where did they fit?

163
00:07:54,620 --> 00:07:55,420
They're in the suites.

164
00:07:55,420 --> 00:07:58,780
But if I was going to put them on a spectrum from horribly recorded to

165
00:07:58,780 --> 00:08:03,140
overproduced, they're definitely a little bit more on the produced side,

166
00:08:03,300 --> 00:08:04,820
but they don't overdo it.

167
00:08:04,980 --> 00:08:06,180
They don't overdo it.

168
00:08:06,660 --> 00:08:10,500
And Roman Mars has the, his voice.

169
00:08:10,500 --> 00:08:11,820
I could just listen to forever.

170
00:08:12,100 --> 00:08:13,900
He does another podcast.

171
00:08:14,340 --> 00:08:17,940
If you know that it's multiple, but have you looked, my favorite is what

172
00:08:17,940 --> 00:08:20,300
Trump can teach us about constitutional law.

173
00:08:20,780 --> 00:08:22,020
I listened to that one.

174
00:08:22,020 --> 00:08:22,460
I don't.

175
00:08:24,380 --> 00:08:24,740
Yeah.

176
00:08:25,300 --> 00:08:30,740
It's mostly his neighbor, the lawyer talking, but she's really good as well.

177
00:08:30,740 --> 00:08:34,220
And again, the sounds good as production and I'm interested in the topic.

178
00:08:34,220 --> 00:08:35,100
It's great stuff.

179
00:08:35,340 --> 00:08:39,980
So if you want me to listen to your podcast, just do a decent job on sound.

180
00:08:40,580 --> 00:08:42,860
Don't add too many sound effects and things.

181
00:08:42,860 --> 00:08:45,740
Although I do add them sometimes to our podcast, not too many.

182
00:08:46,340 --> 00:08:46,660
Yeah.

183
00:08:46,660 --> 00:08:48,460
I haven't done a mail bag in forever.

184
00:08:48,780 --> 00:08:49,180
Yeah.

185
00:08:49,180 --> 00:08:50,300
Big.

186
00:08:51,140 --> 00:08:51,460
Yeah.

187
00:08:51,740 --> 00:08:58,300
Cause we can't read one podcast done by pretty sure it's the BBC.

188
00:08:58,780 --> 00:08:59,260
Maybe not.

189
00:08:59,300 --> 00:08:59,660
No.

190
00:08:59,740 --> 00:09:01,980
Cause it's, it's bashing the BBC.

191
00:09:02,180 --> 00:09:04,820
Have you heard of the podcast stuff?

192
00:09:04,860 --> 00:09:06,500
The British stole?

193
00:09:06,820 --> 00:09:07,940
No, I have not.

194
00:09:08,460 --> 00:09:08,780
Okay.

195
00:09:08,780 --> 00:09:16,460
It, the guy is the, the narrator, the primary person there is, um, Australian.

196
00:09:16,940 --> 00:09:21,660
Uh, so I think it's actually probably based out of Australia, but it's fascinating.

197
00:09:21,660 --> 00:09:23,140
Like, holy crap.

198
00:09:23,140 --> 00:09:26,980
The British stole a lot of crap over the years with the colonization.

199
00:09:27,340 --> 00:09:31,700
There is not for someone with a growth mindset, like AB testing,

200
00:09:31,700 --> 00:09:36,220
listeners, there is just not enough time in the world to acquire the

201
00:09:36,220 --> 00:09:37,940
knowledge we would like to acquire.

202
00:09:38,380 --> 00:09:38,900
Yeah.

203
00:09:38,980 --> 00:09:44,140
You know, for me, I, I, I like, okay, let's listen to stuff.

204
00:09:44,620 --> 00:09:45,540
The British stole.

205
00:09:45,580 --> 00:09:47,820
And for me, I'm like, you know what?

206
00:09:47,900 --> 00:09:50,580
Um, use me and teach me something and that's it.

207
00:09:51,100 --> 00:09:55,340
Like my bar that high, that high on that one, 99% invisible.

208
00:09:55,340 --> 00:09:59,220
Like I have a passion around design of all things.

209
00:09:59,220 --> 00:10:03,700
Like one of the things you, when I have shared his experience in the architecture

210
00:10:03,700 --> 00:10:10,860
role, right, we've had to design things and it's fun for me to learn the design.

211
00:10:11,660 --> 00:10:14,100
Of all random things, right?

212
00:10:14,100 --> 00:10:15,700
It's like, okay, why is that there?

213
00:10:15,700 --> 00:10:18,700
Like, um, I bought Roman Mars's book.

214
00:10:19,180 --> 00:10:19,460
Ooh.

215
00:10:19,460 --> 00:10:19,860
Right.

216
00:10:20,540 --> 00:10:21,660
Do you know what a love lock is?

217
00:10:21,660 --> 00:10:24,060
I would only get the audio book read by him.

218
00:10:24,540 --> 00:10:27,820
Oh, I don't know if that's, I don't know if that exists, but I love it.

219
00:10:28,260 --> 00:10:30,380
Have you ever heard of the term a love lock?

220
00:10:30,780 --> 00:10:31,100
No.

221
00:10:31,940 --> 00:10:32,420
Okay.

222
00:10:32,820 --> 00:10:34,260
I got the book.

223
00:10:34,460 --> 00:10:36,980
It was one of the first chapters I had read it.

224
00:10:37,420 --> 00:10:41,940
And then I went for a hike to the, um, snow call me falls.

225
00:10:42,420 --> 00:10:44,620
They added the very end of it.

226
00:10:44,980 --> 00:10:49,420
There is a chain link fence and there is a crap load of.

227
00:10:50,020 --> 00:10:50,940
Oh, okay.

228
00:10:50,940 --> 00:10:51,340
I know.

229
00:10:51,380 --> 00:10:52,300
I know what those are.

230
00:10:52,300 --> 00:10:53,700
I didn't know they had a name like that.

231
00:10:53,700 --> 00:10:56,220
I have seen thousands of those around the world.

232
00:10:56,540 --> 00:10:56,860
Yeah.

233
00:10:56,900 --> 00:10:58,500
Those are called love locks.

234
00:10:59,340 --> 00:11:05,380
And, and I've always wondered like, what the hell is all of these locks here?

235
00:11:05,620 --> 00:11:06,500
They throw the keys.

236
00:11:06,540 --> 00:11:07,980
They throw the keys into the waterfall.

237
00:11:08,260 --> 00:11:08,540
Right.

238
00:11:08,540 --> 00:11:10,980
They, they write, you know, they're locking their love.

239
00:11:11,020 --> 00:11:16,100
A plus B with a heart and then check the key into the thing.

240
00:11:16,700 --> 00:11:20,970
Chucking the key, you know, fish, that's probably bad, but you

241
00:11:20,970 --> 00:11:25,190
know, symbolic symbolism, planet money, free economics.

242
00:11:25,230 --> 00:11:28,310
These are all like freaking omics, especially.

243
00:11:28,310 --> 00:11:31,430
That's what got me into data science, but not necessarily

244
00:11:31,430 --> 00:11:32,950
for economics, but that topic.

245
00:11:33,470 --> 00:11:33,710
Right.

246
00:11:34,230 --> 00:11:38,750
So it's always fun to still connect with the data science and

247
00:11:38,750 --> 00:11:40,270
the customer behavior aspect.

248
00:11:40,550 --> 00:11:41,470
No, it's cool.

249
00:11:41,710 --> 00:11:47,150
We can talk more about new podcasts in our upcoming end of year episode, but

250
00:11:47,790 --> 00:11:48,150
I just,

251
00:11:49,350 --> 00:11:56,330
anime, um, new season of invincible is out.

252
00:11:56,530 --> 00:11:58,770
Not really anime, but close enough.

253
00:11:59,530 --> 00:12:00,690
It's I love that show.

254
00:12:01,050 --> 00:12:03,050
That one just completely turned me off.

255
00:12:03,090 --> 00:12:04,490
Like, yeah, that's just like dark.

256
00:12:05,270 --> 00:12:05,670
Yeah.

257
00:12:06,270 --> 00:12:10,630
My daughter, we're spending a lot of quality time together.

258
00:12:10,750 --> 00:12:19,320
Um, and she has been a fan of anime for a while and we just watched, uh,

259
00:12:19,360 --> 00:12:25,090
one called demon slayer and, oh my God, is it good?

260
00:12:25,610 --> 00:12:30,890
I got a couple topics to get through today and I forget what those are.

261
00:12:30,890 --> 00:12:31,530
No, they're right here.

262
00:12:31,970 --> 00:12:36,170
Uh, one I called out on my five for Friday and I shared with you.

263
00:12:36,170 --> 00:12:37,610
I don't know if you had a chance to look at it.

264
00:12:38,250 --> 00:12:43,290
Is our, our buddy front of the show, Jason Arbin did the thing you can do

265
00:12:43,290 --> 00:12:47,550
with chat GPT where you can give it a bunch more information and make

266
00:12:47,550 --> 00:12:52,620
your own little chat engine, which basically it's Chad GPT plus plus.

267
00:12:53,540 --> 00:12:55,380
And I've seen a few of these floating around.

268
00:12:55,660 --> 00:12:58,540
And I think you have to be on the paid plan to be able to use them

269
00:12:58,660 --> 00:12:59,660
to be able to get at it.

270
00:12:59,660 --> 00:13:00,940
So that's, that's what it is.

271
00:13:01,420 --> 00:13:08,440
But he sucked in a whole bunch of information from what he considers expert

272
00:13:08,440 --> 00:13:12,660
testers, so he included Brent and I, regardless of our status within

273
00:13:12,660 --> 00:13:13,620
the testing community.

274
00:13:14,220 --> 00:13:19,580
And then, uh, it just works like GPT and I'm going to tangent there.

275
00:13:20,180 --> 00:13:25,260
And I saw yet another post of like, I don't know what some

276
00:13:25,580 --> 00:13:29,980
luminaries hate about chat GPT, but they were mad that it couldn't

277
00:13:29,980 --> 00:13:31,180
alphabetize for them.

278
00:13:31,780 --> 00:13:33,860
And again, use it for what it's for.

279
00:13:33,860 --> 00:13:37,420
It's powerful, or you can, or you can find things that it won't do

280
00:13:37,420 --> 00:13:38,620
and get mad at your call.

281
00:13:38,860 --> 00:13:43,740
But anyway, Jason, uh, made this thing, pulling in information from

282
00:13:43,740 --> 00:13:44,960
expert testers all over the place.

283
00:13:44,960 --> 00:13:47,980
And I asked it, you know, we've talked about, and again, I'm not going to

284
00:13:48,020 --> 00:13:52,300
chuck James under the bus, James Bach under the bus, and it's not on the podcast.

285
00:13:52,940 --> 00:13:57,740
Uh, we have different approaches to quality and testing and that's fair.

286
00:13:57,740 --> 00:13:58,660
He can do his thing.

287
00:13:58,660 --> 00:13:59,500
We'll do ours.

288
00:13:59,540 --> 00:14:02,060
Uh, I think he's done some questionable things as a human.

289
00:14:02,340 --> 00:14:05,660
Again, not going to, that's not where the topic is going to be here today.

290
00:14:06,180 --> 00:14:10,920
But I was curious because we do kind of, we cross paths in a weird way.

291
00:14:10,920 --> 00:14:16,940
We have occasionally a sort of distant respect for each other where we leave

292
00:14:16,940 --> 00:14:19,940
each other alone, we chatted on the phone before we said, okay, blah, blah, blah.

293
00:14:20,540 --> 00:14:21,280
He'll do his thing.

294
00:14:21,280 --> 00:14:22,020
I'll do mine.

295
00:14:23,040 --> 00:14:24,520
That was many, many years ago.

296
00:14:24,720 --> 00:14:28,200
And then lately somebody brought up the modern testing principles and his

297
00:14:28,200 --> 00:14:31,680
reply was Alan, Alan's work is damaging the craft of testing.

298
00:14:31,680 --> 00:14:33,400
So I ignored that anyway.

299
00:14:33,440 --> 00:14:38,440
Drama aside, one thing I like to do as part of critical thinking is when I

300
00:14:38,440 --> 00:14:42,960
hear something somebody doesn't agree with is I want to try and do as

301
00:14:42,960 --> 00:14:47,200
empathetic humans is put ourselves in their shoes and wonder kind of

302
00:14:47,200 --> 00:14:48,320
where they're coming from.

303
00:14:48,320 --> 00:14:50,120
How can I see things from their side?

304
00:14:50,600 --> 00:14:54,040
So the way I did it with chat GPT was one simple question.

305
00:14:54,400 --> 00:14:57,160
Now I'm not going to read the whole answer, although I think it's very good.

306
00:14:58,080 --> 00:15:01,680
But I asked it, how would you compare the approach to quality between

307
00:15:01,680 --> 00:15:03,040
Alan Page and James Bach?

308
00:15:03,600 --> 00:15:04,920
And I kind of was unfair.

309
00:15:04,920 --> 00:15:08,920
I said quality and not testing, but so I probably led the witness, but

310
00:15:09,120 --> 00:15:11,920
chat GPT gave a very fair answer.

311
00:15:12,320 --> 00:15:13,560
Blah, blah, blah.

312
00:15:14,100 --> 00:15:15,320
I am not an expert.

313
00:15:15,640 --> 00:15:17,600
Alan known for his work at Microsoft.

314
00:15:17,760 --> 00:15:18,760
I wouldn't say that.

315
00:15:19,720 --> 00:15:23,720
I worked on let's list some of the products I've worked on a windows

316
00:15:23,720 --> 00:15:24,280
millennium.

317
00:15:24,560 --> 00:15:29,090
There's a lot of hate there and well, there's some, I will list things

318
00:15:29,090 --> 00:15:32,890
people like, but I was involved in the quality of both windows millennium

319
00:15:33,250 --> 00:15:34,690
and Microsoft teams.

320
00:15:34,730 --> 00:15:39,770
Please send your hate mail to Alan care of a B testing at the north bowl.com.

321
00:15:39,970 --> 00:15:44,930
In the answer talks about where I focus on business value and team

322
00:15:44,930 --> 00:15:49,290
responsibility, data-driven approaches, evolving the test to roll.

323
00:15:49,730 --> 00:15:51,250
All stuff you've heard here.

324
00:15:52,000 --> 00:15:55,840
Whereas James is again, context-driven testing, exploratory testing,

325
00:15:55,840 --> 00:16:00,640
critical thinking, craftsmanship, and a skeptical approach to automation.

326
00:16:00,640 --> 00:16:03,200
That that's all we know where we're coming from, but the comparison

327
00:16:03,200 --> 00:16:04,320
is actually pretty interesting.

328
00:16:04,960 --> 00:16:06,800
It is in perspective on quality.

329
00:16:06,800 --> 00:16:09,600
It says Alan, and this is actually, I have nothing to argue with here.

330
00:16:09,600 --> 00:16:11,640
I don't know if, I mean, the question was fair.

331
00:16:11,680 --> 00:16:13,440
I don't know if James would argue either of us.

332
00:16:13,760 --> 00:16:15,520
It's kind of worth bringing up and getting your thoughts.

333
00:16:15,520 --> 00:16:16,080
I read it.

334
00:16:16,080 --> 00:16:19,040
And just so you're aware, I read every one of these things.

335
00:16:20,280 --> 00:16:20,800
So I'll read it.

336
00:16:20,800 --> 00:16:23,800
Because I was just like, I was just like, yep, check.

337
00:16:23,800 --> 00:16:24,080
Yeah.

338
00:16:24,800 --> 00:16:25,040
Yeah.

339
00:16:25,080 --> 00:16:26,160
It's, it's really good.

340
00:16:26,160 --> 00:16:29,600
Nothing I, and I, again, I think it's fair and I love fair.

341
00:16:30,080 --> 00:16:33,600
And the summary, the summary I found fascinating as well.

342
00:16:33,600 --> 00:16:36,800
Alan is quality in a broader business and team context.

343
00:16:36,800 --> 00:16:37,320
True.

344
00:16:37,800 --> 00:16:41,400
Bock on the other hand, focus is more on the skill and judgment of the tester.

345
00:16:41,720 --> 00:16:47,480
It's really made me think, and in fairness to James, we are doing two different things.

346
00:16:48,200 --> 00:16:52,900
James wants better testing and I want better quality.

347
00:16:52,900 --> 00:16:57,060
And I could argue on my high horse that ultimately quality is what matters.

348
00:16:57,060 --> 00:17:02,020
And I think James wants better testing or does James want better testers?

349
00:17:02,580 --> 00:17:04,740
I think he wants people that do better testing.

350
00:17:04,740 --> 00:17:09,220
He's, I think he's, I would say he's involved in the craft of software testing.

351
00:17:09,220 --> 00:17:13,220
He wants testers who can have that, that deep critical thinking approach.

352
00:17:13,220 --> 00:17:14,100
I think that's fair.

353
00:17:14,100 --> 00:17:15,860
And I think quality comes out of that.

354
00:17:15,860 --> 00:17:18,020
I'm focusing on the outcome purely.

355
00:17:18,020 --> 00:17:21,460
He's focusing on a root cause that will get likely to the same outcome.

356
00:17:21,460 --> 00:17:28,660
Well, so again, I'm going to push back on that because I do think James is likely to

357
00:17:29,780 --> 00:17:32,900
write the critical distance concept.

358
00:17:32,900 --> 00:17:37,620
Like if he was focused on better testing, then why wouldn't he be supportive of our

359
00:17:37,620 --> 00:17:38,820
approach of whole team?

360
00:17:39,380 --> 00:17:40,340
Devs can test.

361
00:17:40,900 --> 00:17:45,780
I don't think that, well, the devs contest thing is that that's a whole,

362
00:17:46,700 --> 00:17:47,180
right?

363
00:17:47,180 --> 00:17:50,540
I don't want to, it's not fair for me to try and speak for him.

364
00:17:50,540 --> 00:17:53,740
I can look at the comments of chat GPT and interpret those.

365
00:17:53,740 --> 00:17:55,260
I don't want to try and speak for him.

366
00:17:55,900 --> 00:17:59,260
I think a lot of things, he just looks at what we do and says,

367
00:17:59,260 --> 00:18:01,180
you guys care about delivery.

368
00:18:01,180 --> 00:18:02,780
You're, you're, you're about something different.

369
00:18:03,420 --> 00:18:05,180
Developers being able to test.

370
00:18:05,180 --> 00:18:06,460
That's the thing he pushes back on.

371
00:18:06,540 --> 00:18:11,900
He thinks it requires he, his belief is in the specialist to do that, that deep work.

372
00:18:11,900 --> 00:18:16,220
And again, some other comparisons, but the summary I'll read to you the whole thing,

373
00:18:16,220 --> 00:18:18,620
which is, and then I'll get more comments from you, Brent.

374
00:18:18,620 --> 00:18:23,020
In summary, Alan's approach is more systemic, focusing on the role of testing within the

375
00:18:23,020 --> 00:18:25,980
broader context of software dev and business objectives.

376
00:18:26,780 --> 00:18:30,940
Well, James approaches more centered on the individual testers skills and the

377
00:18:30,940 --> 00:18:34,460
adaptability of testing practices to the context at hand.

378
00:18:34,460 --> 00:18:37,740
Both perspectives offer valuable insights in the different dimensions of software

379
00:18:37,740 --> 00:18:40,300
quality and testing, which is kind of what I said about two minutes ago.

380
00:18:40,940 --> 00:18:42,380
We're focused on different things.

381
00:18:42,380 --> 00:18:45,260
We don't, we don't do the same thing anymore.

382
00:18:45,260 --> 00:18:47,980
There was a time when James Bock and I were both testers.

383
00:18:47,980 --> 00:18:50,220
We're not, I don't want to talk a ton about him.

384
00:18:50,220 --> 00:18:53,180
I don't want to talk about James, but he's not here too.

385
00:18:53,180 --> 00:18:55,580
I don't want to say anything where I feel like James have to defend himself.

386
00:18:55,580 --> 00:19:01,340
It's not fair, but I feel like this is a pretty fair comparison of where we're coming from

387
00:19:01,340 --> 00:19:04,860
and where some, where some conflict may be.

388
00:19:04,860 --> 00:19:13,260
And honestly, I wonder if, you know, sometimes if I generate this conflict, because I am so adamant

389
00:19:13,260 --> 00:19:20,220
that the ultimate goal is quality, therefore discounting the craft of testing.

390
00:19:21,510 --> 00:19:26,550
I'm, I am on Jason's train.

391
00:19:26,550 --> 00:19:28,310
Oh, so you asked it something.

392
00:19:28,870 --> 00:19:29,270
I did.

393
00:19:29,750 --> 00:19:33,030
Duh, it will be edited out by the time you hear this listener.

394
00:19:33,030 --> 00:19:37,110
But as I was saying that last thing that, and, and Brent has no idea what I said,

395
00:19:37,110 --> 00:19:39,670
cause he was typing furiously.

396
00:19:39,670 --> 00:19:40,470
But what did you ask it?

397
00:19:40,470 --> 00:19:41,110
What did you ask?

398
00:19:41,110 --> 00:19:45,910
I actually did have what it is, but the second you challenged me on that, it did flush.

399
00:19:45,910 --> 00:19:46,150
Yes.

400
00:19:46,710 --> 00:19:51,110
I asked it, what are the key conflicts between Alan Page and James Bock?

401
00:19:51,670 --> 00:19:53,750
Oh, didn't ask that.

402
00:19:54,390 --> 00:19:55,430
Fill me in Jedi.

403
00:19:56,070 --> 00:19:58,710
Structure versus flexibility.

404
00:19:58,710 --> 00:20:03,030
Alan's approach involves more structured testing process.

405
00:20:03,030 --> 00:20:03,270
What?

406
00:20:03,910 --> 00:20:05,750
I, I, I wonder.

407
00:20:05,750 --> 00:20:06,950
I think that's backward.

408
00:20:06,950 --> 00:20:10,950
In contrast, James promotes a more flexible, less formal approach,

409
00:20:10,950 --> 00:20:12,950
emphasizing exploratory testing.

410
00:20:13,590 --> 00:20:13,830
Right.

411
00:20:13,830 --> 00:20:14,710
That part is true.

412
00:20:15,270 --> 00:20:17,670
And I'm wondering, actually, here's the thing.

413
00:20:17,670 --> 00:20:22,870
I'm wondering how much Jason train this or how much the training was based off of your book.

414
00:20:23,670 --> 00:20:23,990
Because.

415
00:20:24,070 --> 00:20:26,470
Oh, it does pull that in.

416
00:20:27,270 --> 00:20:28,870
It would pull that in.

417
00:20:28,870 --> 00:20:29,190
Yeah.

418
00:20:29,830 --> 00:20:31,110
My data is weird.

419
00:20:32,150 --> 00:20:38,870
If we were comparing the Alan Page of 10 years ago or 15 years ago, yeah, that might be true.

420
00:20:38,870 --> 00:20:40,230
Well, do this, do this.

421
00:20:40,230 --> 00:20:44,390
I'm going to take the time for you to type this, ask it to disregard the information from

422
00:20:44,390 --> 00:20:48,550
how we test software at Microsoft and make that same and asking the same question again.

423
00:20:48,550 --> 00:20:50,550
Rewrite, but disregard this.

424
00:20:50,550 --> 00:20:57,800
We regard the information from how we test Microsoft.

425
00:20:57,800 --> 00:20:59,240
Does it give the same answer?

426
00:20:59,240 --> 00:21:02,040
Previously was structure versus flexibility.

427
00:21:02,600 --> 00:21:07,480
Now it's structured versus adaptive and you're still structured.

428
00:21:07,480 --> 00:21:07,960
Weird.

429
00:21:07,960 --> 00:21:09,080
Like, yeah.

430
00:21:09,640 --> 00:21:10,280
Okay.

431
00:21:10,280 --> 00:21:10,600
All right.

432
00:21:11,320 --> 00:21:13,160
Anyway, I there's a.

433
00:21:13,160 --> 00:21:14,600
Don't you want to know the others?

434
00:21:14,600 --> 00:21:15,000
I do.

435
00:21:15,000 --> 00:21:15,320
I do.

436
00:21:15,320 --> 00:21:15,640
I guess.

437
00:21:16,280 --> 00:21:17,480
Already discarded.

438
00:21:17,480 --> 00:21:19,880
Everything else because the first answer was wrong.

439
00:21:19,880 --> 00:21:20,280
Yeah.

440
00:21:20,280 --> 00:21:22,200
And the third answer is also wrong.

441
00:21:23,160 --> 00:21:23,720
All right.

442
00:21:23,720 --> 00:21:25,400
So here's something that I did do.

443
00:21:26,280 --> 00:21:30,360
If you are ready for attention, we're always ready for a tangent on the EBT.

444
00:21:30,360 --> 00:21:31,800
I need a tangent sound effect.

445
00:21:34,200 --> 00:21:42,360
How would you compare the approach to quality between Alan Page and Brent Jensen?

446
00:21:46,310 --> 00:21:48,950
So what the world doesn't know is we're actually the same person.

447
00:21:50,890 --> 00:21:52,330
He did that fine.

448
00:21:52,330 --> 00:21:57,930
So on the background, known for his work at Microsoft and co-authoring the book,

449
00:21:57,930 --> 00:22:03,460
but the fact that it brings out the book, like, really makes me think it's like it's over.

450
00:22:03,460 --> 00:22:05,300
It might be over pivoting.

451
00:22:05,300 --> 00:22:05,540
Yeah.

452
00:22:05,540 --> 00:22:09,780
But you may have the same problem I do in terms of like the last decade.

453
00:22:09,780 --> 00:22:10,980
I've been pigeonholed.

454
00:22:10,980 --> 00:22:11,700
Yeah.

455
00:22:11,700 --> 00:22:11,940
Yeah.

456
00:22:12,820 --> 00:22:17,940
While Brent Jensen's specific approach to quality in software testing is less documented

457
00:22:17,940 --> 00:22:25,540
in public sources, based on industry trends and practices, one might infer that his approach

458
00:22:25,540 --> 00:22:28,100
would focus on pragmatism and efficiency.

459
00:22:29,380 --> 00:22:29,700
Okay.

460
00:22:29,700 --> 00:22:31,140
So it knows who I am.

461
00:22:32,330 --> 00:22:36,060
I think I haven't tested to see if it's...

462
00:22:36,060 --> 00:22:36,380
Yeah.

463
00:22:36,380 --> 00:22:37,580
It could be making it up.

464
00:22:37,580 --> 00:22:42,380
I wonder if I don't want to go too deep into this, but Jason, I know you're listening

465
00:22:42,380 --> 00:22:45,820
because you get mad when we don't have a podcast every two weeks.

466
00:22:45,820 --> 00:22:51,580
Make sure you feed it the transcribed, the transcriptions of our podcasts.

467
00:22:53,030 --> 00:22:53,430
I'm going to do...

468
00:22:53,430 --> 00:22:56,070
Here Jason, you didn't get paid for any of this, but do a bunch more work.

469
00:22:56,710 --> 00:22:59,030
I'm going to do Mickey Duck.

470
00:22:59,030 --> 00:23:04,630
I'm going to compare Alan Page to Mickey Duck, which I just made up.

471
00:23:04,630 --> 00:23:05,030
Of course you do.

472
00:23:05,030 --> 00:23:07,190
Because Mickey Mouse might be in here.

473
00:23:07,990 --> 00:23:08,390
Okay.

474
00:23:08,390 --> 00:23:12,790
Mickey Duck is not a recognized figure in a software testing group.

475
00:23:12,790 --> 00:23:14,550
Not part of the expert field.

476
00:23:15,190 --> 00:23:16,230
So he does have something...

477
00:23:16,230 --> 00:23:17,190
You know what though?

478
00:23:17,190 --> 00:23:19,510
Did you ask it about Gent Brinson?

479
00:23:19,510 --> 00:23:19,990
I didn't.

480
00:23:20,790 --> 00:23:21,910
I could do that.

481
00:23:21,910 --> 00:23:23,510
We are losing listeners.

482
00:23:23,510 --> 00:23:25,750
We are doubt for our three listeners in round one.

483
00:23:25,750 --> 00:23:26,580
So let me go back.

484
00:23:26,580 --> 00:23:30,740
Let me go back to our approaches.

485
00:23:32,740 --> 00:23:38,340
Alan's approach is likely to be more holistic and integrated into every stage of the software

486
00:23:38,340 --> 00:23:42,180
development process, focusing on the overall system quality.

487
00:23:42,820 --> 00:23:49,060
In contrast, and I'll tell you, I am already disturbed by the term contrast being used here.

488
00:23:49,700 --> 00:23:56,580
Brinson's approach as inferred might be more focused on immediate and practical

489
00:23:57,300 --> 00:23:59,940
outcomes, emphasizing quick feedback loops.

490
00:24:01,430 --> 00:24:01,830
Okay.

491
00:24:01,830 --> 00:24:02,070
Yeah.

492
00:24:02,070 --> 00:24:03,110
It's making crap up.

493
00:24:03,110 --> 00:24:03,590
It's fine.

494
00:24:04,150 --> 00:24:06,390
But you didn't do that, but it's guessing.

495
00:24:07,750 --> 00:24:08,390
So anyway...

496
00:24:08,550 --> 00:24:13,900
I do emphasize, but it's not really a contrast.

497
00:24:14,780 --> 00:24:15,260
Not really.

498
00:24:15,980 --> 00:24:16,940
Let me ask it.

499
00:24:16,940 --> 00:24:17,900
Let me do one last thing.

500
00:24:17,900 --> 00:24:18,860
No, we're done with questions.

501
00:24:18,860 --> 00:24:20,220
We're going to go on to the rest of the podcast.

502
00:24:20,220 --> 00:24:23,820
I have another topic to cover and we got like 20 minutes here.

503
00:24:24,540 --> 00:24:26,620
Main thing here is very cool stuff.

504
00:24:26,620 --> 00:24:27,580
Going to plug it.

505
00:24:27,580 --> 00:24:33,260
You can find the link to this little chat GPT wonder on my latest five for Friday.

506
00:24:33,260 --> 00:24:35,900
And you can ask questions and submit.

507
00:24:35,900 --> 00:24:41,610
Oh, we should get it to submit questions to the mail bank.

508
00:24:41,610 --> 00:24:45,130
What are good questions for Alan and Brent to answer on their podcast?

509
00:24:45,770 --> 00:24:47,290
We'll have to type that one.

510
00:24:47,290 --> 00:24:47,690
Okay.

511
00:24:47,690 --> 00:24:49,530
I'm not going to go into that row there.

512
00:24:50,090 --> 00:24:56,660
I wanted to follow up on something we started talking about briefly last time.

513
00:24:57,220 --> 00:24:58,420
Oh, sorry.

514
00:24:59,670 --> 00:25:00,470
This is bad.

515
00:25:01,740 --> 00:25:02,620
Are you still with Chashing?

516
00:25:02,620 --> 00:25:03,100
I am.

517
00:25:03,980 --> 00:25:07,900
So, so I, I, I, what are the key conflicts between you and me?

518
00:25:08,540 --> 00:25:08,780
Okay.

519
00:25:10,040 --> 00:25:14,600
You dude, you are old school according to this thing.

520
00:25:14,600 --> 00:25:21,000
Like even between you and me, I'm all about rapid agile and you are like structured.

521
00:25:22,840 --> 00:25:23,560
Systematic.

522
00:25:24,520 --> 00:25:27,240
Jason, stupid bot.

523
00:25:28,310 --> 00:25:31,300
Now pause this and go fix it.

524
00:25:31,300 --> 00:25:31,620
Okay.

525
00:25:31,620 --> 00:25:33,220
So anyway, on with the podcast.

526
00:25:34,100 --> 00:25:37,220
I want to talk about, so I'm on the podcast today with, with of course,

527
00:25:37,220 --> 00:25:38,020
Gent Brinson.

528
00:25:38,580 --> 00:25:42,180
I want to talk about a more famous Brent, a little bit more.

529
00:25:42,180 --> 00:25:42,980
Okay.

530
00:25:42,980 --> 00:25:43,460
Stop.

531
00:25:43,460 --> 00:25:44,740
No, I just want to do one more.

532
00:25:45,460 --> 00:25:46,180
One more.

533
00:25:46,180 --> 00:25:48,500
Is my podcast too well.

534
00:25:50,580 --> 00:25:57,880
The role of data and metrics pages likely you dude, I lost your audio.

535
00:25:58,570 --> 00:25:59,290
I hit mute.

536
00:25:59,930 --> 00:26:05,370
It's likely use of data metrics to drive testing decisions.

537
00:26:05,370 --> 00:26:10,330
My contrast with a more intuitive experience based approach, like someone

538
00:26:10,330 --> 00:26:15,930
like Jensen might favor assuming he leads towards a less data driven method.

539
00:26:15,930 --> 00:26:16,730
Okay.

540
00:26:16,730 --> 00:26:18,250
I don't know which one's better.

541
00:26:18,250 --> 00:26:24,570
So this GPT knows my name knows something about me, but not nearly enough.

542
00:26:25,210 --> 00:26:28,730
And has made a decision about you and it's wrong.

543
00:26:28,730 --> 00:26:30,730
Remember, it's just, no, I get it.

544
00:26:30,730 --> 00:26:31,130
Yeah.

545
00:26:31,130 --> 00:26:33,130
Remember how the, you know, how these things work.

546
00:26:33,130 --> 00:26:37,450
It's just you, a bunch of our work has been tokenized and it's trying to make

547
00:26:37,450 --> 00:26:39,610
up words, it doesn't know what the words mean.

548
00:26:39,610 --> 00:26:43,130
It's just making up words in an order that, that is grammatically correct.

549
00:26:43,130 --> 00:26:47,610
So anyway, I want to talk more about Brent Geller a little bit and lead

550
00:26:47,610 --> 00:26:49,850
that into a discussion of heroes.

551
00:26:50,570 --> 00:26:54,150
Do not ask Chad GPT who Brent Geller is.

552
00:26:54,150 --> 00:26:57,110
Brent Geller is Brent from the Phoenix.

553
00:26:57,110 --> 00:26:57,670
Thank you.

554
00:26:57,750 --> 00:26:59,670
I figured I'd like, okay.

555
00:26:59,670 --> 00:27:01,110
He's probably talking about that guy.

556
00:27:01,110 --> 00:27:01,670
Yeah.

557
00:27:01,670 --> 00:27:02,310
Heroes.

558
00:27:02,310 --> 00:27:04,870
So we talked, we talked about Brent a little last time.

559
00:27:04,870 --> 00:27:09,030
And I want to recap that whole thing, but Brent was the, he was the bottleneck

560
00:27:09,030 --> 00:27:10,630
because he was the expert.

561
00:27:10,630 --> 00:27:13,270
He was a knowledge silo.

562
00:27:13,830 --> 00:27:17,590
He kind of becomes the hero of the story as he, again, I hated him

563
00:27:17,590 --> 00:27:19,830
because he was fricking in the way.

564
00:27:19,830 --> 00:27:23,350
I want a root cause and see how we ever built a culture that got,

565
00:27:23,350 --> 00:27:26,470
got us to a place where one person was the bottleneck.

566
00:27:26,710 --> 00:27:31,590
One person was the bottleneck for all this stuff, but he did evolve and he was happy in the end.

567
00:27:31,590 --> 00:27:36,550
I think you could say he was both the victim and the hero at the same time,

568
00:27:37,270 --> 00:27:40,150
but definitely at the end, he becomes this agent of change.

569
00:27:40,150 --> 00:27:40,790
All good stuff.

570
00:27:40,790 --> 00:27:43,190
He grows up all good, happy ending.

571
00:27:43,190 --> 00:27:45,670
But it's made me think about heroes.

572
00:27:46,540 --> 00:27:49,580
The David Bowie song from the Berlin trilogy produced by Brian.

573
00:27:49,580 --> 00:27:51,580
No, heroes in the organization.

574
00:27:51,580 --> 00:27:55,940
You have, I don't know if you still believe this, but you in the past,

575
00:27:55,940 --> 00:28:01,620
you've said something like it's okay to have heroes if that's their job to be the hero.

576
00:28:02,220 --> 00:28:02,780
Is that true?

577
00:28:02,780 --> 00:28:04,140
Do I remember remembering?

578
00:28:04,140 --> 00:28:05,660
No, so that is true.

579
00:28:06,380 --> 00:28:15,780
And that is around the problem of heroes as sort of a knowledge expert.

580
00:28:17,140 --> 00:28:19,460
Brent and the Phoenix project, right?

581
00:28:20,220 --> 00:28:24,140
I don't think he started off his day intending to be a hero.

582
00:28:24,810 --> 00:28:34,090
What happened is, as you listen to the story, what happened is he was really passionate about his job.

583
00:28:35,210 --> 00:28:35,610
He was.

584
00:28:35,610 --> 00:28:37,370
And I think you're right about that.

585
00:28:37,370 --> 00:28:47,690
And when people discovered his passion, that began sort of the snowball that became the avalanche.

586
00:28:47,690 --> 00:28:55,450
And without anyone there to say, hey, this needs to be knowledge shared, then it very quickly

587
00:28:55,450 --> 00:29:01,050
becomes a situation where like someone like Brent, when you have a knowledge bottleneck,

588
00:29:02,090 --> 00:29:09,530
it's kind of like a person who, you know, fell off the ocean liner and has been treading water

589
00:29:09,530 --> 00:29:13,690
for five, six hours and is now struggling, right?

590
00:29:13,690 --> 00:29:15,290
Brent, I think we can agree.

591
00:29:15,290 --> 00:29:18,490
You know, I don't like how he got himself in this situation, but I think we agree that

592
00:29:18,490 --> 00:29:22,410
Brent from the Phoenix project, his intentions were good.

593
00:29:22,410 --> 00:29:24,810
He did not want to be the bottleneck.

594
00:29:24,810 --> 00:29:27,210
He did not want to work 80 hours a week.

595
00:29:27,210 --> 00:29:30,010
He didn't want to be the only person who knew that stuff.

596
00:29:30,010 --> 00:29:32,810
Just that happened to him within their culture.

597
00:29:32,810 --> 00:29:37,370
I was rereading that part of the Phoenix project and I thought of something I wanted to throw at you

598
00:29:37,370 --> 00:29:41,770
because there are sort of the Brent anti-hero.

599
00:29:42,330 --> 00:29:49,290
So there are, again, expertise is expertise, but someone who's the bottleneck who wants

600
00:29:49,290 --> 00:29:56,090
to be the bottleneck becomes a gatekeeper. Someone who's a knowledge silo will hoard their knowledge

601
00:29:56,090 --> 00:30:01,370
in order to provide value and be able to have, be able to be that hero.

602
00:30:01,370 --> 00:30:02,730
We've worked with these people in the past.

603
00:30:02,730 --> 00:30:03,130
Oh, yeah.

604
00:30:04,170 --> 00:30:08,570
I work with the people who refuse to share information because literally they would say

605
00:30:08,570 --> 00:30:10,810
out loud, that's the only reason I'm employed here.

606
00:30:10,810 --> 00:30:13,770
I need to be the only person that knows this for job security.

607
00:30:13,770 --> 00:30:14,650
I've heard that too.

608
00:30:15,450 --> 00:30:23,850
And for those type of people, like what, again, this is where I see, there's two things I say

609
00:30:23,850 --> 00:30:29,290
commonly, depending on where I'm at, either number one, then that needs to be their job.

610
00:30:29,290 --> 00:30:36,410
Like the type of hero who's essentially a firefighter, you know, critical and exceptional

611
00:30:36,410 --> 00:30:38,730
at diagnosing and putting out fires.

612
00:30:40,330 --> 00:30:44,490
In today's DevOps language, we might say that they're the DRI,

613
00:30:44,490 --> 00:30:46,170
or the designated responsibility.

614
00:30:47,050 --> 00:30:49,960
That should be their job. That's their job.

615
00:30:49,960 --> 00:30:55,960
Yeah. When there's a job is when there's a problem, they go in, or when there's a bottleneck

616
00:30:55,960 --> 00:30:59,080
or a problem, they go in and solve it or mitigate it until it's not a big problem anymore.

617
00:30:59,080 --> 00:30:59,480
I get that.

618
00:30:59,480 --> 00:30:59,960
Right.

619
00:30:59,960 --> 00:31:10,490
The type of hero that you describe, usually that's where I'll respond with,

620
00:31:10,490 --> 00:31:14,490
I want to remind everybody, hero is a four-letter word.

621
00:31:14,490 --> 00:31:15,130
Great.

622
00:31:15,130 --> 00:31:16,410
And this is where I want to get into.

623
00:31:16,410 --> 00:31:20,970
I want to get into the leadership aspect of this because I was reflecting back to earlier

624
00:31:20,970 --> 00:31:24,170
times at Microsoft, and this was definitely even better by the time I left.

625
00:31:24,170 --> 00:31:25,770
So I imagine it's even better now.

626
00:31:26,700 --> 00:31:34,140
But there were people who would hoard information or be a bottleneck or clean up their own mess

627
00:31:35,190 --> 00:31:41,830
so they could be recognized as the hero because they had leadership who would call out when heroes

628
00:31:41,830 --> 00:31:45,670
did things. I mean, you can remember stories like, I want to thank so-and-so for coming

629
00:31:45,670 --> 00:31:50,390
in and working all weekend to solve this problem that they created in the first place.

630
00:31:50,390 --> 00:31:57,350
So I want to talk about how as leaders in tech, how do we make sure we don't get that kind of

631
00:31:57,350 --> 00:32:01,110
hero? What are the preventative measures to make sure we, like I'm good with you.

632
00:32:01,110 --> 00:32:04,950
If you want to have somebody be the hero because their job is to be like the smoke jumper,

633
00:32:04,950 --> 00:32:10,230
I call them. That's fine. How do we prevent the people who want to be heroes because they think

634
00:32:10,950 --> 00:32:14,390
it's, they actually believe it's good for their career?

635
00:32:15,260 --> 00:32:16,300
How do we prevent them?

636
00:32:16,700 --> 00:32:18,700
So I think...

637
00:32:18,700 --> 00:32:21,580
I love the hero as a four-letter word thing. Maybe expand on that.

638
00:32:21,580 --> 00:32:28,060
Well, so I love, as you were saying, hey, maybe that's another place where Microsoft

639
00:32:28,060 --> 00:32:34,140
has softened over the years. And I'll say, yeah, it has. The hero of the type of,

640
00:32:34,140 --> 00:32:37,180
that we just described for Greg Keller, that's still there.

641
00:32:38,300 --> 00:32:39,420
That's still there.

642
00:32:39,420 --> 00:32:44,860
I think culturally that one may be easier to fix than the, I'll call them the anti-hero.

643
00:32:44,860 --> 00:32:49,500
It will be, no, actually, I think the other way is easier to fix.

644
00:32:50,060 --> 00:32:57,020
There has ever since, ever since, I was just thinking, a couple of things that come into play.

645
00:32:57,020 --> 00:33:03,580
Number one, a big portion of your review is not just on the stuff you've got done.

646
00:33:04,140 --> 00:33:09,980
It is also on how did you contribute to others and how did you incorporate others'

647
00:33:09,980 --> 00:33:19,560
feedback into your thing? And so as managers continue, as managers age out from the old

648
00:33:19,560 --> 00:33:25,560
school system and new managers are coming in more trained around this and things like the

649
00:33:25,560 --> 00:33:33,480
coaching habit. And here is one thing, if I were to do a big hypothesis that I had no proof on this,

650
00:33:33,480 --> 00:33:38,760
I would say hitting hard on growth versus fixed mindset was key here.

651
00:33:39,480 --> 00:33:39,960
Yeah.

652
00:33:39,960 --> 00:33:45,320
Because what you described as a hero, tell me how they can be more of a fixed mindset.

653
00:33:46,020 --> 00:33:49,780
No, I think you're 100% right. And this is really interesting.

654
00:33:49,780 --> 00:33:53,060
I was having a conversation when I think through these things, I have,

655
00:33:53,060 --> 00:33:57,620
when I think through things, I don't know answers to, I have conversations with chat GPT.

656
00:33:57,620 --> 00:34:05,780
And I told chat GPT, people who hoard information and are bottlenecks and want to be gatekeepers.

657
00:34:06,340 --> 00:34:11,140
Oh, no, actually I'll bring it up here. Dear chat GPT. I like to use

658
00:34:11,780 --> 00:34:15,460
dear and please and thank you with my computer counterparts. But I said,

659
00:34:16,470 --> 00:34:21,750
I'm discovering that I am hoarding information, gatekeeping people and overall slowing people

660
00:34:21,750 --> 00:34:25,980
down because I'm a jerk. What are some books I can read so I can improve?

661
00:34:26,620 --> 00:34:28,300
That's clever. That's clever.

662
00:34:29,180 --> 00:34:32,220
And of course, it led with How to Win Friends and Influence People,

663
00:34:32,220 --> 00:34:35,740
which I read a million years ago, but I wouldn't recommend. It's a good book.

664
00:34:35,740 --> 00:34:40,380
That Crucial Conversations, I think we've both read. Emotion Intelligence 2.0, which I read.

665
00:34:40,380 --> 00:34:42,300
I've read all of these so far.

666
00:34:42,300 --> 00:34:46,620
When I first learned I was an asshole, difficult conversations, how to discover what matters most.

667
00:34:46,620 --> 00:34:51,580
I've read that. The No Asshole Rule, which I'm rereading because it's actually very, very good.

668
00:34:51,580 --> 00:34:57,340
And then funny, you mentioned Growth Mindset, Mindset, the Carol Dweck book on the Growth

669
00:34:57,340 --> 00:35:01,900
Mindset. So those are the books I read to get better at this stuff.

670
00:35:02,650 --> 00:35:05,770
It did. ChatGPT, by the way, did congratulate me in my self-awareness.

671
00:35:09,500 --> 00:35:13,980
Very nice of it. Yeah, I just loaded up ChatGPT. I was going to ask it a question as well,

672
00:35:13,980 --> 00:35:15,020
but I forgot what it was.

673
00:35:16,060 --> 00:35:22,300
But as a quick tangent, this is asking ChatGPT to alphabetize your list of test case inputs,

674
00:35:22,300 --> 00:35:25,260
maybe not as good of an idea as it using it to think about, you know,

675
00:35:25,260 --> 00:35:28,380
help you become a little bit more self-aware than maybe you think you are.

676
00:35:28,380 --> 00:35:32,460
But anyway, I love it for stuff like this. And I said, you know what?

677
00:35:32,540 --> 00:35:38,540
There's a couple of these I'm going to go reread because even though I hope I don't do these things,

678
00:35:38,540 --> 00:35:44,860
I want to be able to make sure that I can navigate a world where I may run across some of these people.

679
00:35:44,860 --> 00:35:51,100
Yeah, and guide them. The biggest problem I've seen is that these folks,

680
00:35:51,660 --> 00:36:01,100
I remember the last person who told me straight to my face, yeah, I'm not going to mentor that

681
00:36:01,100 --> 00:36:06,940
person because then there'll be two people who know how to do what I do. And that will,

682
00:36:07,660 --> 00:36:14,620
oh my God. And I said, well, why not? And then it was a she, she then said,

683
00:36:15,180 --> 00:36:22,070
because this is my only value proposition. I'm like, well, learn, grow a new one. Oh, I can't.

684
00:36:22,630 --> 00:36:28,150
Like she had convinced herself that she had a secret sauce on how to test.

685
00:36:29,110 --> 00:36:32,950
And then her only option was learning how to code and that she couldn't do that.

686
00:36:33,670 --> 00:36:38,310
Yeah, there's something to that. And the growth mindset is huge. I was part of what triggered my

687
00:36:38,310 --> 00:36:43,750
thinking about this was everything. There's a soup in my head and ideas go and sometimes some

688
00:36:43,750 --> 00:36:48,870
ingredients clogged together. I was listening to a Pat Lencioni podcast and he was bringing up

689
00:36:48,870 --> 00:36:53,990
some ideas from his book called the ideal team player, which was originally titled the three signs

690
00:36:54,070 --> 00:36:58,550
of a miserable job. And he changed the title about five years after it was out because people would

691
00:36:58,550 --> 00:37:02,790
not leave a copy on their desk at work. But he talks about the ideal team player being three

692
00:37:02,790 --> 00:37:08,520
things, humble, hungry, and smart. Humble, meaning you're not a jerk. Hungry, meaning you love to

693
00:37:08,520 --> 00:37:13,640
learn and smart, meaning you make good decisions and you know, and you don't get like, you know,

694
00:37:13,640 --> 00:37:19,960
when to ask for help. You know how to, you know how to navigate the workplace. And it talks

695
00:37:19,960 --> 00:37:25,960
about like the people who are only have maybe two of those because of some labels for them.

696
00:37:25,960 --> 00:37:32,440
They said, if you are, if you are hungry and smart, but you don't have any humility,

697
00:37:32,440 --> 00:37:39,640
he calls that person the skillful politician. I think, I'm thinking, oh yeah, I've known some

698
00:37:39,640 --> 00:37:46,200
skillful politicians. I have known some skillful politicians. So that got me thinking about this

699
00:37:46,200 --> 00:37:51,000
whole, you know, and then thinking about Brent was in my head, Brent Geller from the Phoenix project.

700
00:37:51,000 --> 00:37:56,680
And that got me thinking about this whole hero slash anti-hero thing and just wanted to get

701
00:37:56,680 --> 00:38:00,600
your take. And then the books that I could like the brainstorming chat GPT, good stuff.

702
00:38:00,600 --> 00:38:06,360
So I forget what is your, as you're looking for chat, we should have chat GPT. If it could talk,

703
00:38:06,360 --> 00:38:13,880
it could be our third. We could be the ABC podcast. But anyway, can you please, how are we?

704
00:38:13,880 --> 00:38:14,920
I mean that directly.

705
00:38:15,990 --> 00:38:17,190
Can it, can it, can it love?

706
00:38:17,830 --> 00:38:19,270
I, I sure as hell hope.

707
00:38:19,270 --> 00:38:20,470
Can it give you a hug?

708
00:38:20,470 --> 00:38:22,230
No, no, but

709
00:38:22,230 --> 00:38:23,030
How do you,

710
00:38:23,030 --> 00:38:31,670
INTPs like us, like gross, right? My daughter has a shirt. She's very much like her father.

711
00:38:31,670 --> 00:38:33,990
Good. I'm glad. I'm glad you give clothes to your daughter.

712
00:38:33,990 --> 00:38:39,990
Yeah. And her shirt says at the very top, free hugs. And then in small letters,

713
00:38:40,630 --> 00:38:41,990
just kidding. Don't touch me.

714
00:38:41,990 --> 00:38:46,470
My, my insights report, somebody was asking about the disk report. I've never done the disk

715
00:38:46,470 --> 00:38:52,950
evaluation, but I'll do that sometime. But I remember my insights manual, which is not

716
00:38:52,950 --> 00:38:57,430
handy right now, but it has this little bullet point that says,

717
00:38:57,430 --> 00:39:02,950
do not get too close to Alan or touch him. And I love that. Okay. Very quickly here. Then I got

718
00:39:02,950 --> 00:39:08,150
to go. What are we doing about these people who hoard information? How did, what did you do with

719
00:39:08,150 --> 00:39:12,710
that woman who did not want to share information? What was your solution with her? How did you coach

720
00:39:12,710 --> 00:39:20,310
her? I was wired differently back then. I solved the problem that the business had

721
00:39:20,310 --> 00:39:31,400
without necessitating coaching her. You lazy. I, I basically said, I see. And started,

722
00:39:32,120 --> 00:39:36,440
I'd mentioned the snowball that rolled down the hill started the snowball that resulted

723
00:39:36,440 --> 00:39:40,280
in this person no longer being employed. I'm going to repeat something. I said this a lot,

724
00:39:40,280 --> 00:39:44,200
but I'm going to repeat it. Uh, cause I said it today to somebody over slack.

725
00:39:44,200 --> 00:39:51,320
Feedback has an incredibly short half life. Yes. And I think a lot of times we, we fail to give

726
00:39:51,320 --> 00:39:55,480
this feedback in timely enough manner and we go up. It's too late. Can't even give that feedback.

727
00:39:55,480 --> 00:39:59,320
Now I think if you were thinking that would happen today, you'd be able to give that person that

728
00:39:59,320 --> 00:40:05,160
coaching and that feedback in the moment. Yes. And well, absolutely. Right. And, and

729
00:40:06,120 --> 00:40:11,640
even more so like at Microsoft, like everyone's gone through and they've seen like what happened

730
00:40:11,640 --> 00:40:17,720
with tests. And there was this brief moment where everything was blamed off of the lack of testers,

731
00:40:17,720 --> 00:40:23,560
but now it, no one has that conversation. All right. So how do we, and did you ever answer,

732
00:40:23,560 --> 00:40:28,600
like you didn't have a good answer for this particular woman. So what's your general answer

733
00:40:28,600 --> 00:40:34,040
on how, how do we deal with these people? How do we, what would you do is my quest,

734
00:40:34,120 --> 00:40:37,000
you could do a whole other podcast on this, but in briefly, what do you do? Say you're

735
00:40:37,000 --> 00:40:42,360
working with someone and they are hoarding information and they are keeping everything

736
00:40:42,360 --> 00:40:46,360
to himself. They want to be the bottleneck or gatekeeper. What do you do? I put friction

737
00:40:46,360 --> 00:40:53,000
in that path. Number one, what do you mean? Uh, the first and foremost thing is I make it very

738
00:40:53,000 --> 00:41:01,640
clear that me as a business manager can't have that as a risk. I can't have one person on

739
00:41:01,640 --> 00:41:08,280
the team that is the only one that understands things like, and I'll do like the accidents

740
00:41:08,280 --> 00:41:17,240
happens in what's up, the bus factor. If the behavior continues, then, then I go down to,

741
00:41:18,360 --> 00:41:27,160
I will try to, to influence them that it's actually in their better interest, but I will go.

742
00:41:27,160 --> 00:41:33,160
So the, like, you know this from years ago, one of the books that really had a strong influence

743
00:41:33,160 --> 00:41:42,840
on me was titled influencer. So I try to use tricks from that and go, but actually what you're doing

744
00:41:42,840 --> 00:41:49,400
is harming yourself, not helping what you're doing. Now there's language on the fixed mindset. I,

745
00:41:49,400 --> 00:41:54,920
I would probably go and do some investigation on that one. Like I am firmly on the growth

746
00:41:54,920 --> 00:41:59,960
mindset aspect, but I would go through and I would try to get them to convince them.

747
00:42:00,680 --> 00:42:07,960
I would try to convince them that this is not, not a big behavior that's acceptable to them.

748
00:42:07,960 --> 00:42:18,360
I will say I have since adopted a strategy where I will do an earnest try to, to get them to

749
00:42:18,360 --> 00:42:26,120
understand this no more than four times, three times as typical, because at some point in time,

750
00:42:26,120 --> 00:42:32,600
I have to decide that, you know what? The ROI of continuing to have this conversation is quite low

751
00:42:33,620 --> 00:42:42,980
and, and if especially that the ROI of the behavior I'm asking for is high, then, then

752
00:42:42,980 --> 00:42:47,620
it's going to go down a similar route as the last person, just honest.

753
00:42:47,620 --> 00:42:50,900
I think the key thing here is you're just giving that feedback right away.

754
00:42:50,900 --> 00:42:51,300
Right.

755
00:42:51,300 --> 00:42:55,220
All right. Well, some good stuff in there, probably stuff we can lean into for next time,

756
00:42:55,220 --> 00:43:01,700
but we are out of time today. That was it. That was episode 190. Thanks everyone for listening

757
00:43:01,700 --> 00:43:06,420
and making it to the end. All right, everybody. Once again, A.B. testing. I'm Alan.

758
00:43:06,420 --> 00:43:07,460
I'm Brent.

759
00:43:07,460 --> 00:43:08,180
See you next time.

760
00:43:08,820 --> 00:43:10,180
Happy Thanksgiving.

761
00:43:10,180 --> 00:43:11,860
Yes. Happy Thanksgiving.

