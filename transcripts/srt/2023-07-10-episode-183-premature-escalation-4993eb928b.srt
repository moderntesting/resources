1
00:00:00,000 --> 00:00:06,260
It needs to be safe to just no matter what level, it's your manager, your skip level, your skip level, your whatever level.

2
00:00:06,260 --> 00:00:13,360
It needs to be safe to ask questions and challenge what you see other people say regardless of level. I hate that.

3
00:00:13,360 --> 00:00:21,200
Welcome to A.B. Testing Podcast, your modern testing podcast.

4
00:00:21,200 --> 00:00:30,200
Your hosts, Alan and Brent, will be here to guide you through topics on testing, leadership, agile, and anything else that comes to mind.

5
00:00:30,200 --> 00:00:32,040
Now, on with the show.

6
00:00:32,160 --> 00:00:36,080
Welcome back to the A.B. Testing Podcast. I'm here with Brent.

7
00:00:36,080 --> 00:00:39,240
Howdy, oh, yeah. Long time. Yeah.

8
00:00:39,240 --> 00:00:47,820
Listen, a long time. We took a little break. Yeah. So a couple of things going on. One, Zencaster is working. That's cool.

9
00:00:47,820 --> 00:00:52,880
Yeah, you I think you beat your record on getting it to do what you want to do.

10
00:00:52,880 --> 00:00:56,760
We're going to do a little bit of a shorter podcast. We have stuff to catch up on. We're talking.

11
00:00:56,760 --> 00:01:00,680
But I when I slug into Zencaster and Zencaster, I love you.

12
00:01:00,680 --> 00:01:08,200
And I should say that because you work most of the time and I don't pay for you as I personify Zencaster.

13
00:01:08,200 --> 00:01:12,280
I guess this has been true since March. I just never noticed before.

14
00:01:12,280 --> 00:01:18,160
But we do have a two hour recording limit per month, which does feel record every other week.

15
00:01:18,160 --> 00:01:21,520
I think we're probably good. So I'm not going to worry about it too much. I just noticed it today.

16
00:01:21,520 --> 00:01:29,600
I never noticed the time remaining counter. We have one hundred and nineteen minutes left to record in July.

17
00:01:29,600 --> 00:01:33,360
So I guess as long as I don't do a bunch of bonus episodes, long stuff, we should be in good shape.

18
00:01:33,360 --> 00:01:36,480
But yeah, it's going to be back. Took some breaks. Got stuff going on.

19
00:01:36,480 --> 00:01:41,120
It's summertime in Seattle. How are you doing with the heat, Brent?

20
00:01:41,120 --> 00:01:46,440
Oh, so I have AC at home. Same. It's not on right now. Today.

21
00:01:46,440 --> 00:01:49,640
Today has been a little bit better. I'll just share it this way.

22
00:01:49,880 --> 00:01:58,600
My wife and I have a bit of a disagreement around what is an appropriate temperature for the AC.

23
00:01:58,600 --> 00:02:05,240
For me, wives are like cats and they seem to like things about five to ten degrees warmer than I do.

24
00:02:05,240 --> 00:02:14,520
Yeah. Plus one. Right. So this is one of the things I have a sensei.

25
00:02:15,320 --> 00:02:20,760
Okay. That's the temperature I'm showing. Alan, the temperature it says seven four.

26
00:02:20,760 --> 00:02:26,760
Yeah, that's the temperature of my house. You also notice right there, three letter word says off.

27
00:02:28,200 --> 00:02:35,800
The last two days I have come home and the temperature of the house has been above 80.

28
00:02:36,860 --> 00:02:43,580
And I have been now at a point where I don't even talk about it. I just go upstairs. There's

29
00:02:43,580 --> 00:02:55,860
an app for that. And I open up the app and I say air conditioner on 74. 74 is my max tolerable

30
00:02:55,860 --> 00:03:02,260
range. I have noticed that it's about the same for me. I would prefer it slightly cooler.

31
00:03:02,260 --> 00:03:07,140
I would too. But I can't if it's above 74, I actually can't work.

32
00:03:07,860 --> 00:03:13,220
I can work. I can't keep my concentration up. I just the heat gets me.

33
00:03:13,300 --> 00:03:20,260
The thing that bothers me is and I say 74 and I think that's a bit of a mistake, but

34
00:03:20,260 --> 00:03:26,740
I have noticed particularly in the last week that if it's above 73, I can't sleep.

35
00:03:28,070 --> 00:03:33,910
Oh, same. So our bed is me, you know, with the window open with no blankets on my wife

36
00:03:33,910 --> 00:03:38,840
next to me with it with a blanket plus an extra blanket on her. Yeah. It doesn't matter what

37
00:03:38,840 --> 00:03:44,520
time of year. It's ridiculous. That is crazy talk. Like the other day, the other day I came home

38
00:03:45,400 --> 00:03:54,440
and it was, it was 80 in the house, right? And it was 85 outside. And I'm like, what the hell?

39
00:03:54,440 --> 00:03:59,560
She's like, just open a window. Why would I do that? It's hotter outside than inside. I don't

40
00:03:59,560 --> 00:04:04,680
want to heat my house. I want to cool it down. True, true, true, true. All right. So that's

41
00:04:05,000 --> 00:04:08,360
the podcast for today, everybody. Thank you. I'm Alan. He's Brent. And no,

42
00:04:09,320 --> 00:04:15,160
how temperature, we're going to do a short podcast today. Yes. And a couple of things for,

43
00:04:15,160 --> 00:04:19,480
I have two topics and we'll do, I think the order I put them in Slack is probably good.

44
00:04:20,280 --> 00:04:29,740
And then what do we got to know? Oh, these are both, both these topics are open to drive some

45
00:04:29,740 --> 00:04:34,940
discussion. So if you'd like to discuss these topics, give us more things to think about,

46
00:04:35,740 --> 00:04:40,780
go to modern testing.org where there's a link that usually works. And if it doesn't,

47
00:04:41,660 --> 00:04:47,340
you can email me and tell me I'm stupid and I'll fix it to join our Slack group at one of the

48
00:04:47,340 --> 00:04:55,020
three.slack.com. And I can tell you right now that we are, we are driving towards a thousand.

49
00:04:55,020 --> 00:04:59,820
We have 905 members in the Slack group and not all those are active, but a chunk of them are

50
00:04:59,820 --> 00:05:06,060
there's activity almost every day. Yep. You can do things there like, you know, bonus, bonus material

51
00:05:06,060 --> 00:05:10,220
one, you can just give us, you can yell at us there and we'll listen to it. You can give tacos.

52
00:05:10,220 --> 00:05:15,820
I posted photos from my hike last weekend, all kinds of great stuff, but it's a good part to be

53
00:05:15,820 --> 00:05:21,020
part of the community and tell us what's going on. So that's going on. I don't know. Do you want

54
00:05:21,020 --> 00:05:30,860
to get into the topics? Yeah. Okay. So the first one, this is something that I see once in a while.

55
00:05:31,830 --> 00:05:35,430
I just, I just, I, I just was kind of curious on your thoughts, Brent. We'll have a little

56
00:05:35,430 --> 00:05:39,270
bit of discussion around it. The second one is a more interesting topic, but I'm going to call

57
00:05:39,270 --> 00:05:51,290
this the age old issue of premature escalation. Okay. And, uh, what this is, this happened this

58
00:05:51,290 --> 00:05:55,290
week. There's a little bit of a fire drill on Wednesday when I got back and I'm not going to

59
00:05:55,290 --> 00:06:02,010
go into the full story to protect those who must remain innocent, but there was a thing going on

60
00:06:02,010 --> 00:06:11,860
with a vendor and it was just, it's look in software writing code. The technical part is easy.

61
00:06:11,860 --> 00:06:19,220
It's the people stuff that's hard. And basically the story is we had an issue with a timeline.

62
00:06:19,940 --> 00:06:24,020
We wanted to figure out what we could do with it to make it work better for us. And the end ended

63
00:06:24,020 --> 00:06:31,110
up being a non-issue. It doesn't matter. But someone in the meeting pulled out premature

64
00:06:31,110 --> 00:06:38,420
escalation. And what they did was we are still very much in the diplomatic, uh, portion of

65
00:06:38,420 --> 00:06:44,040
this discussion where we're trying to figure out what mitigations are, uh, what we want to go

66
00:06:44,040 --> 00:06:50,280
investigate next steps, et cetera. And they jumped right to the I'm going to tell dad card.

67
00:06:51,370 --> 00:06:56,330
You know what I'm talking about, Brad? I, yeah, I, I call it the mission from God.

68
00:06:58,810 --> 00:07:05,850
Yeah. It's essentially, I have authority on God from, from God to tell you what to do.

69
00:07:06,810 --> 00:07:16,890
And if you do not make me happy, then you will be on slide number one for the next God update deck.

70
00:07:16,890 --> 00:07:22,490
Yeah, it was interesting. It was, I thought things were progressing well and someone jumped in with

71
00:07:22,490 --> 00:07:27,770
the wall. If this doesn't get solved, this is going to go to dad and dad being some level

72
00:07:27,770 --> 00:07:34,630
of upper management and which is a car that you can, it's not the one you never play that card.

73
00:07:34,710 --> 00:07:41,320
You never play that card in the firsthand too often. If you're going to, if it will

74
00:07:41,320 --> 00:07:45,880
dis equate this, we'll just see if I can keep a metaphor of some sort of card game going.

75
00:07:45,880 --> 00:07:51,080
There's one, you don't play it in the first, first round. You got to know when to hold them.

76
00:07:51,080 --> 00:07:57,160
You may even play it in the background. You may not even need to tell. I mean, the, the fact

77
00:07:57,160 --> 00:08:01,640
that it was a, I was going to call it a thinly veiled threat, but I'll leave off the thinly

78
00:08:01,640 --> 00:08:09,640
veiled part. Yeah. To me, it's cringy. It's a cringy way to, it's a cringy method of diplomacy.

79
00:08:10,360 --> 00:08:15,940
It's not diplomacy at all. Right. I don't know if you've, you ever read getting the yes.

80
00:08:16,580 --> 00:08:21,780
Oh yeah. Yeah. Yeah. Very much. It's, it's a perfect example of what's known as a positional

81
00:08:22,980 --> 00:08:27,140
argument when it comes to negotiation. I don't care what happens to you.

82
00:08:28,020 --> 00:08:33,300
I want to win, right? You're basically trying to work out what's the definition of a win-win scenario

83
00:08:34,180 --> 00:08:40,340
and all of a sudden you have somebody who's losing patience and just goes for the throat on a win

84
00:08:40,340 --> 00:08:47,780
lose. Yeah. Yeah. And now you have people defensive, which makes it even harder to get to a win-win.

85
00:08:47,780 --> 00:08:54,340
So it's an interesting leadership trait that I realized it's a, it's a, it's a, I don't know

86
00:08:54,340 --> 00:09:00,260
how I learned it. And I, maybe I did this at some point too. I was, you know, I've, I grew up being

87
00:09:00,260 --> 00:09:05,780
mentored and led by type A assholes at Microsoft. So I'm sure I did this at some point, but at some

88
00:09:05,780 --> 00:09:14,890
point I realized some later point I have learned and realized that the high road's going to work

89
00:09:14,890 --> 00:09:24,120
99% of the time. And just having a discussion, being cordial, being, it's in it together

90
00:09:24,120 --> 00:09:30,600
attitudes of problem solving. It's going to work far better than trying to put a thread in there to

91
00:09:30,600 --> 00:09:37,000
try and put like I motivate again, 99% of the time with carrots and 1% with sticks

92
00:09:38,870 --> 00:09:43,590
building shared problems, building shared solutions for those problems or shared

93
00:09:43,590 --> 00:09:48,070
understanding of the problems and shared solutions of those problems for me just works much better

94
00:09:48,070 --> 00:09:54,310
than this weird, I'm not going to call it political because political is not bad. A lot of times it's

95
00:09:54,310 --> 00:09:59,430
the political, it's just influence. Call it the mission from God. I'm going to call it premature

96
00:09:59,430 --> 00:10:04,230
escalation. Interesting. It came up. I had been thinking about it all week because I thought

97
00:10:04,230 --> 00:10:11,670
the situation was kind of cringy and just weird. So whenever something doesn't sit right with me,

98
00:10:11,670 --> 00:10:17,030
I can't help but reflect on why does this feel weird? So I was wanting to share that with you

99
00:10:17,110 --> 00:10:26,950
and go into your thoughts. I pay active attention to people who take that tact. They're basically

100
00:10:26,950 --> 00:10:35,450
willing to in a political war, they're going to go straight to the nuke. I have a habit

101
00:10:36,330 --> 00:10:44,550
when someone tries to do that against me. And I'm like, look, I have a one on one with that guy

102
00:10:44,550 --> 00:10:51,910
every other week. Like let's call him right now if that's important to you. And you can be the one

103
00:10:51,910 --> 00:11:04,310
to inform him that even though you are paid at extremely senior level salary, you need to go to

104
00:11:04,310 --> 00:11:10,630
a CVP in order to work out this part of the business that you're supposedly accountable for.

105
00:11:11,660 --> 00:11:17,430
Like I don't see the reason why we can't work it through. I feel like you're threatening.

106
00:11:18,390 --> 00:11:21,110
That's what you want to do. Actually, the other thing to do

107
00:11:22,630 --> 00:11:28,390
in today's environment is just call them out and say, I feel like you're threatening me.

108
00:11:32,490 --> 00:11:38,710
Right. Because just those words are fighting words in a world where

109
00:11:39,700 --> 00:11:42,740
everyone's sort of anti toxic environments.

110
00:11:43,780 --> 00:11:47,060
Yeah. So this I want to dove.

111
00:11:47,060 --> 00:11:51,700
It's like, okay, you're going to go to the executive at the same time. I'm talking to HR.

112
00:11:52,580 --> 00:11:55,100
Right. But let's see. Let's see what happens.

113
00:11:57,420 --> 00:12:04,220
Yeah. So it really comes down to culture and you know, we've talked about the cultures I try

114
00:12:04,780 --> 00:12:12,280
and have on my teams and and what's interesting is I'm not going to talk about any specifics of

115
00:12:12,280 --> 00:12:16,600
work because I've perhaps signed things that said I wouldn't. But.

116
00:12:16,600 --> 00:12:17,720
Perhaps.

117
00:12:17,720 --> 00:12:23,480
Culturally what I want to do, whether I worked at Subway making sandwiches or at a

118
00:12:23,480 --> 00:12:29,720
broadcast company that happened to have software teams, regardless, there's a culture I want to

119
00:12:29,800 --> 00:12:36,920
try and build of. It's the opposite of telling dad. I want a culture where telling dad doesn't matter.

120
00:12:37,640 --> 00:12:42,760
And I'm very much in a Ronnie Kohavi talked forever at my when he was at Microsoft and

121
00:12:42,760 --> 00:12:46,440
since then about the hippo, the highest paid person's opinion and why it doesn't matter.

122
00:12:47,000 --> 00:12:47,240
Right.

123
00:12:47,240 --> 00:12:56,360
Where a lot of the data driven decision making comes from. But also I remind my teams,

124
00:12:57,320 --> 00:13:05,860
very generic here all the time that I may spout off ideas. I may have thoughts on how to do things, but

125
00:13:06,500 --> 00:13:10,580
my way is rarely the right way. It's just one of many opinions,

126
00:13:10,580 --> 00:13:14,340
regardless of my hierarchy and regardless of my title.

127
00:13:15,140 --> 00:13:23,700
No, it's I agree. I view my job. Right. Part of my job is to make decisions when

128
00:13:24,660 --> 00:13:31,380
when we're bottlenecked. OK. However, like the definition of bottleneck in my world view,

129
00:13:31,380 --> 00:13:38,020
and I think I think you share with this. This is for some reason my team is unable to make this

130
00:13:38,020 --> 00:13:46,860
decision. Right. Whether it be lack of experience or right. They're not certain what the tradeoff is.

131
00:13:47,580 --> 00:13:55,820
Right. But I really view my my long term goal with the team is to have them understand the

132
00:13:55,820 --> 00:14:01,260
principles by which I want decisions being made and then let them go.

133
00:14:02,600 --> 00:14:08,200
Yes. Yes. And that's a conversation I've had very much that decisions should be made as close to

134
00:14:08,200 --> 00:14:15,480
the people, close people close to the work as possible. I here's the hard one. I want

135
00:14:15,480 --> 00:14:24,310
to be challenged. I can give us an example scenario today. I posted something and someone said,

136
00:14:24,310 --> 00:14:28,710
what did you mean by this basically? And I said, I thought I meant this. I said,

137
00:14:28,710 --> 00:14:35,990
that's not right. Not private DM. And and I said, can you please clarify, go ahead and clarify

138
00:14:37,030 --> 00:14:42,550
what I wrote or question what I wrote in the other conversation. And they said something that

139
00:14:42,630 --> 00:14:47,350
lets me know that I still have work to do something to the effect of I've been taught

140
00:14:47,350 --> 00:14:55,320
not to oppose my manager in public channels. And so something for me to work on because I actually

141
00:14:55,320 --> 00:15:03,320
want that I want to be. Oh, I may have a fancy title and I may have hierarchy, but I need to

142
00:15:03,320 --> 00:15:09,240
be challenged, not because it's it makes me I'm going to go beat you up, but it needs to be

143
00:15:09,240 --> 00:15:13,320
safe to just no matter what level it's your manager, you skip level, you skip level,

144
00:15:13,320 --> 00:15:19,400
you're whatever level it needs to be safe to ask questions and challenge what you see other

145
00:15:19,400 --> 00:15:23,960
people say, regardless of level. There's different level. There's different levels of challenge,

146
00:15:23,960 --> 00:15:30,280
right? It's yet don't be a douchebag. No, obviously, you do it respectfully. Right.

147
00:15:31,400 --> 00:15:35,000
I love it when people tell me I'm wrong because I know they're right.

148
00:15:36,070 --> 00:15:44,180
But when they do it respectfully, they don't just call me dumb. But so many times, like I really,

149
00:15:44,180 --> 00:15:50,730
really value because it gives me a chance to learn. And I know and I also know that I that

150
00:15:51,530 --> 00:15:55,210
a couple of things happen. One is an example of the culture I want to have. So I feel like,

151
00:15:55,210 --> 00:15:59,210
okay, they're getting it. But also then other people see it and the next person isn't afraid

152
00:15:59,210 --> 00:16:04,970
to challenge. And it's hard and it takes time. But it's so important for people to feel empowered.

153
00:16:05,690 --> 00:16:15,720
It is it is the the worst. You need them to have enough trust to be able to speak their mind so that

154
00:16:16,840 --> 00:16:21,880
you kind of understand what, okay, what additional changes you need to make to your culture.

155
00:16:22,840 --> 00:16:28,600
Right. I'm thinking through the two things that you told me so far, right? This inappropriate

156
00:16:28,680 --> 00:16:35,560
escalation, premature escalation. And, and I have been taught to not challenge

157
00:16:37,540 --> 00:16:47,160
my manager in public. And I'm like, okay, yeah, the feels right right now I'm walking away with

158
00:16:47,160 --> 00:16:55,580
all right. There's a big opportunity there for Alan, because I feel like he is potentially in

159
00:16:56,460 --> 00:17:01,500
a big command and control environment that needs to be brought forward.

160
00:17:01,500 --> 00:17:06,460
I am not, but there are people I would say I'm working with people who have been brought up that

161
00:17:06,460 --> 00:17:13,660
way. And I am very I mean, this is my job as a pointy here, senior manager, right?

162
00:17:14,220 --> 00:17:19,740
My job isn't to go implement a bunch of terraform. My job isn't to go tell a bunch of people smarter

163
00:17:19,740 --> 00:17:24,620
than me what to do. My entire job is to create an environment where these people can be successful

164
00:17:24,620 --> 00:17:30,060
doing this stuff. And I 100% believe that a transparent and psychologically safe

165
00:17:30,860 --> 00:17:33,980
environment is the best way for them to do that. So that's what that's what I'm going to work on.

166
00:17:34,820 --> 00:17:42,200
Yeah, it's, in my view, it's sort of set the direction and then get out of the way.

167
00:17:44,310 --> 00:17:51,750
Yes, yeah, yeah. And that comes from there is a there's this writer whose name is going to come

168
00:17:51,750 --> 00:17:57,910
to me wrote the leaders guide to radical management. And I forgotten his name and he wrote the age of

169
00:17:57,910 --> 00:18:02,860
agile. And I still don't remember his name, but in the leaders guide to radical management, he's

170
00:18:02,860 --> 00:18:08,940
talking about very early on an agile, maybe not that early, but in the in the early 2000s,

171
00:18:10,390 --> 00:18:16,870
he is talking about how agile applies not just to software teams, but in the way teams need to

172
00:18:16,870 --> 00:18:23,510
work before Reese wrote his stuff. Just he really got he really saw something exciting coming.

173
00:18:24,300 --> 00:18:28,780
And in that book, in the leaders guide to radical management, one of the phrases I took away from

174
00:18:28,780 --> 00:18:33,900
that, which has been, you know, paraphrased in my mind over the two decades since I read it,

175
00:18:34,620 --> 00:18:40,140
is that the leader's job is to give people a framework they can work in and then get out

176
00:18:40,140 --> 00:18:48,420
of their way. Stephen Dunning. Denning Stephen Denning. See together together we can accomplish

177
00:18:48,420 --> 00:18:53,060
so much you can you can look up the book while I'm talking and then mispronounce the name that I can

178
00:18:53,060 --> 00:18:58,260
correct you because it gives me enough information. Perfect. Teamwork right there. Yes. Yes. Hey,

179
00:18:58,260 --> 00:19:03,860
I got another topic a different a different direction. So I don't know if you caught my last

180
00:19:03,860 --> 00:19:10,780
sub stack post. Is that the five for Friday? Because I actually read that today. No,

181
00:19:10,780 --> 00:19:16,540
so my sub stack is the one I did last Saturday. So I do. So now I have to go on a tangent. So

182
00:19:16,540 --> 00:19:22,300
once upon a time I used to write a blog haphazardly I did it for years and years. My very first blog,

183
00:19:22,300 --> 00:19:28,220
which is still up on whatever blogs dot MSDN.com came says I'm not a blogger is the title of my

184
00:19:28,220 --> 00:19:37,820
very first blog post and I want this is back in 2000 and four, three and I just wanted a way to

185
00:19:37,820 --> 00:19:41,820
engage with the windows CE community. And why did I get into this story? Now I have to finish it.

186
00:19:41,820 --> 00:19:46,460
And then I ended up blogging more and more and sometimes good, sometimes bad, mostly bad,

187
00:19:46,460 --> 00:19:50,060
but I wanted to get better at writing and then end up writing a book and I got a little better

188
00:19:50,060 --> 00:19:53,820
at writing or a better blog post and eventually move those blogs to anger weasel dot com or

189
00:19:53,820 --> 00:19:58,300
blog there. And then eventually I got too busy to blog at anger weasel dot com. And then I got

190
00:19:58,300 --> 00:20:02,860
inspired by Tim Ferriss and his five bullet Friday and about three years ago began doing five for

191
00:20:02,860 --> 00:20:13,590
Fridays on anger weasel dot com. And then kind of the end of 2022 I was thinking, you know what,

192
00:20:13,590 --> 00:20:17,670
I miss writing. I want to blog again. And I thought, well, you know what, I'm going to commit

193
00:20:17,670 --> 00:20:21,590
to writing a long story here. I'm going to skip most of it. I'm going to commit to writing

194
00:20:21,590 --> 00:20:27,590
a blog post every week on anger weasel dot sub stack dot com. And I have so far from,

195
00:20:27,590 --> 00:20:35,110
I think from the end or middle of December until now, I have written a blog post every week,

196
00:20:35,110 --> 00:20:41,270
usually on Saturday, sometimes Sunday. Last week I wrote it on Thursday instead of auto post

197
00:20:41,270 --> 00:20:47,110
on Saturday. And, but so far so good. So I've done about half a year. So that's like 20,

198
00:20:47,110 --> 00:20:53,270
26, 27, 28 regular weekly posts there. I'll read another one tomorrow or Sunday,

199
00:20:53,270 --> 00:20:55,590
probably Sunday this weekend. I have some plans tomorrow.

200
00:20:56,390 --> 00:21:01,270
I did read this one. So, but the gist is I was revisiting something I put in,

201
00:21:01,270 --> 00:21:08,380
it's the diffusion of innovation curve from crossing the chasm, which I originally posted

202
00:21:08,380 --> 00:21:13,100
the very first time I talked about modern testing at a conference at a test bash in,

203
00:21:13,100 --> 00:21:22,630
I don't remember what year 2016, I think. And my hypothesis there was that modern testing or

204
00:21:23,430 --> 00:21:27,430
again, modern testing isn't that modern, not a lot about testing, but sometimes it is

205
00:21:27,990 --> 00:21:34,950
depends on the kind of testing and your definition of modern. But at the time I gave that talk at a

206
00:21:34,950 --> 00:21:40,230
testing conference, I was a little freaked out, thought I'd get a lot of anger, but they let me

207
00:21:40,230 --> 00:21:45,190
give the talk on what it was like to have a team that didn't have any testers or may not have the

208
00:21:45,190 --> 00:21:51,430
need for a dedicated testing specialist. And what I was pleasantly surprised at that talk and many

209
00:21:51,430 --> 00:21:58,070
talks afterwards was that people came up to me, multiple people came up to me and said,

210
00:21:59,400 --> 00:22:05,480
thank you for giving a name to what we're already doing. Oh, this is actually, and again,

211
00:22:05,480 --> 00:22:09,320
is what Brent and I had seen, we know we're in a little bit of a bubble, but the bubble was

212
00:22:09,320 --> 00:22:17,240
bigger happily, much bigger than we thought. And here we are seven years after that talk,

213
00:22:18,040 --> 00:22:26,280
and a lot of people are still freaked out by this idea of delivering quality software

214
00:22:26,280 --> 00:22:32,280
without dedicated testing specialists. And you and I both know hundreds, if not thousands of

215
00:22:32,280 --> 00:22:37,960
companies do this, and it's crossing that, it's getting over that hump. And we've talked about

216
00:22:37,960 --> 00:22:44,940
this a lot before, but I want to talk about it in a slightly different context. One of the best

217
00:22:44,940 --> 00:22:51,340
testing conferences remaining is coming up in a month or two, which is the Agile Testing Days in

218
00:22:51,340 --> 00:22:57,660
Potstom. There every year, it's always great speakers. This year, no exception. Good speakers,

219
00:22:57,660 --> 00:23:03,100
good content, it's well put together. I've never been there, but every year I follow it on social

220
00:23:03,100 --> 00:23:09,980
media and read the reports. I look at what talks are there. And again, all the talks are good,

221
00:23:11,020 --> 00:23:15,660
but what's interesting, because Brent, when you and I first started talking about this thing that

222
00:23:15,660 --> 00:23:21,260
became modern testing, it was in reaction to watching teams become agile, watching what

223
00:23:21,260 --> 00:23:27,500
happened when they moved quicker and could get data and feedback and testers doing what they did

224
00:23:27,580 --> 00:23:33,740
before just slowed them down. So what we talked about, what does that change? And we talked about

225
00:23:33,740 --> 00:23:38,460
delivery, which is really what modern testing principles are. So long preamble aside, but I

226
00:23:38,460 --> 00:23:42,300
want to get your thoughts on them. I look at the conference talks for Agile Testing Days.

227
00:23:42,860 --> 00:23:47,420
And again, I think they're all very good. This is not a dig on them, but they're all

228
00:23:49,320 --> 00:23:56,200
one step still, one step back from that edge I talked about seven years ago at the early,

229
00:23:56,680 --> 00:24:03,400
the innovation I talked about seven years ago at Test Bash in that they're all about having dedicated

230
00:24:03,400 --> 00:24:12,040
testers on the team, testers writing automation versus developers. Everything's about what testers

231
00:24:12,040 --> 00:24:17,880
can do to improve quality, how to improve testing. Some of it's about improving testing mindset on

232
00:24:17,880 --> 00:24:21,720
the team, I don't know the talks in front of me, I read them earlier today. But it's,

233
00:24:23,540 --> 00:24:29,060
you know, what I'm going to say is it's not a lot different from the talks we saw,

234
00:24:29,060 --> 00:24:35,620
I saw at Agile Testing five, six, seven years ago. So I'm just curious, why do you think that's not

235
00:24:35,620 --> 00:24:39,460
changing? Why do you think that's not, I'm not going to use shift left, not going to use shift

236
00:24:39,460 --> 00:24:46,020
left. Why do you think that's not drifting across the chasm on the diffusion of innovation?

237
00:24:46,260 --> 00:24:48,340
Uh, or am I wrong?

238
00:24:48,980 --> 00:24:55,850
I, I, I think you have a subject, you have a selection bias.

239
00:24:56,730 --> 00:24:59,530
Ah, talk to more.

240
00:24:59,530 --> 00:25:09,130
So crossing the chasm. So as you mentioned, this, this is one of the better test conferences

241
00:25:10,090 --> 00:25:15,290
out there. I would say, right, anything from the ministry of testing is another one.

242
00:25:16,250 --> 00:25:22,410
So the best, let's just say this is the best testing conference, right? Let's say the industry

243
00:25:22,410 --> 00:25:34,490
as a whole has made a transition. Okay. I argue that the best testing conference will be the last

244
00:25:34,490 --> 00:25:43,400
one to die. Right. So in here, I would actually, I'd be more interested in looking at, okay,

245
00:25:44,620 --> 00:25:51,180
has the rate of testing conferences worldwide over the last several years gone up, gone down,

246
00:25:51,180 --> 00:25:57,260
stayed flat, right? That sort of thing. Like something like agile testing days,

247
00:25:57,260 --> 00:26:02,540
that's probably going to be the, one of the last ones to, to go, right? And they're going to

248
00:26:02,540 --> 00:26:06,780
continue to talk to their audience, which is still dedicated testers.

249
00:26:07,740 --> 00:26:08,060
Yeah.

250
00:26:08,460 --> 00:26:16,900
Yeah. But, but if, if, if we, as the migration towards non-dedicated testers continues,

251
00:26:16,900 --> 00:26:21,540
over time, there's going to be fewer people in that role. They're going to be mostly developers

252
00:26:21,540 --> 00:26:27,820
and that content's going to show up in developer centric con and you're going to see the popularity

253
00:26:27,820 --> 00:26:32,310
for these test conferences fall, right? They're not going to be able to, they're not going to

254
00:26:32,310 --> 00:26:39,820
be able to sell enough tickets to, to support the conference. Um, yeah, maybe you're right. Okay. Well,

255
00:26:41,180 --> 00:26:46,600
I mean, I see some things in here, right? There's some things in here that are absolutely,

256
00:26:47,850 --> 00:26:52,970
do you remember what year it was? Were you asked me to come in and present to unity?

257
00:26:54,170 --> 00:27:02,250
Oh yeah. That would have been November, 2017. Okay. I see a talk refactoring your end-to-end

258
00:27:02,250 --> 00:27:12,440
tests from an ice cone to a pyramid. And I'm like, yeah, I saw Alan present that same freaking talk.

259
00:27:12,440 --> 00:27:18,200
That was Marcello. Marcello on my team presented that he's, he's less unity. He is back at Thought

260
00:27:18,200 --> 00:27:24,280
Works, but cool guy. But it's right next to another one called embracing home team quality,

261
00:27:24,280 --> 00:27:29,560
making myself obsolete, which to me feels like, yeah, that's, that's, that's very empty.

262
00:27:30,680 --> 00:27:34,920
Um, and, and, and actually that one wouldn't have been there six or seven years ago. So,

263
00:27:34,920 --> 00:27:41,260
no. And actually I want to touch on that a lot. I think, you know, I see so many,

264
00:27:41,260 --> 00:27:45,420
I still haven't done this, not gonna my post tomorrow, but someday I'm gonna write about this.

265
00:27:46,140 --> 00:27:52,380
So many posts I see on LinkedIn as I go there talking about how unique and special testing is

266
00:27:52,380 --> 00:27:58,780
because it requires creativity and autonomy. As Peter Drucker would have told you 80 million

267
00:27:58,780 --> 00:28:03,340
years ago, all knowledge work does get 50 years ago, whenever, whenever that was.

268
00:28:03,340 --> 00:28:09,820
Right. So one thing that I think all knowledge work is about making yourself

269
00:28:09,820 --> 00:28:16,380
obsolete. And I don't, I don't think enough people in, I'm gonna call them traditional test

270
00:28:16,380 --> 00:28:22,940
roles think that that's as critical. I think it's the opposite. They want to make themselves

271
00:28:22,940 --> 00:28:31,100
more important. And I have as long now, now, because I'm old and I have less ability to remember,

272
00:28:31,100 --> 00:28:36,620
as long as I can remember, I've tried to make myself obsolete. And, and maybe it's not even

273
00:28:36,620 --> 00:28:43,020
I've tried to make myself obsolete by doing the things I do, I've made myself obsolete.

274
00:28:43,020 --> 00:28:47,740
So I just think that's a, maybe that's the eighth principle. It's not, but it,

275
00:28:47,740 --> 00:28:52,620
but it's a critical thing that we have to do. No, it's the thing is, and I think about

276
00:28:52,620 --> 00:28:57,500
the series we've done on GPT. The thing is, we almost made it a whole episode without

277
00:28:57,500 --> 00:29:03,180
talking at all about AI. There was no way. Cause I, I have already loaded up the next

278
00:29:03,180 --> 00:29:09,100
topic on this one, but without talking without the words GPT, I completely agree. Right. There

279
00:29:09,100 --> 00:29:19,590
is, cause what you and I have learned is as we pursue obsolescence, that we learn new skills

280
00:29:19,590 --> 00:29:24,630
that enables us to even become more valuable than the things we're leaving behind.

281
00:29:25,350 --> 00:29:34,060
Yes. Yes. In terms of the world where, where GPT exists, like it really is the same way

282
00:29:34,060 --> 00:29:42,760
that the, um, whatever happens as we move forward with these potentially very beneficial or very

283
00:29:42,760 --> 00:29:51,160
terrifying, uh, AI systems, right? Really it's, it's always going to be the case that, that

284
00:29:51,160 --> 00:29:58,280
human plus AI outperforms human or AI alone. And this is the way I like to put it now. AI

285
00:29:58,280 --> 00:30:06,040
is not taking your job away. People who know how to use AI, however, will. Yes. Yes. That's

286
00:30:06,040 --> 00:30:12,120
absolutely the case. Number one, I don't know if you saw, saw first off, just sort of tangent.

287
00:30:12,120 --> 00:30:19,240
I don't know if you saw this, we can't screen share on this stupid app. Um, but one of the

288
00:30:19,240 --> 00:30:25,800
time, it doesn't matter. One of the talks is building an awesome character sheet for agile

289
00:30:25,800 --> 00:30:33,900
teams. Right. And I'm totally thinking of your war craft model for four teams. Yeah. Character

290
00:30:33,900 --> 00:30:39,740
sheet is different than the war craft model of project management. So that well, but you want

291
00:30:39,740 --> 00:30:45,100
to have a, you need your barbarian, you need your cleric. You do. You need to balance it. And that's,

292
00:30:45,100 --> 00:30:49,180
um, you know, it's like when you're quick out of the tangent, like when you're building a team,

293
00:30:49,180 --> 00:30:56,090
if you have four head count, you might have one, uh, job description for all of them. But when you

294
00:30:56,090 --> 00:31:00,570
hire the first one, maybe it has to change a little bit, what you're looking for the other

295
00:31:00,570 --> 00:31:05,450
three. Every time you get to that last one, you're actually being kind of a lot more specific

296
00:31:05,450 --> 00:31:11,130
about what you need because you know what gaps remain. You it's it's puzzle building. It's fun.

297
00:31:11,690 --> 00:31:17,530
Great. It's building the right party. Or you could even call it like, uh, in war craft or any of

298
00:31:17,530 --> 00:31:22,330
those games, it's coming up with the right skill tree to balance your attack even on a single

299
00:31:22,330 --> 00:31:30,810
character. Uh, yes, completely agree. One of the things that I, the other thing I'll say around

300
00:31:30,810 --> 00:31:40,700
AI is so far I have found at least two talks, uh, at Agile testing days around, around this

301
00:31:40,700 --> 00:31:47,020
concept we talked about, like one of them is titled 10 times software testing. However,

302
00:31:47,020 --> 00:31:54,950
you dig into it and the, the mission is incorporating AI into our software testing workflows has

303
00:31:54,950 --> 00:32:00,230
significantly improved our processes leading to faster and higher quality results.

304
00:32:00,230 --> 00:32:05,110
Sounds like a great talk. And I, again, I, I expect every single talk of that conference to be good.

305
00:32:05,910 --> 00:32:09,990
I just as I always look at the talks that are happening there. And again,

306
00:32:09,990 --> 00:32:16,700
why I started this conversation is I, and again, maybe in hindsight, some of them are more on the

307
00:32:16,700 --> 00:32:20,700
empty side than I thought in my first pass. I think that AI one's definitely one too.

308
00:32:21,900 --> 00:32:30,740
I just, you know, I, I, I want more companies to leap to be less afraid to leap the chasm.

309
00:32:31,060 --> 00:32:36,020
And not again, the goal isn't to get rid of your testers. The goal is to improve

310
00:32:36,900 --> 00:32:44,260
the way you ship, the way you deliver software so much that you need fewer or no,

311
00:32:44,260 --> 00:32:51,260
or fewer dedicated testers, dedicated specialists. Totally agree. And actually like this AI trend,

312
00:32:51,260 --> 00:32:56,780
I absolutely adore like there's another one that's a workshop. Like you used to do workshops.

313
00:32:56,860 --> 00:33:03,580
I did. I did. This is a workshop where two guys are going to guide people through training

314
00:33:04,460 --> 00:33:13,450
an AI model and even using basic, the, the, the basic scoring mechanisms that we,

315
00:33:13,450 --> 00:33:20,090
we generally use in data science. Like I have gone through and had GPT write unit tests.

316
00:33:20,730 --> 00:33:28,010
Like if, if I don't know if you've coded recently, but the, the GitHub co-pilot is fantastic.

317
00:33:28,730 --> 00:33:35,290
I haven't played with it, but I, I've been meaning to, I don't, I don't, actually I'm going to write

318
00:33:35,290 --> 00:33:41,900
some code this weekend, but not anything significant. So I don't even go into the project. So I will

319
00:33:41,900 --> 00:33:46,570
want to play with that. All right, man. Well, that is good stuff. And this is stuff that again,

320
00:33:46,570 --> 00:33:52,730
we would appreciate your input on, do we talk about, I guess talk about testing a little bit.

321
00:33:52,730 --> 00:34:02,730
All right. Well, when, when I'm waiting, we'll see waiting. Ah, damn it. I like you.

322
00:34:03,770 --> 00:34:13,770
I asked, um, I asked GPT to give me the number of worldwide test conferences in the last 10 years.

323
00:34:14,680 --> 00:34:21,800
Okay. And, and it told you my cutoff is in 2019 or wherever. It's 2021, but no, it, it said,

324
00:34:21,800 --> 00:34:27,640
no, I, I don't have the ability to do that. And then it gave me some random link to

325
00:34:28,440 --> 00:34:35,750
IEEE conferences. So it was stupid. Like really, really bully it. What happened?

326
00:34:35,750 --> 00:34:40,950
What happens when you, the thing is it doesn't care when you bully it. Just apologizes.

327
00:34:41,190 --> 00:34:43,670
It'll probably tell me I'm done with this conversation.

328
00:34:44,470 --> 00:34:47,430
Okay. Brent, do you know what episode this has been?

329
00:34:47,430 --> 00:34:48,550
One 83.

330
00:34:48,550 --> 00:34:53,830
Yeah. Cause it's in the title of our Zen Castro link. All right, everybody. Uh, we are going to call it

331
00:34:53,830 --> 00:34:58,230
good, but please engage with us online and we will, you know, think about replying. No,

332
00:34:58,230 --> 00:35:01,110
we'll reply for somebody else. Somebody will, somebody will talk to you.

333
00:35:01,110 --> 00:35:04,870
There'll be a, maybe it's AI who knows. Yeah, really.

334
00:35:04,870 --> 00:35:07,590
All right. I'm Alan. I'm Brent. We'll see you next time.

335
00:35:07,590 --> 00:35:08,470
Bye.

