1
00:00:01,390 --> 00:00:09,290
Welcome to AB testing podcast, your modern testing podcast.

2
00:00:09,290 --> 00:00:15,510
Your hosts, Alan and Brent will be here to guide you through topics on testing, leadership,

3
00:00:15,510 --> 00:00:18,030
agile, and anything else that comes to mind.

4
00:00:18,030 --> 00:00:20,140
Now on with the show.

5
00:00:20,140 --> 00:00:21,140
Hey everybody.

6
00:00:21,140 --> 00:00:22,140
It's Alan.

7
00:00:22,140 --> 00:00:27,570
It's Brent, mostly the anything else that comes to mind.

8
00:00:27,570 --> 00:00:30,250
That's really, that's kind of the story here.

9
00:00:30,250 --> 00:00:33,210
We're not a great podcast, but we're a fun podcast.

10
00:00:33,210 --> 00:00:35,070
Yeah.

11
00:00:35,070 --> 00:00:42,150
You know, I miss the days where it was literally, well, we only did it a couple of times, the

12
00:00:42,150 --> 00:00:43,150
vodka episodes.

13
00:00:43,150 --> 00:00:44,150
Not the vodka.

14
00:00:44,150 --> 00:00:46,150
Oh, those are fun too.

15
00:00:46,150 --> 00:00:50,810
And every time I open Riverside, I look at the live streaming option.

16
00:00:50,810 --> 00:00:52,930
I think, you know, we should just, no, we shouldn't.

17
00:00:52,930 --> 00:00:54,130
So we always can though.

18
00:00:54,130 --> 00:00:56,970
We can't, but those shouldn't involve drinking.

19
00:00:56,970 --> 00:01:04,490
So anything before I get into my story here and why I'm just freaking delirious today and

20
00:01:04,490 --> 00:01:05,950
not in a good way.

21
00:01:05,950 --> 00:01:08,010
Anything new, exciting with you need to share?

22
00:01:08,010 --> 00:01:13,260
I think last time I had just recovered from COVID.

23
00:01:13,260 --> 00:01:15,700
No, no, really good.

24
00:01:15,700 --> 00:01:20,180
So I did the opposite of had COVID I did for, I did this last year.

25
00:01:20,180 --> 00:01:21,180
You'll remember as well.

26
00:01:21,180 --> 00:01:26,780
I'll probably write a blog post about it again tomorrow, but I just finished walking

27
00:01:26,780 --> 00:01:28,740
around Mount Rainier again.

28
00:01:28,740 --> 00:01:29,740
Okay.

29
00:01:29,740 --> 00:01:35,480
I took seven days to walk 95 miles around a big freaking mountain, which is fun.

30
00:01:35,480 --> 00:01:39,380
So anyway, let me just get all the way to the end.

31
00:01:39,380 --> 00:01:40,380
I do that.

32
00:01:40,380 --> 00:01:42,060
I have, was it snowy at the level you were at?

33
00:01:42,060 --> 00:01:43,060
I assume not.

34
00:01:43,060 --> 00:01:44,060
No, no.

35
00:01:44,060 --> 00:01:49,580
The highest point of the trail is about 6,600 feet, 6,800 feet.

36
00:01:49,580 --> 00:01:53,660
And that was, I could see there, there was snow around me that on the trail.

37
00:01:53,660 --> 00:01:55,580
Anyway, I did this trail seven days.

38
00:01:55,580 --> 00:01:56,580
It's kind of fast.

39
00:01:56,620 --> 00:01:58,220
I had a couple of big days in there.

40
00:01:58,220 --> 00:01:59,220
I get to the last day.

41
00:01:59,220 --> 00:02:00,220
I start with a big climb.

42
00:02:00,220 --> 00:02:01,220
The weather is beautiful.

43
00:02:01,220 --> 00:02:02,380
I have great pictures.

44
00:02:02,380 --> 00:02:03,380
I'm cruising along.

45
00:02:03,380 --> 00:02:05,820
This is the last day.

46
00:02:05,820 --> 00:02:07,420
I'm feeling good.

47
00:02:07,420 --> 00:02:13,860
I have breakfast, kind of a late, I like to walk like four or five miles before I eat.

48
00:02:13,860 --> 00:02:18,800
And I had breakfast and then I said, I'm going to the car.

49
00:02:18,800 --> 00:02:22,840
And I booked, I walked seven miles without stopping at all.

50
00:02:22,840 --> 00:02:26,820
Except for a couple of places, I had a little drink of water and I just booked it.

51
00:02:26,820 --> 00:02:30,900
And I get into the parking lot and there's nobody there cheering for me, but I'm cheering

52
00:02:30,900 --> 00:02:31,900
for myself.

53
00:02:31,900 --> 00:02:32,900
Yay.

54
00:02:32,900 --> 00:02:38,160
And I walk over to my car and I can't get in because it is completely dead so much.

55
00:02:38,160 --> 00:02:41,500
I can't even get the key fob to unlock the door.

56
00:02:41,500 --> 00:02:45,840
Oh, someone left their lights on?

57
00:02:45,840 --> 00:02:51,720
No, it's just a, it's, I, time to upgrade someone's car.

58
00:02:51,720 --> 00:02:55,440
Time to upgrade someone's 12 volt battery in their car for sure.

59
00:02:55,440 --> 00:02:57,240
So anyway, that was a little.

60
00:02:57,800 --> 00:03:03,880
So I ended up not even making it home last night, but getting home early this morning.

61
00:03:03,880 --> 00:03:11,760
When, when, when was the, the, oh crap, my car screwed.

62
00:03:11,760 --> 00:03:12,760
What time did that occur?

63
00:03:12,760 --> 00:03:16,840
Well, I got to the parking lot at two and it took me.

64
00:03:16,840 --> 00:03:17,840
PM.

65
00:03:17,840 --> 00:03:18,840
PM.

66
00:03:18,840 --> 00:03:19,840
Okay.

67
00:03:19,840 --> 00:03:23,160
And it took me a couple hours to get to the, I can't get out of this.

68
00:03:23,160 --> 00:03:24,240
This won't, this won't jumpstart.

69
00:03:24,240 --> 00:03:25,920
This won't nothing.

70
00:03:25,920 --> 00:03:30,680
And yeah, but anyway, I'm just, it's great.

71
00:03:30,680 --> 00:03:31,680
The hike was great.

72
00:03:31,680 --> 00:03:33,440
I have to get rid of the gray cloud over it.

73
00:03:33,440 --> 00:03:34,440
I'm working on that.

74
00:03:34,440 --> 00:03:40,670
So by the way, and I'll leave this part in the podcast with my phone rings.

75
00:03:40,670 --> 00:03:43,910
I have to answer it because I have a couple of calls in to get it fixed because it's

76
00:03:43,910 --> 00:03:49,550
still, my car is still way the F out in the mountains and I have to go rescue it.

77
00:03:49,550 --> 00:03:52,470
How the hell did you get home?

78
00:03:52,470 --> 00:03:54,390
Mrs. Weasel came and picked me up.

79
00:03:54,390 --> 00:03:55,390
I see.

80
00:03:55,390 --> 00:03:56,480
Okay.

81
00:03:57,400 --> 00:03:58,400
So yeah, so that happens.

82
00:03:58,400 --> 00:03:59,400
I'm a little tired.

83
00:03:59,400 --> 00:04:00,400
So yeah, yeah.

84
00:04:00,400 --> 00:04:01,680
And then that's it.

85
00:04:01,680 --> 00:04:07,330
And then today I spent the entire day as one does when they take a week off, catching

86
00:04:07,330 --> 00:04:16,010
up on messages in Slack and Teams and email because why have one solid and effective communication

87
00:04:16,010 --> 00:04:21,070
platform when you can have three mediocre methods to choose from?

88
00:04:21,070 --> 00:04:22,070
Okay.

89
00:04:22,070 --> 00:04:23,070
You just pause there.

90
00:04:23,070 --> 00:04:27,070
I'm sure it picked up fine, but I had no idea what you just said.

91
00:04:27,950 --> 00:04:29,950
It'll be in the recording.

92
00:04:29,950 --> 00:04:30,950
Don't worry.

93
00:04:30,950 --> 00:04:36,150
I was making a crack around too many methods of communication.

94
00:04:36,150 --> 00:04:38,350
Ah, yeah.

95
00:04:38,350 --> 00:04:41,670
So that's an excellent point, Alan.

96
00:04:41,670 --> 00:04:42,670
Yes.

97
00:04:42,670 --> 00:04:43,670
Yes.

98
00:04:43,670 --> 00:04:50,950
Speaking of excellent points, have you played with, and I had both my boss at work and

99
00:04:50,950 --> 00:04:58,790
Jason Arbin had awaiting pings for me today asking if I've played with notebook LM.

100
00:04:58,790 --> 00:05:01,310
Have you played with notebook LM yet?

101
00:05:01,310 --> 00:05:02,540
No.

102
00:05:02,540 --> 00:05:04,180
So we're going to go into the AI portion here.

103
00:05:04,180 --> 00:05:05,820
I brand had to ask some topics.

104
00:05:05,820 --> 00:05:12,640
So let me just, before you go dive in there, before you go dive in there, let me see

105
00:05:12,640 --> 00:05:16,220
if I can play something for you, if I can find it here.

106
00:05:16,220 --> 00:05:19,680
I'll just cut to the middle here if I can.

107
00:05:19,840 --> 00:05:20,840
Okay.

108
00:05:20,840 --> 00:05:24,080
So are you ready to dive into something kind of controversial today?

109
00:05:24,080 --> 00:05:27,960
Always up for a good debate, especially when it comes to the ever-changing world of software

110
00:05:27,960 --> 00:05:28,960
development.

111
00:05:28,960 --> 00:05:29,960
Right.

112
00:05:29,960 --> 00:05:31,640
And this one is a hot button issue.

113
00:05:31,640 --> 00:05:36,720
The idea that maybe we don't need dedicated software testers anymore.

114
00:05:36,720 --> 00:05:37,720
Yeah.

115
00:05:37,720 --> 00:05:40,120
That's definitely a statement that's going to ruffle some feathers.

116
00:05:40,120 --> 00:05:41,120
You got that right.

117
00:05:41,120 --> 00:05:43,160
And the person shaking things up is Alan Page.

118
00:05:43,160 --> 00:05:44,160
Oh yeah.

119
00:05:44,160 --> 00:05:46,480
I know Alan very well respected in the testing world.

120
00:05:46,480 --> 00:05:47,480
Yeah.

121
00:05:47,480 --> 00:05:49,960
You could say he wrote the book on it literally.

122
00:05:50,080 --> 00:05:53,360
We're looking at a couple of his articles where he really throws down the gauntlet

123
00:05:53,360 --> 00:05:57,360
claiming that most software teams don't need dedicated testers anymore.

124
00:05:57,880 --> 00:05:58,880
Interesting.

125
00:05:58,880 --> 00:06:02,800
And that most stood out to me too, because he's not saying all teams, right?

126
00:06:02,800 --> 00:06:06,200
Yeah. And that's an important distinction right off the bat, because he's

127
00:06:06,200 --> 00:06:09,240
acknowledging that there are always going to be exceptions.

128
00:06:09,360 --> 00:06:10,360
Like what?

129
00:06:10,440 --> 00:06:11,480
I'm going to stop there.

130
00:06:11,480 --> 00:06:17,360
And this incredible podcast you've been listening to was generated by Notebook

131
00:06:17,360 --> 00:06:19,880
LM by me feeding it two of my blog posts.

132
00:06:20,480 --> 00:06:21,880
Holy crap.

133
00:06:25,560 --> 00:06:27,120
I mean, I'm fascinated.

134
00:06:30,430 --> 00:06:34,270
So I did it with some, you know, very few of my posts are about testing, but I

135
00:06:34,270 --> 00:06:36,270
want to bring that up in context of today.

136
00:06:36,270 --> 00:06:39,550
And just like, oh, well, that's interesting.

137
00:06:39,590 --> 00:06:43,950
So, um, I gave it, I did feed it all the rest of my blog posts and I

138
00:06:43,950 --> 00:06:45,110
asked it a couple of questions here.

139
00:06:45,110 --> 00:06:46,030
And it's actually kind of interesting.

140
00:06:46,030 --> 00:06:47,070
It's only based on.

141
00:06:47,670 --> 00:06:49,710
You make like a notebook, like a Jupiter notebook.

142
00:06:50,070 --> 00:06:53,870
And it, oh my God, I'm just kind of blown away by it.

143
00:06:54,310 --> 00:06:57,270
So I asked it, I gave it all my blog posts and I asked two questions.

144
00:06:58,880 --> 00:07:01,840
Question number one, why do managers suck?

145
00:07:05,450 --> 00:07:09,730
I won't read the whole thing, but it's, um, you know, it, it, it's, you

146
00:07:09,730 --> 00:07:13,450
know, it's like the answers are written by me, uh, micromanagement and failure

147
00:07:13,450 --> 00:07:16,490
to delegate lack of focus on people and engagement.

148
00:07:16,490 --> 00:07:19,970
And that's my big one ineffective communication and lack of clarity,

149
00:07:20,370 --> 00:07:25,570
failure to adapt and embrace change, toxic behaviors and lack of accountability.

150
00:07:26,210 --> 00:07:30,690
I mean, those are, I mean, you know, those are me, but those are pretty good answers too.

151
00:07:30,690 --> 00:07:32,370
I was there all tried and true.

152
00:07:33,010 --> 00:07:36,690
So I said, what attributes to the best managers have, I haven't looked at the

153
00:07:36,690 --> 00:07:37,890
answer yet, so we just come up here.

154
00:07:38,170 --> 00:07:38,410
Okay.

155
00:07:38,810 --> 00:07:41,850
They prioritize employee engagement and wellbeing.

156
00:07:42,170 --> 00:07:45,170
They trust their teams and empower them to make decisions.

157
00:07:45,730 --> 00:07:48,530
They are strong communicators and promote transparency.

158
00:07:49,010 --> 00:07:52,490
And they cultivate a culture of learning and continuous improvement.

159
00:07:52,850 --> 00:07:56,130
Again, great answers again, all, all based on me.

160
00:07:56,130 --> 00:07:59,810
So of course I'm going to like them, but, uh, it's, there's a whole bunch of

161
00:07:59,810 --> 00:08:05,250
texts below that, that goes in there, but oh my God, the, what it can do.

162
00:08:06,080 --> 00:08:08,640
Already is kind of scaring me.

163
00:08:08,680 --> 00:08:15,000
This, uh, the idea that I could create auto create a whole series of blog posts.

164
00:08:15,720 --> 00:08:21,160
Like I have, you know, I've, I've written 80 articles on anger weasel.substack.com.

165
00:08:21,160 --> 00:08:24,160
Now, uh, I could have 80 blog posts.

166
00:08:25,580 --> 00:08:29,100
It would be funny if I did that, those AI generated ones and they got more

167
00:08:29,100 --> 00:08:30,580
listeners than AB testing did.

168
00:08:34,280 --> 00:08:41,160
I, I don't, not only do I not think it's funny, I think it's reasonable.

169
00:08:41,160 --> 00:08:46,670
And I'm like, you know, that would save an hour of my time every two weeks.

170
00:08:46,710 --> 00:08:47,110
Right.

171
00:08:48,390 --> 00:08:53,630
We get a little deeper and they're a little too, you know, chat GPT is a little

172
00:08:53,630 --> 00:08:55,790
too positive and always knows the right answer.

173
00:08:56,270 --> 00:08:59,830
I think the, the, this does the same thing in a way.

174
00:09:00,270 --> 00:09:03,310
It's a little too, I need it to not be me.

175
00:09:03,310 --> 00:09:05,350
I need it to be influenced by me.

176
00:09:06,390 --> 00:09:06,830
Well, yeah.

177
00:09:06,990 --> 00:09:11,390
But like the, when you played, when you played the two characters, right?

178
00:09:11,390 --> 00:09:16,310
I'm still thinking about, about the, the one like, like, Oh yeah.

179
00:09:16,310 --> 00:09:17,270
I know Alan.

180
00:09:17,950 --> 00:09:22,030
He, he literally wrote the, like, like the way they phrase it.

181
00:09:22,030 --> 00:09:27,070
So much about me, but the thing that they phrased it was sort of like, um,

182
00:09:27,470 --> 00:09:31,950
it came across like, um, a vague recollection, right?

183
00:09:31,950 --> 00:09:34,870
Wasn't he the guy that literally wrote the book on testing?

184
00:09:34,910 --> 00:09:37,150
Like, I'm like, okay.

185
00:09:37,510 --> 00:09:37,910
Yeah.

186
00:09:37,910 --> 00:09:40,310
Someone who doesn't know Alan might do that.

187
00:09:40,350 --> 00:09:42,470
And immediately thought of like, yeah.

188
00:09:42,470 --> 00:09:44,310
Whitaker would probably argue about that.

189
00:09:44,870 --> 00:09:54,560
So would Kainer, but you know, uh, but yeah, it took me, this is sort of the state

190
00:09:54,560 --> 00:09:55,400
of affairs, right?

191
00:09:55,400 --> 00:10:02,720
It took me a little while, like literally maybe 10 seconds before you turned it off.

192
00:10:02,760 --> 00:10:04,120
I'm like, Oh, wait a minute.

193
00:10:05,040 --> 00:10:07,280
This is, this is AI generated audio.

194
00:10:07,280 --> 00:10:09,130
It's gotta be right.

195
00:10:09,210 --> 00:10:13,410
And, um, it's why it's wild though.

196
00:10:13,410 --> 00:10:13,930
Right.

197
00:10:14,170 --> 00:10:14,570
Yeah.

198
00:10:14,570 --> 00:10:21,140
And, and honestly, like there was something and I still can't put my finger on it.

199
00:10:21,140 --> 00:10:25,700
That was something that was odd that led me to believe it was AI generated.

200
00:10:25,980 --> 00:10:26,140
Right.

201
00:10:26,140 --> 00:10:26,300
Yeah.

202
00:10:26,300 --> 00:10:28,420
But we're really approaching uncanny Valley.

203
00:10:29,300 --> 00:10:29,700
Yeah.

204
00:10:30,100 --> 00:10:30,460
Yeah.

205
00:10:31,490 --> 00:10:34,730
I don't know what uncanny Valley is, but I'm going to perfectly agree.

206
00:10:34,930 --> 00:10:36,130
Uncanny Valley.

207
00:10:36,130 --> 00:10:40,370
It's from, I think it's from Valley of the dolls like in the 60s of book.

208
00:10:40,610 --> 00:10:44,170
It's where it's like, maybe I think it's something different now.

209
00:10:44,370 --> 00:10:48,750
Um, but it's, we're creeped out.

210
00:10:49,030 --> 00:10:49,950
Humans are creeped out.

211
00:10:49,950 --> 00:10:54,760
Like we can see androids that look very androidy, like in the movies and that's,

212
00:10:54,800 --> 00:10:55,480
that's fine.

213
00:10:55,680 --> 00:10:59,120
They could look exactly human like they do in some movies and that's fine.

214
00:10:59,480 --> 00:11:02,920
But when they're right on that line, it's, it's creepy.

215
00:11:02,960 --> 00:11:05,960
And they call that uncanny Valley where it's, it's kind of here where it's

216
00:11:05,960 --> 00:11:09,240
like, this is, oh wait, this isn't real or is it real or is it not real?

217
00:11:10,400 --> 00:11:10,840
Right.

218
00:11:11,200 --> 00:11:11,680
Right.

219
00:11:12,700 --> 00:11:19,230
Um, yeah, like it's happening.

220
00:11:19,870 --> 00:11:20,510
It's happening.

221
00:11:20,510 --> 00:11:21,550
Yeah, we're getting there.

222
00:11:21,550 --> 00:11:28,900
I've, I've been, uh, uh, interviewing folks on, uh, for AI, for some AI related

223
00:11:28,900 --> 00:11:33,780
positions at, at, at current job, not in my org, but it's interesting.

224
00:11:33,780 --> 00:11:35,140
The folks I talked to, they get it.

225
00:11:35,140 --> 00:11:40,220
They get like, is a weird, we're going to go onto some of your topics, but

226
00:11:40,500 --> 00:11:45,120
what I've noticed is, uh, and the reason I brought this up again, lack of

227
00:11:45,120 --> 00:11:50,360
sleep, uh, AI isn't magic.

228
00:11:50,680 --> 00:11:57,080
AI today isn't even really AI and people want it to be magic and they want it

229
00:11:57,080 --> 00:12:01,880
to be real AI and I think there are a set of realists who kind of get it.

230
00:12:02,360 --> 00:12:06,840
Who know what it can do, what problems it can solve, what problems it can't solve.

231
00:12:06,840 --> 00:12:11,960
So I've been talking to a few of those folks, uh, as well.

232
00:12:13,670 --> 00:12:15,270
Um, anyway, uh,

233
00:12:15,310 --> 00:12:16,950
AI can solve everything.

234
00:12:17,110 --> 00:12:19,910
It can't solve hardly anything.

235
00:12:19,990 --> 00:12:24,390
So, uh, here's what I would like to do.

236
00:12:25,160 --> 00:12:29,280
I would like, I think you had a couple topics you were going to bring up,

237
00:12:29,280 --> 00:12:32,880
which I think is better for you, for me to comment and you to give us the

238
00:12:32,880 --> 00:12:37,160
topic ideas than for me to think of topics because I'm a little, a little

239
00:12:37,160 --> 00:12:38,520
not at a hundred percent.

240
00:12:39,590 --> 00:12:40,470
Oh, okay.

241
00:12:42,310 --> 00:12:47,480
So the topic that this.

242
00:12:49,540 --> 00:12:55,560
Let's we, we probably, we've probably talked about this a bunch of times, but

243
00:12:55,640 --> 00:12:58,320
let me, let me just phrase it this way.

244
00:12:58,880 --> 00:13:06,450
I've come to learn of, of certain organizations that when they went too

245
00:13:06,450 --> 00:13:09,410
fast and got rid of tests, right?

246
00:13:09,450 --> 00:13:15,410
Piggybacking off of your idea, uh, as per the, you know, the, the, the

247
00:13:15,410 --> 00:13:18,770
snippet from the other podcasts you just played, right?

248
00:13:18,770 --> 00:13:27,710
That, that test doesn't need or test, uh, test specialists aren't necessarily needed.

249
00:13:28,880 --> 00:13:29,320
Right.

250
00:13:29,800 --> 00:13:37,560
The, one of the things that was observed from this organization is they did that.

251
00:13:37,800 --> 00:13:44,600
They did not follow the advice, um, that maybe you and I have had around,

252
00:13:44,600 --> 00:13:46,000
Hey, be cautious here.

253
00:13:46,960 --> 00:13:55,100
Make, make the change carefully, uh, because you don't want to lose the knowledge.

254
00:13:55,380 --> 00:13:55,660
Right.

255
00:13:55,740 --> 00:14:01,440
Um, the advice I have most organizations have ignored anyway.

256
00:14:01,560 --> 00:14:04,640
Uh, the advice I have is if you want to do this, right.

257
00:14:05,240 --> 00:14:05,480
Right.

258
00:14:05,480 --> 00:14:12,290
Obviously to me, it's make your assets, your, your, your key go-to people.

259
00:14:12,930 --> 00:14:20,570
Cause I find teaching them how to design and code properly is for some odd reason,

260
00:14:20,570 --> 00:14:25,850
way harder than teaching people how that don't want to test how to test.

261
00:14:26,920 --> 00:14:27,200
Right.

262
00:14:27,240 --> 00:14:32,760
And so I often will, you know, I still stand by I've experienced it.

263
00:14:33,400 --> 00:14:35,320
If you're in this phase, right.

264
00:14:35,640 --> 00:14:37,760
My view focus on your assets.

265
00:14:37,800 --> 00:14:39,280
Cause I think they're your way forward.

266
00:14:40,270 --> 00:14:42,310
Well, I, I, hold on.

267
00:14:42,310 --> 00:14:48,080
Cause I was going to just go on from that, but you don't have, you don't have

268
00:14:48,080 --> 00:14:49,120
Estet's in your org.

269
00:14:49,600 --> 00:14:51,920
No, no, no, I'm, I'm whining back.

270
00:14:53,000 --> 00:14:55,400
Oh, you're, you're back on how we made the transition.

271
00:14:55,560 --> 00:14:56,880
How we made the transition.

272
00:14:56,880 --> 00:14:57,080
Yeah.

273
00:14:57,920 --> 00:15:04,700
But now, but now there's a situation, um, where this organization also made that

274
00:15:04,700 --> 00:15:10,140
transition a long time ago, managed to, to muddle through it.

275
00:15:11,540 --> 00:15:19,440
But now we have quote unquote, I'll call them generations of dev leadership, all

276
00:15:19,440 --> 00:15:26,190
who, which never really understood test, never really understood agile, never

277
00:15:26,190 --> 00:15:28,390
really understood TDD.

278
00:15:28,870 --> 00:15:37,480
And now you have sort of this, this culture of dysfunction, um, that we're

279
00:15:37,480 --> 00:15:43,600
trying to unwind and the, the people that came and talked to me were like, yeah,

280
00:15:45,170 --> 00:15:49,810
we are going to swing the pendulum all the way back to 1998.

281
00:15:50,450 --> 00:15:52,450
And they asked me this one question.

282
00:15:53,330 --> 00:15:53,730
Yeah.

283
00:15:53,730 --> 00:15:56,690
And I, and they did it this way.

284
00:15:56,810 --> 00:15:58,770
And I'm going to ask you, Alan.

285
00:16:00,640 --> 00:16:08,980
When was the last time you even saw a test plan last week?

286
00:16:09,660 --> 00:16:10,300
Did you really?

287
00:16:11,160 --> 00:16:11,360
Yeah.

288
00:16:11,360 --> 00:16:13,280
We make, I make, I make the devs write them.

289
00:16:14,140 --> 00:16:14,940
Oh, all right.

290
00:16:15,380 --> 00:16:15,700
Yeah.

291
00:16:15,740 --> 00:16:17,100
That wasn't my response.

292
00:16:17,220 --> 00:16:17,700
All right.

293
00:16:17,860 --> 00:16:25,180
My response was, uh, 2007.

294
00:16:25,220 --> 00:16:27,460
And I hope to keep that status.

295
00:16:27,500 --> 00:16:30,740
Well, it depends if you're talking about the, like some of those old big

296
00:16:30,740 --> 00:16:35,220
tome test plans versus let's please have a strategy of how we're going to test

297
00:16:35,220 --> 00:16:36,220
this thing that we're building.

298
00:16:36,340 --> 00:16:37,420
That was the context.

299
00:16:37,420 --> 00:16:37,900
They want us.

300
00:16:37,900 --> 00:16:38,660
What do I consider?

301
00:16:38,740 --> 00:16:42,100
They want to know 50 page piece of shit that no one reads.

302
00:16:42,580 --> 00:16:47,300
Well, uh, Microsoft has always been very good about swinging the pendulum hard.

303
00:16:47,460 --> 00:16:47,700
Right.

304
00:16:47,700 --> 00:16:50,740
Um, so I know, um, it could happen.

305
00:16:51,300 --> 00:16:56,140
It, I mean, but actually, but maybe less so now, maybe more other places.

306
00:16:56,140 --> 00:16:57,580
I think people freak out.

307
00:16:57,660 --> 00:16:59,500
Actually, I shouldn't even put Microsoft in there.

308
00:16:59,900 --> 00:17:06,360
The industry has been infatuated with swinging the pendulum hard as a reaction.

309
00:17:06,800 --> 00:17:12,030
And this is a common, be careful of that band date.

310
00:17:12,030 --> 00:17:13,430
It may be a turnip good thing.

311
00:17:14,110 --> 00:17:21,790
When people, when teams made the transition to not having dedicated testers, uh, you

312
00:17:21,790 --> 00:17:23,390
know, I used to talk about this a lot.

313
00:17:23,470 --> 00:17:28,160
Like you can, you, if you don't have a plan, you're going to fail.

314
00:17:29,000 --> 00:17:35,000
And the plan includes how do you get as Elizabeth Henderson used to say, how do

315
00:17:35,000 --> 00:17:37,080
you get the development team test infected?

316
00:17:37,360 --> 00:17:38,120
How do you get them?

317
00:17:38,160 --> 00:17:40,920
And now you get them to take testing seriously.

318
00:17:41,360 --> 00:17:46,680
And the way I did it, my first couple of teams, as we eliminated the role was a

319
00:17:46,680 --> 00:17:51,080
lot of coaching and mentoring and teaching devs how to test, giving them

320
00:17:51,080 --> 00:17:55,800
permission to test, making them feel like they knew what testing, what testing

321
00:17:55,840 --> 00:18:01,080
was, and they could do it without some dedicated, uh, person to help them.

322
00:18:01,790 --> 00:18:07,150
And as Brent's looking up by, he's actually probably AI generating

323
00:18:07,150 --> 00:18:08,670
his response while I talk here.

324
00:18:08,870 --> 00:18:18,630
So if you never had someone to teach developers more about testing that

325
00:18:18,910 --> 00:18:21,990
you're not going to get free for, they have to have at least some ideas.

326
00:18:22,350 --> 00:18:22,830
And it's funny.

327
00:18:22,830 --> 00:18:29,690
It reminds me, uh, many, many, many years ago, someone asked me about this

328
00:18:29,690 --> 00:18:32,090
exact situation, like what happened?

329
00:18:32,570 --> 00:18:34,450
That's like, it's the quality culture maturity guide.

330
00:18:34,450 --> 00:18:38,090
Let's say you get to this level where of team owned quality and the

331
00:18:38,090 --> 00:18:41,650
developers get testing and there's, and there's good testing in place.

332
00:18:41,650 --> 00:18:47,920
And, and, uh, the culture is correct for that to happen.

333
00:18:48,400 --> 00:18:50,240
But how do you maintain that?

334
00:18:50,720 --> 00:18:57,680
Say the coach leaves, uh, how do you need the developers to now become

335
00:18:57,680 --> 00:18:59,480
the coaches for the other developers?

336
00:18:59,840 --> 00:19:04,360
And when that begins to fail, you end up with a bunch of developers who

337
00:19:04,400 --> 00:19:11,160
have never been given any idea how to test and they don't, and again, it's

338
00:19:11,160 --> 00:19:13,880
not, oh shit, here's more controversy.

339
00:19:14,160 --> 00:19:20,280
It's not like testing's hard, but it's, it's, it's, it is.

340
00:19:20,600 --> 00:19:28,290
And I put it this way, coding's not hard either, but it's the ability to go low

341
00:19:28,290 --> 00:19:32,490
level heads down, figure how to implement this thing and then step out

342
00:19:32,490 --> 00:19:37,850
the 10,000 feet and ask yourself, does it work in which ways will this not work?

343
00:19:38,170 --> 00:19:44,610
Let me, let me write some more code to evaluate my hypothesis on whether

344
00:19:44,610 --> 00:19:46,810
this works and which ways it won't work.

345
00:19:47,130 --> 00:19:52,090
And it's just getting used to that workflow, which is different.

346
00:19:52,090 --> 00:19:56,690
It's different from when you're building a application in college for your professor

347
00:19:56,690 --> 00:20:00,930
versus you're building an application at a company for 10,000, 100,000 million users.

348
00:20:01,290 --> 00:20:05,810
Um, before you go on, I want to, I want to, um, see if I can with my best voice

349
00:20:05,810 --> 00:20:09,090
impressions, act out a little bit of a skit on this very topic.

350
00:20:09,410 --> 00:20:11,130
It needs to feel like they own quality.

351
00:20:11,370 --> 00:20:12,010
Absolutely.

352
00:20:12,130 --> 00:20:13,530
It can't be a one person job.

353
00:20:13,730 --> 00:20:17,250
It's got to be baked into the DNA of how the entire organization operates from

354
00:20:17,250 --> 00:20:20,170
the product managers to the developers, to the folks in operations.

355
00:20:20,410 --> 00:20:21,490
Everyone has a role to play.

356
00:20:21,770 --> 00:20:22,050
Okay.

357
00:20:22,050 --> 00:20:26,290
So we're painting this picture of a more collaborative data driven way of building

358
00:20:26,290 --> 00:20:29,330
software and getting away from this codependent relationship.

359
00:20:30,090 --> 00:20:33,930
What are some practical things teams can do to make that shift happen?

360
00:20:34,250 --> 00:20:37,450
Well, for starters, it's about embracing that coaching mentality.

361
00:20:37,490 --> 00:20:37,890
Yeah.

362
00:20:37,930 --> 00:20:42,330
We can't just expect developers to magically transform into testing experts overnight.

363
00:20:42,370 --> 00:20:42,730
Right.

364
00:20:42,810 --> 00:20:47,050
It's like any skill you don't become a master chef just by reading a cookbook.

365
00:20:47,490 --> 00:20:51,010
You need somebody to show you the ropes, teach you the techniques, help

366
00:20:51,010 --> 00:20:52,690
you troubleshoot when things go wrong.

367
00:20:52,690 --> 00:20:53,770
Couldn't have said it better myself.

368
00:20:53,810 --> 00:20:54,130
Yeah.

369
00:20:55,420 --> 00:20:59,900
So I'm just like, you know what?

370
00:20:59,940 --> 00:21:04,740
We should just do the podcast and then transcript it and then feed it to these

371
00:21:04,740 --> 00:21:08,620
two, please suck.

372
00:21:10,020 --> 00:21:10,540
You know what?

373
00:21:10,540 --> 00:21:14,300
I bet you even by today, there are podcasts posted with these

374
00:21:14,300 --> 00:21:15,460
two talking about something.

375
00:21:15,660 --> 00:21:18,340
Oh, I'm sure somebody's way ahead of my idea.

376
00:21:18,340 --> 00:21:20,900
So I'm going to wait till there's more voices out there.

377
00:21:21,580 --> 00:21:27,490
But anyway, it, I, I listened to the whole, it's a nine minute podcast they

378
00:21:27,490 --> 00:21:31,010
made based on my testing articles, but I knew there are some stuff about

379
00:21:31,010 --> 00:21:34,450
this somewhere and I literally dropped the needle and that's what we got.

380
00:21:35,130 --> 00:21:37,130
So let me, let me ask you this.

381
00:21:37,130 --> 00:21:38,690
So the answer is not.

382
00:21:38,690 --> 00:21:43,450
If you're the answer is not to swing the pendulum, go back to night 1992

383
00:21:43,850 --> 00:21:48,600
and, uh, create a one to one test to dev ratio.

384
00:21:48,920 --> 00:21:49,720
Not the right answer.

385
00:21:49,920 --> 00:21:50,360
No.

386
00:21:50,440 --> 00:21:53,760
What advice would you give a team who comes?

387
00:21:53,840 --> 00:21:58,830
I mean, they come to you, they came to you with a solution, not a problem.

388
00:21:59,270 --> 00:22:03,350
They came to you with a solution to say here, we don't understand our problem,

389
00:22:03,430 --> 00:22:06,590
but the solution is we should have a full test team.

390
00:22:07,190 --> 00:22:07,990
What do you say to them?

391
00:22:08,510 --> 00:22:19,970
I, um, well, so a full test team, I would go like that's, um, dumb, dumb,

392
00:22:19,970 --> 00:22:25,010
asinine, idiotic, I would do all sorts of adjectives along those lines.

393
00:22:25,370 --> 00:22:25,690
Right.

394
00:22:25,690 --> 00:22:30,050
The, um, I'll tell you what I did tell these folks.

395
00:22:31,310 --> 00:22:37,510
Um, so when people come in and ask me these type of questions, like my answer

396
00:22:37,790 --> 00:22:42,630
is often in the strategic realm because I'm like, okay, what are the two key

397
00:22:42,630 --> 00:22:47,310
things that are two or three, the small number of simple key things as a

398
00:22:47,310 --> 00:22:52,070
strategy that they can execute that would generate the self-sustaining momentum.

399
00:22:52,810 --> 00:22:53,050
Right.

400
00:22:53,050 --> 00:22:55,450
For me, it's, it's right.

401
00:22:55,490 --> 00:22:58,050
The, the strategy around, oh, let's teach.

402
00:22:58,730 --> 00:22:59,210
Right.

403
00:22:59,450 --> 00:23:03,170
Even if it, even if that happened at the beginning, you're exactly right.

404
00:23:03,210 --> 00:23:07,290
If it doesn't continue, then you get new people coming in because

405
00:23:07,330 --> 00:23:11,480
this is still not a topic that's really trained in college.

406
00:23:12,040 --> 00:23:12,480
Right.

407
00:23:12,560 --> 00:23:17,440
So you, and if you let that happen a couple generations, even if it is

408
00:23:17,440 --> 00:23:20,880
trained in college, right, they'll come in and their manager was like,

409
00:23:20,920 --> 00:23:21,680
what are you doing?

410
00:23:21,680 --> 00:23:25,960
Why do you, why are you spending all your time running this test code?

411
00:23:25,960 --> 00:23:26,520
Just ship it.

412
00:23:27,000 --> 00:23:27,280
Right.

413
00:23:27,760 --> 00:23:30,000
I don't know if that's what they do, but yeah.

414
00:23:31,040 --> 00:23:31,320
Right.

415
00:23:31,360 --> 00:23:38,670
For me, I'm like, look, for me, it was when they came to me, I said,

416
00:23:39,070 --> 00:23:44,590
look, there are two practices that, that I would encourage you guys to

417
00:23:44,590 --> 00:23:46,270
implement immediately.

418
00:23:46,750 --> 00:23:51,070
Everything else will come as a result of these two practices.

419
00:23:51,190 --> 00:23:52,750
This is from my experience.

420
00:23:53,480 --> 00:23:57,800
Number one, immediately implement and require TDD.

421
00:23:58,650 --> 00:24:08,760
Number two, instead of creating practices that, um, go back to the

422
00:24:08,760 --> 00:24:15,500
prevention model, go the, um, essentially go the opposite direction.

423
00:24:15,500 --> 00:24:20,340
Instead of like creating practices where you deploy once every 10 months,

424
00:24:21,520 --> 00:24:29,380
go the other way, deploy 10 times a day, because doing that successfully

425
00:24:29,380 --> 00:24:33,580
requires the correct amount of testing, the correct amount of muscle memory.

426
00:24:34,400 --> 00:24:38,380
Uh, and it then becomes a lot easier, small batch.

427
00:24:38,740 --> 00:24:38,900
Yeah.

428
00:24:39,220 --> 00:24:40,860
And I can build on two points in there.

429
00:24:40,860 --> 00:24:43,820
First is, and I kind of hinted at it in my setup for the question.

430
00:24:44,620 --> 00:24:48,900
I like to remind people, it says it doesn't, it doesn't surprise me.

431
00:24:48,900 --> 00:24:52,660
They came with a solution without understanding the problem, ask them

432
00:24:52,660 --> 00:24:55,740
what problems they're solving because they may not even know.

433
00:24:57,000 --> 00:25:00,360
And, and that, and there's a reason I bring that up, not because it's, I

434
00:25:00,360 --> 00:25:02,120
wanted to poop on the rest of your answer.

435
00:25:02,120 --> 00:25:06,920
It's because it's a, it's a stepping stone of critical thinking and testing

436
00:25:06,920 --> 00:25:10,320
in large part is just critical thinking, looking at things from different

437
00:25:10,320 --> 00:25:13,600
ways, looking at your things, critical thinking, or looking at your

438
00:25:13,600 --> 00:25:17,840
application from different directions to understand in what scenarios

439
00:25:17,840 --> 00:25:22,520
and situations will it work and not work, developing hypotheses around that.

440
00:25:22,960 --> 00:25:29,120
And then implementing more code to help you understand if necessary or telemetry

441
00:25:29,320 --> 00:25:31,240
to help you understand those hypotheses.

442
00:25:31,520 --> 00:25:34,040
So understand the problem, dive in there.

443
00:25:34,400 --> 00:25:36,880
You can't just say, I know you, I know you didn't mean it.

444
00:25:36,880 --> 00:25:41,160
This way, we can just say implement TDD because if I just tell a dev dev team

445
00:25:41,160 --> 00:25:44,600
or a developer to go do TDD, they're probably going to do it in a really

446
00:25:44,600 --> 00:25:51,600
dumb way just to satisfy the requirement of must do TDD, uh, what, and again,

447
00:25:51,640 --> 00:25:56,240
TDD, it, it really isn't about testing.

448
00:25:56,680 --> 00:26:01,600
It's about writing testable code and about, and, but it does handle the

449
00:26:01,600 --> 00:26:04,200
critical thinking part of makes you think about how the code should

450
00:26:04,200 --> 00:26:05,760
work before you write it.

451
00:26:05,880 --> 00:26:09,920
So you begin to think about code differently than just implementing

452
00:26:09,920 --> 00:26:11,320
the thing over and over and over.

453
00:26:11,800 --> 00:26:16,920
Now, I think there's still more to it because as you and I have talked,

454
00:26:16,920 --> 00:26:21,120
dev teams are 100% reliable for functional correctness, but I don't

455
00:26:21,120 --> 00:26:26,720
think the limitation that that's the minimum bar, the minimum bar for a

456
00:26:26,720 --> 00:26:30,080
dev team is to ensure functional correctness.

457
00:26:31,250 --> 00:26:32,330
They can do more.

458
00:26:32,810 --> 00:26:33,170
Yes.

459
00:26:33,170 --> 00:26:36,370
They can, they can do their own security testing.

460
00:26:36,370 --> 00:26:38,250
They can do their own performance testing.

461
00:26:38,530 --> 00:26:43,930
They can, if you want to hire me as a very highly paid consultant to help

462
00:26:43,970 --> 00:26:46,930
help this team out, um, I'll get it.

463
00:26:46,970 --> 00:26:50,490
I'll see if I can get a moonlighting exception and add to my retirement

464
00:26:50,490 --> 00:26:53,570
portfolio, but they may need a coach for a little while.

465
00:26:54,010 --> 00:26:57,530
Uh, but what I found, and I found this as you know, repeated for

466
00:26:57,530 --> 00:27:03,300
everybody here for many, many hundreds of developers, uh, in

467
00:27:03,300 --> 00:27:09,100
affecting them with the ability to test really well is far more common

468
00:27:09,300 --> 00:27:13,500
than you might think, like in a team of example of a hundred developers,

469
00:27:13,500 --> 00:27:18,300
I'm going to, going to, uh, mentally merge some things here, but in

470
00:27:18,300 --> 00:27:22,260
the team of a hundred developers, if I am giving them coaching and I,

471
00:27:22,300 --> 00:27:26,060
and coaching is such an overblown word now too, if I'm helping them,

472
00:27:26,060 --> 00:27:28,700
my goal is to help them become better testers.

473
00:27:29,420 --> 00:27:35,300
About 10 of those developers are going to be better testers than 95% of

474
00:27:35,300 --> 00:27:37,140
the testers I know they just pick it up.

475
00:27:37,180 --> 00:27:37,660
They get it.

476
00:27:37,660 --> 00:27:41,820
They have the right, um, mental capacity, whether they've, you know,

477
00:27:41,820 --> 00:27:44,540
just the way they think about things, they get it and they go, oh my

478
00:27:44,540 --> 00:27:46,340
God, and they're, they're great.

479
00:27:46,820 --> 00:27:52,940
Um, another 50 or 50 of those are really, really good at it.

480
00:27:53,500 --> 00:27:56,700
Not, not, you know, phenomenal at that higher level, but they're,

481
00:27:56,780 --> 00:27:57,940
they're good testers.

482
00:27:57,940 --> 00:28:00,260
The kind of testers that if you're a tester, you would always get,

483
00:28:00,300 --> 00:28:01,460
you could always find a job.

484
00:28:02,610 --> 00:28:06,170
The remaining 40 are going to, there's going to be 10 or 15 at the

485
00:28:06,170 --> 00:28:07,490
bottom who just don't get it.

486
00:28:07,490 --> 00:28:09,970
And those are your low performers who probably get fired anyway,

487
00:28:09,970 --> 00:28:13,570
because you can find, you can find developers who not only know how to

488
00:28:13,570 --> 00:28:15,810
test, but want to test their own code.

489
00:28:15,810 --> 00:28:19,250
Well, just fire the shit heads and hire those folks to be done with them.

490
00:28:19,690 --> 00:28:22,930
And then I left about 10 or 15 in the middle who are probably kind of

491
00:28:22,930 --> 00:28:25,890
struggling a little bit, but they're coachable and fixable over time.

492
00:28:26,530 --> 00:28:31,050
And in general, I'm, I'm, I'm amalgating amp.

493
00:28:31,050 --> 00:28:35,370
Is that the word I'm combining in my head, a bunch of different teams I work with,

494
00:28:35,370 --> 00:28:38,810
but they just need a little hand holding.

495
00:28:39,210 --> 00:28:44,050
And, you know, in the coaching, again, overused word, the coaching you give them

496
00:28:44,050 --> 00:28:46,330
need to be, you need someone who can be adaptive.

497
00:28:46,330 --> 00:28:48,170
It can't be a very rote process.

498
00:28:48,530 --> 00:28:51,930
It's always, you need that bigger, critical thinking of what's

499
00:28:51,930 --> 00:28:52,730
working, what's not working.

500
00:28:52,730 --> 00:28:53,250
Let's try this.

501
00:28:53,250 --> 00:28:53,810
Let's try that.

502
00:28:53,810 --> 00:28:55,490
Let's let's disappoint them.

503
00:28:55,490 --> 00:28:55,810
Lovely.

504
00:28:55,810 --> 00:28:59,690
Can absorb and help them understand that they are actually going back to feedback

505
00:28:59,690 --> 00:29:01,250
loops, I'll shut up for a second here.

506
00:29:01,330 --> 00:29:03,330
They are actually faster.

507
00:29:03,650 --> 00:29:03,970
Yes.

508
00:29:03,970 --> 00:29:08,250
If they do more of their own testing and.

509
00:29:08,690 --> 00:29:14,930
Well, and again, this is why, and I agree with your comments on TDD, but not

510
00:29:14,930 --> 00:29:19,890
only, like I said, not only should they, they, they do their own testing,

511
00:29:19,890 --> 00:29:21,650
like accelerate, blah, blah, blah.

512
00:29:21,650 --> 00:29:27,130
See, see, you know, 70% of the last 100 podcasts we've done.

513
00:29:27,650 --> 00:29:27,930
Right.

514
00:29:27,970 --> 00:29:38,120
Um, the, but if they don't know how I absolutely believe, uh, the two key

515
00:29:38,120 --> 00:29:42,160
things are TDD and small batch.

516
00:29:42,720 --> 00:29:42,960
Right.

517
00:29:43,120 --> 00:29:43,480
Yeah.

518
00:29:44,080 --> 00:29:48,320
And, and, and, and I agree with you that TDD isn't necessarily around covering,

519
00:29:49,000 --> 00:29:53,200
but it does, it does kind of kill two birds with one stone.

520
00:29:53,200 --> 00:29:59,560
It makes a better design, which, which not only makes it more testable, but,

521
00:29:59,680 --> 00:30:06,150
um, uh, the better design makes it a lot easier to add features to it later.

522
00:30:06,470 --> 00:30:06,870
Yeah.

523
00:30:07,590 --> 00:30:12,310
Um, the, but I think the, the second part of that, I'm going to interrupt

524
00:30:12,310 --> 00:30:15,830
because the second part of that is more important and Brian Finster, I had

525
00:30:16,270 --> 00:30:18,190
never really articulate like he had.

526
00:30:18,190 --> 00:30:19,950
And I use this all the time now.

527
00:30:22,210 --> 00:30:28,050
Do CD or figure out what will be involved to do continuous deployment, because

528
00:30:28,050 --> 00:30:32,530
even that, even the thought experiment will help highlight everything

529
00:30:32,530 --> 00:30:34,250
blocking you from doing CD.

530
00:30:34,490 --> 00:30:38,290
So if you go to a team that requests this and they say, uh, we want to

531
00:30:38,290 --> 00:30:41,490
go hire a bunch of testers to solve a problem we don't understand.

532
00:30:41,850 --> 00:30:45,290
And their problem is once you dig in that, well, we're, we have a bunch of

533
00:30:45,290 --> 00:30:46,810
bugs that are getting to customers.

534
00:30:47,290 --> 00:30:50,130
And so we need, we need more time to bake them in or whatever it is.

535
00:30:50,490 --> 00:30:52,610
Say what's, what's missing.

536
00:30:52,770 --> 00:30:55,410
If you need to do continuous deployment, we're going to need to have, you know,

537
00:30:55,410 --> 00:30:56,210
more tests, great.

538
00:30:56,650 --> 00:30:58,050
Why can't your developers read those tests?

539
00:30:58,170 --> 00:31:03,250
As just anyway, do CD, even if you'd never ever do it, go through the process.

540
00:31:04,490 --> 00:31:09,070
I still, uh, yeah.

541
00:31:09,110 --> 00:31:09,470
Okay.

542
00:31:09,630 --> 00:31:10,590
Number one, you're right.

543
00:31:10,590 --> 00:31:16,470
Go through the process because that will probably inspire things that you

544
00:31:16,470 --> 00:31:17,910
realize that you can do.

545
00:31:17,950 --> 00:31:20,190
You can't just say, no, we can't do CD.

546
00:31:20,430 --> 00:31:20,710
Right.

547
00:31:21,310 --> 00:31:30,320
The thing is you will never do CD if you do not ever start thinking

548
00:31:30,320 --> 00:31:32,680
about how to do CD, right.

549
00:31:33,520 --> 00:31:35,400
In order to finish it, you have to start.

550
00:31:35,800 --> 00:31:41,440
So don't use, don't use your perception of it to avoid starting.

551
00:31:41,520 --> 00:31:43,520
Like it's sort of the same thing.

552
00:31:43,520 --> 00:31:48,160
I, I encountered with agile people, people like we

553
00:31:48,160 --> 00:31:53,200
talked about it many times before and many years ago, like my hatred of the

554
00:31:53,200 --> 00:31:56,600
manifesto, because people use it as a shortcut.

555
00:31:56,600 --> 00:31:58,640
They don't spend time thinking about it.

556
00:31:58,640 --> 00:32:00,920
Intellectual lazy kicks, kicks in.

557
00:32:01,400 --> 00:32:04,280
And one side says, Oh, agile will never work here.

558
00:32:04,280 --> 00:32:08,640
And the other side abuses it to dysfunction.

559
00:32:08,760 --> 00:32:10,880
Fragile as, as you call it.

560
00:32:11,560 --> 00:32:11,920
Right.

561
00:32:12,040 --> 00:32:17,400
Um, to me, it's, it's encouraged people to.

562
00:32:18,680 --> 00:32:23,640
Every six months, figure out a way to reduce by an order of magnitude,

563
00:32:24,320 --> 00:32:26,830
your deployment time, right.

564
00:32:26,830 --> 00:32:37,950
It, it, and, um, a lot of the strategies around preventing error to the customer.

565
00:32:38,970 --> 00:32:43,380
Um, that we used to do, well, certainly a lot of the strategies we used to do in

566
00:32:43,380 --> 00:32:49,740
the old package, pre-packaged software world, um, just start dumb today.

567
00:32:50,430 --> 00:32:50,710
Right.

568
00:32:50,910 --> 00:32:52,270
Yeah, you should prevent.

569
00:32:52,670 --> 00:32:53,110
Okay.

570
00:32:53,230 --> 00:32:56,900
But don't over prevent, right?

571
00:32:56,900 --> 00:32:58,620
How, well, how do we figure that out?

572
00:32:58,660 --> 00:33:02,060
Well, you know, flight control is a great system.

573
00:33:02,060 --> 00:33:05,500
That's an exposure controls, a great system for this.

574
00:33:05,820 --> 00:33:10,460
It's better to improve your observability to understand the errors in flight than

575
00:33:10,460 --> 00:33:15,900
it is to, um, when you're operating the service, then to put all of that energy

576
00:33:15,900 --> 00:33:19,660
into your prevention test code that you can't reuse once operating.

577
00:33:20,220 --> 00:33:29,880
Like the other thing, just to briefly rant around testing, um, the, that the

578
00:33:29,880 --> 00:33:33,960
same organization talked to me and they're like, but Brent, we really

579
00:33:33,960 --> 00:33:35,880
want to prevent regressions.

580
00:33:36,720 --> 00:33:40,760
And I'm like, what do you mean?

581
00:33:40,800 --> 00:33:46,380
Well, we had a bug that was in the product for seven years and it just

582
00:33:46,380 --> 00:33:49,040
hit us, uh, and cause an outage.

583
00:33:49,850 --> 00:33:54,700
And I'm like, okay, but it had no impact for seven years.

584
00:33:55,180 --> 00:34:03,080
And so now you want to, to spawn up a needle in the haystack exercise where

585
00:34:03,080 --> 00:34:07,160
you don't even know if there's a needle in the haystack and your rate at which

586
00:34:07,160 --> 00:34:12,040
you can go through the haystacks is significantly slower in which, in

587
00:34:12,080 --> 00:34:17,230
terms of the rate at which new haystacks are for me, I'm like, you're asking.

588
00:34:18,720 --> 00:34:23,200
The old ways will not scale to solve the problem you have today.

589
00:34:23,240 --> 00:34:27,240
What you need to do going to your point around what's the goal.

590
00:34:27,840 --> 00:34:31,860
What you need to do is a minimize the amount of time the customer is in,

591
00:34:32,120 --> 00:34:37,180
is in pain, not move all of that energy to, we must prevent pain.

592
00:34:37,500 --> 00:34:37,700
Okay.

593
00:34:37,740 --> 00:34:40,500
Brent, it is 2024.

594
00:34:41,060 --> 00:34:42,220
Yes, I agree.

595
00:34:42,480 --> 00:34:46,340
Any, any problem as you're describing your sounds really hard.

596
00:34:46,700 --> 00:34:47,380
Easy answer.

597
00:34:48,100 --> 00:34:48,820
Always AI.

598
00:34:49,380 --> 00:34:49,900
LLM.

599
00:34:50,340 --> 00:34:52,380
Tell, tell, tell them to use an LLM to solve it.

600
00:34:53,460 --> 00:34:57,820
That's just what you can do because as we know, AI is magic.

601
00:34:58,140 --> 00:35:03,660
What you do is you feed, you make an LLM out of your code and then you ask a

602
00:35:03,660 --> 00:35:09,080
prompt where the needle is and it just tells you, cause it's AI and it's magic.

603
00:35:11,020 --> 00:35:11,460
Right.

604
00:35:11,580 --> 00:35:12,060
Actually.

605
00:35:12,060 --> 00:35:16,540
And we can just do multi-agent AI and just have the AI talk to each other.

606
00:35:17,620 --> 00:35:17,740
Yeah.

607
00:35:17,740 --> 00:35:18,940
Have one that generates the code.

608
00:35:18,980 --> 00:35:23,660
In fact, why don't we get rid of the customers and just deliver our software to AI?

609
00:35:24,100 --> 00:35:27,580
And it'll tell us if there are bugs because it's AI and it's magic.

610
00:35:28,220 --> 00:35:28,580
Right.

611
00:35:28,620 --> 00:35:31,460
And that's an excellent point.

612
00:35:31,500 --> 00:35:35,900
And like, tell me how we would even get, I mean, how would we get a

613
00:35:35,900 --> 00:35:37,420
faster feedback loop than that?

614
00:35:37,980 --> 00:35:38,460
We can't.

615
00:35:38,780 --> 00:35:43,940
And as we know, fast feedback loops and, and, but obviously we are being facetious.

616
00:35:44,540 --> 00:35:48,300
But I do know that you had another story we talked about briefly in the,

617
00:35:48,380 --> 00:35:51,300
in the, in the intro, I'm going to put you on the spot for a bit.

618
00:35:51,900 --> 00:35:55,900
Um, and it goes back to people thinking AI is magic.

619
00:35:56,420 --> 00:36:01,820
And there's, I forget the details now, but there is something around a team wanting

620
00:36:01,820 --> 00:36:07,380
to use AI or LLMs to solve one of the longest known problems in testing.

621
00:36:07,660 --> 00:36:08,380
Yes.

622
00:36:08,740 --> 00:36:10,380
And, and I will set it up a little bit.

623
00:36:10,380 --> 00:36:14,140
Cause I didn't remember as I was talking, I went to GTAC, the Google

624
00:36:14,140 --> 00:36:16,100
test automation conference in 2008.

625
00:36:17,010 --> 00:36:23,530
And I saw speakers from reputable, high quality software engineering

626
00:36:23,530 --> 00:36:25,210
companies across the industry.

627
00:36:25,650 --> 00:36:29,610
And I remember I tweeted, which is the thing we did back when, um, used to be

628
00:36:29,610 --> 00:36:34,370
a platform called Twitter that was fun for it's like, you know, sharing ideas

629
00:36:34,370 --> 00:36:35,410
with the little community there.

630
00:36:35,650 --> 00:36:36,970
It was pretty popular for a while.

631
00:36:36,970 --> 00:36:42,290
I think it's been dead for a while, but on Twitter, I tweeted about the

632
00:36:42,290 --> 00:36:45,890
fact that they should rename the conference, the flaky test conference.

633
00:36:45,890 --> 00:36:50,850
Cause of these illuminaries from around Facebooks and Netflix's and

634
00:36:50,850 --> 00:36:55,570
Google's every single talk had at least one section, not a large section

635
00:36:55,850 --> 00:36:57,330
talking about flaky tests.

636
00:36:59,180 --> 00:36:59,780
Yes.

637
00:37:01,520 --> 00:37:09,600
The, the primary bane, uh, in existence, like just to go back to like,

638
00:37:09,600 --> 00:37:14,040
but one of my experiences around, and I think you've done speeches on this,

639
00:37:14,040 --> 00:37:16,560
so you can probably rattle off all the causes.

640
00:37:16,960 --> 00:37:22,320
I've done a great deal of time trying to repress, um, my time as a tester.

641
00:37:22,960 --> 00:37:30,750
Um, but one of the causes that kind of goes into the last topic around overuse

642
00:37:30,750 --> 00:37:38,950
of the prevention techniques is, um, One of the main reasons why software doesn't

643
00:37:38,950 --> 00:37:42,350
work when it goes to production is because production is dirty.

644
00:37:43,060 --> 00:37:47,340
And when we test in a local thing, we try to, we kind of do it in a clean room

645
00:37:47,340 --> 00:37:52,300
exercise, some teams will do things like, you know, they, they have the ability to

646
00:37:52,300 --> 00:37:57,780
dirty up their current, their current environment, but it eventually gets out

647
00:37:57,780 --> 00:38:01,380
of sync and, um, that's why they should just test in production.

648
00:38:01,940 --> 00:38:02,540
Agreed.

649
00:38:02,940 --> 00:38:11,310
Um, the, but that's also one of the causes of flakiness.

650
00:38:12,360 --> 00:38:12,600
Right.

651
00:38:12,600 --> 00:38:16,600
It's, oh, well, it's because you haven't really set up your test.

652
00:38:17,520 --> 00:38:23,280
Uh, in my experience, you haven't really set up, set up the initial sets of, uh,

653
00:38:23,280 --> 00:38:33,530
the test before you engage the Oracle part of it to, to guarantee that there

654
00:38:33,530 --> 00:38:35,890
isn't variance in the Oracle bit of it.

655
00:38:35,890 --> 00:38:38,250
It's like, no, right.

656
00:38:38,290 --> 00:38:43,690
Sometimes system goes slower and, and, and if you're waiting for this

657
00:38:43,730 --> 00:38:48,010
event to trigger within five seconds, like sometimes it doesn't do that.

658
00:38:48,770 --> 00:38:49,090
Right.

659
00:38:49,170 --> 00:38:56,110
Um, anyway, I'm going to, so I guess the question is, okay, to what degree

660
00:38:56,110 --> 00:38:58,150
could we apply LLM today?

661
00:38:58,150 --> 00:39:03,790
That's the question I have is can we, it's flaky tests, age old problem.

662
00:39:04,150 --> 00:39:07,750
As you know, as I just stated five minutes ago, anytime we have a hard

663
00:39:07,750 --> 00:39:08,950
problem, it's unsolvable.

664
00:39:09,270 --> 00:39:12,430
All we do is all we do is throw AI at it and it's solved.

665
00:39:12,470 --> 00:39:13,310
It's magic.

666
00:39:13,910 --> 00:39:14,470
Right.

667
00:39:16,380 --> 00:39:16,740
Okay.

668
00:39:16,780 --> 00:39:17,340
Is that it?

669
00:39:17,940 --> 00:39:18,260
That's it.

670
00:39:18,260 --> 00:39:19,380
So, so is that true?

671
00:39:19,860 --> 00:39:21,260
Tell me why that is or isn't true.

672
00:39:22,490 --> 00:39:31,420
Oh, um, I'm not entirely certain at this point in time, because I do think, I do

673
00:39:31,420 --> 00:39:37,720
think, to me, I do think we could apply LLM to solve that problem.

674
00:39:38,240 --> 00:39:45,380
Um, but at the end of it, what I'm trying to load up, uh, into it using

675
00:39:45,380 --> 00:39:54,180
my intuition is, okay, but is the ROI of that approach going to be lesser?

676
00:39:54,380 --> 00:39:55,420
Is it going to be worth it?

677
00:39:55,700 --> 00:39:56,060
Right.

678
00:39:56,660 --> 00:39:58,100
Because I could go, all right.

679
00:39:58,100 --> 00:40:03,100
Well, we could chain together a bulge of multi-agent LLMs, one covering each

680
00:40:03,100 --> 00:40:05,780
other, one, you know, we run code.

681
00:40:06,460 --> 00:40:11,450
And then we go, Oh, how do we make this, um, less flaky, right?

682
00:40:11,450 --> 00:40:13,530
And it's going to be around setting up the environment.

683
00:40:13,530 --> 00:40:15,930
A lot of the times from my experience.

684
00:40:16,530 --> 00:40:19,000
Um, but then, right.

685
00:40:19,000 --> 00:40:26,620
What happens at the LLM, um, goes after, goes after the same hack we used to do

686
00:40:26,620 --> 00:40:31,700
in tests and, you know, Oh, just change the sleep from five to 15.

687
00:40:32,700 --> 00:40:33,180
Sure.

688
00:40:33,820 --> 00:40:34,460
Sure.

689
00:40:34,500 --> 00:40:35,500
More sleeps.

690
00:40:35,900 --> 00:40:38,180
That's the solution and more retries.

691
00:40:38,340 --> 00:40:38,740
Right.

692
00:40:39,990 --> 00:40:41,790
More retries, more sleeps.

693
00:40:42,430 --> 00:40:47,030
Uh, if, if we want to implement that, then absolutely, then I'm going to change my

694
00:40:47,030 --> 00:40:49,150
answer as far less complex, absolutely.

695
00:40:49,150 --> 00:40:51,150
L L and could solve all of those problems.

696
00:40:55,240 --> 00:41:02,190
It falls into that, you know, it's just, it's not magic.

697
00:41:02,830 --> 00:41:04,030
That's, that's really the answer.

698
00:41:04,030 --> 00:41:04,790
It's not magic.

699
00:41:05,670 --> 00:41:09,430
You'd have to look at, I'm not even sure what data you would feed into the

700
00:41:09,430 --> 00:41:16,680
LLM to help solve the flaky test problem flaky tests that, I mean, there's

701
00:41:16,760 --> 00:41:21,240
multiple, multiple criteria to define flaky at the very least level, the very

702
00:41:21,240 --> 00:41:27,960
smallest level, uh, it's tests that either fail or pass when they shouldn't based

703
00:41:27,960 --> 00:41:29,000
on the condition of the system.

704
00:41:29,320 --> 00:41:32,000
The, the approach I would take initially.

705
00:41:32,880 --> 00:41:38,360
What essentially, um, the way I'm thinking of it, it's probably simpler ways of doing

706
00:41:38,360 --> 00:41:48,120
it, but run, uh, take the code, run it through, um, LLM with a series of prompts

707
00:41:48,940 --> 00:41:55,380
that are related to testing the code, similar to like a code review.

708
00:41:56,240 --> 00:42:06,290
Hey, Hey, LLM evaluate, uh, to what degree this, this test case is going to be

709
00:42:06,290 --> 00:42:10,500
resilient, um, or flaky, right.

710
00:42:10,500 --> 00:42:12,140
And then propose fix.

711
00:42:13,300 --> 00:42:20,940
Again, it's, it's too magic key because when testers write or developers, you

712
00:42:20,940 --> 00:42:25,980
know, back in this century, write test code, they run that test and it gives

713
00:42:25,980 --> 00:42:33,710
them the proper result, the flaky part comes from, uh, almost a drift into failure

714
00:42:33,710 --> 00:42:35,390
of Sydney Decker type situation.

715
00:42:35,630 --> 00:42:42,870
It, a test that should pass or a test that should fail passes because of multiple

716
00:42:42,870 --> 00:42:46,990
different system factors happening at the same time, this test always passes

717
00:42:47,390 --> 00:42:54,670
in less run while memory is below 60% and time is changing over from 11 59

718
00:42:54,670 --> 00:42:55,830
am to 12 p.m.

719
00:42:57,520 --> 00:42:58,040
Okay.

720
00:42:58,360 --> 00:43:02,960
Uh, your L how is your LLM going to find that bit of it?

721
00:43:03,320 --> 00:43:09,800
I guess you could note again, I wouldn't use an LLM for this is for traditionally

722
00:43:10,080 --> 00:43:14,400
maybe cause maybe cause I don't know AI or LLMs well enough, but this is

723
00:43:14,400 --> 00:43:18,880
traditionally where we'd write a model to try it like a scoring to look at.

724
00:43:18,880 --> 00:43:19,040
Okay.

725
00:43:19,040 --> 00:43:21,440
This test has timing dependencies.

726
00:43:21,680 --> 00:43:23,560
This test has memory dependencies.

727
00:43:23,760 --> 00:43:28,320
They make it more prone to flakiness and I could, I would want

728
00:43:28,320 --> 00:43:30,800
to reduce my flakiness score.

729
00:43:31,320 --> 00:43:33,080
Um, but I think every test, like I

730
00:43:33,160 --> 00:43:37,360
have a test that does, you know, verify that two divided by two equals one,

731
00:43:37,800 --> 00:43:41,600
the flakiness of that test, the flakiness factor is zero.

732
00:43:42,280 --> 00:43:46,040
If I have a test that's very complicated, that relies on a bunch of systems

733
00:43:46,040 --> 00:43:50,000
things, I would say the flakiness factor is a much higher number.

734
00:43:50,000 --> 00:43:52,600
If it's zero to one, it's probably somewhere in the point, you know,

735
00:43:52,600 --> 00:43:57,290
seven, 5.8 area, uh, and that, but that's just an algorithm.

736
00:43:57,330 --> 00:43:58,410
That's not AI.

737
00:43:58,690 --> 00:44:02,770
I still don't understand how the LLM is going to help you understand and

738
00:44:02,770 --> 00:44:05,570
fix flaky tests other than a wish for magic.

739
00:44:07,240 --> 00:44:07,720
Yeah.

740
00:44:07,920 --> 00:44:12,320
Uh, I don't, I, I'm, I'm, for the listeners, I am sharing screen.

741
00:44:12,320 --> 00:44:17,560
I've gotten the Google scholar look, just did a search for LLM solving flaky tests.

742
00:44:18,200 --> 00:44:26,850
And there are a bunch of articles on this topic, at least the top four seem to be on that.

743
00:44:27,050 --> 00:44:33,390
So, um, it's, it isn't magic.

744
00:44:33,390 --> 00:44:35,070
It's probably going to be work.

745
00:44:35,960 --> 00:44:40,720
And now I am fascinated by this and I'll be typing into it.

746
00:44:40,760 --> 00:44:45,280
I'm not going to try to read it and regurgitate it here.

747
00:44:45,600 --> 00:44:50,680
Um, but again, they talked about something called a neuro symbolic technique.

748
00:44:51,890 --> 00:44:53,770
Great, great.

749
00:44:54,170 --> 00:44:58,010
Here's, I'm going to go back 10 years to what I know and what I know is not.

750
00:44:58,010 --> 00:45:02,250
I mean, I know probably more about AI than the average software engineer,

751
00:45:02,250 --> 00:45:07,090
but I know enough to know, I know very, very little, but as you know, I, I, I fake

752
00:45:07,090 --> 00:45:09,250
things quite well in the old days.

753
00:45:09,490 --> 00:45:09,610
Yeah.

754
00:45:09,610 --> 00:45:11,770
As you remember at the time, I worked a lot with not cheating.

755
00:45:11,770 --> 00:45:16,170
I got the pond over an MSR doing a bunch of, he did, he did all the heavy work.

756
00:45:16,170 --> 00:45:18,050
I just helped him review and think of ideas.

757
00:45:18,410 --> 00:45:24,850
Um, but, uh, in that old MSR software development model, they would take,

758
00:45:25,130 --> 00:45:29,730
they would analyze every test that's ever been labeled as flaky and come up with

759
00:45:29,730 --> 00:45:34,370
factors for what made them flaky, why they were, you know, what, what factors were in

760
00:45:34,370 --> 00:45:37,890
there and they would build a model that would generate a flakiness score.

761
00:45:38,690 --> 00:45:44,260
Uh, to me that, and again, a flaky test isn't a bad test.

762
00:45:45,280 --> 00:45:51,000
Um, it, but it requires more human time to understand if the results are something

763
00:45:51,000 --> 00:45:52,240
you need to care about or not.

764
00:45:53,190 --> 00:45:57,190
Uh, you could, I mean, you can, once you know, a test is flaky through an

765
00:45:57,190 --> 00:46:00,910
algorithm, you could refactor it and make it into two less flaky tests or, or

766
00:46:00,910 --> 00:46:03,030
three, even less flaky tests as possible.

767
00:46:03,510 --> 00:46:08,070
You could put constraints around some of the external inputs to reduce that flakiness.

768
00:46:08,750 --> 00:46:14,740
But I, given how long I've been in software, given what I know about how

769
00:46:14,740 --> 00:46:19,860
LLMs are not magic, I don't think the flaky test today, at least with the

770
00:46:19,860 --> 00:46:24,420
technology we have today, the flaky test problem is not a solvable problem.

771
00:46:25,060 --> 00:46:27,220
Not, not, not a hundred percent solvable problem.

772
00:46:29,160 --> 00:46:34,080
Meaning do all the work you want with LLMs and burning up the environment.

773
00:46:34,360 --> 00:46:37,300
You will still have flaky tests fewer.

774
00:46:37,380 --> 00:46:38,020
You'll still have them.

775
00:46:38,790 --> 00:46:47,500
That is the closest thing I have heard ever from you shutting,

776
00:46:47,580 --> 00:46:49,300
shutting the door on a topic.

777
00:46:49,300 --> 00:46:49,820
That's fast.

778
00:46:49,900 --> 00:46:51,900
That by itself is fascinating to me.

779
00:46:52,540 --> 00:46:58,740
Um, yeah, but the, the thing is, um,

780
00:46:59,300 --> 00:47:01,660
you're right, the tech may not be there today.

781
00:47:02,630 --> 00:47:03,070
Right.

782
00:47:03,110 --> 00:47:14,680
Um, the, but like one of the things, one of the things I, um, just noticed, like

783
00:47:14,680 --> 00:47:20,080
one of the papers that I found on Google scholar, they, it's a small sample size,

784
00:47:20,120 --> 00:47:29,420
but they tried, um, they tried using their algorithm to fix 79 tests, uh, on,

785
00:47:29,580 --> 00:47:33,420
on public get hubs and 19 of them were accepted.

786
00:47:34,600 --> 00:47:34,880
Right.

787
00:47:34,880 --> 00:47:36,720
So yeah, that's, that's your point.

788
00:47:36,720 --> 00:47:45,140
It's not a hundred percent, but, um, 25% pears down the problem, uh,

789
00:47:45,180 --> 00:47:47,140
in a way that is helpful.

790
00:47:47,540 --> 00:47:53,220
Here's another study I want, uh, again, I, I'm just going to lean on what I know.

791
00:47:54,020 --> 00:48:00,190
Uh, I wonder if, and going back to TDD and how TDD makes more testable

792
00:48:00,190 --> 00:48:05,650
code, uh, like we talked about earlier, I would also like to look at a code

793
00:48:05,650 --> 00:48:11,450
base and understand from a code base, how light, like there's a likelihood.

794
00:48:11,450 --> 00:48:14,330
I don't know how to measure it yet, but there is a likelihood based on the

795
00:48:14,330 --> 00:48:20,890
characteristics of a code base or a code, a code module of how likely it

796
00:48:20,890 --> 00:48:23,810
is that flaky tests exists for that module.

797
00:48:24,330 --> 00:48:29,450
For example, if you have a, an API that takes 13 input parameters and they

798
00:48:29,450 --> 00:48:35,980
interact with each other, uh, I would, there's a good chance that you will

799
00:48:35,980 --> 00:48:38,180
have flaky tests for that module.

800
00:48:38,220 --> 00:48:38,820
Why?

801
00:48:40,530 --> 00:48:45,650
I mean, it's an interesting hypothesis and, and I'm probably well positioned.

802
00:48:47,040 --> 00:48:55,080
No, I don't have yet automated access to a sort of get hub app, but for me,

803
00:48:55,080 --> 00:49:02,930
it's, it's more around timing, right?

804
00:49:02,930 --> 00:49:08,450
Clicky test comes from there's some element of non-deterministic behavior.

805
00:49:09,630 --> 00:49:16,360
Uh, in the system you're evaluating or actually in the test code itself, it's

806
00:49:16,360 --> 00:49:19,040
that non-determinism that causes flakiness.

807
00:49:22,320 --> 00:49:22,920
Maybe.

808
00:49:23,040 --> 00:49:23,440
Yeah.

809
00:49:23,880 --> 00:49:25,040
I think there's something there.

810
00:49:25,120 --> 00:49:31,890
Anyway, I think this is truly one of those hard problems that, well, actually,

811
00:49:32,050 --> 00:49:34,170
I'm going to change my answer in the middle of it before you even heard

812
00:49:34,170 --> 00:49:37,330
what my answer was, I think this is a hard problem in test.

813
00:49:38,120 --> 00:49:43,000
I think it will remain a hard problem, but because I think you and I know this

814
00:49:43,160 --> 00:49:48,080
flaky tests can often, in fact, I won't even say from time to time can often

815
00:49:48,080 --> 00:49:53,280
actually provide value, even though they're flaky, I don't know if this is

816
00:49:53,280 --> 00:49:55,800
a problem I talked about not being solvable today.

817
00:49:56,440 --> 00:49:58,720
Is it a problem worth solving?

818
00:50:12,730 --> 00:50:16,160
Probably to some degree, right?

819
00:50:16,160 --> 00:50:18,600
We talked about testing in production.

820
00:50:18,640 --> 00:50:23,040
Wait, we want to test in dirty systems, right?

821
00:50:23,160 --> 00:50:29,840
Dirty systems is one of the sources of non-deterministic behavior, right?

822
00:50:30,040 --> 00:50:36,730
Um, like the alternative is not test and let outages occur and react that way.

823
00:50:37,290 --> 00:50:42,770
I'm not certain that that's right, but I definitely don't think we're going

824
00:50:42,770 --> 00:50:49,470
to resolve flaky tests that occur in the prevention side of it.

825
00:50:49,830 --> 00:50:53,760
I mean, that one should be resolvable, I think.

826
00:50:53,960 --> 00:50:59,960
Like, but part of me is just like, yeah, quit trying to create

827
00:50:59,960 --> 00:51:05,120
pre-production environments where you try to test how well this stuff

828
00:51:05,120 --> 00:51:09,690
works in the real world when it's not even related to the real world.

829
00:51:10,010 --> 00:51:14,040
Yeah, well, I think it's worth it.

830
00:51:14,040 --> 00:51:18,950
I know we need to close here in a second, but I worry, especially based on

831
00:51:18,950 --> 00:51:23,390
the first hypothesis you brought, um, and it could be, I'm worrying

832
00:51:23,390 --> 00:51:29,200
because my brain is sleep deprived, but I'm going to come up with a generality,

833
00:51:29,200 --> 00:51:31,400
which I, which I think is true here for me at least.

834
00:51:32,040 --> 00:51:34,040
Uh, and I want to fix this problem.

835
00:51:34,960 --> 00:51:43,400
Uh, why do we continuously try and solve the wrong problem or have a solution

836
00:51:43,760 --> 00:51:45,240
for the wrong problem?

837
00:51:46,160 --> 00:51:48,040
Uh, and again, not this isn't a big problem.

838
00:51:48,040 --> 00:51:49,000
We should try and solve.

839
00:51:49,000 --> 00:51:56,310
I think, uh, there's a lot more systems thinking needed in software for it to advance.

840
00:51:56,310 --> 00:51:58,070
How do all the pieces fit together?

841
00:51:58,790 --> 00:52:01,510
Is our flaky tests a problem?

842
00:52:01,950 --> 00:52:02,470
Yes.

843
00:52:02,790 --> 00:52:06,590
Are they my biggest problem for satisfying my customers and

844
00:52:06,590 --> 00:52:07,790
improving retention and stuff?

845
00:52:08,190 --> 00:52:11,300
Mmm, maybe, maybe not.

846
00:52:11,620 --> 00:52:14,980
Uh, here I think about Jimbo and his, his last work.

847
00:52:14,980 --> 00:52:15,900
I remember, right.

848
00:52:15,940 --> 00:52:19,580
It's he created a tool called the riskitizer.

849
00:52:19,940 --> 00:52:20,300
Yeah.

850
00:52:20,420 --> 00:52:25,620
Which, and it's just like, like my answer to your question is, well, it

851
00:52:25,620 --> 00:52:34,440
depends on what it's testing and like how much that represents, uh, risk to our

852
00:52:34,440 --> 00:52:36,520
definition of customer quality, right?

853
00:52:36,520 --> 00:52:40,120
The, the ability for the customer to solve their problem, right?

854
00:52:40,240 --> 00:52:46,130
The, if it's a small risk, then flakiness doesn't really matter.

855
00:52:46,450 --> 00:52:46,810
Yeah.

856
00:52:46,890 --> 00:52:50,810
And, and if, if you, maybe it is, maybe, yeah, we want our feedback loops from

857
00:52:50,810 --> 00:52:55,490
our CI to be, uh, they gotta be much more accurate because we lost a million

858
00:52:55,490 --> 00:52:58,650
dollars yesterday because one of our flaky tests passed, it should have failed.

859
00:52:58,650 --> 00:52:59,690
It'll be made a bad deployment.

860
00:53:00,050 --> 00:53:00,450
Right.

861
00:53:00,570 --> 00:53:04,730
Uh, then yeah, you gotta go fix that and you don't, and again, uh, theory

862
00:53:04,730 --> 00:53:08,330
of constraints, you don't eliminate the problem completely.

863
00:53:08,410 --> 00:53:12,410
You mitigate the problem until it's no longer your biggest sticking point,

864
00:53:12,730 --> 00:53:15,810
which you could do then, which you would solve enough of it.

865
00:53:15,810 --> 00:53:17,090
You would make that test less flaky.

866
00:53:17,090 --> 00:53:19,530
You would temporarily remove that test till you could refactor it.

867
00:53:19,530 --> 00:53:20,090
Whatever.

868
00:53:20,610 --> 00:53:23,790
Um, write a smaller test that gave you, you know, 90% of the

869
00:53:23,790 --> 00:53:24,970
act three that you could trust.

870
00:53:25,290 --> 00:53:28,130
Whatever the solution is, you're trying to mitigate that problem.

871
00:53:28,250 --> 00:53:30,330
So you can solve your overall problem.

872
00:53:30,330 --> 00:53:32,530
But I think people just look at, Oh, this is, this is broken.

873
00:53:32,530 --> 00:53:33,570
Let me go fix this.

874
00:53:34,050 --> 00:53:37,650
Software developers aren't just infatuated with solving a problem.

875
00:53:38,490 --> 00:53:42,130
Well, no, my friends that differently software developers in general are

876
00:53:42,130 --> 00:53:47,810
infatuated with developing solutions for perceived problems, not wallowing

877
00:53:47,810 --> 00:53:53,150
in the problem they want to solve and not weighing and debating to see if

878
00:53:53,150 --> 00:53:56,050
that's the biggest problem in their system that needs to be solved.

879
00:53:56,410 --> 00:53:59,370
That's where we, and that's where LLMs are not going to help us.

880
00:53:59,370 --> 00:54:00,530
It requires humans.

881
00:54:00,850 --> 00:54:02,050
Maybe an LLM can do this.

882
00:54:02,050 --> 00:54:06,610
I could I feed an LLM here are all my known problems of my software development.

883
00:54:06,770 --> 00:54:10,390
The problem is you can't know them all, but you have to find the one that

884
00:54:10,390 --> 00:54:12,370
matters the most and work on that one first.

885
00:54:12,470 --> 00:54:16,650
And then just God, people just like dive right to the, I'm going to implement

886
00:54:16,650 --> 00:54:18,410
an algorithm for that or put AI on it.

887
00:54:18,410 --> 00:54:19,010
It's magic.

888
00:54:19,090 --> 00:54:23,450
There is, there is, and I wouldn't be surprised.

889
00:54:23,450 --> 00:54:28,250
I'll, I'll save my, my check on Google scholar until after the podcast.

890
00:54:28,530 --> 00:54:28,810
Good.

891
00:54:28,850 --> 00:54:36,250
But there is a, um, to me, it does feel like there is.

892
00:54:36,410 --> 00:54:42,410
Some room for, you know, the next doctorate, um, PhD.

893
00:54:42,410 --> 00:54:43,650
I have a topic for them.

894
00:54:44,130 --> 00:54:44,530
All right.

895
00:54:44,570 --> 00:54:47,610
It's in, it's in there somewhere in systems thinking.

896
00:54:48,250 --> 00:54:49,770
It's, it's okay.

897
00:54:50,090 --> 00:54:59,390
System thinking is super important, but when the system grows, um, orders

898
00:54:59,390 --> 00:55:05,010
of magnitude beyond the cognitive limitations of the human, right?

899
00:55:05,010 --> 00:55:09,530
How do we, how do we as humans go about solving that?

900
00:55:10,920 --> 00:55:11,240
Right?

901
00:55:11,280 --> 00:55:15,800
The, the, like there's simple things all the time that I am dealing

902
00:55:15,800 --> 00:55:17,360
with and I can put out fires too.

903
00:55:17,400 --> 00:55:19,880
Like people come to me all the times.

904
00:55:19,880 --> 00:55:20,400
They break.

905
00:55:20,400 --> 00:55:22,600
Can you give me advice on this KPI?

906
00:55:23,400 --> 00:55:25,200
And then I'm like, yeah, I can.

907
00:55:25,640 --> 00:55:26,000
Right.

908
00:55:26,120 --> 00:55:30,960
Um, the problem with that KPI though, is that there's this other KPI

909
00:55:31,000 --> 00:55:32,600
that's battling against it.

910
00:55:33,200 --> 00:55:37,320
And if you guys don't work together to try to solve both of your KPI's

911
00:55:37,320 --> 00:55:41,400
and one's going to continuously cannibalize the other, and you're just

912
00:55:41,400 --> 00:55:43,840
going to go in circles because you're not evaluating the system.

913
00:55:44,780 --> 00:55:46,500
So this is, and we got it.

914
00:55:46,500 --> 00:55:49,540
We got to end cause I got to go to another meeting, but this is

915
00:55:49,540 --> 00:55:57,100
where like the software developers, they got to help them not teaching them testing.

916
00:55:57,180 --> 00:55:59,660
I think that's relatively easy testers.

917
00:55:59,660 --> 00:56:00,260
Don't get mad at me.

918
00:56:00,260 --> 00:56:01,780
There's there's yes, there's nuance.

919
00:56:02,100 --> 00:56:05,260
It's systems thinking, critical thinking.

920
00:56:05,780 --> 00:56:12,240
It's those skills, those, those, those thinking skills that I see

921
00:56:12,240 --> 00:56:14,520
missing the most from software developers.

922
00:56:15,080 --> 00:56:15,640
Teach them that.

923
00:56:16,960 --> 00:56:23,040
Uh, even more so teach them to the degree that they create, in my view,

924
00:56:23,360 --> 00:56:29,920
create automated systems that help you analyze what you were about to do.

925
00:56:30,160 --> 00:56:31,440
Now, what that means.

926
00:56:31,480 --> 00:56:32,600
I don't, I don't know.

927
00:56:32,640 --> 00:56:37,430
Look before you leap a little bit, stop this ready fire aim stuff already.

928
00:56:37,430 --> 00:56:38,230
Already fire.

929
00:56:38,670 --> 00:56:38,990
No.

930
00:56:39,110 --> 00:56:46,350
So, so like here is a, here is a problem with a, with a large enough, uh, system.

931
00:56:46,830 --> 00:56:47,070
Right.

932
00:56:47,070 --> 00:56:54,740
You have one dev team way over here has no idea that after, after goes through

933
00:56:54,740 --> 00:57:01,360
the entire complex domino chain, that his check-in could, could break this product.

934
00:57:01,360 --> 00:57:04,440
He's never even heard of, right?

935
00:57:04,440 --> 00:57:12,010
It's it's how, how, how is it even possible for us to proactively determine that?

936
00:57:12,290 --> 00:57:18,370
And if it's not possible, which I would argue that not possible in linear time

937
00:57:18,370 --> 00:57:28,850
anyway, um, then what we need to do is figure out how do we detect and react to it?

938
00:57:29,990 --> 00:57:30,230
Right.

939
00:57:30,910 --> 00:57:35,630
To me, I think it's pointless to focus so much on prevention.

940
00:57:36,310 --> 00:57:40,830
It's no, you need to detect and react to it optimized for reaction.

941
00:57:41,390 --> 00:57:42,150
That's my view.

942
00:57:42,790 --> 00:57:43,790
Sounds good.

943
00:57:43,790 --> 00:57:44,110
All right.

944
00:57:44,110 --> 00:57:45,950
We got to, you got to close this thing.

945
00:57:46,030 --> 00:57:46,790
That's close.

946
00:57:47,030 --> 00:57:48,830
This has been AI Alan.

947
00:57:48,990 --> 00:57:50,190
And just Brent.

