WEBVTT

00:00:00.000 --> 00:00:04.440
And, and Brent has no idea what I said because he was typing furiously.

00:00:04.760 --> 00:00:05.480
But what did you ask it?

00:00:05.480 --> 00:00:06.080
What did you ask?

00:00:06.080 --> 00:00:10.400
I actually did have what it is, but the second you challenged me on that, it did

00:00:10.400 --> 00:00:11.120
flush. Yes.

00:00:14.770 --> 00:00:18.930
Welcome to AB testing podcast, your modern testing podcast.

00:00:19.250 --> 00:00:24.650
Your hosts, Alan and Brent will be here to guide you through topics on testing,

00:00:24.890 --> 00:00:27.850
leadership, agile, and anything else that comes to mind.

00:00:28.130 --> 00:00:29.730
Now on with the show.

00:00:29.890 --> 00:00:30.770
Hello, everyone.

00:00:30.970 --> 00:00:31.730
It's Alan.

00:00:32.210 --> 00:00:33.260
And Brent.

00:00:33.460 --> 00:00:38.930
And we're here today to bring light to your life, like rays of sunshine sparkling

00:00:38.930 --> 00:00:44.010
into your living room or your car or wherever you listen to our wonderful podcast.

00:00:44.410 --> 00:00:47.790
Calm, motion, gently crash.

00:00:47.830 --> 00:00:51.910
This is the Pretty Little Things podcast where we talk about things that make us

00:00:51.910 --> 00:00:54.950
happy. No, we talk about things that make us mad and piss us off.

00:00:55.270 --> 00:00:57.030
This is AB testing, damn it.

00:00:57.550 --> 00:00:58.110
Yes.

00:00:59.340 --> 00:01:01.900
Who wants to listen to what makes us happy?

00:01:02.060 --> 00:01:04.380
So I think I may get the recording right the first time here.

00:01:04.380 --> 00:01:06.060
We will see what happens.

00:01:06.380 --> 00:01:07.860
I'm learning new stuff.

00:01:08.300 --> 00:01:09.500
Just had another problem.

00:01:09.540 --> 00:01:11.580
I accidentally unplugged my recording device.

00:01:11.580 --> 00:01:13.140
Hopefully I won't do that again.

00:01:13.620 --> 00:01:14.860
But how you been doing, Brent?

00:01:15.980 --> 00:01:17.500
Uh, it's review season.

00:01:17.780 --> 00:01:19.840
So yay.

00:01:19.880 --> 00:01:21.320
You didn't use that like a month ago.

00:01:21.320 --> 00:01:23.280
Is it, how long does review season last?

00:01:23.920 --> 00:01:28.260
Uh, this time it was three, three weeks.

00:01:28.300 --> 00:01:29.060
It's not too bad.

00:01:29.220 --> 00:01:30.020
That's not too bad.

00:01:30.420 --> 00:01:31.620
We have that coming up.

00:01:32.020 --> 00:01:36.820
We should probably talk about not specifics of that, but I have a lot of

00:01:36.820 --> 00:01:41.220
thoughts that are thought were ubiquitous, but are not around how to do fair

00:01:41.220 --> 00:01:45.100
employee reviews, but that is not on my bullet list for today.

00:01:45.380 --> 00:01:45.940
What a pain.

00:01:45.940 --> 00:01:48.940
And at Microsoft too, it's, it's, it's weird.

00:01:49.380 --> 00:01:50.980
Flip a coin, right?

00:01:50.980 --> 00:01:51.500
It's fair.

00:01:51.500 --> 00:01:52.340
50 50.

00:01:52.380 --> 00:01:53.220
Just flip a coin.

00:01:54.100 --> 00:01:54.700
Throw darts.

00:01:55.300 --> 00:01:56.820
Nine boxes and darts.

00:01:57.140 --> 00:01:57.860
That's all we need.

00:01:58.260 --> 00:02:01.380
Have you gone through a review season at the current place?

00:02:01.380 --> 00:02:01.780
No.

00:02:02.500 --> 00:02:03.020
Okay.

00:02:03.220 --> 00:02:11.140
That should be a topic because I'm very curious as to, as to how much Microsoft

00:02:11.180 --> 00:02:14.460
and unity have influenced your style at the new place.

00:02:14.460 --> 00:02:18.140
Well, it's also, you have to do your style as much as you can within a

00:02:18.140 --> 00:02:21.060
confine of rules given to you by your context.

00:02:21.700 --> 00:02:22.620
Yes.

00:02:23.020 --> 00:02:24.580
So I will do what I can.

00:02:24.620 --> 00:02:26.700
My big value with me is fairness.

00:02:26.700 --> 00:02:31.140
I'll try and be fair, but sometimes the fair thing to do is to give one

00:02:31.260 --> 00:02:34.300
if someone's 0% merit, it's fair.

00:02:34.460 --> 00:02:36.540
What's critical is that we're fair all the time.

00:02:36.540 --> 00:02:38.180
Anyway, that is another topic.

00:02:38.460 --> 00:02:42.580
We're probably not going to get there in 2023.

00:02:43.340 --> 00:02:47.460
If we record in two weeks, we may get two more episodes in before the end of the

00:02:47.460 --> 00:02:51.100
year, we've got to coordinate calendars and figure that out to make sure we get

00:02:51.100 --> 00:02:56.860
the 2023 predictions and recap episode recorded properly.

00:02:57.460 --> 00:03:00.940
So let's spend a little bit of calendar time offline here, but that's coming

00:03:00.940 --> 00:03:02.100
up as a little preview.

00:03:02.100 --> 00:03:05.580
So one ninety one or one ninety two will be that the year end recap and

00:03:05.580 --> 00:03:09.940
predictions episode, it'll be fun to look back and look forward like we always do

00:03:09.940 --> 00:03:12.540
for the last million years we've been doing this podcast.

00:03:13.060 --> 00:03:15.460
So speak at a podcast.

00:03:16.510 --> 00:03:19.790
I've been slowly catching up on my backlog of podcasts.

00:03:20.390 --> 00:03:21.030
Do you listen?

00:03:21.070 --> 00:03:25.870
You listen to I know 99% invisible used to be on your radar.

00:03:26.270 --> 00:03:28.030
Do you listen to podcasts much anymore?

00:03:28.430 --> 00:03:29.950
Not as much.

00:03:29.950 --> 00:03:34.030
I still do like podcasts are still my favorite thing to do.

00:03:34.030 --> 00:03:38.930
Like when I'm mowing the lawn or chores, chore casts.

00:03:39.610 --> 00:03:44.610
Right. 99% visible is is still top.

00:03:45.170 --> 00:03:49.330
It's still it's listened to enough that it's still top in my little

00:03:49.610 --> 00:03:51.450
M.R.U. list on Spotify.

00:03:51.850 --> 00:03:52.850
Cool.

00:03:53.730 --> 00:03:57.210
The 60 songs I talked to you about this a while ago, the 60 songs.

00:03:57.250 --> 00:03:59.050
Yeah, I got to check that one out.

00:03:59.050 --> 00:04:04.180
60 songs that explain the 90s episode.

00:04:04.900 --> 00:04:06.180
What episode are they on?

00:04:06.220 --> 00:04:09.900
Oh, dude, by the way, like he's gone way more than 60.

00:04:10.140 --> 00:04:13.540
No, I got to check that one out because I forgot I'm slowly getting caught up.

00:04:13.540 --> 00:04:20.280
I was literally a hundred podcasts behind a while back between the move and

00:04:20.280 --> 00:04:25.160
everything and I've been walking to the gym every day and I walk a lot living

00:04:25.160 --> 00:04:29.240
where I live, so slowly catching up and I want to add some new podcasts.

00:04:29.240 --> 00:04:33.150
I'm going to get to the end and there are I want to check this one out and my

00:04:33.150 --> 00:04:38.470
quick tangent there is speaking of the 90s and currently to today, even.

00:04:39.190 --> 00:04:43.550
Are you going to you don't do you leave your house much because the food fighters

00:04:43.550 --> 00:04:44.910
are playing next summer.

00:04:45.310 --> 00:04:48.710
Yeah, no, the are you inviting me to the food fighters?

00:04:48.750 --> 00:04:49.710
I only have one ticket.

00:04:49.710 --> 00:04:50.710
I'm asking for your.

00:04:52.510 --> 00:04:55.870
I'm not that guy that buys one ticket to a concert goes by himself.

00:04:56.150 --> 00:04:56.670
I'm that guy.

00:04:57.270 --> 00:04:57.830
Oh, are you?

00:04:57.990 --> 00:04:58.190
Yeah.

00:04:58.510 --> 00:05:04.990
Oh, my, my daughter would be upset as well as well.

00:05:05.070 --> 00:05:10.110
Actually my middle son who, who, I don't know if I talked about it, but he just got

00:05:10.110 --> 00:05:15.070
married and congratulations, but he's in Florida, so he's not going to make that

00:05:15.070 --> 00:05:15.310
trip.

00:05:15.630 --> 00:05:20.150
Well, I'm in Florida, so the food fighters.

00:05:20.230 --> 00:05:25.910
Yeah, that's, that's a, that's a good van and I really enjoyed the YouTube of

00:05:25.910 --> 00:05:26.630
the food fighters.

00:05:26.710 --> 00:05:28.030
Have you done much of that?

00:05:28.430 --> 00:05:33.830
Like Dave Grohl does a whole lot of like random songs and bringing people from

00:05:33.830 --> 00:05:35.670
it is just a good person.

00:05:36.150 --> 00:05:37.550
He's a good man.

00:05:37.550 --> 00:05:38.870
Fantastic person.

00:05:38.870 --> 00:05:39.750
He's a good guy.

00:05:39.790 --> 00:05:40.830
That's why I like the band.

00:05:41.030 --> 00:05:44.070
Their songs are kind of okay, but Dave Grohl's I'm a, I'm a Dave Grohl fan.

00:05:44.550 --> 00:05:45.070
I'm kidding.

00:05:45.110 --> 00:05:45.910
The songs are good too.

00:05:47.910 --> 00:05:52.270
So anyway, I wanted to mention that, but the real topic I wanted to mention is as

00:05:52.310 --> 00:05:54.710
I add new podcasts, there are two things.

00:05:55.530 --> 00:06:00.730
There's a quality of podcast as brand types, while I'm talking again, but I'll go

00:06:00.730 --> 00:06:02.970
ahead and tell my story anyway, cause I can edit that shit out.

00:06:03.450 --> 00:06:05.290
I looked for a couple of things in a podcast.

00:06:05.490 --> 00:06:13.210
One, of course, a topic I'm remotely interested in, but that's almost sub

00:06:13.290 --> 00:06:14.610
to two things are there.

00:06:14.970 --> 00:06:19.890
I don't know how to describe this, but I listened to a podcast where I

00:06:20.010 --> 00:06:26.380
loved the content, but the recording was so awful that I could not continue

00:06:26.380 --> 00:06:27.020
listening to it.

00:06:27.540 --> 00:06:28.900
It was recorded low.

00:06:29.020 --> 00:06:30.220
There was echo.

00:06:30.540 --> 00:06:32.260
It was just, I could not listen to it.

00:06:32.580 --> 00:06:33.460
That's on one end.

00:06:33.460 --> 00:06:35.980
Was that, was that our podcast last episode?

00:06:35.980 --> 00:06:36.860
No, shut up.

00:06:36.860 --> 00:06:41.740
Oh, we have top notch video and audio editors working on our

00:06:41.740 --> 00:06:43.100
podcast around the clock.

00:06:43.540 --> 00:06:47.900
And then, so that one was hard, but also I tried listening to, like I'm a big

00:06:47.900 --> 00:06:52.080
fan of, ah, crap, I'm forgetting names cause it's Friday.

00:06:52.080 --> 00:06:53.320
Who's the Netflix guy?

00:06:53.320 --> 00:06:54.360
Read what?

00:06:54.360 --> 00:07:00.280
Not the, not the Netflix guy, the, um, LinkedIn guy read, which one's Hoffman?

00:07:00.720 --> 00:07:01.760
Hastings Hoffman.

00:07:01.760 --> 00:07:02.920
I get him confused sometimes.

00:07:03.040 --> 00:07:04.040
Former LinkedIn guy.

00:07:04.040 --> 00:07:08.480
He wrote this great book called, um, the Alliance, which I love.

00:07:09.200 --> 00:07:13.200
I align well with the Alliance to book on, on managing people in the 21st

00:07:13.200 --> 00:07:16.480
century, but his podcast, good material.

00:07:16.680 --> 00:07:20.360
I can't listen to it because it's so overproduced.

00:07:20.800 --> 00:07:24.880
It has sound effects all over the place and weird music and weird places.

00:07:24.880 --> 00:07:26.920
It just, it's, it's too cheesy.

00:07:27.040 --> 00:07:28.480
It's too, too cheesy.

00:07:28.760 --> 00:07:31.040
It's like, it's like a podcast for an amusement park.

00:07:31.120 --> 00:07:35.160
I just need a subject that's remotely interesting, which is nothing

00:07:35.160 --> 00:07:36.520
you'll find on this podcast.

00:07:37.080 --> 00:07:41.080
And then a reasonably good recording, which you'll sometimes find on this podcast.

00:07:41.900 --> 00:07:44.740
This is not the podcast to compare against other ones.

00:07:44.740 --> 00:07:48.460
This is just your guilty pleasure to do while you're cleaning the bathroom.

00:07:48.660 --> 00:07:50.740
You've listened to 99% of visible.

00:07:50.780 --> 00:07:51.340
I have.

00:07:51.860 --> 00:07:52.260
Okay.

00:07:52.620 --> 00:07:54.020
Where did they fit?

00:07:54.620 --> 00:07:55.420
They're in the suites.

00:07:55.420 --> 00:07:58.780
But if I was going to put them on a spectrum from horribly recorded to

00:07:58.780 --> 00:08:03.140
overproduced, they're definitely a little bit more on the produced side,

00:08:03.300 --> 00:08:04.820
but they don't overdo it.

00:08:04.980 --> 00:08:06.180
They don't overdo it.

00:08:06.660 --> 00:08:10.500
And Roman Mars has the, his voice.

00:08:10.500 --> 00:08:11.820
I could just listen to forever.

00:08:12.100 --> 00:08:13.900
He does another podcast.

00:08:14.340 --> 00:08:17.940
If you know that it's multiple, but have you looked, my favorite is what

00:08:17.940 --> 00:08:20.300
Trump can teach us about constitutional law.

00:08:20.780 --> 00:08:22.020
I listened to that one.

00:08:22.020 --> 00:08:22.460
I don't.

00:08:24.380 --> 00:08:24.740
Yeah.

00:08:25.300 --> 00:08:30.740
It's mostly his neighbor, the lawyer talking, but she's really good as well.

00:08:30.740 --> 00:08:34.220
And again, the sounds good as production and I'm interested in the topic.

00:08:34.220 --> 00:08:35.100
It's great stuff.

00:08:35.340 --> 00:08:39.980
So if you want me to listen to your podcast, just do a decent job on sound.

00:08:40.580 --> 00:08:42.860
Don't add too many sound effects and things.

00:08:42.860 --> 00:08:45.740
Although I do add them sometimes to our podcast, not too many.

00:08:46.340 --> 00:08:46.660
Yeah.

00:08:46.660 --> 00:08:48.460
I haven't done a mail bag in forever.

00:08:48.780 --> 00:08:49.180
Yeah.

00:08:49.180 --> 00:08:50.300
Big.

00:08:51.140 --> 00:08:51.460
Yeah.

00:08:51.740 --> 00:08:58.300
Cause we can't read one podcast done by pretty sure it's the BBC.

00:08:58.780 --> 00:08:59.260
Maybe not.

00:08:59.300 --> 00:08:59.660
No.

00:08:59.740 --> 00:09:01.980
Cause it's, it's bashing the BBC.

00:09:02.180 --> 00:09:04.820
Have you heard of the podcast stuff?

00:09:04.860 --> 00:09:06.500
The British stole?

00:09:06.820 --> 00:09:07.940
No, I have not.

00:09:08.460 --> 00:09:08.780
Okay.

00:09:08.780 --> 00:09:16.460
It, the guy is the, the narrator, the primary person there is, um, Australian.

00:09:16.940 --> 00:09:21.660
Uh, so I think it's actually probably based out of Australia, but it's fascinating.

00:09:21.660 --> 00:09:23.140
Like, holy crap.

00:09:23.140 --> 00:09:26.980
The British stole a lot of crap over the years with the colonization.

00:09:27.340 --> 00:09:31.700
There is not for someone with a growth mindset, like AB testing,

00:09:31.700 --> 00:09:36.220
listeners, there is just not enough time in the world to acquire the

00:09:36.220 --> 00:09:37.940
knowledge we would like to acquire.

00:09:38.380 --> 00:09:38.900
Yeah.

00:09:38.980 --> 00:09:44.140
You know, for me, I, I, I like, okay, let's listen to stuff.

00:09:44.620 --> 00:09:45.540
The British stole.

00:09:45.580 --> 00:09:47.820
And for me, I'm like, you know what?

00:09:47.900 --> 00:09:50.580
Um, use me and teach me something and that's it.

00:09:51.100 --> 00:09:55.340
Like my bar that high, that high on that one, 99% invisible.

00:09:55.340 --> 00:09:59.220
Like I have a passion around design of all things.

00:09:59.220 --> 00:10:03.700
Like one of the things you, when I have shared his experience in the architecture

00:10:03.700 --> 00:10:10.860
role, right, we've had to design things and it's fun for me to learn the design.

00:10:11.660 --> 00:10:14.100
Of all random things, right?

00:10:14.100 --> 00:10:15.700
It's like, okay, why is that there?

00:10:15.700 --> 00:10:18.700
Like, um, I bought Roman Mars's book.

00:10:19.180 --> 00:10:19.460
Ooh.

00:10:19.460 --> 00:10:19.860
Right.

00:10:20.540 --> 00:10:21.660
Do you know what a love lock is?

00:10:21.660 --> 00:10:24.060
I would only get the audio book read by him.

00:10:24.540 --> 00:10:27.820
Oh, I don't know if that's, I don't know if that exists, but I love it.

00:10:28.260 --> 00:10:30.380
Have you ever heard of the term a love lock?

00:10:30.780 --> 00:10:31.100
No.

00:10:31.940 --> 00:10:32.420
Okay.

00:10:32.820 --> 00:10:34.260
I got the book.

00:10:34.460 --> 00:10:36.980
It was one of the first chapters I had read it.

00:10:37.420 --> 00:10:41.940
And then I went for a hike to the, um, snow call me falls.

00:10:42.420 --> 00:10:44.620
They added the very end of it.

00:10:44.980 --> 00:10:49.420
There is a chain link fence and there is a crap load of.

00:10:50.020 --> 00:10:50.940
Oh, okay.

00:10:50.940 --> 00:10:51.340
I know.

00:10:51.380 --> 00:10:52.300
I know what those are.

00:10:52.300 --> 00:10:53.700
I didn't know they had a name like that.

00:10:53.700 --> 00:10:56.220
I have seen thousands of those around the world.

00:10:56.540 --> 00:10:56.860
Yeah.

00:10:56.900 --> 00:10:58.500
Those are called love locks.

00:10:59.340 --> 00:11:05.380
And, and I've always wondered like, what the hell is all of these locks here?

00:11:05.620 --> 00:11:06.500
They throw the keys.

00:11:06.540 --> 00:11:07.980
They throw the keys into the waterfall.

00:11:08.260 --> 00:11:08.540
Right.

00:11:08.540 --> 00:11:10.980
They, they write, you know, they're locking their love.

00:11:11.020 --> 00:11:16.100
A plus B with a heart and then check the key into the thing.

00:11:16.700 --> 00:11:20.970
Chucking the key, you know, fish, that's probably bad, but you

00:11:20.970 --> 00:11:25.190
know, symbolic symbolism, planet money, free economics.

00:11:25.230 --> 00:11:28.310
These are all like freaking omics, especially.

00:11:28.310 --> 00:11:31.430
That's what got me into data science, but not necessarily

00:11:31.430 --> 00:11:32.950
for economics, but that topic.

00:11:33.470 --> 00:11:33.710
Right.

00:11:34.230 --> 00:11:38.750
So it's always fun to still connect with the data science and

00:11:38.750 --> 00:11:40.270
the customer behavior aspect.

00:11:40.550 --> 00:11:41.470
No, it's cool.

00:11:41.710 --> 00:11:47.150
We can talk more about new podcasts in our upcoming end of year episode, but

00:11:47.790 --> 00:11:48.150
I just,

00:11:49.350 --> 00:11:56.330
anime, um, new season of invincible is out.

00:11:56.530 --> 00:11:58.770
Not really anime, but close enough.

00:11:59.530 --> 00:12:00.690
It's I love that show.

00:12:01.050 --> 00:12:03.050
That one just completely turned me off.

00:12:03.090 --> 00:12:04.490
Like, yeah, that's just like dark.

00:12:05.270 --> 00:12:05.670
Yeah.

00:12:06.270 --> 00:12:10.630
My daughter, we're spending a lot of quality time together.

00:12:10.750 --> 00:12:19.320
Um, and she has been a fan of anime for a while and we just watched, uh,

00:12:19.360 --> 00:12:25.090
one called demon slayer and, oh my God, is it good?

00:12:25.610 --> 00:12:30.890
I got a couple topics to get through today and I forget what those are.

00:12:30.890 --> 00:12:31.530
No, they're right here.

00:12:31.970 --> 00:12:36.170
Uh, one I called out on my five for Friday and I shared with you.

00:12:36.170 --> 00:12:37.610
I don't know if you had a chance to look at it.

00:12:38.250 --> 00:12:43.290
Is our, our buddy front of the show, Jason Arbin did the thing you can do

00:12:43.290 --> 00:12:47.550
with chat GPT where you can give it a bunch more information and make

00:12:47.550 --> 00:12:52.620
your own little chat engine, which basically it's Chad GPT plus plus.

00:12:53.540 --> 00:12:55.380
And I've seen a few of these floating around.

00:12:55.660 --> 00:12:58.540
And I think you have to be on the paid plan to be able to use them

00:12:58.660 --> 00:12:59.660
to be able to get at it.

00:12:59.660 --> 00:13:00.940
So that's, that's what it is.

00:13:01.420 --> 00:13:08.440
But he sucked in a whole bunch of information from what he considers expert

00:13:08.440 --> 00:13:12.660
testers, so he included Brent and I, regardless of our status within

00:13:12.660 --> 00:13:13.620
the testing community.

00:13:14.220 --> 00:13:19.580
And then, uh, it just works like GPT and I'm going to tangent there.

00:13:20.180 --> 00:13:25.260
And I saw yet another post of like, I don't know what some

00:13:25.580 --> 00:13:29.980
luminaries hate about chat GPT, but they were mad that it couldn't

00:13:29.980 --> 00:13:31.180
alphabetize for them.

00:13:31.780 --> 00:13:33.860
And again, use it for what it's for.

00:13:33.860 --> 00:13:37.420
It's powerful, or you can, or you can find things that it won't do

00:13:37.420 --> 00:13:38.620
and get mad at your call.

00:13:38.860 --> 00:13:43.740
But anyway, Jason, uh, made this thing, pulling in information from

00:13:43.740 --> 00:13:44.960
expert testers all over the place.

00:13:44.960 --> 00:13:47.980
And I asked it, you know, we've talked about, and again, I'm not going to

00:13:48.020 --> 00:13:52.300
chuck James under the bus, James Bach under the bus, and it's not on the podcast.

00:13:52.940 --> 00:13:57.740
Uh, we have different approaches to quality and testing and that's fair.

00:13:57.740 --> 00:13:58.660
He can do his thing.

00:13:58.660 --> 00:13:59.500
We'll do ours.

00:13:59.540 --> 00:14:02.060
Uh, I think he's done some questionable things as a human.

00:14:02.340 --> 00:14:05.660
Again, not going to, that's not where the topic is going to be here today.

00:14:06.180 --> 00:14:10.920
But I was curious because we do kind of, we cross paths in a weird way.

00:14:10.920 --> 00:14:16.940
We have occasionally a sort of distant respect for each other where we leave

00:14:16.940 --> 00:14:19.940
each other alone, we chatted on the phone before we said, okay, blah, blah, blah.

00:14:20.540 --> 00:14:21.280
He'll do his thing.

00:14:21.280 --> 00:14:22.020
I'll do mine.

00:14:23.040 --> 00:14:24.520
That was many, many years ago.

00:14:24.720 --> 00:14:28.200
And then lately somebody brought up the modern testing principles and his

00:14:28.200 --> 00:14:31.680
reply was Alan, Alan's work is damaging the craft of testing.

00:14:31.680 --> 00:14:33.400
So I ignored that anyway.

00:14:33.440 --> 00:14:38.440
Drama aside, one thing I like to do as part of critical thinking is when I

00:14:38.440 --> 00:14:42.960
hear something somebody doesn't agree with is I want to try and do as

00:14:42.960 --> 00:14:47.200
empathetic humans is put ourselves in their shoes and wonder kind of

00:14:47.200 --> 00:14:48.320
where they're coming from.

00:14:48.320 --> 00:14:50.120
How can I see things from their side?

00:14:50.600 --> 00:14:54.040
So the way I did it with chat GPT was one simple question.

00:14:54.400 --> 00:14:57.160
Now I'm not going to read the whole answer, although I think it's very good.

00:14:58.080 --> 00:15:01.680
But I asked it, how would you compare the approach to quality between

00:15:01.680 --> 00:15:03.040
Alan Page and James Bach?

00:15:03.600 --> 00:15:04.920
And I kind of was unfair.

00:15:04.920 --> 00:15:08.920
I said quality and not testing, but so I probably led the witness, but

00:15:09.120 --> 00:15:11.920
chat GPT gave a very fair answer.

00:15:12.320 --> 00:15:13.560
Blah, blah, blah.

00:15:14.100 --> 00:15:15.320
I am not an expert.

00:15:15.640 --> 00:15:17.600
Alan known for his work at Microsoft.

00:15:17.760 --> 00:15:18.760
I wouldn't say that.

00:15:19.720 --> 00:15:23.720
I worked on let's list some of the products I've worked on a windows

00:15:23.720 --> 00:15:24.280
millennium.

00:15:24.560 --> 00:15:29.090
There's a lot of hate there and well, there's some, I will list things

00:15:29.090 --> 00:15:32.890
people like, but I was involved in the quality of both windows millennium

00:15:33.250 --> 00:15:34.690
and Microsoft teams.

00:15:34.730 --> 00:15:39.770
Please send your hate mail to Alan care of a B testing at the north bowl.com.

00:15:39.970 --> 00:15:44.930
In the answer talks about where I focus on business value and team

00:15:44.930 --> 00:15:49.290
responsibility, data-driven approaches, evolving the test to roll.

00:15:49.730 --> 00:15:51.250
All stuff you've heard here.

00:15:52.000 --> 00:15:55.840
Whereas James is again, context-driven testing, exploratory testing,

00:15:55.840 --> 00:16:00.640
critical thinking, craftsmanship, and a skeptical approach to automation.

00:16:00.640 --> 00:16:03.200
That that's all we know where we're coming from, but the comparison

00:16:03.200 --> 00:16:04.320
is actually pretty interesting.

00:16:04.960 --> 00:16:06.800
It is in perspective on quality.

00:16:06.800 --> 00:16:09.600
It says Alan, and this is actually, I have nothing to argue with here.

00:16:09.600 --> 00:16:11.640
I don't know if, I mean, the question was fair.

00:16:11.680 --> 00:16:13.440
I don't know if James would argue either of us.

00:16:13.760 --> 00:16:15.520
It's kind of worth bringing up and getting your thoughts.

00:16:15.520 --> 00:16:16.080
I read it.

00:16:16.080 --> 00:16:19.040
And just so you're aware, I read every one of these things.

00:16:20.280 --> 00:16:20.800
So I'll read it.

00:16:20.800 --> 00:16:23.800
Because I was just like, I was just like, yep, check.

00:16:23.800 --> 00:16:24.080
Yeah.

00:16:24.800 --> 00:16:25.040
Yeah.

00:16:25.080 --> 00:16:26.160
It's, it's really good.

00:16:26.160 --> 00:16:29.600
Nothing I, and I, again, I think it's fair and I love fair.

00:16:30.080 --> 00:16:33.600
And the summary, the summary I found fascinating as well.

00:16:33.600 --> 00:16:36.800
Alan is quality in a broader business and team context.

00:16:36.800 --> 00:16:37.320
True.

00:16:37.800 --> 00:16:41.400
Bock on the other hand, focus is more on the skill and judgment of the tester.

00:16:41.720 --> 00:16:47.480
It's really made me think, and in fairness to James, we are doing two different things.

00:16:48.200 --> 00:16:52.900
James wants better testing and I want better quality.

00:16:52.900 --> 00:16:57.060
And I could argue on my high horse that ultimately quality is what matters.

00:16:57.060 --> 00:17:02.020
And I think James wants better testing or does James want better testers?

00:17:02.580 --> 00:17:04.740
I think he wants people that do better testing.

00:17:04.740 --> 00:17:09.220
He's, I think he's, I would say he's involved in the craft of software testing.

00:17:09.220 --> 00:17:13.220
He wants testers who can have that, that deep critical thinking approach.

00:17:13.220 --> 00:17:14.100
I think that's fair.

00:17:14.100 --> 00:17:15.860
And I think quality comes out of that.

00:17:15.860 --> 00:17:18.020
I'm focusing on the outcome purely.

00:17:18.020 --> 00:17:21.460
He's focusing on a root cause that will get likely to the same outcome.

00:17:21.460 --> 00:17:28.660
Well, so again, I'm going to push back on that because I do think James is likely to

00:17:29.780 --> 00:17:32.900
write the critical distance concept.

00:17:32.900 --> 00:17:37.620
Like if he was focused on better testing, then why wouldn't he be supportive of our

00:17:37.620 --> 00:17:38.820
approach of whole team?

00:17:39.380 --> 00:17:40.340
Devs can test.

00:17:40.900 --> 00:17:45.780
I don't think that, well, the devs contest thing is that that's a whole,

00:17:46.700 --> 00:17:47.180
right?

00:17:47.180 --> 00:17:50.540
I don't want to, it's not fair for me to try and speak for him.

00:17:50.540 --> 00:17:53.740
I can look at the comments of chat GPT and interpret those.

00:17:53.740 --> 00:17:55.260
I don't want to try and speak for him.

00:17:55.900 --> 00:17:59.260
I think a lot of things, he just looks at what we do and says,

00:17:59.260 --> 00:18:01.180
you guys care about delivery.

00:18:01.180 --> 00:18:02.780
You're, you're, you're about something different.

00:18:03.420 --> 00:18:05.180
Developers being able to test.

00:18:05.180 --> 00:18:06.460
That's the thing he pushes back on.

00:18:06.540 --> 00:18:11.900
He thinks it requires he, his belief is in the specialist to do that, that deep work.

00:18:11.900 --> 00:18:16.220
And again, some other comparisons, but the summary I'll read to you the whole thing,

00:18:16.220 --> 00:18:18.620
which is, and then I'll get more comments from you, Brent.

00:18:18.620 --> 00:18:23.020
In summary, Alan's approach is more systemic, focusing on the role of testing within the

00:18:23.020 --> 00:18:25.980
broader context of software dev and business objectives.

00:18:26.780 --> 00:18:30.940
Well, James approaches more centered on the individual testers skills and the

00:18:30.940 --> 00:18:34.460
adaptability of testing practices to the context at hand.

00:18:34.460 --> 00:18:37.740
Both perspectives offer valuable insights in the different dimensions of software

00:18:37.740 --> 00:18:40.300
quality and testing, which is kind of what I said about two minutes ago.

00:18:40.940 --> 00:18:42.380
We're focused on different things.

00:18:42.380 --> 00:18:45.260
We don't, we don't do the same thing anymore.

00:18:45.260 --> 00:18:47.980
There was a time when James Bock and I were both testers.

00:18:47.980 --> 00:18:50.220
We're not, I don't want to talk a ton about him.

00:18:50.220 --> 00:18:53.180
I don't want to talk about James, but he's not here too.

00:18:53.180 --> 00:18:55.580
I don't want to say anything where I feel like James have to defend himself.

00:18:55.580 --> 00:19:01.340
It's not fair, but I feel like this is a pretty fair comparison of where we're coming from

00:19:01.340 --> 00:19:04.860
and where some, where some conflict may be.

00:19:04.860 --> 00:19:13.260
And honestly, I wonder if, you know, sometimes if I generate this conflict, because I am so adamant

00:19:13.260 --> 00:19:20.220
that the ultimate goal is quality, therefore discounting the craft of testing.

00:19:21.510 --> 00:19:26.550
I'm, I am on Jason's train.

00:19:26.550 --> 00:19:28.310
Oh, so you asked it something.

00:19:28.870 --> 00:19:29.270
I did.

00:19:29.750 --> 00:19:33.030
Duh, it will be edited out by the time you hear this listener.

00:19:33.030 --> 00:19:37.110
But as I was saying that last thing that, and, and Brent has no idea what I said,

00:19:37.110 --> 00:19:39.670
cause he was typing furiously.

00:19:39.670 --> 00:19:40.470
But what did you ask it?

00:19:40.470 --> 00:19:41.110
What did you ask?

00:19:41.110 --> 00:19:45.910
I actually did have what it is, but the second you challenged me on that, it did flush.

00:19:45.910 --> 00:19:46.150
Yes.

00:19:46.710 --> 00:19:51.110
I asked it, what are the key conflicts between Alan Page and James Bock?

00:19:51.670 --> 00:19:53.750
Oh, didn't ask that.

00:19:54.390 --> 00:19:55.430
Fill me in Jedi.

00:19:56.070 --> 00:19:58.710
Structure versus flexibility.

00:19:58.710 --> 00:20:03.030
Alan's approach involves more structured testing process.

00:20:03.030 --> 00:20:03.270
What?

00:20:03.910 --> 00:20:05.750
I, I, I wonder.

00:20:05.750 --> 00:20:06.950
I think that's backward.

00:20:06.950 --> 00:20:10.950
In contrast, James promotes a more flexible, less formal approach,

00:20:10.950 --> 00:20:12.950
emphasizing exploratory testing.

00:20:13.590 --> 00:20:13.830
Right.

00:20:13.830 --> 00:20:14.710
That part is true.

00:20:15.270 --> 00:20:17.670
And I'm wondering, actually, here's the thing.

00:20:17.670 --> 00:20:22.870
I'm wondering how much Jason train this or how much the training was based off of your book.

00:20:23.670 --> 00:20:23.990
Because.

00:20:24.070 --> 00:20:26.470
Oh, it does pull that in.

00:20:27.270 --> 00:20:28.870
It would pull that in.

00:20:28.870 --> 00:20:29.190
Yeah.

00:20:29.830 --> 00:20:31.110
My data is weird.

00:20:32.150 --> 00:20:38.870
If we were comparing the Alan Page of 10 years ago or 15 years ago, yeah, that might be true.

00:20:38.870 --> 00:20:40.230
Well, do this, do this.

00:20:40.230 --> 00:20:44.390
I'm going to take the time for you to type this, ask it to disregard the information from

00:20:44.390 --> 00:20:48.550
how we test software at Microsoft and make that same and asking the same question again.

00:20:48.550 --> 00:20:50.550
Rewrite, but disregard this.

00:20:50.550 --> 00:20:57.800
We regard the information from how we test Microsoft.

00:20:57.800 --> 00:20:59.240
Does it give the same answer?

00:20:59.240 --> 00:21:02.040
Previously was structure versus flexibility.

00:21:02.600 --> 00:21:07.480
Now it's structured versus adaptive and you're still structured.

00:21:07.480 --> 00:21:07.960
Weird.

00:21:07.960 --> 00:21:09.080
Like, yeah.

00:21:09.640 --> 00:21:10.280
Okay.

00:21:10.280 --> 00:21:10.600
All right.

00:21:11.320 --> 00:21:13.160
Anyway, I there's a.

00:21:13.160 --> 00:21:14.600
Don't you want to know the others?

00:21:14.600 --> 00:21:15.000
I do.

00:21:15.000 --> 00:21:15.320
I do.

00:21:15.320 --> 00:21:15.640
I guess.

00:21:16.280 --> 00:21:17.480
Already discarded.

00:21:17.480 --> 00:21:19.880
Everything else because the first answer was wrong.

00:21:19.880 --> 00:21:20.280
Yeah.

00:21:20.280 --> 00:21:22.200
And the third answer is also wrong.

00:21:23.160 --> 00:21:23.720
All right.

00:21:23.720 --> 00:21:25.400
So here's something that I did do.

00:21:26.280 --> 00:21:30.360
If you are ready for attention, we're always ready for a tangent on the EBT.

00:21:30.360 --> 00:21:31.800
I need a tangent sound effect.

00:21:34.200 --> 00:21:42.360
How would you compare the approach to quality between Alan Page and Brent Jensen?

00:21:46.310 --> 00:21:48.950
So what the world doesn't know is we're actually the same person.

00:21:50.890 --> 00:21:52.330
He did that fine.

00:21:52.330 --> 00:21:57.930
So on the background, known for his work at Microsoft and co-authoring the book,

00:21:57.930 --> 00:22:03.460
but the fact that it brings out the book, like, really makes me think it's like it's over.

00:22:03.460 --> 00:22:05.300
It might be over pivoting.

00:22:05.300 --> 00:22:05.540
Yeah.

00:22:05.540 --> 00:22:09.780
But you may have the same problem I do in terms of like the last decade.

00:22:09.780 --> 00:22:10.980
I've been pigeonholed.

00:22:10.980 --> 00:22:11.700
Yeah.

00:22:11.700 --> 00:22:11.940
Yeah.

00:22:12.820 --> 00:22:17.940
While Brent Jensen's specific approach to quality in software testing is less documented

00:22:17.940 --> 00:22:25.540
in public sources, based on industry trends and practices, one might infer that his approach

00:22:25.540 --> 00:22:28.100
would focus on pragmatism and efficiency.

00:22:29.380 --> 00:22:29.700
Okay.

00:22:29.700 --> 00:22:31.140
So it knows who I am.

00:22:32.330 --> 00:22:36.060
I think I haven't tested to see if it's...

00:22:36.060 --> 00:22:36.380
Yeah.

00:22:36.380 --> 00:22:37.580
It could be making it up.

00:22:37.580 --> 00:22:42.380
I wonder if I don't want to go too deep into this, but Jason, I know you're listening

00:22:42.380 --> 00:22:45.820
because you get mad when we don't have a podcast every two weeks.

00:22:45.820 --> 00:22:51.580
Make sure you feed it the transcribed, the transcriptions of our podcasts.

00:22:53.030 --> 00:22:53.430
I'm going to do...

00:22:53.430 --> 00:22:56.070
Here Jason, you didn't get paid for any of this, but do a bunch more work.

00:22:56.710 --> 00:22:59.030
I'm going to do Mickey Duck.

00:22:59.030 --> 00:23:04.630
I'm going to compare Alan Page to Mickey Duck, which I just made up.

00:23:04.630 --> 00:23:05.030
Of course you do.

00:23:05.030 --> 00:23:07.190
Because Mickey Mouse might be in here.

00:23:07.990 --> 00:23:08.390
Okay.

00:23:08.390 --> 00:23:12.790
Mickey Duck is not a recognized figure in a software testing group.

00:23:12.790 --> 00:23:14.550
Not part of the expert field.

00:23:15.190 --> 00:23:16.230
So he does have something...

00:23:16.230 --> 00:23:17.190
You know what though?

00:23:17.190 --> 00:23:19.510
Did you ask it about Gent Brinson?

00:23:19.510 --> 00:23:19.990
I didn't.

00:23:20.790 --> 00:23:21.910
I could do that.

00:23:21.910 --> 00:23:23.510
We are losing listeners.

00:23:23.510 --> 00:23:25.750
We are doubt for our three listeners in round one.

00:23:25.750 --> 00:23:26.580
So let me go back.

00:23:26.580 --> 00:23:30.740
Let me go back to our approaches.

00:23:32.740 --> 00:23:38.340
Alan's approach is likely to be more holistic and integrated into every stage of the software

00:23:38.340 --> 00:23:42.180
development process, focusing on the overall system quality.

00:23:42.820 --> 00:23:49.060
In contrast, and I'll tell you, I am already disturbed by the term contrast being used here.

00:23:49.700 --> 00:23:56.580
Brinson's approach as inferred might be more focused on immediate and practical

00:23:57.300 --> 00:23:59.940
outcomes, emphasizing quick feedback loops.

00:24:01.430 --> 00:24:01.830
Okay.

00:24:01.830 --> 00:24:02.070
Yeah.

00:24:02.070 --> 00:24:03.110
It's making crap up.

00:24:03.110 --> 00:24:03.590
It's fine.

00:24:04.150 --> 00:24:06.390
But you didn't do that, but it's guessing.

00:24:07.750 --> 00:24:08.390
So anyway...

00:24:08.550 --> 00:24:13.900
I do emphasize, but it's not really a contrast.

00:24:14.780 --> 00:24:15.260
Not really.

00:24:15.980 --> 00:24:16.940
Let me ask it.

00:24:16.940 --> 00:24:17.900
Let me do one last thing.

00:24:17.900 --> 00:24:18.860
No, we're done with questions.

00:24:18.860 --> 00:24:20.220
We're going to go on to the rest of the podcast.

00:24:20.220 --> 00:24:23.820
I have another topic to cover and we got like 20 minutes here.

00:24:24.540 --> 00:24:26.620
Main thing here is very cool stuff.

00:24:26.620 --> 00:24:27.580
Going to plug it.

00:24:27.580 --> 00:24:33.260
You can find the link to this little chat GPT wonder on my latest five for Friday.

00:24:33.260 --> 00:24:35.900
And you can ask questions and submit.

00:24:35.900 --> 00:24:41.610
Oh, we should get it to submit questions to the mail bank.

00:24:41.610 --> 00:24:45.130
What are good questions for Alan and Brent to answer on their podcast?

00:24:45.770 --> 00:24:47.290
We'll have to type that one.

00:24:47.290 --> 00:24:47.690
Okay.

00:24:47.690 --> 00:24:49.530
I'm not going to go into that row there.

00:24:50.090 --> 00:24:56.660
I wanted to follow up on something we started talking about briefly last time.

00:24:57.220 --> 00:24:58.420
Oh, sorry.

00:24:59.670 --> 00:25:00.470
This is bad.

00:25:01.740 --> 00:25:02.620
Are you still with Chashing?

00:25:02.620 --> 00:25:03.100
I am.

00:25:03.980 --> 00:25:07.900
So, so I, I, I, what are the key conflicts between you and me?

00:25:08.540 --> 00:25:08.780
Okay.

00:25:10.040 --> 00:25:14.600
You dude, you are old school according to this thing.

00:25:14.600 --> 00:25:21.000
Like even between you and me, I'm all about rapid agile and you are like structured.

00:25:22.840 --> 00:25:23.560
Systematic.

00:25:24.520 --> 00:25:27.240
Jason, stupid bot.

00:25:28.310 --> 00:25:31.300
Now pause this and go fix it.

00:25:31.300 --> 00:25:31.620
Okay.

00:25:31.620 --> 00:25:33.220
So anyway, on with the podcast.

00:25:34.100 --> 00:25:37.220
I want to talk about, so I'm on the podcast today with, with of course,

00:25:37.220 --> 00:25:38.020
Gent Brinson.

00:25:38.580 --> 00:25:42.180
I want to talk about a more famous Brent, a little bit more.

00:25:42.180 --> 00:25:42.980
Okay.

00:25:42.980 --> 00:25:43.460
Stop.

00:25:43.460 --> 00:25:44.740
No, I just want to do one more.

00:25:45.460 --> 00:25:46.180
One more.

00:25:46.180 --> 00:25:48.500
Is my podcast too well.

00:25:50.580 --> 00:25:57.880
The role of data and metrics pages likely you dude, I lost your audio.

00:25:58.570 --> 00:25:59.290
I hit mute.

00:25:59.930 --> 00:26:05.370
It's likely use of data metrics to drive testing decisions.

00:26:05.370 --> 00:26:10.330
My contrast with a more intuitive experience based approach, like someone

00:26:10.330 --> 00:26:15.930
like Jensen might favor assuming he leads towards a less data driven method.

00:26:15.930 --> 00:26:16.730
Okay.

00:26:16.730 --> 00:26:18.250
I don't know which one's better.

00:26:18.250 --> 00:26:24.570
So this GPT knows my name knows something about me, but not nearly enough.

00:26:25.210 --> 00:26:28.730
And has made a decision about you and it's wrong.

00:26:28.730 --> 00:26:30.730
Remember, it's just, no, I get it.

00:26:30.730 --> 00:26:31.130
Yeah.

00:26:31.130 --> 00:26:33.130
Remember how the, you know, how these things work.

00:26:33.130 --> 00:26:37.450
It's just you, a bunch of our work has been tokenized and it's trying to make

00:26:37.450 --> 00:26:39.610
up words, it doesn't know what the words mean.

00:26:39.610 --> 00:26:43.130
It's just making up words in an order that, that is grammatically correct.

00:26:43.130 --> 00:26:47.610
So anyway, I want to talk more about Brent Geller a little bit and lead

00:26:47.610 --> 00:26:49.850
that into a discussion of heroes.

00:26:50.570 --> 00:26:54.150
Do not ask Chad GPT who Brent Geller is.

00:26:54.150 --> 00:26:57.110
Brent Geller is Brent from the Phoenix.

00:26:57.110 --> 00:26:57.670
Thank you.

00:26:57.750 --> 00:26:59.670
I figured I'd like, okay.

00:26:59.670 --> 00:27:01.110
He's probably talking about that guy.

00:27:01.110 --> 00:27:01.670
Yeah.

00:27:01.670 --> 00:27:02.310
Heroes.

00:27:02.310 --> 00:27:04.870
So we talked, we talked about Brent a little last time.

00:27:04.870 --> 00:27:09.030
And I want to recap that whole thing, but Brent was the, he was the bottleneck

00:27:09.030 --> 00:27:10.630
because he was the expert.

00:27:10.630 --> 00:27:13.270
He was a knowledge silo.

00:27:13.830 --> 00:27:17.590
He kind of becomes the hero of the story as he, again, I hated him

00:27:17.590 --> 00:27:19.830
because he was fricking in the way.

00:27:19.830 --> 00:27:23.350
I want a root cause and see how we ever built a culture that got,

00:27:23.350 --> 00:27:26.470
got us to a place where one person was the bottleneck.

00:27:26.710 --> 00:27:31.590
One person was the bottleneck for all this stuff, but he did evolve and he was happy in the end.

00:27:31.590 --> 00:27:36.550
I think you could say he was both the victim and the hero at the same time,

00:27:37.270 --> 00:27:40.150
but definitely at the end, he becomes this agent of change.

00:27:40.150 --> 00:27:40.790
All good stuff.

00:27:40.790 --> 00:27:43.190
He grows up all good, happy ending.

00:27:43.190 --> 00:27:45.670
But it's made me think about heroes.

00:27:46.540 --> 00:27:49.580
The David Bowie song from the Berlin trilogy produced by Brian.

00:27:49.580 --> 00:27:51.580
No, heroes in the organization.

00:27:51.580 --> 00:27:55.940
You have, I don't know if you still believe this, but you in the past,

00:27:55.940 --> 00:28:01.620
you've said something like it's okay to have heroes if that's their job to be the hero.

00:28:02.220 --> 00:28:02.780
Is that true?

00:28:02.780 --> 00:28:04.140
Do I remember remembering?

00:28:04.140 --> 00:28:05.660
No, so that is true.

00:28:06.380 --> 00:28:15.780
And that is around the problem of heroes as sort of a knowledge expert.

00:28:17.140 --> 00:28:19.460
Brent and the Phoenix project, right?

00:28:20.220 --> 00:28:24.140
I don't think he started off his day intending to be a hero.

00:28:24.810 --> 00:28:34.090
What happened is, as you listen to the story, what happened is he was really passionate about his job.

00:28:35.210 --> 00:28:35.610
He was.

00:28:35.610 --> 00:28:37.370
And I think you're right about that.

00:28:37.370 --> 00:28:47.690
And when people discovered his passion, that began sort of the snowball that became the avalanche.

00:28:47.690 --> 00:28:55.450
And without anyone there to say, hey, this needs to be knowledge shared, then it very quickly

00:28:55.450 --> 00:29:01.050
becomes a situation where like someone like Brent, when you have a knowledge bottleneck,

00:29:02.090 --> 00:29:09.530
it's kind of like a person who, you know, fell off the ocean liner and has been treading water

00:29:09.530 --> 00:29:13.690
for five, six hours and is now struggling, right?

00:29:13.690 --> 00:29:15.290
Brent, I think we can agree.

00:29:15.290 --> 00:29:18.490
You know, I don't like how he got himself in this situation, but I think we agree that

00:29:18.490 --> 00:29:22.410
Brent from the Phoenix project, his intentions were good.

00:29:22.410 --> 00:29:24.810
He did not want to be the bottleneck.

00:29:24.810 --> 00:29:27.210
He did not want to work 80 hours a week.

00:29:27.210 --> 00:29:30.010
He didn't want to be the only person who knew that stuff.

00:29:30.010 --> 00:29:32.810
Just that happened to him within their culture.

00:29:32.810 --> 00:29:37.370
I was rereading that part of the Phoenix project and I thought of something I wanted to throw at you

00:29:37.370 --> 00:29:41.770
because there are sort of the Brent anti-hero.

00:29:42.330 --> 00:29:49.290
So there are, again, expertise is expertise, but someone who's the bottleneck who wants

00:29:49.290 --> 00:29:56.090
to be the bottleneck becomes a gatekeeper. Someone who's a knowledge silo will hoard their knowledge

00:29:56.090 --> 00:30:01.370
in order to provide value and be able to have, be able to be that hero.

00:30:01.370 --> 00:30:02.730
We've worked with these people in the past.

00:30:02.730 --> 00:30:03.130
Oh, yeah.

00:30:04.170 --> 00:30:08.570
I work with the people who refuse to share information because literally they would say

00:30:08.570 --> 00:30:10.810
out loud, that's the only reason I'm employed here.

00:30:10.810 --> 00:30:13.770
I need to be the only person that knows this for job security.

00:30:13.770 --> 00:30:14.650
I've heard that too.

00:30:15.450 --> 00:30:23.850
And for those type of people, like what, again, this is where I see, there's two things I say

00:30:23.850 --> 00:30:29.290
commonly, depending on where I'm at, either number one, then that needs to be their job.

00:30:29.290 --> 00:30:36.410
Like the type of hero who's essentially a firefighter, you know, critical and exceptional

00:30:36.410 --> 00:30:38.730
at diagnosing and putting out fires.

00:30:40.330 --> 00:30:44.490
In today's DevOps language, we might say that they're the DRI,

00:30:44.490 --> 00:30:46.170
or the designated responsibility.

00:30:47.050 --> 00:30:49.960
That should be their job. That's their job.

00:30:49.960 --> 00:30:55.960
Yeah. When there's a job is when there's a problem, they go in, or when there's a bottleneck

00:30:55.960 --> 00:30:59.080
or a problem, they go in and solve it or mitigate it until it's not a big problem anymore.

00:30:59.080 --> 00:30:59.480
I get that.

00:30:59.480 --> 00:30:59.960
Right.

00:30:59.960 --> 00:31:10.490
The type of hero that you describe, usually that's where I'll respond with,

00:31:10.490 --> 00:31:14.490
I want to remind everybody, hero is a four-letter word.

00:31:14.490 --> 00:31:15.130
Great.

00:31:15.130 --> 00:31:16.410
And this is where I want to get into.

00:31:16.410 --> 00:31:20.970
I want to get into the leadership aspect of this because I was reflecting back to earlier

00:31:20.970 --> 00:31:24.170
times at Microsoft, and this was definitely even better by the time I left.

00:31:24.170 --> 00:31:25.770
So I imagine it's even better now.

00:31:26.700 --> 00:31:34.140
But there were people who would hoard information or be a bottleneck or clean up their own mess

00:31:35.190 --> 00:31:41.830
so they could be recognized as the hero because they had leadership who would call out when heroes

00:31:41.830 --> 00:31:45.670
did things. I mean, you can remember stories like, I want to thank so-and-so for coming

00:31:45.670 --> 00:31:50.390
in and working all weekend to solve this problem that they created in the first place.

00:31:50.390 --> 00:31:57.350
So I want to talk about how as leaders in tech, how do we make sure we don't get that kind of

00:31:57.350 --> 00:32:01.110
hero? What are the preventative measures to make sure we, like I'm good with you.

00:32:01.110 --> 00:32:04.950
If you want to have somebody be the hero because their job is to be like the smoke jumper,

00:32:04.950 --> 00:32:10.230
I call them. That's fine. How do we prevent the people who want to be heroes because they think

00:32:10.950 --> 00:32:14.390
it's, they actually believe it's good for their career?

00:32:15.260 --> 00:32:16.300
How do we prevent them?

00:32:16.700 --> 00:32:18.700
So I think...

00:32:18.700 --> 00:32:21.580
I love the hero as a four-letter word thing. Maybe expand on that.

00:32:21.580 --> 00:32:28.060
Well, so I love, as you were saying, hey, maybe that's another place where Microsoft

00:32:28.060 --> 00:32:34.140
has softened over the years. And I'll say, yeah, it has. The hero of the type of,

00:32:34.140 --> 00:32:37.180
that we just described for Greg Keller, that's still there.

00:32:38.300 --> 00:32:39.420
That's still there.

00:32:39.420 --> 00:32:44.860
I think culturally that one may be easier to fix than the, I'll call them the anti-hero.

00:32:44.860 --> 00:32:49.500
It will be, no, actually, I think the other way is easier to fix.

00:32:50.060 --> 00:32:57.020
There has ever since, ever since, I was just thinking, a couple of things that come into play.

00:32:57.020 --> 00:33:03.580
Number one, a big portion of your review is not just on the stuff you've got done.

00:33:04.140 --> 00:33:09.980
It is also on how did you contribute to others and how did you incorporate others'

00:33:09.980 --> 00:33:19.560
feedback into your thing? And so as managers continue, as managers age out from the old

00:33:19.560 --> 00:33:25.560
school system and new managers are coming in more trained around this and things like the

00:33:25.560 --> 00:33:33.480
coaching habit. And here is one thing, if I were to do a big hypothesis that I had no proof on this,

00:33:33.480 --> 00:33:38.760
I would say hitting hard on growth versus fixed mindset was key here.

00:33:39.480 --> 00:33:39.960
Yeah.

00:33:39.960 --> 00:33:45.320
Because what you described as a hero, tell me how they can be more of a fixed mindset.

00:33:46.020 --> 00:33:49.780
No, I think you're 100% right. And this is really interesting.

00:33:49.780 --> 00:33:53.060
I was having a conversation when I think through these things, I have,

00:33:53.060 --> 00:33:57.620
when I think through things, I don't know answers to, I have conversations with chat GPT.

00:33:57.620 --> 00:34:05.780
And I told chat GPT, people who hoard information and are bottlenecks and want to be gatekeepers.

00:34:06.340 --> 00:34:11.140
Oh, no, actually I'll bring it up here. Dear chat GPT. I like to use

00:34:11.780 --> 00:34:15.460
dear and please and thank you with my computer counterparts. But I said,

00:34:16.470 --> 00:34:21.750
I'm discovering that I am hoarding information, gatekeeping people and overall slowing people

00:34:21.750 --> 00:34:25.980
down because I'm a jerk. What are some books I can read so I can improve?

00:34:26.620 --> 00:34:28.300
That's clever. That's clever.

00:34:29.180 --> 00:34:32.220
And of course, it led with How to Win Friends and Influence People,

00:34:32.220 --> 00:34:35.740
which I read a million years ago, but I wouldn't recommend. It's a good book.

00:34:35.740 --> 00:34:40.380
That Crucial Conversations, I think we've both read. Emotion Intelligence 2.0, which I read.

00:34:40.380 --> 00:34:42.300
I've read all of these so far.

00:34:42.300 --> 00:34:46.620
When I first learned I was an asshole, difficult conversations, how to discover what matters most.

00:34:46.620 --> 00:34:51.580
I've read that. The No Asshole Rule, which I'm rereading because it's actually very, very good.

00:34:51.580 --> 00:34:57.340
And then funny, you mentioned Growth Mindset, Mindset, the Carol Dweck book on the Growth

00:34:57.340 --> 00:35:01.900
Mindset. So those are the books I read to get better at this stuff.

00:35:02.650 --> 00:35:05.770
It did. ChatGPT, by the way, did congratulate me in my self-awareness.

00:35:09.500 --> 00:35:13.980
Very nice of it. Yeah, I just loaded up ChatGPT. I was going to ask it a question as well,

00:35:13.980 --> 00:35:15.020
but I forgot what it was.

00:35:16.060 --> 00:35:22.300
But as a quick tangent, this is asking ChatGPT to alphabetize your list of test case inputs,

00:35:22.300 --> 00:35:25.260
maybe not as good of an idea as it using it to think about, you know,

00:35:25.260 --> 00:35:28.380
help you become a little bit more self-aware than maybe you think you are.

00:35:28.380 --> 00:35:32.460
But anyway, I love it for stuff like this. And I said, you know what?

00:35:32.540 --> 00:35:38.540
There's a couple of these I'm going to go reread because even though I hope I don't do these things,

00:35:38.540 --> 00:35:44.860
I want to be able to make sure that I can navigate a world where I may run across some of these people.

00:35:44.860 --> 00:35:51.100
Yeah, and guide them. The biggest problem I've seen is that these folks,

00:35:51.660 --> 00:36:01.100
I remember the last person who told me straight to my face, yeah, I'm not going to mentor that

00:36:01.100 --> 00:36:06.940
person because then there'll be two people who know how to do what I do. And that will,

00:36:07.660 --> 00:36:14.620
oh my God. And I said, well, why not? And then it was a she, she then said,

00:36:15.180 --> 00:36:22.070
because this is my only value proposition. I'm like, well, learn, grow a new one. Oh, I can't.

00:36:22.630 --> 00:36:28.150
Like she had convinced herself that she had a secret sauce on how to test.

00:36:29.110 --> 00:36:32.950
And then her only option was learning how to code and that she couldn't do that.

00:36:33.670 --> 00:36:38.310
Yeah, there's something to that. And the growth mindset is huge. I was part of what triggered my

00:36:38.310 --> 00:36:43.750
thinking about this was everything. There's a soup in my head and ideas go and sometimes some

00:36:43.750 --> 00:36:48.870
ingredients clogged together. I was listening to a Pat Lencioni podcast and he was bringing up

00:36:48.870 --> 00:36:53.990
some ideas from his book called the ideal team player, which was originally titled the three signs

00:36:54.070 --> 00:36:58.550
of a miserable job. And he changed the title about five years after it was out because people would

00:36:58.550 --> 00:37:02.790
not leave a copy on their desk at work. But he talks about the ideal team player being three

00:37:02.790 --> 00:37:08.520
things, humble, hungry, and smart. Humble, meaning you're not a jerk. Hungry, meaning you love to

00:37:08.520 --> 00:37:13.640
learn and smart, meaning you make good decisions and you know, and you don't get like, you know,

00:37:13.640 --> 00:37:19.960
when to ask for help. You know how to, you know how to navigate the workplace. And it talks

00:37:19.960 --> 00:37:25.960
about like the people who are only have maybe two of those because of some labels for them.

00:37:25.960 --> 00:37:32.440
They said, if you are, if you are hungry and smart, but you don't have any humility,

00:37:32.440 --> 00:37:39.640
he calls that person the skillful politician. I think, I'm thinking, oh yeah, I've known some

00:37:39.640 --> 00:37:46.200
skillful politicians. I have known some skillful politicians. So that got me thinking about this

00:37:46.200 --> 00:37:51.000
whole, you know, and then thinking about Brent was in my head, Brent Geller from the Phoenix project.

00:37:51.000 --> 00:37:56.680
And that got me thinking about this whole hero slash anti-hero thing and just wanted to get

00:37:56.680 --> 00:38:00.600
your take. And then the books that I could like the brainstorming chat GPT, good stuff.

00:38:00.600 --> 00:38:06.360
So I forget what is your, as you're looking for chat, we should have chat GPT. If it could talk,

00:38:06.360 --> 00:38:13.880
it could be our third. We could be the ABC podcast. But anyway, can you please, how are we?

00:38:13.880 --> 00:38:14.920
I mean that directly.

00:38:15.990 --> 00:38:17.190
Can it, can it, can it love?

00:38:17.830 --> 00:38:19.270
I, I sure as hell hope.

00:38:19.270 --> 00:38:20.470
Can it give you a hug?

00:38:20.470 --> 00:38:22.230
No, no, but

00:38:22.230 --> 00:38:23.030
How do you,

00:38:23.030 --> 00:38:31.670
INTPs like us, like gross, right? My daughter has a shirt. She's very much like her father.

00:38:31.670 --> 00:38:33.990
Good. I'm glad. I'm glad you give clothes to your daughter.

00:38:33.990 --> 00:38:39.990
Yeah. And her shirt says at the very top, free hugs. And then in small letters,

00:38:40.630 --> 00:38:41.990
just kidding. Don't touch me.

00:38:41.990 --> 00:38:46.470
My, my insights report, somebody was asking about the disk report. I've never done the disk

00:38:46.470 --> 00:38:52.950
evaluation, but I'll do that sometime. But I remember my insights manual, which is not

00:38:52.950 --> 00:38:57.430
handy right now, but it has this little bullet point that says,

00:38:57.430 --> 00:39:02.950
do not get too close to Alan or touch him. And I love that. Okay. Very quickly here. Then I got

00:39:02.950 --> 00:39:08.150
to go. What are we doing about these people who hoard information? How did, what did you do with

00:39:08.150 --> 00:39:12.710
that woman who did not want to share information? What was your solution with her? How did you coach

00:39:12.710 --> 00:39:20.310
her? I was wired differently back then. I solved the problem that the business had

00:39:20.310 --> 00:39:31.400
without necessitating coaching her. You lazy. I, I basically said, I see. And started,

00:39:32.120 --> 00:39:36.440
I'd mentioned the snowball that rolled down the hill started the snowball that resulted

00:39:36.440 --> 00:39:40.280
in this person no longer being employed. I'm going to repeat something. I said this a lot,

00:39:40.280 --> 00:39:44.200
but I'm going to repeat it. Uh, cause I said it today to somebody over slack.

00:39:44.200 --> 00:39:51.320
Feedback has an incredibly short half life. Yes. And I think a lot of times we, we fail to give

00:39:51.320 --> 00:39:55.480
this feedback in timely enough manner and we go up. It's too late. Can't even give that feedback.

00:39:55.480 --> 00:39:59.320
Now I think if you were thinking that would happen today, you'd be able to give that person that

00:39:59.320 --> 00:40:05.160
coaching and that feedback in the moment. Yes. And well, absolutely. Right. And, and

00:40:06.120 --> 00:40:11.640
even more so like at Microsoft, like everyone's gone through and they've seen like what happened

00:40:11.640 --> 00:40:17.720
with tests. And there was this brief moment where everything was blamed off of the lack of testers,

00:40:17.720 --> 00:40:23.560
but now it, no one has that conversation. All right. So how do we, and did you ever answer,

00:40:23.560 --> 00:40:28.600
like you didn't have a good answer for this particular woman. So what's your general answer

00:40:28.600 --> 00:40:34.040
on how, how do we deal with these people? How do we, what would you do is my quest,

00:40:34.120 --> 00:40:37.000
you could do a whole other podcast on this, but in briefly, what do you do? Say you're

00:40:37.000 --> 00:40:42.360
working with someone and they are hoarding information and they are keeping everything

00:40:42.360 --> 00:40:46.360
to himself. They want to be the bottleneck or gatekeeper. What do you do? I put friction

00:40:46.360 --> 00:40:53.000
in that path. Number one, what do you mean? Uh, the first and foremost thing is I make it very

00:40:53.000 --> 00:41:01.640
clear that me as a business manager can't have that as a risk. I can't have one person on

00:41:01.640 --> 00:41:08.280
the team that is the only one that understands things like, and I'll do like the accidents

00:41:08.280 --> 00:41:17.240
happens in what's up, the bus factor. If the behavior continues, then, then I go down to,

00:41:18.360 --> 00:41:27.160
I will try to, to influence them that it's actually in their better interest, but I will go.

00:41:27.160 --> 00:41:33.160
So the, like, you know this from years ago, one of the books that really had a strong influence

00:41:33.160 --> 00:41:42.840
on me was titled influencer. So I try to use tricks from that and go, but actually what you're doing

00:41:42.840 --> 00:41:49.400
is harming yourself, not helping what you're doing. Now there's language on the fixed mindset. I,

00:41:49.400 --> 00:41:54.920
I would probably go and do some investigation on that one. Like I am firmly on the growth

00:41:54.920 --> 00:41:59.960
mindset aspect, but I would go through and I would try to get them to convince them.

00:42:00.680 --> 00:42:07.960
I would try to convince them that this is not, not a big behavior that's acceptable to them.

00:42:07.960 --> 00:42:18.360
I will say I have since adopted a strategy where I will do an earnest try to, to get them to

00:42:18.360 --> 00:42:26.120
understand this no more than four times, three times as typical, because at some point in time,

00:42:26.120 --> 00:42:32.600
I have to decide that, you know what? The ROI of continuing to have this conversation is quite low

00:42:33.620 --> 00:42:42.980
and, and if especially that the ROI of the behavior I'm asking for is high, then, then

00:42:42.980 --> 00:42:47.620
it's going to go down a similar route as the last person, just honest.

00:42:47.620 --> 00:42:50.900
I think the key thing here is you're just giving that feedback right away.

00:42:50.900 --> 00:42:51.300
Right.

00:42:51.300 --> 00:42:55.220
All right. Well, some good stuff in there, probably stuff we can lean into for next time,

00:42:55.220 --> 00:43:01.700
but we are out of time today. That was it. That was episode 190. Thanks everyone for listening

00:43:01.700 --> 00:43:06.420
and making it to the end. All right, everybody. Once again, A.B. testing. I'm Alan.

00:43:06.420 --> 00:43:07.460
I'm Brent.

00:43:07.460 --> 00:43:08.180
See you next time.

00:43:08.820 --> 00:43:10.180
Happy Thanksgiving.

00:43:10.180 --> 00:43:11.860
Yes. Happy Thanksgiving.

