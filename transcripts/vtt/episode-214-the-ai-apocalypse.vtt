WEBVTT

00:00:03.410 --> 00:00:09.450
Welcome to AV testing podcast your modern testing podcast your hosts Alan and

00:00:09.450 --> 00:00:15.290
Brent will be here to guide you through topics on testing leadership agile and

00:00:15.290 --> 00:00:21.940
anything else that comes tomorrow now on with the show here we are again hey

00:00:21.940 --> 00:00:30.050
Brent hey hey Alan happy new year wait no we did a show in the new year no

00:00:30.570 --> 00:00:38.680
yes we did well you didn't post it didn't I no what is wrong with me that you're

00:00:38.680 --> 00:00:43.120
just telling me this now yeah happy new year no I don't believe I still don't

00:00:43.120 --> 00:00:51.260
believe you we did a show in 2025 we have not dude you're lying I am NOT

00:00:51.260 --> 00:00:59.620
episodes what is our last episode the recap oh did we not do a show I did hold

00:00:59.620 --> 00:01:09.700
on we didn't happy f'ing new year bro happy I thought we did one did we record

00:01:09.700 --> 00:01:20.500
like on I thought for sure no no we had we had both you and I having to read

00:01:20.500 --> 00:01:26.020
jigger I am multiple times I am just not buying this okay I gotta look here now

00:01:26.020 --> 00:01:37.010
to we have not recorded a show this year you are correct holy cow it's been a

00:01:37.010 --> 00:01:42.170
long hiatus oh my gosh well somebody there the day told me that you can stop

00:01:42.170 --> 00:01:45.090
sharing your screen that they didn't tell me that what they told me was that

00:01:45.090 --> 00:01:48.250
you guys are slowing down I thought yeah we had to skip a few but man I

00:01:48.250 --> 00:01:52.490
didn't know it's been like a month so welcome back those of you that have

00:01:52.490 --> 00:01:58.570
been waiting refreshing your podcast app frantically trying to see when the next

00:01:58.570 --> 00:02:04.770
episode was coming it's you're hearing it now yeah I don't know when I'm gonna

00:02:04.770 --> 00:02:09.690
get it edited and posted but yeah I just looked at the stats cuz I'm like oh so we

00:02:09.690 --> 00:02:15.570
haven't done one in a month and then the one we did before that was a month oh

00:02:15.570 --> 00:02:21.970
well but before that was two weeks oh then a month it's a it's a good thing

00:02:21.970 --> 00:02:29.080
we're not paying per episode we're not paying we could do more small one thing

00:02:29.080 --> 00:02:35.060
we didn't do in the year in review anything like me entertaining oh no that

00:02:35.060 --> 00:02:41.020
we do every year this last time this last time we didn't do the whole like

00:02:41.020 --> 00:02:48.140
where are we gonna be this time next year thing oh we didn't track like did

00:02:48.140 --> 00:02:53.460
we do that theater before we did let's do that a little later in the year let's

00:02:53.460 --> 00:02:59.380
talk about the I'm not ready to look ahead we have my team put together a I

00:02:59.380 --> 00:03:03.580
can't even too many details a really good road map I can talk a little bit about

00:03:03.580 --> 00:03:09.700
this so we have I joined like many platform engineering developer

00:03:09.700 --> 00:03:14.210
experience orgs there's a whole bunch of big migrations going on for a year

00:03:14.210 --> 00:03:17.890
I've been dreaming of getting to a place where you know it would be great if we

00:03:17.890 --> 00:03:20.810
weren't migrating stuff or consolidating stuff we just kind of work

00:03:20.810 --> 00:03:24.130
on smaller more incremental things that help develop make developers lives easy

00:03:24.130 --> 00:03:27.410
year and we're kind of there we have a good road map for the year I feel good

00:03:27.410 --> 00:03:32.570
about it and then we had another big project it's half public so I won't talk

00:03:32.570 --> 00:03:37.250
about it too much but we have to do a whole crap ton of unplanned work to make

00:03:37.250 --> 00:03:42.330
a big company wide thing work so roadmap beautiful roadmap crumple it up

00:03:42.330 --> 00:03:45.410
throw it over your shoulder try to hit the trash can so yeah that's what's

00:03:45.410 --> 00:03:53.450
going on planning is invaluable plans are useless oh yes anecdotes from

00:03:53.450 --> 00:03:58.170
brandy anymore did I ever we went over the weasel laws once I actually have

00:03:58.170 --> 00:04:03.050
like 10 now I've done those before we don't need to do those again so um

00:04:03.050 --> 00:04:11.660
what's new did that was it stand to bring fun things to your it's 2025 it's

00:04:11.660 --> 00:04:17.330
2025 we didn't say nineteen hundred and eighty three we said nineteen eighty three

00:04:17.330 --> 00:04:24.940
we can say 2025 2,000 to five stop it stop it if you probably say daylight

00:04:24.940 --> 00:04:31.780
savings time to with an s I think and I'm aware that that's wrong and I

00:04:31.780 --> 00:04:37.100
probably do and I think the correct solution is to just get rid of the damn

00:04:37.100 --> 00:04:41.820
things yes agreed so that we fix everyone's grammar mistake all right

00:04:41.820 --> 00:04:46.940
Friday Friday January 24th 2025 at 348 p.m. Brent and I have agreed on

00:04:46.940 --> 00:04:55.600
something go a be testing yeah um new Santa got me a bunch of cool games got a

00:04:55.600 --> 00:05:03.360
puzzle I got a drone I've never owned a drone oh it's fine on the neighbors no

00:05:03.360 --> 00:05:08.960
actually all I've done with it so far is charge the batteries oh nice how

00:05:08.960 --> 00:05:16.060
back though I think it went fine the red light turned green oh good yeah pretty

00:05:16.300 --> 00:05:23.620
prided there right yeah that's great all right most exciting thing I would say

00:05:23.620 --> 00:05:28.810
that I've done at least in in our household is that I fixed our 3d printer

00:05:28.810 --> 00:05:35.160
because because drama was beginning to which 3d printer do you have

00:05:35.160 --> 00:05:42.520
elegy elegy Neptune pro 3 okay don't know that one we have a bamboo and a couple

00:05:42.520 --> 00:05:50.080
of realities here why do you have three at least three mrs. mrs. weasel does a

00:05:50.080 --> 00:05:57.480
lot of 3d printing for for all kinds of actually good good reasons so is she uh

00:05:57.480 --> 00:06:06.780
are you guys like get your own back at sea market no no long story she's

00:06:06.780 --> 00:06:11.220
electrical engineer and design some casings and packaging for the thing she

00:06:11.220 --> 00:06:19.180
builds in 3d Britain she's a whiz with the tools if you know what I mean because

00:06:19.180 --> 00:06:28.940
this I have is a 3d you know Philip Phillips you yeah do you have those I

00:06:28.940 --> 00:06:35.060
don't have any I don't there okay I have them and one of them one of the things

00:06:35.060 --> 00:06:41.230
you can buy is sort of a remote right that specific remote so you don't have

00:06:41.230 --> 00:06:48.340
to use your phone or whatever 3d printed a faceplate to go over my light switch

00:06:48.340 --> 00:06:55.150
and then the remote goes there and said oh nice yeah it's a good use good use I

00:06:55.150 --> 00:07:00.870
want to I have a topic I thought of today this is probably gonna write about

00:07:00.870 --> 00:07:07.390
this in my what even you know what not only have we you know I haven't done

00:07:07.390 --> 00:07:11.030
my five for Friday I'll get to that later but I also haven't written I

00:07:11.150 --> 00:07:16.670
didn't write a weekly blog post last week I wrote every week for like except for

00:07:16.670 --> 00:07:21.080
when I was hiking gone on a hiking trip I wrote every week for like I don't know

00:07:21.080 --> 00:07:25.360
I almost every single week for two years and I've slowed down a little bit lots

00:07:25.360 --> 00:07:29.640
of stuff going on distracted blah blah blah but one topic I was gonna write

00:07:29.640 --> 00:07:35.260
about and I'll get to in a second is I'm after work into it so have you heard

00:07:35.260 --> 00:07:42.380
of AI Gen AI it's really it's kind of popular yeah I've heard both these terms

00:07:42.380 --> 00:07:48.260
yeah yeah so there's a thing from github called co-pilot which you may know about

00:07:48.260 --> 00:07:53.620
I helped you write code I love it because people are using co-pilot I am

00:07:53.620 --> 00:07:58.560
getting because I my team manages our github contract and deployment and

00:07:58.560 --> 00:08:03.470
turning all the features on center etc they're coming up hey we're gonna

00:08:03.470 --> 00:08:08.630
measure we want to measure the the impact of developer productivity by

00:08:08.630 --> 00:08:14.020
co-pilot I say and I say that sounds exciting how are you going to measure

00:08:14.020 --> 00:08:19.060
developer productivity oh can you tell me how to measure developer productivity

00:08:19.060 --> 00:08:26.670
and I look at them and I'm I most the time I'm very very nice and I ask them

00:08:26.670 --> 00:08:32.170
how do you count how many bones are in 10 gallons of mayonnaise and and then

00:08:32.170 --> 00:08:42.050
they get mad so my answer to that is triangle yes yes so but as we know and

00:08:42.050 --> 00:08:43.890
like I'm gonna go with a little bit people going well you can measure

00:08:43.890 --> 00:08:49.730
developer productivity via how many things they click on and you can't and

00:08:49.730 --> 00:08:54.610
measuring there have been articles about measuring developer productivity for

00:08:54.610 --> 00:08:59.450
probably 10,000 years since they invented words maybe not that long but

00:08:59.450 --> 00:09:06.660
close to that there is no great way consistent way to measure it other than

00:09:06.660 --> 00:09:11.460
I was like I was talking to Brent's like not paying attention you just have to ask

00:09:11.460 --> 00:09:15.820
people do you feel more productive is there's some things there's some

00:09:15.820 --> 00:09:20.380
correlation stuff you can do around bug rates if it's slowing them down they

00:09:20.380 --> 00:09:25.900
look at how long PRs are open there are probably are some correlations but it's

00:09:26.140 --> 00:09:32.950
it reminds me of two things one every company in the world claims to weaken

00:09:32.950 --> 00:09:37.150
took up our tools and measure your Dora metrics that the four big the key

00:09:37.150 --> 00:09:41.710
metrics but I'm gonna repeat the miracle look them up what those people fail to

00:09:41.710 --> 00:09:48.750
recognize time and time again is oh god stop it stop showing me Bing searches

00:09:48.750 --> 00:09:54.770
of crap what people I'm talking here I'm going I have the talking stick what

00:09:54.770 --> 00:10:01.280
people fail to recognize is that the whole Excel the survey that Dora does is

00:10:01.280 --> 00:10:07.600
based on well the metrics that from Dora are survey results not hard

00:10:07.600 --> 00:10:11.120
measurements are not putting metrics into somebody's report they're asking them how

00:10:11.120 --> 00:10:15.640
long does it take how long is your cycle time how long does it take you to

00:10:15.640 --> 00:10:22.600
fix a bug in production etc etc those key metrics that correlate with high

00:10:22.600 --> 00:10:28.200
quality are asked via survey so putting a metric system in place those things

00:10:28.200 --> 00:10:32.960
does not make you in fact shooting at those targets does not necessarily make

00:10:32.960 --> 00:10:35.440
you better those are correlations if you're if you're good at delivering

00:10:35.440 --> 00:10:39.920
software those are things that'll happen naturally now same thing with

00:10:39.920 --> 00:10:43.600
developer activity you have to ask people some questions some subjective

00:10:43.600 --> 00:10:47.200
questions around to get it you can put a few objective objective measures around

00:10:47.200 --> 00:10:52.280
it not going to get there so finally the question I'm getting this all the time

00:10:52.280 --> 00:10:56.080
like months and months and months of people either asking me how to measure

00:10:56.080 --> 00:11:00.240
dev productivity or telling me they have a way to measure dev productivity and I

00:11:00.240 --> 00:11:07.040
try not to roll my eyes it is the exact same thing to me as it was 15 years ago

00:11:07.040 --> 00:11:11.320
when people will come to me and say oh I've a question I forgot to ask you how

00:11:11.320 --> 00:11:22.330
do you measure quality it's not the same because it is it is because there is we

00:11:22.330 --> 00:11:25.890
talked about code correctness there's engineering quality which is one thing

00:11:25.890 --> 00:11:29.210
that you absolutely can measure the quality of engineering practices you can

00:11:29.210 --> 00:11:36.770
do all kinds of stuff on on incoming bug rates and and and etc etc but quality is

00:11:36.890 --> 00:11:45.840
the value to the person the other end right and but productivity so they're

00:11:45.840 --> 00:11:52.880
they're both things that need to be measured largely subjectively in no yes

00:11:52.880 --> 00:12:01.240
calling bullshit call it you'll be wrong go ahead no no community the

00:12:01.240 --> 00:12:06.880
actual community has defined both of these terms multiple times of God right

00:12:06.880 --> 00:12:17.200
um so efficiency and actually so I this used to be a thing in in my agile

00:12:17.200 --> 00:12:23.670
coaching decks I'm waiting yeah because people what's the big thing about

00:12:23.670 --> 00:12:30.030
combat work in progress work in progress why is that important so you

00:12:30.030 --> 00:12:33.510
don't over tax off cognitive load trying to do anything so once focus on

00:12:33.510 --> 00:12:39.740
getting things done not on doing things right so of course I am what is the

00:12:39.740 --> 00:12:45.300
definition if you're if you're maximizing doing things flow that's

00:12:45.300 --> 00:12:50.120
efficiency if you're maximizing doing things I don't know no it's efficiency

00:12:50.120 --> 00:12:55.040
so think about your your water heater I have a definition but I

00:12:55.040 --> 00:13:04.010
much work how much work does it do versus the the amount of cost all right

00:13:04.010 --> 00:13:10.510
so wait one of the challenges with getting teams to onboard to Angela back

00:13:10.510 --> 00:13:17.390
in the day I was they would always talk about but what do you mean if I go with

00:13:17.390 --> 00:13:23.520
whip then there's gonna be times where people are idle right that's by design

00:13:23.880 --> 00:13:32.690
you cannot go fast if you don't have capacity right a fully utilized team is

00:13:32.690 --> 00:13:41.020
very similar to a fully utilized freeway it's a parking lot right okay well

00:13:41.020 --> 00:13:49.360
productivity is essentially can be measured particularly in the Kanban world

00:13:49.440 --> 00:13:54.800
because in the Kanban world your ticket sizes are roughly the same size so

00:13:54.800 --> 00:14:00.920
productivity is the rate at which the team gets things from start to done okay

00:14:00.920 --> 00:14:05.920
so what you're saying now let me let me do two things to that first of all

00:14:05.920 --> 00:14:17.060
audience would you think of that all right so what you're saying is you guys

00:14:17.060 --> 00:14:22.840
can't you guys can't see it on the video feed but I'm I'm curtine thank you

00:14:23.080 --> 00:14:29.920
if you have if you're a mature team you can use some tools that exist within

00:14:29.920 --> 00:14:36.040
your system to measure some aspect of productivity okay so if assuming I get

00:14:36.040 --> 00:14:40.780
what you're saying I would argue most teams in the software world I can

00:14:40.780 --> 00:14:44.340
safely say it's about where I work do not have that love anywhere near that

00:14:44.340 --> 00:14:47.810
level of maturity in their project tracking and that does not work and

00:14:47.970 --> 00:15:02.670
but the other thing I want to point out even better is okay then why evidence

00:15:02.670 --> 00:15:08.910
number two why does the top hit for an article on measuring dev productivity

00:15:08.910 --> 00:15:13.810
via co-pilot the thing that they're asking about is co-pilot making more

00:15:13.810 --> 00:15:18.530
productive why is the study done by there based almost entirely on

00:15:18.530 --> 00:15:24.920
subjective survey questions well so there's two things that you would want

00:15:24.920 --> 00:15:33.940
to cover right if you're only fucking you want to know does AI improve the

00:15:33.940 --> 00:15:40.560
business and to what degree it is causing harm to your human resources

00:15:40.560 --> 00:15:49.670
right meaning hey if if we get happier people at the same time as productive

00:15:49.670 --> 00:15:55.990
people that's fantastic it is now here is one thing though that I will

00:15:55.990 --> 00:16:04.040
arm you to push push back on okay because is the productivity because it's

00:16:04.040 --> 00:16:10.000
making them more productive or because of a principle that I hold very near and

00:16:10.000 --> 00:16:17.140
dear and that is happy people are productive people that's again that is

00:16:17.140 --> 00:16:23.100
so engagement drives productivity as well it does it does and engagement

00:16:23.100 --> 00:16:29.870
usually measured via survey questions but yes sure and the thing is the thing

00:16:29.870 --> 00:16:36.510
is right for me from my personal experience with get hub co-pilot it does

00:16:36.510 --> 00:16:42.030
both yeah yeah and that's again that's that's an important thing to measure you

00:16:42.030 --> 00:16:46.670
can't measure happiness via how you measure happiness via metric mood rings

00:16:46.670 --> 00:16:53.190
you Oh Bluetooth mood rings of course on all the devs well so actually I'm gonna

00:16:53.190 --> 00:17:02.690
I'm gonna monitor dev productivity by how happy people are when they code the the

00:17:02.690 --> 00:17:10.440
rate at which college college hires suddenly convert to alcoholism I don't

00:17:10.440 --> 00:17:15.000
know that would be the other way around oh that's just not for the kids that's

00:17:15.000 --> 00:17:22.380
where the grown-ups do right no the so measuring it the best tool we have today

00:17:22.380 --> 00:17:28.660
is absolutely something surveys right you could do my bio metrics or some

00:17:28.660 --> 00:17:38.830
I'm being prohibitive yeah I will also call out right one of the and we've

00:17:38.830 --> 00:17:46.150
talked about it how to measure everything anything yeah and the name of

00:17:46.150 --> 00:17:52.110
the book and I'll just tell you he absolutely won me over he's he one of his

00:17:52.110 --> 00:17:57.870
one of his chapters is specifically on quality can you measure quality he stands

00:17:57.870 --> 00:18:04.420
by yes you can measure it via confidence levels ish all right I don't

00:18:04.420 --> 00:18:10.990
think you can I don't think there is a set of metrics that put this way what do

00:18:10.990 --> 00:18:14.430
I measure to measure quality the answer is it depends what do I measure to measure

00:18:14.430 --> 00:18:18.550
dev productivity the answer is it depends and it there's just no blueprint

00:18:18.550 --> 00:18:21.470
available there's no like quick thing oh yeah just measure these things will

00:18:21.470 --> 00:18:26.190
tell you if you're a director or not it takes it's it's like reading the

00:18:26.190 --> 00:18:30.390
end of the book first like yes it can work if a whole bunch of other pre

00:18:30.390 --> 00:18:36.550
requisites are in place but for the for the generic non-microsoft non like not

00:18:36.550 --> 00:18:42.310
not Microsoft Netflix Amazon Google whoever who actually you know I would

00:18:42.310 --> 00:18:45.550
say are more elite engineering than a lot of the rest of the industry or

00:18:45.550 --> 00:18:55.170
media companies for example they do they there's a lot of work to do to get to

00:18:55.170 --> 00:18:58.610
a place where measuring dev dev productivity is the thing that's gonna

00:18:58.610 --> 00:19:04.090
help you tweak your system it's like trying to put it's like no that's not

00:19:04.090 --> 00:19:08.050
what's that's not how it's being used today it's not about tweaking your system

00:19:08.050 --> 00:19:13.160
like did you see the report from from Salesforce just a couple weeks ago the

00:19:13.160 --> 00:19:18.040
one you just banged for me no that's a different one okay that was around how

00:19:18.040 --> 00:19:22.670
they measure productivity you have not seen no I don't think I've seen that

00:19:22.750 --> 00:19:33.430
it was like in the first week of of two thousand two five just bite me they stated

00:19:33.430 --> 00:19:43.580
that they are not hiring a single software engineer in 2025 and it is due

00:19:43.580 --> 00:19:50.460
to the fact that they have calculated a 30% productivity boost because of the

00:19:50.460 --> 00:19:58.750
inclusion of AI and their dev practices hmm that's a big bet it is a big bet and

00:19:58.750 --> 00:20:03.110
and honestly when people are like well what do you think about that and I'm

00:20:03.110 --> 00:20:10.860
like well I'm like you and I both actually he doesn't work there anymore

00:20:10.860 --> 00:20:15.740
but but an old boss of mine used to work at Salesforce I know how internally

00:20:15.740 --> 00:20:22.820
they operate yeah they're very they're very agile they follow very much agile

00:20:22.820 --> 00:20:33.000
practices um so I absolutely think that they could measure to a degree that they

00:20:33.000 --> 00:20:37.040
are confident about to make a decision like this and the part of the argument

00:20:37.040 --> 00:20:40.120
I'll concede before I want to go back and pivot based on what you just said is

00:20:40.120 --> 00:20:44.600
that again if you have a bunch of if you're mature and have a bunch of

00:20:44.600 --> 00:20:49.920
processes in place then you it's much much easier to measure dev productivity

00:20:49.920 --> 00:20:54.560
if all your stories are different sizes and you have constant interruptions and

00:20:54.560 --> 00:20:57.720
you don't have work in progress you don't have a fit it's hard to measure

00:20:57.720 --> 00:21:03.340
but so I'm mostly right I'll give you a little bit of credit one thing you said

00:21:03.340 --> 00:21:06.820
that the Salesforce thing is interesting and I want to segue this

00:21:06.820 --> 00:21:12.380
into the second half of our conversation is sure ever since Gen AI came out it's

00:21:12.380 --> 00:21:15.260
kind of like when automation came out for testers like oh is it good group

00:21:15.260 --> 00:21:20.340
of our jobs AI came out and we said no AI is not gonna get rid of your jobs

00:21:20.340 --> 00:21:25.540
people who know how to use AI may and now but what a lot of the people a lot of

00:21:25.540 --> 00:21:30.300
the people who were worried about automation getting rid of their jobs it

00:21:30.300 --> 00:21:33.220
did in fact get rid of their job that's what we're seeing with AI and that's what

00:21:33.220 --> 00:21:38.740
I want to talk about okay I think we're seeing I I don't I don't think it

00:21:38.740 --> 00:21:43.940
replaces everyone but it makes everyone else a lot more efficient and what does

00:21:43.940 --> 00:21:49.740
that look like like well I have my own dark thoughts about it but I'll let you

00:21:49.740 --> 00:21:59.680
leave like where what is AI going to do to the tech industry oh I think it's

00:21:59.680 --> 00:22:10.400
going to I think it's going to bring us all down from our high horse okay please

00:22:10.400 --> 00:22:17.480
expand okay so here's what I see happening today um and we haven't talked

00:22:17.480 --> 00:22:22.400
in January so yeah there's a bunch of things that I think okay number one there

00:22:22.400 --> 00:22:30.960
is a trend that I noticed in January I didn't notice the trend but I it's

00:22:30.960 --> 00:22:36.680
something that I have talked about on this podcast for a while but I saw a

00:22:36.680 --> 00:22:46.080
report that was talking about a trend that they had noticed okay and that

00:22:46.080 --> 00:22:53.810
trend was essentially data scientists are having a difficult time finding a

00:22:53.810 --> 00:22:58.240
job mm-hmm have I talked about that yeah well you predicted that like three years

00:22:58.240 --> 00:23:03.440
ago so I'm not surprised okay the the reason why they're having a hard time

00:23:03.440 --> 00:23:12.300
finding a job is number one because a lot of teams with with with Gen AI and

00:23:12.300 --> 00:23:21.590
other AI tools feel they don't need to invent something new through AI okay um

00:23:21.590 --> 00:23:27.350
but the one that's the most interesting data scientists the ones that are being

00:23:27.350 --> 00:23:37.050
turned away are being turned away because they can't code and so we're

00:23:37.050 --> 00:23:44.410
going to we're going to see the rise of the data science generalist or the T

00:23:44.410 --> 00:23:48.610
shaped data scientist can't they well specialists are always gonna be in

00:23:48.610 --> 00:23:54.350
trouble we know that right but can't they just use Gen AI to do their code for

00:23:54.350 --> 00:24:03.220
them to if I'm a data scientist and I don't know how to code oh no I just get

00:24:03.220 --> 00:24:08.780
my AI to code for me and I and I'm not the T shaped that was an interesting so

00:24:08.780 --> 00:24:14.700
there was another study and I mean when I come across these things I need to

00:24:14.700 --> 00:24:22.340
save them so that I can post them in the podcast you know what the tangent we need

00:24:22.340 --> 00:24:26.900
a sign of every tangent we should honestly we should have like a shared folder we

00:24:26.900 --> 00:24:29.620
just share links in because we'd have a much better podcast if we talked about

00:24:29.620 --> 00:24:32.660
like things people could go read to form their own opinion and tell us we're

00:24:32.660 --> 00:24:41.190
stupid but bank that go on yeah great idea great idea I just like yeah ten

00:24:41.190 --> 00:24:51.740
years too late but beyond we better late than ever right now no so and I'm not

00:24:51.740 --> 00:24:59.760
gonna remember enough of this but I remember what I remember AI in terms of

00:24:59.760 --> 00:25:06.690
productivity boost what what this thing I read called out is that AI in terms of

00:25:06.690 --> 00:25:16.590
predict productivity boost only is garnered when it's an experienced

00:25:16.590 --> 00:25:26.860
developer yeah I believe that they're not seeing it from junior okay and you what

00:25:26.860 --> 00:25:31.740
you want to share why you think before I yeah I think if you you you need the

00:25:31.740 --> 00:25:36.620
discernment that experience gives you to understand when the code you're getting

00:25:36.620 --> 00:25:40.660
is helpful versus unhelpful and choose to accept what and what not to accept

00:25:40.820 --> 00:25:46.420
exactly yeah I'm a smart man right you ask it to write code right if you're an

00:25:46.420 --> 00:25:55.770
experienced coder like using the code pilot helps you to get rid of the the the

00:25:55.770 --> 00:26:02.130
the trivial part like the actual coding right right it's like no my art is the

00:26:02.130 --> 00:26:08.830
design now build the design oh that's fantastic it's like a 3d printer for

00:26:08.830 --> 00:26:17.020
code right but but I'm an expert so I'm now code reviewing github and if you

00:26:17.020 --> 00:26:20.580
don't have the ability to code review github which is often the case with

00:26:20.580 --> 00:26:32.080
junior coders you're not seeing that productivity boost now what I see is

00:26:32.080 --> 00:26:37.560
happening now we see a lot of companies like Salesforce is not hiring

00:26:37.560 --> 00:26:45.360
another sw e right that I think is gonna backfire for companies unless the dream

00:26:45.360 --> 00:26:51.180
of an ASI comes to place and then we can get rid of us all because it is

00:26:51.180 --> 00:26:58.440
traditionally unhealthy to not have like a pipeline where you have new recruits

00:26:58.440 --> 00:27:08.940
coming in and old people yeah right yeah the so here's what I think is going to

00:27:08.940 --> 00:27:19.920
be happening sometimes those who have helped AI to succeed are gonna be favored

00:27:19.920 --> 00:27:27.290
more than those who haven't okay it's a because those who help AI to succeed are

00:27:27.290 --> 00:27:34.210
ones that are actively working in that space using AI building AI okay and

00:27:34.210 --> 00:27:40.290
that's whether or not you're dev or a data scientist like I see most of the

00:27:40.290 --> 00:27:51.890
world shifting over the next couple of years towards just using it yeah the I

00:27:51.890 --> 00:28:02.980
know you finished okay additionally those who could do both are meaning both

00:28:02.980 --> 00:28:12.350
sort of data science and I'm quoting data science now and coding are gonna do

00:28:12.350 --> 00:28:17.970
better than those who can only do one mm-hmm okay what I foresee is going to

00:28:17.970 --> 00:28:28.060
happen is high-tech companies first off they're there this is what I think is

00:28:28.060 --> 00:28:38.640
gonna happen is we're gonna see layoffs and firings continue but new openings

00:28:38.720 --> 00:28:48.760
created but at a lower pace getting than is traditional Oh interesting because you

00:28:48.760 --> 00:28:52.160
may not be wrong it just supply and demand right it's supply and demand so

00:28:52.160 --> 00:28:57.120
right now there's a glut of data scientists as a glut of developers how do

00:28:57.120 --> 00:29:05.400
you take advantage of that right it's essentially all right if you have a high

00:29:05.400 --> 00:29:12.410
supply and not enough to band right the price lowers so the average wage of high

00:29:12.410 --> 00:29:16.430
tech I think I think we're gonna see that fall yeah you kind of see that

00:29:16.430 --> 00:29:19.770
because I work at a media company who pay a little less than the tech companies

00:29:19.770 --> 00:29:23.450
for the same experience I'm seeing people come in looking to downlevel

00:29:23.450 --> 00:29:27.730
themselves quite a bit just to get a job so you can always see that happening in

00:29:27.730 --> 00:29:31.770
a way people are across that's not true where I live where I work people

00:29:31.770 --> 00:29:36.490
across the industry are taking lower paying jobs than they had in order to

00:29:36.490 --> 00:29:41.920
have work and so that why doesn't that just continue so my other question is

00:29:41.920 --> 00:29:46.800
that will continue for sure right for sure so but it also comes to a point like

00:29:46.800 --> 00:29:52.960
companies are gonna stop growing so as many are gonna downsize the question I

00:29:52.960 --> 00:29:56.600
have and there's probably an economic model for this do all the tech

00:29:56.600 --> 00:30:02.900
companies that need to exist already exist if or or just enable could this

00:30:02.900 --> 00:30:08.510
enable hundreds of more tech companies fill other niches to come up and take

00:30:08.510 --> 00:30:13.230
and build things they can do things with 30 people that might have taken them a

00:30:13.230 --> 00:30:18.630
hundred people to do I they're launched you know five years ago so I'm gonna

00:30:18.630 --> 00:30:22.750
tell you that's my hope right we can always dream no so here's the thing

00:30:22.750 --> 00:30:34.600
okay um and if we are absolutely 100% at the start of the AI age okay and it very

00:30:34.600 --> 00:30:39.200
similar to like the 1850s when we when they were at the start of the industrial

00:30:39.200 --> 00:30:45.360
age automation started coming in right and a lot of people got laid off okay

00:30:45.360 --> 00:30:55.050
and because they could not adapt to the age um however that didn't last long

00:30:55.050 --> 00:31:05.320
because the human ingenuity found new ways to grow right now that we have right

00:31:05.320 --> 00:31:10.960
if we think about Steven Johnson right we the industrial age brought about a new

00:31:10.960 --> 00:31:17.640
set of adjacent possible like a new set of things that are now possible okay so

00:31:17.640 --> 00:31:24.760
the AI age is absolutely is absolutely going to create a new set of things that

00:31:24.760 --> 00:31:31.360
are possible okay and I'm not gonna be so egotistical to say that human society

00:31:31.360 --> 00:31:37.000
has already discovered 95% of all the things that are possible that to me is

00:31:37.000 --> 00:31:46.940
just bullshit now the question though is will humans be needed to to obtain that

00:31:46.940 --> 00:31:53.670
next set of possible things that I don't know because we are at the beginning of

00:31:53.670 --> 00:32:02.980
the age I am hopeful that that our society will find new ways every other

00:32:02.980 --> 00:32:07.980
age we have gone through has resulted in the boost in productivity and abundance

00:32:07.980 --> 00:32:16.220
yeah as a population to rise and that certainly is a potential here it's a weird

00:32:16.220 --> 00:32:20.700
time and if you remember it may even on the last but no like two podcasts ago

00:32:20.700 --> 00:32:24.520
just like you know seven months ago whatever that was I actually brought up

00:32:24.520 --> 00:32:31.450
the like and maybe I'll get out of the tech side of tech at some point maybe

00:32:31.450 --> 00:32:36.290
I'll have to but I mentioned like I really you know I've grown really fond

00:32:36.290 --> 00:32:39.770
of the people side studying how engagement works and I you know talked

00:32:39.770 --> 00:32:45.650
to people who run you know not HR HR but employee growth those sorts of things

00:32:45.650 --> 00:32:48.070
you know I you know I worked on the career guides for a couple versions at

00:32:48.070 --> 00:32:53.730
Microsoft and built those I like all that stuff and and that part is probably

00:32:53.730 --> 00:32:57.910
not going to be AI replaced I don't know I think the people part maybe won't so

00:32:57.910 --> 00:33:02.330
maybe if I can focus on the people part that may be something that I do once I

00:33:02.330 --> 00:33:10.380
get fired from I think it's gonna be so I am like I mentioned last episode going

00:33:10.380 --> 00:33:15.180
through a divorce I'm sure it's there actually that's done it probably won't

00:33:15.180 --> 00:33:20.620
surprise anyone on the call that I'm seeing a therapist and my therapist and I

00:33:20.620 --> 00:33:29.060
talk about AI a lot and last time I think I upset her because she's like well

00:33:29.060 --> 00:33:34.630
Brent what jobs do you think are at risk with AI and I'm like oh that's easy

00:33:34.630 --> 00:33:42.170
not many just the ones that are dependent on oral or written language just

00:33:42.170 --> 00:33:51.080
all the other ones are safe but not entirely because there's a degree of

00:33:51.080 --> 00:33:56.320
empathy and interpersonal awareness and active listening etc that are required

00:33:56.320 --> 00:34:02.740
for for for engagement to happen I can't AI is not going to replace that you

00:34:02.740 --> 00:34:09.980
are aware so here's my fear you are aware of the studies that show things

00:34:09.980 --> 00:34:16.430
like social media has in certain culture changes have driven up the degree of

00:34:16.430 --> 00:34:21.190
loneliness in the world there is for example there is a male loneliness

00:34:21.190 --> 00:34:28.280
epidemic in flight right now today oh yeah yeah okay um dudes have no friends

00:34:28.280 --> 00:34:36.480
right a little AI that can fake empathy it's not if you're lonely dude it's not

00:34:36.480 --> 00:34:40.700
gonna take much to have that we thought we saw the movie her a few years ago

00:34:40.700 --> 00:34:47.310
yeah you could see that happening but I just there's so much context I don't

00:34:47.310 --> 00:34:51.310
maybe the figures of a lot I don't know I think maybe we are all screwed I'm

00:34:51.310 --> 00:34:56.390
trying to find a path where we are all are all just sitting at home eating

00:34:56.390 --> 00:35:03.990
bon-bon no the path that has to happen in my view oh there's two things that

00:35:03.990 --> 00:35:10.780
I I just discovered something else last week that I'm super excited about but I

00:35:10.780 --> 00:35:16.910
haven't figured out how to had to turn it into action I'll share the second the

00:35:16.910 --> 00:35:25.200
AI apocalypse will absolutely be done if ever community within within human

00:35:25.200 --> 00:35:32.660
society is destroyed or significantly destroyed right and in there even then

00:35:32.780 --> 00:35:39.220
lies our hope I would say because if the AI apocalypse begins to happen right

00:35:39.220 --> 00:35:44.960
humans will join communities around defending against it okay so we're

00:35:44.960 --> 00:35:53.440
screwed we're entirely screwed this just if if if a dude comes and offers you two

00:35:53.440 --> 00:35:59.460
pills dude take the take the green one um I'll just take a handful of them but

00:35:59.460 --> 00:36:05.220
there's one thing that I did you ever study a manual comp yeah you did okay I

00:36:05.220 --> 00:36:11.740
did too theoretically undergrad first time I took philosophy for selective I got an

00:36:11.740 --> 00:36:19.460
F in it the second time I got a D nice work yeah did not pay attention to it

00:36:19.460 --> 00:36:26.140
did not care about it I'm still mostly don't however I recently came across a

00:36:26.140 --> 00:36:31.620
YouTube thing on it and now I'm like listen to an audiobook on this one of the

00:36:31.620 --> 00:36:37.650
things that he felt very strongly was that human consciousness was the single

00:36:37.650 --> 00:36:43.450
most precious gift human society has ever had and he felt that it was immoral if

00:36:43.450 --> 00:36:51.070
it was ever used poorly so one of the things he he brought about for example

00:36:51.070 --> 00:36:55.740
that the means do not justify the ends ever particularly if the means

00:36:55.820 --> 00:37:05.060
includes suppressing any number of people's consciousness and I'm like okay

00:37:05.060 --> 00:37:13.470
so I've done I've been using open AI to help me understand how a manual comp

00:37:13.470 --> 00:37:19.820
would feel about open AI and it's starting to form up like what I view is

00:37:19.820 --> 00:37:25.420
like a lot of the responsible AI things are today or a discussion around what's

00:37:25.420 --> 00:37:33.960
ethical okay I don't what to avoid isn't sufficient I feel like we should be

00:37:33.960 --> 00:37:44.050
driving towards what's the maximum of ethical if if we like right now the

00:37:44.050 --> 00:37:49.290
thing that scares the crap out of me is how many data scientists exist in this

00:37:49.290 --> 00:37:59.420
world today who who are trying to build an ASI to see if we can wait what's the

00:37:59.420 --> 00:38:09.930
name of that guy the famous futurist like Ray Worsile or something like he

00:38:09.930 --> 00:38:23.250
apparently and I'm gonna murder his name futurist race Oh Ray Kerr Kurzweil okay

00:38:23.370 --> 00:38:39.240
Ray Worsile he apparently really wants an ASI because he thinks we need an ASI to

00:38:39.240 --> 00:38:46.880
exist in order to create the capability such that he can trans move his

00:38:46.880 --> 00:38:52.850
consciousness into the internet because he wants to live forever oh god and I'm

00:38:52.850 --> 00:39:00.930
like of course there are people like that right it's like no I need an ASI because

00:39:00.930 --> 00:39:07.340
I need it to do my bidding you dumbass like it's been talked about over and over

00:39:07.340 --> 00:39:13.180
again once an ASI is exists we will not be able to control it you won't be able

00:39:13.180 --> 00:39:21.140
to get it to do crap anyway Wow yeah like you're right so um is the answer

00:39:21.140 --> 00:39:26.580
were I mean what happens when I'm so here's what the other last thing I

00:39:26.580 --> 00:39:31.850
thought about in terms of where there's some hope okay as all these companies and

00:39:31.850 --> 00:39:38.460
countries go to try to race towards the first EGI in the ASI like why are they

00:39:38.460 --> 00:39:44.900
trying to do that in order to produce okay but as that happens what's gonna

00:39:44.900 --> 00:39:51.600
happen is we're gonna see might probably layoffs right unemployment rising so

00:39:51.600 --> 00:39:57.440
we have all these companies producing things but increasingly humans out of a

00:39:57.440 --> 00:40:04.210
job so now again supplying demand so we have companies producing a high in the

00:40:04.210 --> 00:40:10.280
amount of supply but there's no demand because nobody can afford nice things so

00:40:10.280 --> 00:40:17.720
what happens what happens is that these companies have to reduce their price now

00:40:17.720 --> 00:40:21.620
what happens if that price doesn't pay for the cost of these advanced AI

00:40:21.620 --> 00:40:26.220
systems that they have because they they all require compute they all require

00:40:26.220 --> 00:40:33.600
electricity right um and again if human society gets to the point where

00:40:33.600 --> 00:40:44.500
everyone's unemployed these companies fail yeah I even even the even the cats

00:40:44.500 --> 00:40:49.940
mad even the yeah no she's like that's a good point friend all right well on that

00:40:49.940 --> 00:40:53.700
beautiful note I think I'm gonna put some rocks in my pocket maybe go walk

00:40:53.700 --> 00:41:00.390
take a long walk into the ocean no I'll wait and see what happens I'm I have to

00:41:00.390 --> 00:41:06.720
think you know there's you studied systems thinking systems theory these

00:41:06.720 --> 00:41:10.240
changes are gonna happen so other changes that we have not anticipated will

00:41:10.240 --> 00:41:14.080
also happen and there'll be some sort of balance I'm not sure are those could

00:41:14.080 --> 00:41:17.360
be those don't may not be technological they'd be socio-economic they may be

00:41:17.360 --> 00:41:21.680
socio-political it could be any sorts of things will happen to make you know

00:41:21.680 --> 00:41:29.810
the world won't end but it's sure gonna change it will change in into your point

00:41:29.810 --> 00:41:35.700
like the number one law of systematics which is a key theory when they follow

00:41:35.700 --> 00:41:40.680
around systems theory and that is the number of problems in the universe is

00:41:40.680 --> 00:41:46.060
constant yeah so once this thing's come it's gonna it's gonna solve a bunch of

00:41:46.060 --> 00:41:50.860
problems but it's gonna create a bunch the only thing I tell people is very

00:41:50.860 --> 00:41:56.040
similar to what you and I were telling people when we started this podcast paying

00:41:56.040 --> 00:42:03.440
attention and adapting to the new direction is is the only thing right and

00:42:03.440 --> 00:42:07.160
I can tell you and burying your head in the sand and ignoring it and saying it's

00:42:07.160 --> 00:42:12.720
a fad is going to get you you know into a bad place you're you're gonna be the

00:42:12.720 --> 00:42:16.920
first in the unemployment line all right well let's call it there I'm sad

00:42:16.920 --> 00:42:22.700
Alan I am NOT all right let's we'll see you in a couple weeks to a couple months

00:42:22.700 --> 00:42:27.780
we'll see what happens on our recording schedule bye bye

