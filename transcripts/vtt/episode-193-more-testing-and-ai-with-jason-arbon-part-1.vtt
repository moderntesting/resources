WEBVTT

00:00:00.000 --> 00:00:08.560
I'll do a bit. I'll bet that both of you are in a QA titled role in 24 months.

00:00:12.260 --> 00:00:19.060
Welcome to AB testing podcast, your modern testing podcast. Your hosts, Alan and Brent

00:00:19.060 --> 00:00:24.580
will be here to guide you through topics on testing, leadership, agile, and anything else

00:00:24.580 --> 00:00:30.420
that comes to mind. Now on with the show. Guess what? It's me again. It's Alan and we're here for

00:00:30.420 --> 00:00:37.360
episode 193 of the AB testing podcast. We have Brent and we have the return of Jason Arvin.

00:00:38.420 --> 00:00:46.300
Hey, the return of Jason Arvin. Because last time, last time, and I'll quote myself,

00:00:46.300 --> 00:00:51.740
Zen Caster shit the bed. And that was the last time then Castro was ever used on this podcast.

00:00:52.780 --> 00:01:00.380
So far been using Riverside FM so far. Very, very good. Very, very happy. Please don't let me down.

00:01:00.380 --> 00:01:04.580
That's where we are. Zen Caster saved me though, because I said some things I'm glad they weren't.

00:01:07.220 --> 00:01:13.140
You know what, Jason, you are clever enough. You could go in, like immediately go hack

00:01:13.140 --> 00:01:16.500
the Zen Caster server and just remove all that stuff.

00:01:18.500 --> 00:01:20.980
Maybe maybe I act, maybe I accent castor.

00:01:23.380 --> 00:01:29.540
Well, it's, it's good to have you here. We're going to do, I think I put it in our prediction

00:01:29.540 --> 00:01:35.380
show. We're going to do more guests here because one, the guests are more interesting than us. And

00:01:35.380 --> 00:01:45.170
two, more importantly, I am so tired of Brent. Totally. It's, it's, I mean, it's good to have

00:01:45.170 --> 00:01:50.130
guests because they bring in a fresh perspective until we figure out the next thing that's

00:01:50.130 --> 00:01:55.010
important to us to talk about. No, I always have important things to talk about. It's in fact,

00:01:55.570 --> 00:02:00.370
do you? I am practically incapable of talking about things that aren't important.

00:02:01.090 --> 00:02:07.410
Okay. I'm happy to be filler. I can't think of the last time I said something that wasn't important.

00:02:08.290 --> 00:02:14.450
Sure. Yeah. So, so Jason, your team's listening to this one. Is that what's going on?

00:02:14.450 --> 00:02:19.490
You know what? It's interesting. When I was at previous company, a lot of people listened to my

00:02:19.490 --> 00:02:24.690
podcast or read my blog. I think, I don't know if anybody listens to my podcast at the

00:02:24.690 --> 00:02:28.690
new place. They do read because I post that on LinkedIn all the time connected there. And

00:02:29.650 --> 00:02:36.290
they don't know how much I'm drawing from my daily life to inspire some of the topics.

00:02:36.290 --> 00:02:41.250
But we'll get more into that later. This is not about me. This is about Jason. And Jason is very

00:02:41.250 --> 00:02:49.250
interested in fine art and the variance of meatballs in the Italian market. So we're going

00:02:49.330 --> 00:02:55.970
to go into all of those subjects deeply. Jason, just as a reminder, kind of tell people what you're

00:02:55.970 --> 00:03:00.130
up to. And then I'll ask on my list of questions that will get us kind of diving into this thing.

00:03:00.130 --> 00:03:07.710
What I'm up to now, I'm actually taken a year off and focused on, focused on applying AI

00:03:07.710 --> 00:03:13.550
to software testing and like exclusively and voraciously. And it's been wonderful because

00:03:14.190 --> 00:03:17.870
the AI robots do what you tell them to do mostly. Yeah. And trying to figure out how to get

00:03:18.430 --> 00:03:23.390
experimenting and trying to see what works and what doesn't and as quickly as possible.

00:03:23.390 --> 00:03:27.230
And I think I've narrowed down a few kind of themes, but I've been experimenting for

00:03:27.790 --> 00:03:32.270
AI for human manual testers, exploratory testers to figure out how I could help them.

00:03:32.990 --> 00:03:37.630
Also kind of a full automation, like everyone's dream, which is how do you get an AI robot to

00:03:37.630 --> 00:03:43.470
just, my testing bot to just test the application and APIs without a human involved. So focusing

00:03:43.470 --> 00:03:47.790
on kind of researching them. Super cool stuff. And I have lots of questions to go in there

00:03:47.870 --> 00:03:52.510
but I had a conversation. Was it yesterday? I was talking to one of my employees. I was in Los

00:03:52.510 --> 00:03:56.990
Angeles and we're talking about AI. It's always a weird question to bring up with somebody like,

00:03:56.990 --> 00:04:00.590
what do you think of AI? Because you never know what people are going to say, right?

00:04:00.590 --> 00:04:04.510
He didn't know me well enough to know. And I said the usual stuff you've heard me say,

00:04:04.510 --> 00:04:09.790
but something I've maybe said on the podcast is referring to something Stephen Johnson calls

00:04:09.790 --> 00:04:16.780
the adjacent possible. Meaning all of a sudden we've made an innovation that enables us to

00:04:16.780 --> 00:04:22.860
build a whole new world of innovation. And I think generative AI is that. And I don't think

00:04:22.860 --> 00:04:30.540
many, if any folks, despite all the cool things people have done, have really made that leap that

00:04:30.540 --> 00:04:35.100
I know is inevitably going to happen. So I'm glad to hear, you know, I think you have a chance to be

00:04:35.100 --> 00:04:40.140
like, like there's people like this trying to figure out what, what is this adjacent

00:04:40.140 --> 00:04:45.180
possible innovation we can make. So I want to talk more about that, but I also want to talk

00:04:45.180 --> 00:04:53.740
more about testers and how AI replaces, enhances, helps, fixes testers. You had an interesting

00:04:53.740 --> 00:05:01.340
LinkedIn post. Was that today or yesterday? I just saw it today on Jason's looking at me like,

00:05:01.340 --> 00:05:03.020
I didn't post something like testing.

00:05:03.020 --> 00:05:06.140
I had about the 737 MAX. I don't think that's what you're talking about.

00:05:06.140 --> 00:05:09.500
No, no, no. Which one was, hold on, hold on, hold on.

00:05:10.290 --> 00:05:16.130
Oh, was it the quote that my prediction that people have left the testing field will come back to it?

00:05:16.770 --> 00:05:21.570
Yes. Yes. I want you to talk more about that. That's interesting.

00:05:21.570 --> 00:05:22.530
That was just click bait.

00:05:22.530 --> 00:05:25.090
I don't believe you yet, but convince me.

00:05:26.620 --> 00:05:27.100
It worked.

00:05:30.780 --> 00:05:32.720
Next question, Alan.

00:05:32.720 --> 00:05:32.960
Next.

00:05:32.960 --> 00:05:41.120
No, I just figured like testers were getting tired of me and they're scared of AI. So I just appealed

00:05:41.120 --> 00:05:47.710
to them. Yeah.

00:05:47.710 --> 00:05:49.470
Yeah. That's the comments.

00:05:50.910 --> 00:05:55.310
This is what I get for skimming articles. I actually think they're not sarcastic.

00:05:55.310 --> 00:05:59.390
Actually very genuine. I think it's for probably kind of not the reasons that people would expect.

00:06:00.190 --> 00:06:04.030
I didn't even really outline those. One is, first of all, we were saying a second ago,

00:06:04.030 --> 00:06:10.190
I think is very right. I think people are like the adjacent stuff, but I think people are not

00:06:10.190 --> 00:06:16.190
thinking AI first still. They're thinking about how to modify existing processes and software or

00:06:16.190 --> 00:06:21.470
to create, like use AI to generate Java code instead of actually just having AI run.

00:06:22.590 --> 00:06:27.870
So I think there's people still haven't kind of gone through that bias yet,

00:06:27.870 --> 00:06:33.070
which is normal when there's technology transitions. But so when it comes to what I

00:06:33.070 --> 00:06:37.790
said was I think a predict that there'll be that a lot of testers have left the field

00:06:37.790 --> 00:06:41.790
as they get further and longer careers. There's a lot of you guys have talked about this before,

00:06:41.790 --> 00:06:45.870
too. There's also like a salary cap and testing to be frank. And so people left it

00:06:45.870 --> 00:06:51.390
just for more money, let alone or like we were talking before that we started this, Alan,

00:06:51.390 --> 00:06:57.230
sometimes people just get sick of testing because it can become mundane or boring or

00:06:57.310 --> 00:07:02.190
exhausting in its own way. I think one is that there'll be one is there's just the general

00:07:02.190 --> 00:07:07.630
pressures are coming on. AI is genuinely helping in the software engineering world.

00:07:07.630 --> 00:07:11.630
People can and Brent's been talking about this too, like where you can just write better code,

00:07:11.630 --> 00:07:16.110
not just better code, but more code. So it'll be more stuff to be tested. But I also think

00:07:16.110 --> 00:07:23.150
that it's a little story where I'm a story. Brent's going out great. But when I walked into

00:07:23.310 --> 00:07:28.430
when I went from Microsoft to Google, I skipped my first week of nuclear training because I thought I

00:07:28.430 --> 00:07:32.430
was too cool for that. And so I went, but I went to the search building and I just walked around

00:07:32.430 --> 00:07:37.790
with my new badge because I wanted to see the Holy Land and everyone's title there and this

00:07:37.790 --> 00:07:42.750
one building that worked on search, everyone's title was a search quality engineer. And so I

00:07:42.750 --> 00:07:46.910
think, and the reason is, is that they weren't building traditional software. They're building AI

00:07:46.910 --> 00:07:52.830
and very high scale algorithmic type software. And so really what it is, it's very easy to write

00:07:52.830 --> 00:07:57.630
some code and then you let 10 or a hundred thousand machines or a million machines process it.

00:07:57.630 --> 00:08:01.470
The hard problem is testing it. How do you know that it's of high quality? Especially when you

00:08:01.470 --> 00:08:07.390
think about a search engine, and we'll come back around is that the hard problem with search box

00:08:07.390 --> 00:08:10.990
is people can type anything they want into it. And it sounds familiar. It sounds a lot like

00:08:10.990 --> 00:08:17.310
chat GPT. Google and the search story though is still constrained because it only returns things

00:08:17.310 --> 00:08:22.430
that are on the internet that exist already. The problem with chat GPT is it can return anything,

00:08:22.510 --> 00:08:29.070
things that either don't exist or things that are made up. And so quality is the hardest

00:08:29.070 --> 00:08:35.230
problem in software engineering, particularly in AI. So I think that it's not just that the people

00:08:35.230 --> 00:08:42.110
will come back to testing to do traditional testing. I think it's that a lot of those engineers

00:08:42.110 --> 00:08:48.270
that left testing to PM or dev will be far more valued because they have that testing context with

00:08:48.270 --> 00:08:54.110
that engineering or PM background. And they can be monsters and incredibly important when software

00:08:54.110 --> 00:09:00.270
goes through this transition where it's AI first, because you need a search quality like testing

00:09:00.270 --> 00:09:07.550
approach for that software. I see where you're coming from. I spent time in Bing.

00:09:08.270 --> 00:09:14.910
Right. And I need to enter up with the editor. Bing is like Google, you can use it to Google

00:09:14.910 --> 00:09:22.720
things. It's from Microsoft. Anyway, go on, Brent. I'm just currently pausing and wondering

00:09:23.360 --> 00:09:32.800
what episode is anyone going to view that horse that is already dead, no longer worth, no longer

00:09:32.800 --> 00:09:39.440
worth kicking. When Bing is known as a search engine, that's when I'll do it.

00:09:40.160 --> 00:09:48.640
Okay, hopefully you're paying attention to news because anyway, moving on, not doing tangent. So

00:09:48.640 --> 00:09:55.600
one of the things that that I learned when going to Bing, it was interesting because this

00:09:55.600 --> 00:10:06.530
was the same thing. Buds did not matter in Bing, because they were not helpful. Because we have a

00:10:07.410 --> 00:10:13.970
machine learning algorithm that's constantly learning the best way given the context, how to present

00:10:13.970 --> 00:10:21.330
answers. And not only that, but we have thousands of streams underneath it that are changing sort of

00:10:21.330 --> 00:10:26.850
the input to that same model. So that's one of the reasons why you might go to Bing and type in

00:10:26.850 --> 00:10:31.810
a search query and then hit refresh and get an entirely different experience. And hit refresh

00:10:31.890 --> 00:10:37.410
again and get an entirely different experience. What ended up being valuable there? Testers that

00:10:37.410 --> 00:10:43.570
went over and thought, oh, I've just my job is to find bugs. They got frustrated because no one,

00:10:43.570 --> 00:10:52.370
they all got one fixed. What was valuable is help us diagnose and find the pattern.

00:10:53.120 --> 00:10:59.120
So to Jason's point of view, I don't know that I agree with specifically testing,

00:10:59.840 --> 00:11:05.120
but that one important skill that I think underlines testing, which is the ability

00:11:05.120 --> 00:11:15.150
to structurally diagnose, that will be critical. Pausing for Jason to say I'm full of shit.

00:11:15.150 --> 00:11:16.510
Alan will always do that.

00:11:19.120 --> 00:11:25.200
I worked at Bing too, like on the search engine. I don't know if you knew that before I went to,

00:11:25.200 --> 00:11:30.000
I was there during the MSN search and the transition to Bing, which nobody

00:11:30.480 --> 00:11:33.760
wanted the logo logo where for some reason.

00:11:34.480 --> 00:11:35.280
That was before me.

00:11:36.000 --> 00:11:40.240
Yeah. So I totally get that. I hit that personally went through that transition

00:11:40.240 --> 00:11:46.720
from a functional kind of testing perspective to dealing with, yeah, bugs were uninteresting.

00:11:48.800 --> 00:11:52.960
There was a page that we shared internally, I think it was still around, where people could

00:11:52.960 --> 00:11:57.040
file bugs and you could actually do a search inside of Microsoft to do a search and it would

00:11:57.040 --> 00:12:00.240
do the search on Bing and Google. And then you could say A or B, which was better. And then you

00:12:00.240 --> 00:12:05.980
could type in why I don't know if I remember that. I remember that.

00:12:05.980 --> 00:12:08.380
You know, that was whole.

00:12:08.380 --> 00:12:13.180
That was still there. That was still there when I left in at least a couple of years

00:12:13.180 --> 00:12:16.300
afterwards. I haven't, I haven't tried the URL in forever.

00:12:16.300 --> 00:12:21.500
Yeah. So guess why it was built. It was because all these functional engineers at Microsoft wanted

00:12:21.500 --> 00:12:26.780
to file a bug. Here's the search. Here's the link. Fix the code. Right. It was just a honey

00:12:26.780 --> 00:12:30.940
pot so that people would type those things in and we never looked at the data because it

00:12:30.940 --> 00:12:37.420
was not useful. Like, like to what Brent saying, it was actually just a, a DDoS against people

00:12:37.420 --> 00:12:43.600
filing bugs. But what Brent said made me think of something. I'm going to add more fuel to the

00:12:43.600 --> 00:12:48.640
fire here before I forget because I'm old and I forget things is when you talk about how AI is

00:12:48.640 --> 00:12:55.040
going to help testers and help testing. And then Brent's comment around, I forget what he said,

00:12:55.040 --> 00:13:01.970
but there's a wide definition of what testing is. And there's a weird thing that Brent and I

00:13:01.970 --> 00:13:09.810
have talked about here where Brent and I care about quality and the testing we do is in the

00:13:09.810 --> 00:13:19.760
search of quality versus there's a school of folks who are focused on the craft of testing as a,

00:13:19.760 --> 00:13:28.080
as an end result almost. And do you think AI helps which school is AI can be more advantageous

00:13:28.080 --> 00:13:33.840
for the people who just want to just do better testing and for the sake of testing or the people

00:13:33.840 --> 00:13:38.800
who want to help use testing to find higher product quality? That's a leading question. You know,

00:13:38.800 --> 00:13:45.920
the answer is the people that search for quality in the day, but not to the world. And why is

00:13:45.920 --> 00:13:52.080
that? Because the, Michael Brent was saying, like you can't actually just go in and fix,

00:13:52.080 --> 00:13:57.760
rewire the search engine, right? And then it'll be good tomorrow. It's dynamic, it's data driven.

00:13:58.480 --> 00:14:02.800
And we can't possibly understand the nets, right? They're doing all that ranking.

00:14:03.360 --> 00:14:09.040
So the end purpose has to be quality and particularly how do you quantify quality? Like

00:14:09.040 --> 00:14:14.720
you might remember Brent, like there's NDCG, like normalize, just kind of communicate. But

00:14:14.720 --> 00:14:19.520
it's a way to measure, you actually have to quantify quality so that you can feedback the

00:14:19.520 --> 00:14:25.840
AI training systems. This is a better or worse building than yesterday's, right? And so it's,

00:14:25.840 --> 00:14:31.200
you actually instead of saying I have got, like the old world is I've written a hundred test cases,

00:14:31.200 --> 00:14:37.680
right? 94% of them happen to have passed. And these are the ones that I've happened to have

00:14:37.680 --> 00:14:42.560
written today. But that quantification doesn't work in AI. You have to actually measure the

00:14:42.560 --> 00:14:48.400
actual statistically significant quantification of quality. You have to measure it, actually get

00:14:48.400 --> 00:14:53.760
down to like a floating point, right? So yeah, that shift in software, how we build software

00:14:53.760 --> 00:15:00.240
from traditional like Java, C-sharp kind of functional coding to AI means that you focus

00:15:00.240 --> 00:15:04.160
on the end game, which is quality and to figure out how to quantify it. Then you have to figure

00:15:04.160 --> 00:15:09.120
out how to measure it. And you have to figure out how to feed that back into the system.

00:15:09.200 --> 00:15:14.800
So it's very much ends versus the means where traditional software is focused on the means

00:15:14.800 --> 00:15:18.000
to an end. I totally agree with what you're saying.

00:15:18.720 --> 00:15:23.920
So I want to share a little story here is there's nothing to do with AI, maybe AI helps here. So

00:15:24.640 --> 00:15:28.800
I did the thing that you do from time to time, Jason, you don't do because you have

00:15:28.800 --> 00:15:35.120
better things to do in life, where I responded to a threat on where I responded to a threat

00:15:35.120 --> 00:15:39.040
on LinkedIn just because I was bored, not because I felt like they were going to listen to me.

00:15:39.440 --> 00:15:45.040
And it was a thread around someone made some comment about asking customers to test. I see,

00:15:45.040 --> 00:15:48.560
actually, I brought it up because it seemed like three or four different posts where they think that

00:15:49.600 --> 00:15:55.600
continuous delivery or, or no dedicated testers means you're asking customers to test. And by that

00:15:55.600 --> 00:16:00.560
you're meaning you're asking customers to enter bug reports. I just added a point of clarity

00:16:00.560 --> 00:16:07.520
around that because generally, we're not we're getting feedback and data from customers to that

00:16:07.520 --> 00:16:12.240
allows us to understand how they're using the product if they're seeing failures, then adjusting

00:16:12.240 --> 00:16:17.440
either backing out making changes, we can automate a whole bunch of that. But a pause there because I

00:16:17.440 --> 00:16:23.420
think that's an area where I think AI can actually help us out a lot. It can help you

00:16:23.420 --> 00:16:28.780
can we got to define quality, I think we use AI to help define that quality criteria. Here's my

00:16:28.780 --> 00:16:33.180
application, here's what it does help me understand what are some metrics I can monitor

00:16:33.180 --> 00:16:38.780
in production to let us know if this if customers are finding value in this. It can help us zero in

00:16:38.780 --> 00:16:43.500
on the right set of engagement metrics, the right set of error metrics to look at to make sure we're

00:16:43.500 --> 00:16:49.660
building the right product from customer customer value point of view. That said, I jumped in and

00:16:49.660 --> 00:16:55.360
said that stuff and if somebody had the most interesting answer, he said, when we get into

00:16:55.360 --> 00:16:59.920
using engagement metrics to evaluate a feature, we're talking about software from a product

00:16:59.920 --> 00:17:06.910
standpoint. True. What I what I'm missing there is, and I'm way off in the weeds here before I get

00:17:06.910 --> 00:17:12.830
the actual question here. Because the product standpoint, customers don't want well tested

00:17:12.830 --> 00:17:18.030
software. They want I gave a talk of this like 20 years ago, I had this like fake box of software

00:17:18.030 --> 00:17:23.390
saying 90% code coverage over 97% of tests passed. Those aren't the bullet points you put

00:17:23.390 --> 00:17:28.670
on the box. The bullet points on the box are the value you give people. So yeah, from core for

00:17:28.670 --> 00:17:33.820
quality perspective, we need to think about things from a product perspective. And then

00:17:33.820 --> 00:17:39.260
Brent, you'll love this from principle number one, they said testing is about more than evaluating

00:17:39.260 --> 00:17:43.900
the profitability of a feature. It's about finding all the ways the software could be used

00:17:43.900 --> 00:17:47.580
that result in the company losing money due to user attrition or reputational damage.

00:17:48.220 --> 00:17:52.860
It's the last line of defense before the company does something stupid they could have prevented.

00:17:53.740 --> 00:17:57.180
So going back to something Brett and I had said, I don't think this is a test

00:17:57.260 --> 00:18:01.180
responsibility functional correctness is a responsibility of the developer.

00:18:01.860 --> 00:18:07.300
So what I understand is there's a shift here. And I don't care if the shift happens goes back to

00:18:07.300 --> 00:18:11.620
your also your post about the late adopters. There's gonna be people testing last. Hey,

00:18:11.620 --> 00:18:17.540
Brent, you get a cat? I've had a cat. She has decided that it is time for

00:18:17.540 --> 00:18:23.700
patents. What I want to get an idea because I don't know how I have a good idea how we'd

00:18:23.700 --> 00:18:29.220
use AI to help define those those metrics at the very beginning. But how do you think we can use

00:18:29.220 --> 00:18:33.380
AI to make sure that we're testing the right things? That's the point of question when I get

00:18:33.380 --> 00:18:38.580
to I took 20 minutes to ask this question. We in test I've been doing this long enough time to

00:18:38.580 --> 00:18:43.940
know that a lot of the time, and I read between the lines in this reply, it's there to we over

00:18:43.940 --> 00:18:48.900
test, we test too much, we test things that customers will actually never do. We spend a

00:18:48.980 --> 00:18:54.500
lot of time trying to hold products up because we find some edge case that's actually never going

00:18:54.500 --> 00:18:59.060
to be seen. And these are smart testers doing this stuff. They just don't know when to stop.

00:19:00.260 --> 00:19:05.460
How can we use AI to optimize like you talked about making manual testers better? How can we

00:19:05.460 --> 00:19:12.020
use AI to optimize that test selection? So we're testing just enough to make sure that we're

00:19:12.020 --> 00:19:17.700
delivering value to customers? I think it goes back to incentives, like management incentives,

00:19:18.420 --> 00:19:24.020
personal goals and incentives like so testers are rewarded for creating test cases,

00:19:24.740 --> 00:19:30.580
and having dashboards. So they got to help more. They're not as closely tied in with

00:19:31.380 --> 00:19:36.100
the business or product or even user satisfaction or happiness, even though they claim to be

00:19:36.100 --> 00:19:42.260
emulating it. There's no real tie to that in money or really rewards or recognition. So I think

00:19:42.980 --> 00:19:46.980
fundamentally, if the changes incentives for testers to agree with your premise,

00:19:46.980 --> 00:19:50.580
and I think the only way to change it is to change their incentives. But I don't think that's

00:19:50.580 --> 00:19:56.100
possible. Adding all that, I think so it goes, what do you say it's back to developers and product

00:19:56.100 --> 00:20:04.500
managers that really need to own that ultimately. Because I don't think testers can or will adapt.

00:20:05.060 --> 00:20:11.300
And specifically, like you're saying, I think it's all going toward, I forget the Microsoft

00:20:11.300 --> 00:20:15.700
E, Microsoft speak term for it, but it's analytics, right? What is it, Brent? What's

00:20:15.700 --> 00:20:19.140
the catchphrase right now? What do you use at Microsoft? It's not instrumentation. It's

00:20:19.780 --> 00:20:24.900
telemetry. So I think it's all about telemetry. And I think literally, I don't know if you guys

00:20:24.900 --> 00:20:28.980
have followed this, but there's open telemetry. So specifically how I can help that there's new

00:20:28.980 --> 00:20:34.500
open telemetry protocol. And that means that all these different, just so people are listening,

00:20:34.500 --> 00:20:40.260
though, like it's used to be like you purchase Splunk or you purchase some specific vendors'

00:20:40.260 --> 00:20:45.620
software and you log to it, and then they render it back to you and do analytics and alerting

00:20:45.620 --> 00:20:49.300
and warning and like New Relic and these things. But they've standardized that layer. So I think

00:20:49.300 --> 00:20:53.220
what's finally now that there's a standardization in that layer, I think the vendors didn't really

00:20:53.220 --> 00:20:57.860
want to do it. They're kind of being dragged into it. But now there's a standardization that layer,

00:20:57.860 --> 00:21:04.020
there's a standard scheme or schema for all that telemetry data. And now that means that you can

00:21:04.020 --> 00:21:12.420
do not just can you write a single kind of AI analytics thing against everyone's data,

00:21:12.420 --> 00:21:18.260
but that you can now compare data. So you can compare one coffee shops websites with another

00:21:18.260 --> 00:21:23.140
coffee shops websites data. Because the problem is baselining. So you can have alerts, but like you're

00:21:23.140 --> 00:21:26.980
saying, is there a bug? Is it important to the business? Does it cause drama? Is it ever going

00:21:26.980 --> 00:21:30.900
to be encountered again? Is it a one-off? And that's where I think AI can do the analytics,

00:21:30.900 --> 00:21:37.220
but particularly if it has access to the data from other similar sites and historical data.

00:21:37.220 --> 00:21:40.900
So I think open telemetry will help open that up a bit because it will have common tools to be

00:21:40.900 --> 00:21:45.780
more incentive to build common tools for analytics. And then you'll be able to share

00:21:45.780 --> 00:21:51.140
kind of that summarize data across these different verticals to get a baseline of quality.

00:21:51.140 --> 00:21:57.300
Open telemetry does a fantastic job in terms of if nothing else, data democratization.

00:21:58.080 --> 00:22:04.400
There is a couple of projects that I am working on within Microsoft today that leverage open

00:22:04.400 --> 00:22:11.840
telemetry. And it's just, I can't wait for that to finish landing, because a big part of my

00:22:11.840 --> 00:22:19.440
effort is often just data cleaning or conforming to schema. And I'm like, Oh, it will not at all

00:22:19.440 --> 00:22:23.120
make me upset if that part of my team's job is just eliminated.

00:22:23.120 --> 00:22:26.240
Right. And even the smart stuff, right and more value. Yep.

00:22:26.240 --> 00:22:26.480
Right.

00:22:27.460 --> 00:22:30.740
I want to double down on my comment from a few minutes ago listening to your talk Jason and

00:22:30.820 --> 00:22:36.740
YouTube rant is that I think at Microsoft we had written so much telemetry and there was so much

00:22:36.740 --> 00:22:42.900
internal knowledge that just writing good telemetry or reasonably good telemetry was common. I'm sure

00:22:42.900 --> 00:22:47.860
it was the same at Google. What I've discovered since then it's difficult for companies to learn

00:22:47.860 --> 00:22:52.260
like there's no guide. I guess there are guidebooks. They don't read them. They're not very

00:22:52.260 --> 00:22:56.900
good at figuring out what to measure and how to look at it. I think that's a great place for it.

00:22:56.900 --> 00:23:05.840
I think just that definition if it's hard, but it's teachable, I think AI can help bridge that gap.

00:23:05.840 --> 00:23:09.040
I totally agree. And this one, but I think it feels in the category still of like,

00:23:09.040 --> 00:23:13.200
we hand wave and AI goes here and then something magic comes out. But I think

00:23:14.080 --> 00:23:18.320
that's the feeling on a lot of AI tools. It's just magic. It's hard. Let's use AI.

00:23:18.320 --> 00:23:18.880
It'll get done.

00:23:18.880 --> 00:23:22.640
It just be magically exactly. And Gartner will write some charts about it. Actually,

00:23:23.280 --> 00:23:28.720
add double down real quick. There's real data. I did some biz dev work with one of those analytics

00:23:28.720 --> 00:23:33.600
companies. I guess you should be anonymous. But I went there and I talked to them about their

00:23:33.600 --> 00:23:39.680
dashboards for their telemetry analytics. And they said, and they make their worth billions of

00:23:39.680 --> 00:23:44.960
dollars, but they said, no one looks at their dashboards. And so they work because it's not

00:23:44.960 --> 00:23:49.680
actionable and they don't know if it's good or bad. So you have a chart wiggling around

00:23:50.480 --> 00:23:53.920
over time. But you don't know what the right thresholds are, like you're saying,

00:23:53.920 --> 00:23:59.440
Alan. No one knows how to set that. No one knows what the high water marks, low water marks should

00:23:59.440 --> 00:24:04.400
be. And if it's good enough. But I think that that's kind of what back to Brent saying,

00:24:04.400 --> 00:24:09.520
if everyone has this common scheme for representing that data, then you can start benchmarking,

00:24:09.520 --> 00:24:14.640
not just against historical timeline series, time series of your own data, but against other

00:24:15.280 --> 00:24:18.960
vendors and other verticals that can be anonymized based on just general purpose

00:24:18.960 --> 00:24:24.880
metrics to see, are you the worst coffee coffee shop website on the planet in terms of

00:24:25.600 --> 00:24:29.760
latency, for example, right? Then you know you should make it better. But I think it's a

00:24:30.960 --> 00:24:36.160
long way to say, I think it also will enable a relative evaluation of whether it's good or bad.

00:24:36.160 --> 00:24:40.720
So you just throw that data in. And it looks at all and says, ah, you're really sucking in this

00:24:40.720 --> 00:24:43.680
area, but you're really doing good in this. Congratulations. Like you don't have a lot of

00:24:43.680 --> 00:24:48.320
crashes in production in the JavaScript, but you have a lot of latency compared to everyone's

00:24:48.320 --> 00:24:52.960
slow loading pitch. So then people can know what to do with those. Those charts are finally

00:24:52.960 --> 00:24:57.120
actionable. I think that might come with open telemetry with a combination of some

00:24:57.120 --> 00:25:04.000
some analytics and the IML. It will. And one of the things like years ago, Alan and I

00:25:04.640 --> 00:25:11.760
had a long series of discussions around dashboards and KPIs. And it was right when we were kind of

00:25:11.760 --> 00:25:18.080
in our honeymoon phase of our love over Eric Reese. And I'll just say like, if you're

00:25:18.080 --> 00:25:22.400
listening to this podcast and you don't know the difference between actionable and vanity metrics,

00:25:22.960 --> 00:25:29.680
pick up Eric Reese's book. Understand that because that's stage one before you even begin to kind

00:25:29.680 --> 00:25:34.080
of go down the path that Jason saw. Also, if you read the book, you'll see where Brett and I

00:25:34.080 --> 00:25:39.680
stole most of our ideas from. A good portion. I mean, I stole from the Pop and Dykes. I stole from

00:25:40.560 --> 00:25:52.960
Leffingwell. And I have shared on the screen, right, to the point of I'm using Jason's

00:25:54.160 --> 00:25:57.520
listeners will need to imagine there's a screen in front of them.

00:25:57.520 --> 00:26:07.440
Yeah, so I went to Jason's expert tester spin off of chat GPT. I don't actually know what that

00:26:07.520 --> 00:26:11.360
should actually be called, but we've talked about this before.

00:26:11.360 --> 00:26:13.200
And it's super cool.

00:26:13.200 --> 00:26:21.120
Yeah. And I'm like, okay, if so not only did I ask it to sort of generate a KPI to evaluate the

00:26:21.120 --> 00:26:27.280
output of LOM, I didn't even tell it the context. And I said, do it as if you are Alan Page.

00:26:27.920 --> 00:26:32.160
And I just scan through it. I'm not going to board our audience on this, but I scan through it. And

00:26:32.240 --> 00:26:38.160
I'm like, all right, some of them, I think you're reasonable. Like it gave a long list that I do

00:26:38.160 --> 00:26:45.120
think Alan, like the categories, I think are definitely Alan. All right. Even includes

00:26:45.120 --> 00:26:51.520
diversity and inclusivity. Now, whether or not the actual measures, right, it, I think it did a

00:26:51.520 --> 00:26:59.200
reasonable job of not only saying what to measure, but the implementation. Now, I only scan through

00:26:59.200 --> 00:27:05.680
it. And this is a problem I face on a daily basis. So I'll go back and read there and go,

00:27:05.680 --> 00:27:12.000
okay, well, well, Alan LLM actually helped me unlock a solution to a problem I'm chasing.

00:27:12.670 --> 00:27:19.950
But yeah, I think that direction is, is, is kind of heading that way. The thing is,

00:27:21.780 --> 00:27:27.700
I'm trying to pair this to what we talked about at the very beginning, Jason's hypothesis that

00:27:27.700 --> 00:27:36.910
these experts will come back. And Jason, does that not potentially contradict? Or how do you see this

00:27:36.910 --> 00:27:44.560
happening at the same time of sort of the AI first? Because the way I see those people coming back,

00:27:44.560 --> 00:27:51.040
in my mind, it would be what they call the centaurs. It's basically those people working

00:27:51.040 --> 00:27:58.240
alongside LLM are going to nail this problem for us. Whereas you're saying that AI first.

00:27:59.120 --> 00:28:02.960
So what is the mechanics of what you're doing right now with that GPT is,

00:28:03.920 --> 00:28:10.720
imagine you had the standard open telemetry was more, you know, tactics, but this part is so

00:28:10.720 --> 00:28:15.840
imagine you have your JSON blob of your high level open telemetry metrics, right? And you just,

00:28:15.840 --> 00:28:19.200
you pass it to this bot or similar bot and the bot can come back and say,

00:28:19.360 --> 00:28:23.600
you know, oh, for a coffee shop, you tell it, this is a coffee shop. These are my core metrics.

00:28:23.600 --> 00:28:27.360
And it might come back with a reasonable assessment and tell you like what you should

00:28:27.360 --> 00:28:32.880
probably be focusing on. That's kind of an early step of in this process. But guess, guess who

00:28:32.880 --> 00:28:42.000
would be the best person or AI or, or person to analyze that those, like we did with this GPT

00:28:42.960 --> 00:28:51.380
with an emulated Allen, Allen, like, like, this is a very loose approximation of Allen.

00:28:51.380 --> 00:28:56.340
Allen, like if Allen want to spend a few hours, or I'm happy to work with him on it, we could

00:28:56.340 --> 00:29:02.820
build an Allen bot that deeply encodes a lot of his thoughts. And I'll make this bet you're

00:29:02.820 --> 00:29:09.700
ready for this wager. I asked you guys, asked you what kind of mood you wanted me to be in.

00:29:09.700 --> 00:29:18.140
But you had your chance. I will, I will make a bet that not not all my cash, but

00:29:20.780 --> 00:29:26.620
I'll do $1,000, whatever, if you want. But anyway, I'll do a bit. I'll bet that both of you

00:29:27.180 --> 00:29:36.700
are in a QA titled role in 24 months. Because of this broad because, because guess who's best

00:29:36.700 --> 00:29:42.620
at testing that system. It's not the engineer working on Brent's all worked up now, because it's

00:29:42.620 --> 00:29:47.740
a, it's a, it's a ladder thing, but it, but you'll be paid. And I also have fault with

00:29:47.740 --> 00:29:52.380
you'd be paid more than you are today. You'd be caught tomorrow because, because these systems

00:29:52.380 --> 00:29:57.260
are complex, the developers don't know how to test it. But the best thing is the best thing

00:29:57.260 --> 00:30:03.260
to analyze that is, is Allen and Allen bot or a Brent and a Brent bot, not the engineers,

00:30:03.260 --> 00:30:08.800
not the PMs that are out there today and not definitely not the tester. So just, just before

00:30:08.800 --> 00:30:10.880
you, I know you're like your antibodies are already out. Yeah.

00:30:12.960 --> 00:30:18.880
Brent's head's about to shoot off of his body. Yeah. Yeah. I've seen this progression over years,

00:30:18.880 --> 00:30:22.160
by the way, because, because what is the progression of every Microsoft tester,

00:30:22.160 --> 00:30:28.560
like to go into management and then somehow escape, get an escape pod to PM or dev. But

00:30:28.560 --> 00:30:35.360
I'm telling you that just building at Google with the smartest PhDs in search and the best

00:30:35.360 --> 00:30:40.000
engineers in the planet working on the most profitable, insanely profitable software on the

00:30:40.000 --> 00:30:46.160
planet, we're all called software quality engineers. When Microsoft acquired Softimage

00:30:46.720 --> 00:30:50.000
and then ignored it for like 10 years and sold it. Anyway, when they acquired it,

00:30:50.000 --> 00:30:54.880
one of the things I learned about them, this is 25 years ago, that was their leveling system was

00:30:55.600 --> 00:31:04.420
dev, senior dev, principal dev, fellow QA, because they were the systems thinkers at the top who

00:31:04.420 --> 00:31:09.140
knew so much about the system. They were in charge of quality. Now it's a different world

00:31:09.140 --> 00:31:16.210
because I almost, I don't know if QA would be in the title, but I could see a path where it's in

00:31:16.210 --> 00:31:28.000
the role because the for whatever QA test, S debt, quality, whatever, has been so bastardized and beat

00:31:28.000 --> 00:31:33.360
down across the industry. It's not even the right title for that. I, I fully believe there will be

00:31:33.360 --> 00:31:40.080
people doing exactly as you describe and Brenton and or I could very well be part of that. Sort of

00:31:40.080 --> 00:31:45.940
is like the AI is my pet and I'm teaching it how to do this thing for everybody. But I don't

00:31:45.940 --> 00:31:53.620
think we'll be able to call the role a QA role because of how badly it's been just smeared across

00:31:53.620 --> 00:32:01.490
the industry. But I think that's the problem is that that role is emergent. And so if you,

00:32:01.490 --> 00:32:08.000
if you look at the long, this long tail, you look, you integrate over like four, five, six, seven

00:32:08.000 --> 00:32:14.880
years and you assume things don't aren't static. What's going on is that the AI starting to write

00:32:15.360 --> 00:32:20.080
the AI, right? That's starting happening now, whether you want to admit it or not. And so

00:32:20.880 --> 00:32:28.640
guess what, guess what isn't automated? The evaluation, the testing of it, right? So what

00:32:28.640 --> 00:32:34.000
will happen is there'll be Brenton go like, no, I'm still going to be using SQL Server.

00:32:34.160 --> 00:32:43.440
And I don't know, but no, I'm not. I'm going to, I'm going to, I'm going to push back and say,

00:32:43.440 --> 00:32:49.040
no, the AI is also evaluating the AI. Like, I don't think that's a whole.

00:32:51.680 --> 00:32:54.080
How does, how does GPT for evaluate or test it today?

00:32:55.020 --> 00:33:02.780
Oh, by a small army of metrics by, by human beings. But not the, but so you know,

00:33:02.780 --> 00:33:09.900
the language around an AGI, you know, a language around an AGI. And I believe AGI's already exist,

00:33:09.900 --> 00:33:14.220
that this, this stuff is already happening. What happened to you since we talked last,

00:33:14.220 --> 00:33:18.540
Brent? What happened to me? You were telling me that stuff will never be thinking or sent

00:33:18.540 --> 00:33:22.700
the intent. It's a stochastic word. Oh, I'm still on the page that yeah, we need to do

00:33:22.700 --> 00:33:27.340
whatever the hell we can do to prevent this from happening. That part's not changed. But

00:33:28.300 --> 00:33:35.180
just because I'm fighting a, what is the old Greek myth, the poor dude that had to push the boulder

00:33:35.180 --> 00:33:41.100
up the hill for it, just because I'm that guy, yeah, it doesn't mean my opinion on that's changed.

00:33:41.900 --> 00:33:46.940
Right. It's, but so back to the, specifically the title thing, which I think is what the

00:33:46.940 --> 00:33:51.260
revulsion comes from in the, the cathartic. Go ahead and Brent, stop playing with your desk.

00:33:51.260 --> 00:33:57.100
I walk, I thought you told him that already. We know testing was a dirty word in quality.

00:33:57.180 --> 00:34:02.460
It was a dirty word. And this debate's been going back like in 2010, right? But I'm telling you,

00:34:02.460 --> 00:34:06.940
I walked into the Google search building and guess what the titles of the engineers were

00:34:07.890 --> 00:34:12.850
search quality engineers. And we're going to stop there for now. We'll pick it up again

00:34:12.850 --> 00:34:19.330
next week with episode one 94. This has been episode one 93 of the AB testing podcast.

