Howdy, I'm Alan. I'm Brent. And we're here for another episode of AB testing. I think we're at 68. 68. Welcome to episode 68. We are way ahead of schedule. No, we're not. We predicted in the year episode would be I think 70. Yeah, we're not doing anymore. No, this is the last one. I'm divorcing. Meanwhile three people on the internet are going, no, no. Are they? Are they? Are they going? Yeah, okay. Potentially. Potentially. Okay, so how you been? What's new? Anything new and exciting in the Jensen household? It's been a rough week this last week working lots of hours and then to top it all off at around 3 o'clock in the morning woke up with a massive leg cramp. I'm tired. I'm in pain. Okay, so Brent. This should be an amusing episode. Bad mood and we have some things to get through and because Brent's slow we're starting a little late because did you sleep in your office? Did I wake you up when I got here? No, no, I had my text. I was I was having a one-on-one with an employee. You are you are an even earlier riser than me. So you may recall those you'd listen to episode 67. We talked about oh wait, what's new with me? Nothing. Back on the show we did a little role playing not that kind of role playing but Brent took on his former persona of a traditional test manager. Yep. And we had a discussion with Alan modern test manager and we stated our points we dug on each other a little bit and Generated some discussion at least among the three on the one of the three slack channel and on Twitter as well Yeah, there was a lot of I mean a lot more than usual activity on on Twitter when we post a new episode You know, it's not uncommon to have several people Retweet the announcement. No, it's all good. I absolutely love the feedback for me the the slack channels become a just a Fantastic resource for the production of the episodes Yeah, it definitely is a way for us to make sure it's way to connect with our fans No, it's a way for Brett and I to figure out what people like and what people don't like and one thing Where we were confusing Where we were extra confusing and where we just plain sounded stupid a couple things I learned that I mentioned this on the last episode and worth bringing up again is One revelation I had at the end of maybe in the middle of our recording I thought about a lot since then and I don't have an answer yet, but I'll bring it up is Coming up with a better elevator pitch on just what the heck I do and and and the value of a modern test manager and how and expressing the value of what I do to connect testers and set vision and strategy and build my community of quality and testing expert to accelerate the achievement of shippable quality It's visible to those I work with I think if not, I definitely work harder on it but in explaining it to someone off the street, it's a Little bit more difficult when so much of the value I bring Maybe not as much as I think of but I think a lot of value I bring is intangible sort of that player on the team who tries to make people around him better, but I Bet there are some tangible things too. I'm just not this don't come consciously to mind it even within the Definition that we talk about if our job is to accelerate the achievement of shippable quality Right. How do you measure acceleration? Spenometer? Is there a? Unity developed a test speedometer. No That's the interesting thing. So what do you? What are saying that this is rhetorical because I don't know the answers But what are some things that you can measure to tell if you're accelerating and I actually I think this is Going back to Doug Hubbard how to measure anything. I think it's a measurable thing, but it's It would take some time and experiments figure out which things are the right things and which things could are more or less likely to be gamed, but It's you can Maybe even before you have the tangible measurements on that you certainly can Feel that it's apparent that we're accelerating the ship the shipment of achievable quality Which is a whole new thing. Yeah Accelerating quality you can tell when that's happening on the team if you you see things happening, but It'll take me all come up with to come up with and to figure out if I need to measure specific things for that Well, first off, I think you do you as the director of the the QA organization you are somewhat accountable for the business of QA and Here I literally mean the business side of it the ROI Yeah, we we've we've talked about this before shot QA is in most organizations perceived as a cost Yes, right. Yes, and it's definitely more on that later in the episode. Yeah a deep dive I'm thinking through things like like if we're an accelerant and our goal is to accelerate quality Then in today's world, I think about Lytle's law Yeah, I don't think I know Lytle's law is Lytle. How does it felt? LIDLE? I think it may be little slaw I think it's spelled exactly the same as as Little all right, but it's okay. It's it's one of the ways you measure the productivity of a of a Kanban team, okay, and you a mature Kanban team over time Their work ends up being roughly same sized It is just a phenomenon that ends up happening and As you tighten and tighten your work gets smaller and smaller and then all you're doing is you're measuring The rate at which you start new items. Ah Interesting Kanban Right if this is only in a pure Kanban system where you have whip on I don't want to get today's on an agile episode I think Thinking we know what our episodes are about right? I've learned what they're about as I'm editing and getting ready to post gotcha So there's in a Kanban board you have this thing called whip which stands for work in progress And it's a limit on how many items are allowed to be in that column at any given time It sort of forces you to not forces your team to not multitask Lidle's law is essentially how they figure out When you when you go to a restaurant and they have a wait time Have you ever wondered how they figure it out how long the wait is? That gives so much complexity you got shifts you get you got chefs you may have two you may have three They have a but after a while they learn that they know no, it's actually really easy All you have to measure is the time delta between when you sit people down So that yeah, that doesn't make any sense. So Kanban when you have no no go back go back to the restaurant So okay, what I think you maybe missed a word in there When so, let's say I get to the restaurant and they tell me it's a 20 minute wait for a table. When do they have? When do they have wait times? When there are too many customers for the tables to have available Correct so that everyone inside the restaurant the restaurant 10 tables their their whip is 10 right perfect. So what they do when they seat a Person that means capacity is opened up, right when they seat a person When they seat a family or a bunch of visitors, they're seating them because a capacity is opened up What they do is they measure the time Delta Between when they last sat somebody. Oh, so if it took them if the Person in front of me took 20 minutes to get their table, then I'm gonna take 20 minutes roughly, yeah, okay that and then as they as they I Guess that works on on average, but let's say I have 10 tables and I had five people come in all at five o'clock cuz they wanted to have dinner early Mm-hmm They all got there together and then I had people trickle in over the next Over the next hour and they all take varying times to finish If those still is five people that got there early all finished at the same time And there's a brief period where the wait time is very is accelerated So the whip opened wide up Over time it spaces out But there are moments of burst. Okay, you can I wreck hold on I wreck I wreck man just pointing out that although I agree that it over time and on average that will work It's it's a fallible heuristic. I would call it a heuristic rather than a law because it is fallible So no I will leave it Again, and I'm too tired to go into the math. I will just say it is an estimator For those who understand the Poisson distribution the value that you're gonna select based off of the history is what's known as the Expected value, but it follows the distribution. So it's always going to be if you wanted the waitress to be precise You would ask her for what's known as the expected value plus the confidence interval and then she's gonna spit in my food Probably she's gonna look at you go. What's a confident confidence interval sir? The no actually the good that where restaurants I go they fire back and say it'll be 17 minutes and 30 seconds Well, then 80% confidence rate and then I kiss her on the lips when my wife punches me Trying to wind this back to whatever the hell we were talking about before Silly man, so like a simple way to apply a measure here would be to measure apply land of light of law the main parameter for Poisson distribution is known as lambda and What you're trying to observe is are Are the things that you're doing number one? positively changing lambda mean which would be a measurement of acceleration Alan's smiling am I going way too geeky on this one? He is but I think What's a baby sheep called a lamb? Duh? Oh Man and but then the other thing is in agile particularly in in Kanban one of the the principles is Optimize the whole right so you don't want to just measure how fast your team is efficiently starting new work You also want to measure as they ship it Are we delivering positive or negative results so you need a measure of quality in some regard sir? I'm actually working on a similar problem today is This is a common corporate problem where you want to know Hey is the is support is our support process in general creating happier or unhappier customers Probably next week. I have several different things. I'm going to try to see if there's a correlation because the What we're trying to do is get online a bunch of self-help assets and we want to know okay so we can measure whether or not self-help is actually Causing people to not have to go through the manual process and contact our support team but how do we know is it improving sentiment or not so gonna start looking for correlations between common pain signals like Do they leave the company do they reduce their usage? Don't want to have to resort to surveys surveys are the lowest form of quality data Yeah, how do we get here? Can we go back you asked? You spoke how do we measure? Yeah, whether or not we're accelerating the achievement of shippable quality Well, you know you need a you need a metric around acceleration you need a metric around quality that you are constantly looking at and distrusting to a point That's forcing you to improve the metric. Okay. I want to go a little deeper into some of that discussion, but I think we can just set it up with a mailbag question from the from The slack channel. Okay, and then from there. I have an article came out recently. I'd like to discuss with you. Okay That's the plan here. So mailbag It's been a while since we had a mailbag so There was a nice discussion around the role of the modern tester And then there was a discussion leading up to this that maybe we'll go back to but I'll go ahead and read the the mailbag question Salty says just last week. I heard a developer complaining about how the company was not supporting them because it was Removing a quote testing resource. So they were having to do more testing It seems like I'm not QA mindset and the testing is for load paid grunts mindset can be very much alive still So how do we go about changing that mindset? How do we show the developers that there is value to them in doing their own testing? So it reminded me of I want to jump in here first. I have a story I'm sure I've mentioned a long long time ago, but I worked on Windows CE from when from night No about 2000 the 2004 2005 Which was an embedded version of Windows a real embedded version like super small it could you could boot a OS with a web server and and and camera drivers off of a 1.44 inch floppy which some of our listeners can't even remember what those look like But very small OS. So anyway, I worked on this very small OS I helped Transition and teach that team to write unit tests for their code. This is back in this time Believe it or not. There are many many teams. In fact, most teams at Microsoft did not even write unit tests That was the testers job. I helped I got the team writing unit tests and Many developers came to me privately and asked this is just unit tests. I said hey if we're writing unit tests What is the test team gonna do and? There's a worst part of this story Someone who hadn't seen the light yet Obviously came to me a tester came to me and said hey if the developers writing unit tests, what are we gonna do? Which is a different I could solve that problem a little bit differently but what we did at the time is just show value in all the other kinds of Testing work and quality work we could do the story shift a little bit, but it's the same answer my short answer for the question is Show value in all the other ways we can improve and accelerate quality in the product And there's a laundry list of those which we can go through in a little bit, but I'll let you Elaborate on your answer first. I think there's multiple answers to this question. No, there can be only one No, I mean the the So I've helped I think now There's at least three teams that I've helped go through this this chain and I've heard every Possible I think I've heard every possible pushback from dev the one sad thing about test is Test sometimes by their words and definitely by their actions over and over and over again Proves that we are load-paid grunts. I Didn't bring this up I should have I like a There's a whole bunch of other things that we could have discussed in the modern versus tradition. Oh, yeah This is discussion that was missed but one of the things That that test in the old school really added value to the org Was by being the organizationals the organization's scapegoat We were the ones That I think of a slide deck I saw from Alan a while ago Where tests were the the people following the elephants in the parade? Yeah, I have the sequence of slides I've shown in a few different talks. It show we are the champions of quality. I showed some superheroes and We are the gatekeepers that shows like some video game. They're guarding the gate. I say, you know, who else? Guards make sure that everything is cleaned up to the end I show these guys shoveling crap in a parade of just piles of horse what and no no Organization would ever Explicitly do this, but I've I've often just paid attention to How are things treated? What are the actions that support the words? And the reality is is that a lot of tests their role is is really to be the scapegoat for the organization That's that's why dev values test in this role If if something gets past me, I don't have to be accountable. I can blame test that's that's why one of the questions in the old school that That was important for a lead was to say to be able to Smartly answer why wasn't this found before? Mm-hmm because that that question comes up all the time the accountability test enables the accountability for dev for the quality of their code to Go downstream, but who wouldn't want that I could write I could do whatever I want and I can blame someone else. That's fantastic Right now That's one of the challenges you're gonna work against In in this world now what I did and an Allen story is a little bit different What I did is I joined dev right, yeah, right I I joined dev I created a team that was a mix of dev and test and Quite honestly, I kicked ass because I understood how the system actually worked I understood what our goals were which was velocity and quality and I understood that bug slowed me down Now I was very well noticed as doing things differently very differently But the results that I delivered was also very well noticed I Wrote an article reminds me that I still point people to It's 10 years old but called the one that got away. It's up on sticky minds. Okay about the same thing like It's a true story. I didn't didn't even change the names Nobody knows them. Did you claim that you change the names? I know oh but The story was about they released a product customer had a bug They complained about it our dev director got really pissed off and and and yelled at my boss and I I was Again, I've spent most my career sort of the technical assistant the test directors paraphrase the article you can go read the damn thing but It talks about this culture of blame and how to kind of get out of it and make sure it's a it's about Understanding when you make mistakes, it's about learning and understanding Obviously, you don't want to make bad ones that cost millions of dollars, but people have and they've learned from them There's plenty of anecdotes and stories around that I have not and maybe you have Alan. I have not found In terms of the problem of hey What is test gonna do the regardless of who comes to it or or as the salty gunner asked? You know, how do we influence dev on this front? I think it has to be through action and showing value and and data where it matters I haven't that's what I was to say. I have not found a way of doing it Via words and philosophizing. Absolutely not Now and so there in is this is a catch-22 Right because if you if if you need approval in order to try and you need to try in order to prove You're in a loop now what I've done in the past is I've gone dark I As a manager, I would keep one or two resources my back pocket hide them from my schedules And then I would just call them resources That traditional test manager coming out there perhaps or just tired Brent it's maybe a little both I had kick-ass employees Resources in my mind actually to do a feeble backtrack I was thinking about Capacity on on my team not necessarily actually people but Essentially available work hours. That's alright But I would I would not use them all up and I would use them on on sort of these proof projects It's actually one of the ways that I helped Get agile I did my part to get agile into the company there was multiple different people back in the day. I remember Back when you were right driving Q tech you asked me to come sit on a panel for agile. Mm-hmm. That was very Early on in Microsoft. I don't even call it adoption because Microsoft still hasn't adopted agile wholeheartedly There's us. It's a lot better than it was back in those days But there was certainly certainly there was a lot of questions from the audience were were really concerned about risk and and You knew they well, how do we prove this to management? I'm like look Any sort of change like this humans by nature are are resistant to change We know how to make it work in this model. Yeah, it's not optimal, but we know how to make it work and the way you Break through that is you have to carve off and and I always frame it as tell you what I'm gonna carve off some of my people And I'm going to do a pilot I'll take two people do a pilot for for three months and I'll report back And I think you can go much much smaller than that it can be Just a couple little things you do here and here and there It doesn't have to be people carved off for three months It can be part of a person for a few weeks just to start showing. Oh what you did that? That's that's cool. Let's do more of that So I I don't want to scare anyone to thinking it has to be even that big of an investment but I do think that You need to experiment and pilot and do things in little chunks even if you're not given permission I have I Have blogged around my experience. So I don't want to spend all of our podcast going through it again The the most important thing that That I did from a leadership point of view is I said, all right Tell you what? I'm gonna run my own dev team and I'll do it with testers and I've done this repeatedly the last team I left I helped I started started off that process The guy that's now running it It was a former test manager and he's known for being one of the strongest engineering teams now and but he had to deal with six months of being put down even in that role because He was just a former test manager pretending to be dev Yeah, and he doesn't hear that anymore at all Anyway, I was anything else practical we could suggest on this one Like you can't use words. It's gonna be context-sensitive That's the best the main point you can't and this is a common failure across a lot of changes and we've and without Actually specifically avoiding a deep dive into how to do organizational change Which I'm sure we've talked about before as well Is You just you need to show Examples and people will recognize it and you need to look for one thing Michael Lop on Ranz and her pose blog one thing he does and I do as well as what's called a trickle list This is not stuff that goes on my combine board because not stuff that ever gets done But it's stuff I need to do consistently One of the and it can be things like Meet with dev dev directors and managers. It's like I don't have specific meetings But I make sure that like once or twice a week I take some time to do a drive-by or a slack chat and check in for 10 or 15 minutes things I need to do continuously and if I don't do for a while I need to notice one of the things may be on there is like show value from QA there's some good things happening I haven't shared to show to show the value of like some tools some process some Data that represents how we are accelerating the achievement of quality If I am going to convince people of or I feel like I need to convince people of that value I need to make sure I find things to share frequently and if I'm not finding things to share Make sure that I'm thinking about that as well. I would Just think rethinking the answer piggybacking off of what you just said. There's another cash 22 How do you convince management to do this? Right, whatever you do if you're gonna start with words You're gonna have to align it to something that the business is concerned with nowadays Speed is something quality is another Thing there's actually a list the big seven Things for a business and it'll be like growth revenue profit efficiency blah blah blah you can look it up the Critical thing I think that that were I in that role today. I would say okay I would talk to to my executives and I say look this is what I'm gonna do you have all of these resources and It only takes a few seconds to realize that It is no longer the best practice If you don't trust me there are I mean this is not like it was Microsoft ten years ago where there was so many companies There were so few companies that that had taken the risk and moved to agile now It's all over you don't have you don't have to do these arguments like I did back in the day Yeah, but I don't know if as many of Again, I don't spend so much time trying to convince Those above me that what I'm doing is the right thing. I just do And and and later they go oh, yeah, of course you're doing the right I think that's still better But I'm trying to come up with what would be my best verbal argument on this one and if I were in your raw I'd say here's this is what I'm gonna do. I'm gonna take a portion of my resources and What I'm going to do is I'm gonna have them spend their time not on doing unit testing But making it friction free for dev to do their own unit testing. Yeah, and that's accelerating the right I'm going I'm going to make it easier and easier for dev to do that's exactly And that is exactly what I'd rather have my team do than write those tests themselves. The second thing I'm going to do is I'm gonna do hands-on Coaching and I'm gonna I'm gonna boost up The the skill sets of your dev team the third thing I'm gonna do is I'm gonna boost up the development skills of your test team so I'm gonna convert your developers into Specializing generalists and I'm gonna convert your testers and do specializing generalists. I'm gonna come after it a different way and I'm gonna take point on Leading the test side of the house as an engineering team. Let's start talking about what features my team works on This is an example of giving people what they need versus what they want Which is another great leadership and change organization skill if your manager were to come to you and say okay You need to I need your team to give me test plans and write tests write all the tests of the dev team can get Work on their features. I hear what you're saying. I Understand we need to have tests make sure everything's done I think I'm gonna try something a little different and I and here's why it's gonna work and then go into your thing Right and then they get with it and they go. Oh, then you go and you go kid Let's just do it for a week. I'm gonna have this Target group one one feature teams gonna do it that way and let's just see how it goes if my way fails If my way fails, we'll go back and do it your way, but I think it's gonna be better in the long run You've hired me to be your manager for this QA team. I I And to own quality air quote. I think this will work and of course all listeners go Well, of course it'll work dub, but but you but again pointing here bosses Brent and I included sometimes have to I think we're a little more open than most but you know what I get people they're like This is the way I've always done it. Let me show you a different way now and Really when they say this is the way I've always done it Right. What's the value in that statement? It's it's like I know this way is of no risk right, so just realize that what you're what you're representing is is is Some risk to them and you do just got to be proactive in communicating Now that's when you talk with executives when you talk with dev you're gonna have to do it a different angle because again, they value you as the person they blame later Mm-hmm right back to that codependency. We've talked about great good discussion I want to tie that into something again was shared on our slack group and an article from Penaya called the 2017 state of functional testing report Which I've read a couple times now highlighted a few things. I just want to kind of bring it up in context of this traditional versus modern Discussion Brent's taking it from me. No, I I did not bring my own copy So I want to share So I'm not gonna read the whole thing It's a survey of people at 150 companies I think largely IT shops versus people shipping software to customers, but maybe actually maybe a combination Based based on the answers, but I both think that makes a relevant difference Maybe it doesn't I don't know how they chose the companies I thought the the insights were both telling and some good some WTF but a few points I wanted to bring up some that are interesting and reflective of just Testing as we've been talking about in general and some that reflect on this modern versus traditional argument, so I I scan the art the article and I do think It's a fantastic piece of work is it's one of those things you definitely need to read with a a critical eye and apply your own Don't take everything at face value read and see what and try and read the intent behind what was there but I definitely think this this document in an abstract is Saying that the stuff that we've been talking about a what's coming next for test is in fact what's coming next for test All right. I'm gonna go through some things. I I circled and just get your comment on them It's going to be a little disjointed because it has like a section then a recap then a section then a recap And then I think it's a little overwritten Like someone took a little bit white papers of the source Yeah, so here's the first thing I circled is test automation is coveted by all but still too costly Even for regression testing to implement without risk Agree coveted by all All except except a few people No, no test automate. I mean we have as a whole and test we haven't moved out of the world where where Test automation isn't the holy grail like and Large companies like having an automated test suite and automated integration suite is the only way to scale. Yeah. No, I know I say it's right but the costly regression I mean what the problem is is that there isn't a lot of intelligence around test selection like if Some of the comments on the slack channel regarding the last episode around how can test start getting into ML Test selection is absolutely an obvious ML problem. Mm-hmm. Yeah, and we should deep dive into that later But just a sentence later in the same paragraph something very cool It is expected by 31 percent of participants that QA and developers roles will eventually merge Yeah, and that is I love that because I think for everyone who sees that that's the path there are at this stage Anecdotally even on Twitter which people actually pay attention to testing much less So it's interesting that executives definitely see that that move happening I don't think 31% of testers or developers or managers overall in the industry See that yet No, but and anyone some will dig in their heels and fight it No, we must have our separate discipline to make sure that we are the checks and balances and gatekeepers for quality And it really what they are doing is their their risk adverse and Going on here again. These are a lot of things we're going to agree with some and if you'll get there'll be a few WTFs In there, but so 31% like I would I would say like 10 years ago. That would probably have been like 3% Yes, yes, right. I definitely think that's on the rise and how about this and the question is is wins the tipping point I bet you soon. I bet it's within the next three years that it I think it is over. I think it is almost half 47% of IT leaders surveyed believe that their tests do not accurately reflect real-life production Scenarios. Yep, and that number is down because I think ten years ago people thought like 90% Yeah, we have our int environment, which is an exact replication of production People are getting it. They go. Oh, yeah, whatever we do internally. It doesn't match the real world I had a conversation with a dev manager here like This is why the testing and production stuff we talked about is way more critical when you ship when you ship a product and you test it in a clean room environment and Then you realize when you shipped it to prod it performs entirely different and the main reason why is when you go to prod It's exactly clean for a microsecond. Yes Because during the Coase life is going to be living in a dirty dirty dirty world if you'd like us to elaborate and give you a hundred examples of The same sort of thing and what things fail in production that work just fine up until then we can do a whole episode Just sharing stories. Yeah Moving on in fact when asked about their top test execution challenges most testing leaders reported tools that are Unfriendly to non-technical testers. Yep So I I pushed my button because of the non technical tester reference But I guess they exist or they maybe not maybe they're labeled that but they're not really if You want to leverage manual labor like technical people are expensive Like the route that you're talking about is like look I would rather have one high paid tester on my team than ten load paid ones Right. Well these guys are they're saying we want to do the opposite strategy. That's fine I'm gonna fly through a few more quotes for you This one is I'm worried that the number so low two out of three testing leaders surveyed Stated that QA and testing initiatives are highly important to their organization's overall strategy There's my WTF like uh, what wouldn't it be more? What about that third? They don't think it's highly important I thought it was extremely important. I didn't read that one. I I That's in the testing is no longer an afterthought section. Oh Okay, cuz I I hear that stat with the cynical eye. Yeah, I'm like wait The testing leader has told you that his QA initiatives are important to the business. Call me shocked. Yeah Well, I read it as two-thirds really at also in the not surprising category as I said as could be expected test automation is not everyone's wish list as 47% of test leaders predict that continuous delivery and agile adoption will lead to test automation for the majority of tests Yeah, yeah There's a section that says business and IT must converge and this is part of I think acceleration and and I Think this is a critical section If it's a section that I think they're talking about It is about connecting business requirements business understanding with the testing effort Yes that actually my summation of this section is it is it's describing the need for modern testers To directly associate their work to business business level outcomes Yeah, this is a section that it's overwhelming that creating a better customer experience is critical for for QA and testing Yes enabling continuous delivery. This is a it is it is not our job to get to a hundred percent pass rate No, it is our job to Grow CSAT or customer satisfaction by 6% Yeah, I wrote in this my notes on this page of the article is all around Accelerating. Yeah Again, this is a section that says the test that did not accurately reflect real-life production scenarios at the regression suite is Hard to create and maintain One of the comments that came back in lower percentage was not enough developers for test automation Which again without having some context around that may not know what they mean So I'm not gonna comment too deeply on that. It's more of an investment And again coming back to automation is too costly. I think I think the not enough developers thing for test automation kind of reminds me of like sort of the The old-school s-tet problem we had all the time. How do we? Take some rockstar coders and Seduce them into an s-tet role instead of a dev role. Mm-hmm I think I think that will change over time because I do firmly think it's a mistake And I think a couple things happen to one is that as we mentioned just a minute ago That it gets easier and easier. Maybe we're already there. It's easy to write tests now. There are testing frameworks for all over the place it's Some set of tests and I think we'll begin to apply as we mentioned before Machine learning and some and some computer generated tests to help cover additional testing. Yeah, and not just based on the code but based on Customer patterns and tying those all together. I think in the next 10 years I think ML is gonna do most of the testing quite honestly the last section is on the Untapped potential on test management and automation and overall there's again. There's a few WTF moments. There's a revealing graph. I wrote yuck shows it 54% among these people surveyed of their functional testing is done manually. What's the point they're trying to make? like 54% doesn't surprise me but That seems quite high to me. Has it gone down? Is it going? That's the thing I I bet that still improved from where it was a few years ago Where we're at now the state of the Union is not where I think it should be. I Know I agree, but I think the point of this argument is is essentially Testing is undergoing a worldwide transformation Yes. Yes, and it's clear. It's interesting because we're in some silos of even you with within a company of Teams that are they get it and they're advanced and they're trying to even move even faster but you know for just from conversations on Twitter and Reading articles on the internet a lot of there are many many more that just don't get it so what I like in reading this article is that We're seeing that there are more people who actually get it than I kind of thought there were which is good We're reaching that tipping point where where the traditional tester the traditional test model is Going to start fading more rapidly it is and we've explained this right? it's because the the the business landscape has changed and Where companies realize that they have all of these resources on testing that aren't necessarily needed sticking to the old model Is a Darwinistic risk? Meaning yeah, right. Yeah, and then I'm gonna still part of one paragraph which reflects some of our discussion Test cases based on business knowledge of the relevant cases to automate is the way forward say yeah So there's some pretty good insight in here. Normally. I hate these survey based. This is confirmation bias I may be because normally I hate these survey based articles, but this one there's a few like head knotters in here It's I'll put a link up to you have to it's one of those places One of those reports where you give that to give them their email address to get the report Ball put a link up for it if you want to check it out yourself like I said it's a little overwritten and a little bombastic but Still I think an interesting read and worth Maybe use your throwaway email address you all have one if you don't you gotta have that throw away You just sign up for shit with right right if you don't have one then just go to you know Google and create another one. Yeah, I recommend Google for that one so that Microsoft doesn't have to pay for everybody's crappy Advertisements only email addresses Anyway, I think that I think the nutshell on this one is yeah, this is an interesting doc I would not hold it as you know the holy truth nothing in fact nothing you read or hear should you ever hold us the holy truth, but I I Would take it seriously, and I think I like it and again This is confirmation bias flying through and I recognize that it's that double comfort. I'm confirming confirmation bias what happens there I think I just exploded You're running late for a meeting but it proves to me that the direction that we see and the direction that many of our listeners see is I Get some validation in that because I think it's not just me in my little world and in fact I meet people who go well I'm in QA, but it's not like everyone else's QA then we have a discussion go. Oh, yeah, we're on the same page Welcome welcome to the world. Yeah. Yeah, yeah, and I've seen that more and more and it's kind of fantastic. I I see the dots connecting. I do think that there's a risk of confirmation bias. I wouldn't use this I Would I use this as hey? this survey seems to see a Similar future as to what I see and it does sort of See a similar timeline, I think yep, and the future so bright we got to wear shades Yeah, and less you know you can You're holding on with white knuckles to 1990s. Yeah, and there are those out there No time to dig into today, but I read another article Recently of for it seems like every one of these I read we just talked about there's another two articles of people holding on tight to traditional testing Yeah, it's I've been in both I Think the biggest problem is when when people are having these polarized arguments They really from where they stand they really can't see where the other person is coming from absolutely I've been in both that last week, and I I I remember the first day I was doing the Kanban, and I'm like shipping things in small little packets that seems so odd to me But then the first day I shipped something and I brought the product on the floor. I'm like oh my god All I have to do is spend 15 minutes and revert this Whereas every other time in the old-school world it was weeks of trying to figure out what the hell the problem was Yeah, yeah, it's a good world. It is all right. I'm gonna book out of here And I'm not and I'm not Brent. I'm Alan. I'm Brent. See ya 
