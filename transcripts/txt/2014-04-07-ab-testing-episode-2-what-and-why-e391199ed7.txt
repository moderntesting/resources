Hey, I'm Alan. And I'm Brent. I held an event, hosted an event at Microsoft two days ago for about 35 senior quality and test people about leading change. And Brent, you were at that event. So what was your big takeaway from that? Well, so first off, I thought that event was fantastic, Alan. Thank you for putting it together. Golf clap. The second thing I would say that I walked away with, I was surprised at the audience. Not the audience per se. The audience was great. But I was surprised at how small the audience was. That actually concerns me. You know, elaborate because I have all kinds of comments. I don't know where to start. No. So the way I see it is we've seen these similar events. That Alan puts together on a monthly basis. And we've seen times where the room is packed. And then we see times where the room is packed with crickets. This time around, I think it's one of the most important topics that to me doesn't seem as resonating with the populace at large. I have another theory. You know, a lot of times when we pack the room, we get a great speaker to come in and people just come listen. They don't have to. They don't have to participate and get involved and, you know, put some skin in the game. When we do an event like this, it's largely discussion based. We get the people there who want to get something out of it. We get the people that embrace learning, have a thirst for learning and want to get some new ideas. And they understand, you know, one of the things that I believe in a lot, that ideas come from ideas, other ideas getting together. And the people in that room understand that. But not everybody in any community gets that. If you look at, you know, Wikipedia, for example, is a great story. You know, 1% and I'm not looking any of this crap up, but like 1% of the users actually contribute and everybody else kind of just consumes. I think with a lot of educational or community opportunities in both in Microsoft and outside of Microsoft, there are people that want to actively participate and put some skin in the game. Then there's a larger majority that just want to consume whatever is put out. Yeah, no, I see that as well. The topic. For last for last week was leading change. And how could the people in the room help to contribute that? What problems they saw? One of the problems that I see is that there's far too few people in that room, given everyone is in a panic, maybe near panic around. What does this mean? What does this mean for me? What does this mean for the team? What does it mean for the company? I think. I think one of the things that will be helpful is for us to figure out, well, what's what's blocking? What is the resistance to getting people to lead themselves? A couple of comments there. One is, you know, there's this huge catch 22, this this chicken and egg problem. People, they need to get they need to get some more ideas and learn, but they're so busy dealing with the stuff they don't have a chance to learn about and deal with. They can't actually ever get a chance to learn how to deal with it. I had a discussion just this last week, just two days ago with an individual in one of the teams who is all excited about going to the data science world and is actually considering leaving their team because they are in one of the we'll call it the execution entrenched. They're considering leaving their team just to have the ability to explore this option, you know, as interesting because data is becoming so important and, you know, data science is obviously a direction that some testers will move in, but it reminds me, do you know what a data scientist is? No, it's a statistician that lives in Silicon Valley. I think there's a couple over in Amazon. Yeah, but the idea is, yes. I think as I think we talked about last time, a lot of testers of Microsoft and a lot of the test approach and quality approach of Microsoft is shifting from just executing a bunch of tests and looking at a test pass rate and going, oh, and to more of looking at real data from customers and making decisions based on that. And both business intelligence, you know, how many users downloaded this thing and doing some building statistical models and making predictions based on what we know on a variety of data sources, which is kind of fun. It's it's. It's a total blast for for those of us who who are in the I'll say the ivory tower currently and get to play around in this playground. Well, you know, it's funny, you know, Brent and I are both people who love to learn new things. And I'm taking a statistical analysis and data inference course on Coursera. And I was sitting at my desk the other night and I looked down at this notepad on my in front of me and there are some math equations written. And, you know, I don't they looked like real math equations. I can't. I can't even remember what I was trying to figure out. But I was it was it was just I thought, oh, my gosh, I'm what am I doing? I'm learning math again. So I just recently started up. I'm pursuing my master's in analytics. And one of the first things that I did when I got my first course is I scan through the book just to make sure I did not have to remember how to integrate. All right. Where are we going? Let's get. As you know, Brent and I also are known as. ADD club. And we're talking about leading change. And I think there's it's you're right. You need leaders lead. Right. They're not just it's not just a figurehead in charge. You need to have ideas for getting people through change. So the thing I'm thinking through. So answering my own question around why others aren't showing up is I think, number one, they don't know what the value is and they don't know why. Why it's valuable. We I've seen a lot of messages lately around leaders standing up and saying, hey, this is what we're going to do and it's going to be awesome. And there'll be unicorns and rainbows and free candy for everyone once we do this. But the problem is, I think there's a lot of resistance culturally around going there. And there's a lot of machinations in place, a lot of processes in place around how to get a good review. People don't know why we're doing these changes. They don't know how it's going to affect the review process. There's cultural changes all the way up to, well, all three roles, dev, test and PM, all three roles in engineering, maybe I guess user user to user design. The. I think the key thing is that the leaders are explaining what they want. They're not really explaining how we know we got there, that what what defines success. And they're certainly not explaining why what we did before no longer works. Right. And the why is super important. We talked about the quality day we did a few weeks back in our last podcast. But. The key behind any sort of when you're making any sort of change, whether it's a small change or a big change, but especially with the big change, the better you can convince people of the why or show them why or show them why it's important and why change is needed and why this particular change is will be successful or is a good chance for successful. But getting that why in place is critical. If you, you know, there's a Lewis Carroll quote you use once in a while. What is it? The Lewis Carroll quote is. If you don't know where you're going, then any road will get you there. Perfect. And that's I think a lot of changes is, you know, done that way. And it's awful. So, you know, when I have a vision in mind, no, it's going to know it may change over time, but you need to understand why change is important. And I think that's sort of the piece that's missing in a lot of the failed change management I've been a part of or seen over the years. There's there's. I'll I'll I'll I'll add to that, Alan. I don't know who's the the quote for this. Maybe it's Sun Tzu. I'm not actually certain, but there is a there's a quote that says strategy without tactics is a dream and tactics without strategy is a nightmare. Yeah, that is that is from the the art of war. Right. I believe so. The the the point there or the way I interpret that is that you not only. Need to know what to do, you need to know why and actually more poignant to what we're talking about. If you only know what and not why, as the quote says, that's a nightmare as opposed to knowing why, but not the what. An example I like to share a lot is about a doctor back in the 1850s, Ignaz Semmelweis, who was a maternal doctor. And he discovered through. Intuition based correlation that exploratory medicine. Sure. It wasn't it wasn't a scientific principle, but what he discovered is that every hospital he went to and he was often hired to be the chief doctor. I don't know what their title is. Master doctor. Super Jedi doctor. Jedi. I love that. Jedi doctor master. He discovered that every time he instituted a policy. That forced his his surgeons to wash their hands once they did that at a sustainable pace, the mortality rate of of women who are pregnant went down to below one percent and he saw this over and over and over again and he tried to share it with the community. The community asked him, well, why he didn't know why. In addition to that, the community was indignant at that time. What you're telling me to watch? My hands like how rude is that? It was sort of the perception at that time. This this poor guy ended up dying in an insane asylum that knowing this knowledge and knowing that he was failing to get it dispersed around the community and knowing that that was killing pregnant women drove him crazy. He ended up dying at in the mid 40s in in a insane asylum. He knew what to do, but he didn't know why. So carrying on what you're talking about, what would be an example that you see a lot around? You said a failed child change management. Probably the biggest one is, you know, teams and I've seen this both inside and outside of Microsoft teams struggle to transition to you can't see my air quotes that they struggle to transition to air quote agile lowercase a or uppercase a. They go, oh, we're doing agile. And. And the people on the team that literally go from one step one day having a very predictable model where they're, you know, testing at the end and testing quality in and and then shipping that product the next day. Now we're we're doing this agile thing and I guess we do this and that and they they have scrum and they have these things called sprints and they don't really know how long they are and and they feel like they have to estimate more and they're going great, but they don't know why they don't know what benefit they get from these changes. Now, their reasoning in some cases literally is someone in our management chain heard of this thing and they want to try it. I don't know what it does or how we're doing it, but we're going to figure it out. And guess what? They fail. Ends up being a they end up creating worse software and they go, oh, and their conclusion is agile doesn't work. Let's go back to what we know. So what sort of failures have you seen? You've heard me reference fragile before. I'll leave it at that. And scrum, but we do scrum, but we have. Three month iterations. I heard a team once said we're agile. So you are. I thought, really, you're agile. Yeah, we have three month iterations and we do planning for a month and then coding for a month, then testing for a month. But, uh, OK. I actually a couple of years ago, a buddy came up and talked to me and he's he's been deeply entrenched in the Windows team for a long time. And this was this was still back in the the Grant Georgians. And he said, I don't understand why you are such a proponent for agile, what's the big deal about agile? And then he said something that simultaneously shocked and amused me. He said, Windows agile. I said, what? And he said, yes, we're just slow agile. I remember. Slagel. What is that? Slagel. Slowjel. Oh, I like slowjel. Slowjel. I like fragile better. Trademarked, patented, whatever we claimed. Yeah. Done. Interesting. First off, I felt it was my my my role to indicate that he was wrong. No, but I am very deeply interested in what led you to that conclusion. And he said very quickly. Oh, well, we're. I don't want to be iterative. Oh, that's and you know, that's not the first time I've heard that not, you know, people think and this is I don't want to, like, tell people they're dumb, but agile is much more than iteration. I mean, and also the thing I've gone off on before is, you know, waterfall and agile are not a dichotomy. And in fact, you know, a lot of people throw out agile and waterfall as like, oh, we're not agile. You're waterfall. And, you know, every team I've been on at Microsoft as waterfall. Lee is. They've been in the past. They're really iterative. You know, my very first project 20 years ago, Windows 95. We had, I think we shipped on our 12th milestone and the milestones were anywhere from three to four months. It was a long project, but it was it was iterative. It was slow. And, you know, we tested quality and like nobody's ever tested quality and before it was still a lot done at the end. It wasn't it was, you know, waterfall is truly predictive and we weren't very predictive. We didn't know when we're going to be done. We had an idea when we wanted to ship and we, you know, of course, we didn't hit that date. And I'm sure I don't remember how late we were, but it wasn't too late. But we weren't done testing quality in until we shipped. I want to I want to call you on a word you just use. You said waterfall is predictive. What do you think about that? Well, what do you think about that? I think if you do waterfall as and a lot of poor, poor Winston Royce is, he said in his paper. He said, here's a way you can make software that's not very good. And you should iterate on it a couple of times for it to work. And somebody looked at that picture, went, that's how to make software. Yeah, I so so, yeah, there was I don't remember the name, as Alan just mentioned, but I read that document and I find that so funny. Someone the document that introduced waterfall to the world talks about these gated spaces. It's a serial of processes in terms of how you take the software and phase quality in and the very last paragraph of that document, the guy essentially says, and this sucks. Yeah, we should not do this. Now, you talk about that doctor earlier. If there is a reason for someone to go to die in an insane asylum, it's that guy, but to answer your question in the long way, say the asylum or in a cornfield in Kansas. I. I don't know, I don't know, the poor guy, but waterfall is very predictive. In fact, you don't need to hire testers till the very end because you don't need them. I want to be careful when you say, because there's also a number of folks in the data science world where predictive is about playing out what if scenarios, whereas really, I would say, perhaps a better word for what you're trying to get to is intuitive, where waterfall. It does start. Start off with a series of predictions, and then they spend the next three years, in some cases, keeping their predictions on track, but never reevaluating them. Right. And that is and let's go ahead and move that forward. If you merely iterate, if you, you know, and here's a better example of what I've seen is teams will have sprints. They'll have four week sprints that are regular, but they plan. Six sprints in advance or every sprint in advance. Like, what are you doing that feature work? I'm doing that feature work in sprint eight. Like, that is sort of mixing, you know, sprinter fall, whatever. I don't know what you want to call that, but they're iterating. But it's not, you know, to me, I don't want to be like an agile, like, you know, this is not agile. That's agile. But so I'm going to stop using that word. I will do that shortly. What I want, what I think is a great way to make software is adaptive, where you can. You're changing, you're adapting to the customer, you're adapting what the needs are. I think my favorite thing to my where planning went from, like, the most painful thing I ever did in software to where it's the part I look forward to the most is reprioritizing that backlog every at the beginning of every sprint. I enjoy that. It's fun. I feel like I'm always working on the most important thing. Yes. Brent, just for those of you not watching the video feed, it doesn't exist. Brent just smiled and pointed his. Finger at me in a vigorous manner. Yes. Indicating that finally, Alan has said something super smart. For those of us keeping track, this is three this year. Is that calendar year or fiscal year? Fiscal. Okay. The. So one of the popular things that have been asked of me lately, and I've done this 10 times in the last three months, is I've gone into teams. And. Taught them how my team executes, which is it's a hybrid model of multiple different agile tools. It's it's fairly successful. But one of the first things that I start off with every time is I compare waterfall and agile. And I say, here's a simple litmus test. And waterfall is probably not the right right word, but it resonates with people. So, Alan, I don't care. I talk about waterfall. Really, it's key goal. If you look at the actions and the behaviors of what everyone is doing and aggregated up to a single question, the question that waterfall is constantly trying to ask is, is the plan on track? They don't evaluate whether or not that first initiative predictive plan is really the right plan. Eric Reeves talks about a build, measure, learn loop. And often I'll draw on on the whiteboard. Build. Measure, learn, circle them and say, this is what waterfall does and draw an arrow from from build to measure and then an arrow from measure back to build and leave learn off on its own orphaned. And one of the things that there are several instances, I'm not going to go into specifics today, but there are several instances where we know that these heavily entrenched waterfall organizations. I'm not going to go into specifics today, but there are several instances where we know that things that are going on and that we are doing this on and on are two very different things. And I'm not going to go into specifics today, but I think two key things. examples at Microsoft would would beどう tanto usa isso , en el caso de que la Valerio del آn, por si alguno quien lo piensa, would be windows and and then office. Office. Although I definitely see office forget the changing, I Windows slowly changing estechn folkなんだ,woman slowly changing. raining beds doubles there's examples where they knew six months in advance that this ah, key chains that they were about to release upon the world was hated by the world, but they didn't have the ability to learn and adapt and create a new direction and integrate into the system so you can be primarily implemented while starting to implement processes it sn Originalvisual beans leave office isъ But they didn't have the ability to learn and adapt and create a new direction and integrate that into the process because their primary focus was on, is the plan on track? And we have to keep the plan on track. Agile is more about, is the plan correct? I love the word that Alan just used, adaptive. And one of the things that I've made it my personal mission, every time I hear someone say Agile is about iterations, I immediately stop and I won't let that conversation continue until they recognize that it's not about iteration. The key thing is creating a common shared language. If people aren't going to spend the time deeply understanding the what and the why, then creating a language that is unambiguous. Unambiguous and constructs the right behavior is very helpful. So iteration should be gone, adaptation should be in. Well, and that ties back to, if you really get down to saying, here's why or what we're doing and why we're doing it. If you get people to understand why, I'll ask a question, I know the answer to because I want you to answer it. Why would a team want to use adaptive software engineering processes? The business reason. Or why teams would want to do this. Is, quite honestly, the world operates much faster than the way we've been operating. It's because, if nothing else, survival. We need to have the ability to add value to customers at increased speed. The primary reason why we need to do this is that the switching cost today. The ability for a customer. To go from one company's product to another company's product is almost instantaneous. So if we aren't creating a continuous stream of value, then it's hard for folks to choose to stay on our platform, assets, product, whatever you want to refer to. So the ultimate reason is speed equals money today. It does. And there's a couple. Other things I've read about that recently. I have no sources for these, so look them up yourself. But, you know, 20 years ago, especially even longer ago, but even 20 years ago, the power of marketing to influence someone to buy a product was the most, of all the different influences, was the largest thing. Actual marketing, commercials, sales, magazine ads, etc. But today, it's influencers from the community. It's customers influencing other customers. People ask. They're friends. People go to social media sites to find out what apps they use. And I can think probably a half a dozen times I've gone to Twitter and asked, hey, Tweeps, what's the best tool these days for blah? And they tell me. And I get, you know, that's the marketing. So you need to react to customers quicker. And if you go to that why thing, it's, you know, you can almost play five whys, a little root cause analysis. You know, and no one buys our product. Why? Because they don't like it. Why don't they like it? Because we're making stuff they don't like. Why don't they like it? Why don't they like it? Because they never get a chance to see it until three years after we planned it and put it in front of them. And it's no longer relevant. So in order to iterate, and I'm going to use iteration as a path here. In order to iterate, actually, in order to respond to customers, you need to iterate quicker and adapt. You can't just iterate. Iterating, just looping in circles like a dog chasing its tail. It's fun to watch, but not that exciting. Maybe a very poor metaphor. But the challenge is you. You really need to listen and know when to listen and use the data, going back to data, wisely. You know, there's people often, and there's, I don't just pick on Microsoft, but a lot of times companies think, well, we know what's best for the customer. In fact, I was so annoyed by a product a couple years ago. You know, there was a feature in a product that I didn't like. And so I went to the product's forum and I posted. And some other people said, yeah, we don't like that either. And the response from the product team was, oh, we thought it would be cool or we thought it would be good if we did it this way. I said, you don't get to make that choice. You don't, as the product developer, you don't get to decide what customers like. Customers get to decide what they like. And you need to listen to them. And often they'll fall back on, say, well, the forward quote, if we just listen to customers, they just want a faster horse. You know, yes, you can innovate. But, yes, you can listen to and you need to listen and react to those customers. And you can't do that if you're purely predictive or purely iterative. You need to be able to listen and adapt and change as needed. The difference between your innovation story and I think the specific story that you're referring to is in terms of adding new value and exploring new markets, go ahead. Experiment away. However, when you deploy something, you should absolutely look at the engagement. You should look at the engagement value of what you just deployed and determine whether or not it's enticing customers or upsetting them. The product group coming to you and saying, we think customers should be delighted by this. They're saying that to a customer. No. Henry Ford also said, we will do any color as long as it's black. Right. How long did that last? I don't have my history book. I don't know. No. We don't have all black cars today. Right. The differentiation, customization, and again, switching cost. Right. I know what Alan's referring to. And I know there are hordes of competitors out there for that same paradigm. The switching cost is so fast. Fine. You're not going to help me build quality from my own subject. Point of view. Then I'm going to go to the company who will. I don't care about your intuition. If you've got data that shows, Alan, our data is showing that the majority of people love this thing. Right. Fine. That's a different story. But if it's we and our elite group of think tank PMs have decided that this is what's best. Right. So one of my classes that I. I am taking now is is on how to build information systems of the future. And one of the key pivots that I find fascinating is most companies and governments now are recognizing that pushing empowerment down and enabling a symbiotic relationship between people and the technology and society. Whether it be a large, a small community or a larger community, by creating an efficient knowledge loop amongst all of those assets speeds things up. It helps collaboration. It helps profitability. It helps market discovery. It helps solidify your position in your current market. There's two things that I'd share. One of the there's a there's a key study in there where they talk about. They talk about X-Box and they talk about a integration between X-Box and Comcast, and they talk about how this might have been a strategy against net neutrality. And as I was reading them, like, holy crap, I was the QA guy for the X-Box during that time period. I own the application for the Comcast interaction. So it was kind of. Freaky to see this whole textbook that has a case study around things. My name's not mentioned in it, but around that scenario. The other thing, though, is that I'm learning best practices from other companies. Salesforce, as an example, has just I don't know when they did it, but there's a case study in there around Salesforce, how they are leveraging their customers to populate their backlog. They have they have a public tool. Where our customers could log in, say, we would like this and other customers can come in and vote up and down. Yeah, we've had products. Microsoft have done that through the connect site, which is, I think, a great way to do that. I love that. I love that. Right after X-Box one came out, there was a community site emerged within a week with the same thing, feature requests and votes. We didn't even sponsor that one. I love finding ways to let, you know, go back to XP extreme programming. And, you know, let's get that customer in the room with us, which works if your customer is the guy in payroll from upstairs. But when your customer, when you have a million customers finding a way to aggregate their voice in a way that you can use to make product decisions and to help you adapt is fantastic. This is one of the reasons why crowdsourcing is so key. Like if you're just talking to the one guy upstairs, then you're really relying on his specific knowledge and more than likely his intuition. On the way to go by leveraging the knowledge of the crowd, that's where you can get people to tell you for free, hey, here's a new market you should perhaps explore. Yeah. And it isn't until you look at numbers. How do you know the one guy you talk to isn't the outlier? Or when you talk to three people, how do you know that, you know, you get, you know, two of them say one thing. One says another. It's not a big enough sample to know if, well, are these two outliers? Is that? So you have to make a decision based on that. You need to use some numbers, you know, based on the size of your product and market reach, et cetera, to help you make, to use that, those voices effectively. Yeah, absolutely. There's another example that I think is related to this that also came out of the book. And part of my study is I had to look at key studies of companies. And I just completed this yesterday and said, how, how does Britain, Britain's going to go all digital. They have a huge report in 2009, and they're going to go all digital throughout everything. And they're hugely excited about it because the, there's a lot of costs that they're going to reduce. And there's a whole bunch of new public good services they're going to be able to provide. And in addition to that, they're going to do an outreach out to rural. One of the things that they have discovered is the first phase that the governments are doing is they're converting analog processes. All those red tapes. Paperwork stuff into digital format. And then what they've realized is like, Hey, wait a minute, because we have all of this stuff digitally. Now we could get rid of some of these analog processes. We can get rid of departmental siloism. For example, farmers in the UK, they used to have to file the same paperwork with each department that is relevant for their means. So now they go to never talk to each other. Because they don't share anything. Right. So now what the farmers do is they go one place and all that paperwork is distributed amongst anyone who's interested. The another common principle and GE's gone to this is around, uh, they call it open procurement for the supply chain. GE will have a site anyone can get on. They say we need 8 million widgets. And instead of having a dedicated supplier for producing. That widget, all the possible suppliers come in. They look at the requirements and say, okay, we need it within this tolerance and, and it needs to do this type of thing. And they bid by making it an open market around bidders for their supply chain. They've reduced their costs. Ginormously. Hey, so, um, how did we get here? I don't know. We were trying to explain why. Well, I. I think why is something we'll continue to explore, but let's go ahead and wrap it up for today. And, uh, we'll come back in another two weeks and, uh, let you know what's new in the world of Brent and Allen. All right. Any final words, Brent? No. So, well, yes, then. Hey guys, what I, if there's anything that you walk away with, please understand the outcome of what you're trying to do. Don't just focus on the minute. It means focus on the ends and tie those together. That is how you're going to make sure as you execute on whatever you execute. Hopefully you do it agilely that you're focusing on what is correct. Yeah. And even as a precursor to that, I would say that don't be passive in watching change go by. Be a part of leading change in your own organization, because that's, that's where the fun is. I think a lot of us can handle technical challenges, whatever, but handling people challenges and adaptive challenges and, and change management across an organization is something that I need. I wish more people in testing and software would embrace and, and, and take on. Amen. All right. We're out of here. See ya. Bye. 
