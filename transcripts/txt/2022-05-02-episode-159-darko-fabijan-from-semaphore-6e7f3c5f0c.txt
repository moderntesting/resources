Hey everyone, it's Alan jumping in to let you know that I screwed up. We have a guest today and we ran out of disk space with about five minutes left in the interview so we don't quite get to the end and say goodbye. Well the good news is is our guest has invited us to be a guest on his podcast so we'll pick it up then some other day but today great conversation. Hope you enjoy. Welcome to AV testing podcast your modern testing podcast your hosts Alan and Brent will be here to guide you through topics on testing, leadership, agile, and anything else that comes to mind. Now on with the show. Hey everyone. Howdy. Hey we have a guest here we have Darko. Darko say hi. Hi guys. We have Darko Fabian he is the co-founder of Semaphore CI and he is gonna he has his own podcast we can talk about that later. Yeah sure. But we can talk about all kinds of stuff so let's we've literally literally just met seconds before I press the record button so tell us a little about a little about yourself. Yeah I agree we couldn't be less prepared. Don't give away it's okay our listeners know that know this. That is absolutely not true. We have proven on the podcast repeatedly we can be even less prepared than we were last time. So so Darko tell us about yourself. Yeah sure. So yeah I have been with my partner running this you know CI CD business for last 10 years prior to starting like back then like a purely hosted CI CD company we were like a rails consultancy and in those waters it was like 2008 2009 we were very exposed to the community to the general the culture of testing TDD BDD all that came with that community and yeah eventually we figured out that we wanted to have better tools that are than were available back then and yeah frankly we also wanted to get away from the consulting business we want something with a pricing page to be honest and that's how we got into you know SaaS business which is a hosted CI CD platform and as I said we have been doing that for the last 10 years and it's getting more interesting and more interesting as we are working with you know bigger companies that have bigger teams more challenges in the area of like testing CI CD so yeah in a couple of words that's that's what I'm doing day to day and I will be glad to you know elaborate and expand on these topics which also seem to be interesting for you guys so yeah I'd like Brent's already smiling you want to go first Brent well so I went to I'm on their page and I love their tagline CI CD for teams that don't like bottlenecks we hate bottlenecks too absolutely hate bottlenecks in all forms it's a period of time I don't want to tangentize on this one but it's it's it's the period of time it's review season at Microsoft oh that's what they say peak in May peak in May that's the Microsoft tagline no so it's it's so I consider myself a responsible and caring manager and so it's the also the time of the year where I retrospect and go oh I am such a bottleneck for my team anyway so yeah doing a lot of self-deprecation for the next couple of weeks around how horrible is it that my poor team reports to me anyway I don't know that I don't know this I can't imagine a worse scenario but whatever I don't know that that's that's part of the scenario that you're working to address with some of four but maybe it is go ahead oh yeah um I again we're not a product advertisement podcast however I'm very curious I'm gonna ask questions anyway CD is a lot of different things like your page all it says I'm intensely curious because CD is like my team solves a lot of it for teams at Unity but CD is a lot of things teams don't want CD they want to be able to maybe they just want to be able to automatically deploy in every change but often they want to be able to roll back or they want to know under what conditions should I roll back or can I do blue green deployments or staged rollouts of things what are I'm just very curious what are the advanced CD features that semaphore has let me maybe start with a bit of history so CI is the part which is which is kind of the first thing that you know people want to solve and that we also saw solved initially then for you know maybe two or three years people were bothering us can you also help us you know to deploy and frankly speaking we we haven't figured out that that's also the thing that we should be doing we were in that mindset we should be doing one thing then doing that thing very well over time we just figured out that you know the number of needs that people have and you just you know explained or you know listed a couple of those is enormous so what we did is in a pretty agnostic way we made a way to connect different pipelines together and those pipelines can model like any automate any process so you have your initial pipeline which is your build and test pipeline then you have a promotion which is a concept which is can be triggered manually or automatically which is just going to trigger a second pipeline and with that pipeline you can do your blue green or something you know any of the deployment patterns that else that you would want to do and on top of that you can chain another pipeline which can then again automate some other process that you that you would like to do for instance a rollback or you know very very very different things so I hopefully answered your question to some extent but I would be happy to expand so it does all of it yes well so so just to make sure I heard correctly it's so you've created sort of a generic reusable pipeline infrastructure is kind of what I've heard there but for things like let's say flight control are there do you have any any features within semaphore that helps you directly manage that or are you at the phase right now that you have the platform to support that but the the management of it is not yet a not yet an integrated feature um well it's probably the first one okay uh yeah yeah no and and and and that's that's fine how long have you been in business uh 10 years 10 years okay interesting and specifically in semaphore for 10 years yeah yeah oh wow okay um the so I looked at your podcast I see it's a who's who oh yeah absolutely like I see I see many friends of ours there like uh two times ago I guess two instances ago Lisa was up um I'm surprised you having hi Lisa because Lisa listens to the podcast hi Lisa yeah hi Lisa hi um I don't know why I do a podcast I have absolutely no podcast presence uh but I'm I am surprised that Alan's not yet on this list Brent's trying to be my agent yeah he might be yeah um Alan definitely gets what he pays for in terms of his agency so just glancing through I do see a lot of our friends on here and and I do see a lot of uh test representation here so are you targeting do you specifically target the the test market or the dev market like can you can you are you open to sharing to what degree you view your solution is test or dev and then how might that have changed in the last 10 years I I can maybe explain what our most interesting customers are and what we are very focusing on and that should you know answer a lot of a lot of your questions so I mean for instance companies coming their team of 20 people they have developed application in whatever tool they're in large percentage of the customers are just you know product companies that want to move as fast as possible and they come into our platform they are hiring aggressively and let's say two years later they're actually a team of 200 people our mission is that they don't have to worry about their CI and CD process at all so we scale automatically we have a number of features that help them you know to support their teams and they don't have to worry about CI CD at all and they also have to be passionate about having a fast fast feedback loop for a lot of years now we have been advocating that you know a feedback on the CI loop should be under 10 minutes you guys probably know for instance Dave Farley he likes to keep that at five and we are helping teams to achieve that and maintain that as applications are growing and complexity is growing that's not trivial and we want to be that you know extended part of their team that is going to help them to to achieve that customer like 99% of our customer all of our customers are you know very technically mature teams that you know practice TDD BDD other you know good testing methodologies and they pretty much once everything is green on master they automatically you know deploy to production or they click and then deploy happens but usually there is nothing you know nothing more that that's really that's really that's really blocking them from from deploying so fast feedback loop no bottlenecks and various elements of testing are parts of our organizations with customers i can expand on that uh but yeah hopefully i answered your your initial question at least let me talk a bit about that and one thing i've seen a lot of teams moving to CI is a challenge they face we saw this at microsoft a lot back in the day brent when tests that the team thought we had to run to make sure things were good take four hours eight hours brent and i both been on teams like that right brent brent's nodding his head for those not not on the video feed of our non-live podcast so what what's the path there is my question like and i i have my own answers but i think you might have an opinion here too like how do you take a team that has an eight hour test pass i'll say four hours a long test pass how do you get them do you just call CI and a eight and a half hour process or do you still try and crank that down to 10 minutes and if so how well a lot of fit in practice you know is just you know brute force horizontal scaling uh depending on the technologies because as you might guess you know i already said a lot of our customers are SaaS companies that involves some um some flavor of web stack uh where a lot of it can be paralyzed and just horizontally scaled and if someone comes in through the door and has something like that you know couple of hours long test suit uh if you would uh run that you know sequentially what what we would offer is like okay let's massively parallelize that let's let's 100 150 jobs in parallel our orchestrator and schedulers are optimized uh to run those jobs like you know in a window of like under five seconds all of those jobs will start and tests will be distributed across across all of those across all of those jobs however um that's never the the end um there are uh depending on the team and um and what their values are and what their culture is um they should really work on um figuring out their testing strategies that will hold for the long term was the testing pyramid a vast majority of of people that i i talk to and we talk to and we talk to um are struggling with having a very expensive integration acceptance tests and really not investing a lot in unit tests and in you know um just cultivating that test suit and how it will work five years from now or ten years from now and then there are like a brittleness of tests and flakiness and and and all of that uh so yeah so i'm gonna i you have a very pragmatic approach here which i love so um i have thought about the a lot of it's the pyramid in a second but also there's a lot of teams focused on writing these brittle i can say writing these brittle web tests in selenium and they take a while to run they're generally flaky they don't last a long time and they write too many of them in general exactly in general exactly so and that's that's kind of the problem with the industry no okay you are you are our kind of people darko it's like it it blows me away to no end and one thing i've stated before i'm curious on your thoughts because you seem to be um smarter than me is that the test pyramid isn't something you strive towards as a model for how you write your tests it's the outcome of what happens when you have a well architected and designed product and suite of tests to test it that's true that's true i got something right check it out listeners that's true um because i think what i've heard and i just want something i'd love to hear your thoughts on this when i hear from teams that say they tell me we have to write all these selenium tests because there's no way to test our software not at the web level and i look at them and i say don't you see the problem of what you just said sadly they don't the yeah so okay so so allen past test number one i do i'm curious i'm curious based on how you told the story so i'm thinking around so some of four started around 10 years ago thinking about what allen and i were doing around 10 years ago allen was 10 years ago that's that's when darko said he started some of war no i don't i'm trying to think what year it is now because i've forgotten i can't figure out what year 10 years ago was if i don't know when it is now brent i just need a moment to figure out my reality it's uh 2022 i figured that up by now okay so um 10 years ago allen was still at microsoft and we were knee deep in actually i know exactly where that was that was the year i actually moved to dev and into bing uh so that was right in the agile transformation period of microsoft so um and i don't think i i don't think anyone on this long on this call today is going to be confused on on the importance of cicb as it relates to agile um but darko before before you co-founded summa four what was your history were you were you a developer were you oh no you mentioned you were a consultant you you were consulting on on what sort of things just uh development test pm all of the above but but what exactly my suspicion i'll let you answer but my suspicion is that you were primary developer is that correct yes yes would say so okay when you started this company did you guess that in order to make it thrive you would essentially need to become a test architect um i'm not sure if i'm a test architect he's a job he's running jobs that do testing because one of the challenges with cicd in order to make that role you have to make that really go right the tests the tests need to be rethought the tests need to be like when you first start off a new team and they have their uh so back in those days you know in my world uh you know month-long test passes right there was no cicd there was no no no we have a code complete date and then we we kick off a month-long test pass in containing i mean i had test cases back in those days so i was a test manager at that time and within my organization we had test cases that take not only multiple hours but multiple days right it was just very poorly designed up front right and in order to make your product succeed it seems like you've learned okay let's go and we we're going to have to advise our customers on how to rethink the test architectures right did that occur that's what i thought i heard well we do that we'll do that but maybe i would add something here of course we want to you know the more successful our customers are the more we are happy with that you know for obvious reasons they have bigger teams and at the end of the month they also have bigger invoices and all of that but a lot of teams and what alan was talking about is they have that huge test suite of those brittle tests and so on there is that part to success that you know starts to start to go through you know they are just throwing the code in and feature with shovel you know in and that that initial team is probably not very good technical team not composed of the best people they are the people that will bring the company to the next i don't know not next financing round next validation of the product and so on and in a lot of cases that for our test suite that needs to be spread across country jobs is is product of success which intersects with you know some poor architecture that was you know just inherited you know and they had to move along fast so i hope that i'm i'm to some extent also continuing to what brad started explaining as the situation that you just end up being in um so and and that test architecture so we we do try to help people you know uh but um i'm not sure to to which extent um we really do uh because that's um we can give like some recipes but in a lot of cases there has to be a some of the cultural shifts you know and the organization of the architecture and the approach and it's kind of a lot of social engineering work though make that happen and we we are with them for a really relatively brief periods of times even if you are meeting every every month you know or so to help them you know steer they're both in the right direction they will still have so many many more hours with themselves and with their old practices that they're pulling them back you know and holding them back um yeah the what you just said really resonated with me so in the last 10 years and i know allen's on this as well we we've had to go go through a lot of period of agile coaching right a lot of the people that have engaged with me in that time period right they kind of approach and they're like oh right well we want to go to agile because we hear agile is the next big thing right and they they're at a phase where at least they're interested but they are not at a phase where where they understand sort of the the price tag uh for that and it's not just money but in terms of like cultural changes and and things of those sorts do you find that people coming to you are already they are already uh you know given your company's tagline that they that they're already sort of understand agile they understand how to execute and now they realize that they absolutely need cicd uh that that's a bottleneck to their process um or and they understand it's probably going to be painful or do you do you find that even with cicd that they're coming to you and say oh well we we you know we heard that we got to be cicd and we want to talk to you like to what degree of ignorance around the end to end are you encountering well i would say that you know i am i'm super happy where they are so they are very uh in a lot of cases they are very lean they are they are very agile and they know they know where they need to go uh just getting there is is a journey that takes a lot of time and as you said a lot of coaching a lot of coaching is needed is needed wanting crossed my mind as you as you were saying this um to jump somewhere else you know um a lot of people want to get that kind of a magic pill that will you know take their cross or down and it's they they don't want to you know walk every day and do this and change you know 10 of their habits but they would like to get that get that pill so that that's one of the things that um is um i mean not really frustrating but yeah cannot come with a better word that a lot of a lot of teams are looking for something like that that there is something that will offer like a quick and easy fix uh however there isn't and the latest thing uh out there are micro services right as as alan explained because there is that test you that takes four hours so what we are going to do well we are going to take the hammer we are going to break that into a hundred pieces and uh you know all our problems will go away because we'll have no longer that embarrassing long test yet but we are going to have a lot of small ones journey to get there is very is uh years long journey and it's also very questionable is that a solution so that's um part of my answer what what they're what they're looking for and um every like five years ago it was containers and um you know there is just so much of that in the air that people cannot not cannot not talk about that and you know seek that is a solution for all their problems and um now five years later it's microservices and it was also like uh lambdas and uh those kind of things so um yeah that that's what i'm seeing that's my my view of the world uh how people would want to solve solve their problems i find it interesting you're saying so from your view the shiny thing that everybody uh thought was the magic pill that would make everything go away five years ago was was containers and it's now microservices it's interesting because for me i would say my experience is kind of the reverse um but it's neither here or there the the absolute tendency so i'm a data scientist now and uh it seems like i keep changing roles into places where there's a new prevailing belief that uh a magic pill will will make the problem go away but um clearly AI can just solve all problems of course right right it gets right it's indistinguishable from magic and then i guess um so do you find day-to-day so you you to what degree have you actually managed to escape uh the consulting business or fully fully but you could you could say that uh i'm still doing it i'm just not aware that's actually my day-to-day job you know to me it feels like that's the case it feels like that you're still doing it but now focused on okay i have to do a consulting business in order to help this customer succeed on some of four okay alan did you have something yeah i want to dive into um we talked we touched on this and uh earlier but i know it's uh from reading the glancing earlier at the ebook on your site that you have some pretty excellent advice on optimizing tests we talked about the slow selenium tests and oh one thing i wanted to mention when you get that when someone has that four hour test pass sorry i should organize my thoughts well they have that long test pass i would say 99 times out of 100 it also includes tests that they do not need to run anymore there is there is a it's a weird uh bias and brent to tell me which one it is like it's been it's been around since i've been in testing once i create an automated test that test will run forever i will never stop running it because if i do the moment i stop the underlying code will break which is all crap but people it's a general belief whether it's uh set out loud or not so often the way to optimize a test pass is to remove tests that are redundant or flaky etc but i know you also have a lot of um uh pretty advanced idea not advanced but you've thought through this problem on optimizing how long tests take to run i just want to just wanted to expand on that a little bit because i think it's it's uh it's pretty sound and accurate advice and it's worth our listeners hearing about um to be honest i'm not sure to which exact you're referring to they are like um well i'll just i'll just say like how do you what's your approach to optimizing a test say you have a bunch of tests that take you think take too long to run what do you do what what's your again you're is that making you asking the consultant question when you're in the business but yeah but how do you go about that well in my particular situation i i rarely think about one isolated test that might take you know three minutes to run and can it be written can it be you know changed and then it can be completed under you know 30 seconds or something like that i usually think as a test you as a whole um to me i i sometimes wonder if i'm doing something wrong but um essentially i need to sort your test by the duration and uh pick those you know couple of percent that they just take a lot of time uh then go each through each of them and first verify um what's the level of confidence that they're bringing and consider you know removing them or rewriting them or is there a test which is you know already already testing that and um that exactly as you explained brings a lot of anxiety you know to remove a test and then also that element of flakiness that's actually huge and um a lot of people you know are kind of okay are we that team that has so many flaky tests and are other people better than us and where are we in that regard so i would say that potentially those flaky tests are the number one thing which is holding the people back and i would say that the the best advice there is just go ahead and delete that test and see what happens and usually everything will be just fine because the level of confidence that that test is bringing you is actually nothing or it's even poisonous you know yeah one thing i did back in the day to and i realized encourage this behavior backward is a simple test selection algorithm we had one way to cut down your test time is to not run all your tests and uh we assigned some we collected some metadata about tests and i won't go through the full list but things like the test length uh last time i found a bug um whether it ever had a flaky result or not and we used that we did those things come up with the tests that would run like maybe we had two hours of tests we were going to do a 15-minute test pass so i picked the best 15 minutes and people would say why didn't your algorithm select my test and we tell them why and they want their tests to be selected so they go optimize our tests to run faster or to fix the flakiness etc and then it would show up and they'd be happy exactly exactly there is also a situation that there is a test from 2014 that has never failed right exactly exactly we don't talk enough about that we've been talking about that internally maybe maybe that test isn't actually bringing us value another thing we measured in that metadata was the time since the test last ran because we choose not to run tests so it's fine that test from 2014 we're going to choose not to run it but every test pass we go or we don't run it that test gets a little bit of its value back until a time when it reaches a point where we run it again it passes it drops back out so that's one way to cut it down but yeah that we i've just had a conversation this week about what do we do with these group of tests that have never ever failed that that's a great question that's a great question and i i don't have an answer to that but it's a discussion topic for teams to have it's one of those things they don't discuss enough now i i'm actually well actually so with with simultaneous tests and data sciences had on and then looking at so i'm currently on some of our site and going through what the reports are and they call out fail tests they call out slowest tests right and in front for their business that makes sense right their their mission is to remove bottlenecks and help power people like i would say that the metric that matters in in from my point of view darko the metric that matters is is time to deployment exactly you're trying to shrink through how long does it take from a check-in to get this new feature in production right so absolutely speed is of the essence what i am not seeing uh on your website which i do think seems like a an opportunity is time to deployment divided by costs in some fashion right if you can identify using historic if you can if you can automatically identify hey this test is not adding any value to your cicd process says um our analytics right um then you could start adding recommendations to people say hey maybe you should you should reduce it basically are you it's sort of a risk to cost evaluation right is this test really you're you're paying for this test right you're paying in terms of time as well as as whatever my team my company charges you um but is it really helping to mitigate risk now now on the on the podcast obviously in some regards the more bad tests they have the i assume you pay or you your your pricing model charges people for the length of time on the cicd so in some regards right long-running tests likely um benefits you but uh in terms of the overall credibility you need mission right it seems like it's actually good motivation you want to get your bill down fix your damn tests um yes but they're parallelizing too yeah yeah yeah yeah well yeah that's one way you can also buy sam for a running to you know like on prem and then you don't pay you know you run it on your infrastructure and then we don't you know but but um what uh what brand explained is exactly uh the main topic of organization that we have with couple of our like largest and most valuable customers uh which is exactly that that they have been you know so successful that they have managed to acquire a test you that literally needs 100 plus jobs in parallel to run so that they get their feedback loop under under 10 minutes you know and they keep adding more people and they are worried about their costs they are worried about that cost and where is that going to go and at this point in time that's uh there is no feature that really helps them with that you know and that kind of analysis that would point out that you know you have this test but what value does it bring and we literally we're having very you know open and honest conversations you know um what's the value that this test run brings you uh because it costs a lot you know and it can you know easily cost you know a couple of dollars for a single test run and developers can make many of them and that can you know be significant cost per uh per developer per month to run to run all those tests so we are working on a couple of things that are related to this and flakiness is the main thing where we want to help people you know track that because people have like excellent spreadsheets with you know uh thousands of lines of flaky tests and they are figuring out how to battle them and um yeah so on flaky tests so i don't see i don't see again on your on your your pr material i don't see any any report around flaky tests do you do you identify those as of today that feature is not is not around but we are we are working on that okay yeah that has been i can say most requested feature i went to so talking about what we're doing 10 years ago this is maybe nine years ago but the conversation reminds me i went to the google test automation conference uh one of the last ones i had in kirkland and i jokingly referred to it as the flaky test conference because every talk talking about test automation either was about or mentioned flaky tests and here we are 10 years later it's still a thing why do you think 
