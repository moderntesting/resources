Hey everybody, howdy. Hey, I'm Alan. I'm Brent and we are here for episode 47. 47 counting down to 50. That should be this year. I know. So what should we do for our, this is a question for our listeners. What should we do for our 50th episode? Meaning? Like anything special? Tequila. We could actually bring in the tequila and before you suggest Naked, Brent and I are actually naked for this podcast. And most of them prior. Yeah, most of them. Most of them. Not the one with Steve. No, no. Speedos for that one. Yeah. Yeah. There's a problem with recording a podcast at eight o'clock in the morning. You don't have enough time to get sufficient caffeine. I know. And I was up late. I was up a little late last night trying to get a couple things done. So guess what, Brent? What? I bought myself a new car. Congratulations. What'd you get? It's a red car. It's got these cool falcon wing doors. The back doors kind of open out and up. They're pretty cool. Up and out. What makes it a falcon wing versus say an I don't know that that's what Tesla calls the back doors. You got yourself a Tesla. I got myself an electric car. Nice. So you already had an electric car. No, I had a hybrid car. Oh, I still have the hybrid car. I got rid of the we had an Audi Q7, which I hated. OK. Now there's another story. That was your other. There's a story I didn't plan on telling. So I got a Prius like I can't remember how many years ago, 2006, maybe 10 years ago, and I like it. I it was perfect for me. I had just enough tech to keep me excited. And my wife got this Audi Q7, treated her Audi wagon and she liked it for a while. She said, I don't like this car anymore. We're trading. And like a good husband, I said, OK, yes, ma'am. So I drove the Q7 for a while. I didn't like it. Just a little too big for me. I don't like really big cars. Some people like driving around these big old monster trucks like Brent has or these big old Ford exhibitionist. Alan's Prius could fit in the back of my car. So I don't really like big cars. So the thing I love about the Model X is it's a smaller car, yet it still has third row seating and it feels so much bigger inside. They really did a really nice job with the cabin. And then there's all the cool like tech, like this massive like iPad pro sized screen, which is totally distracting, which has a web browser, which you should not use while driving. No, the it's OK. The sites I wanted to go to get your mind out of there. Like our VSTS site and our product site won't load on the browser. So I haven't figured out how to hack in there and send some different user agent strings, but I'll get into that. Is it already ready for the the self driving? Yeah, I have it. I have I have auto drive. I haven't used it yet. I'm too afraid. And you're really only supposed to use it on the highway. And I haven't really driven it much on the highway. I just I just kind of drive to work and back with it. But we're taking a road trip this winter, which you really want to use the the auto drive, whatever it's called. That's not called auto drive. It's called something else. Anyway, I'm just thinking on snowy and icy roads driving in the winter. That's the best time to use it, right? Absolutely. Lying. Absolutely. We better get in 50 before the end of the year. Otherwise this can happen. So I'm really enjoying it. It's of course, it has that that massive Tesla acceleration, but it's fun to drive. The kids like it. My daughter, who's 10, said, Dad, can I have this car? I said, yes, I'm going to give it to you when you're 30. I that's nice of your daughter already thinking six years ahead. Yeah. Anyway, yeah. Tesla is something that I will never, ever, ever own. Because you like your internal combustion engine. Do you want to burn some gas, some fossil fuels? Someone needs to know for me in particular, it's it's the price tag. So I go, hmm, I could get that or I could retire a year earlier. Yep. And I was thinking, I was thinking we could not get that or I can work one more year. So exact same train of thought. It's like any time you make a big purchase, I kind of go, well, I'll probably have to work till I'm a little older anyway, so it's fine. I'll get bored if I don't work. Yeah. You got your you still got college to worry about. Have you got that handled? I we are saving frantically for college. We got the college savings plan going. Unless my wife is on the we're on the total financial track here. My wife is of the mind of wherever our kids want to go to school, we will pay for it. And I'm thinking, so well, it's too financially. My money picture is going, no, if they want to go to an Ivy League school, they better get at least a partial scholarship. And then if you read which Malcolm Gladwell book is that I think it outliers. When tells the stories of these kids, like these super straight day students go to the and these are awesome students get scholarships, go to these fantastic colleges. And then they because they've been used to being in the top of the class their whole life, but they're with a hundred other students have been in the top of the class their whole life. They end up being in the bottom half of the class. They get disillusioned and drop out. The best way to succeed and get so much this involves in the Daniel Pink's work around motivation is you want to go to the best school where you can be in the top part of the class. You want to go. Actually, this is for everybody. You want to put yourself in an environment where you are constantly what's known as the flow, where the challenge level is just out of your reach. And then as you improve your skill that brings that challenge back into what you're capable of, that there's a new challenge. If you go just way outside, it is absolutely demoralizing. I've seen this happen to so many people. And you don't want to be the very top either, but you don't want to be the very bottom. There's there's psychological things that affect both parts of that. Yeah. But also this ties into the Heffetz work, which talks about something similar to I can't pronounce the guys that wrote the flow wrote flow. I can't either. But somebody will start with a C. Yeah. Shmoop. Yeah. Yeah. As far as I'm going to go. But he talks about like I'll try to draw with my hands, but I can't help it. But if you are complacent, your productivity and your growth is minimal to nil. If you are in completely over your head and overwhelmed. Same thing. So there's a simmering point where you're challenged just enough to be uncomfortable. And that's where productivity and growth come from uncomfortable, but still have a sense of you need to be a little. If I work a little harder, I can get there is a simmering point. And this is true both for like in university. We're talking about as well as on the job. You want to keep your employees at that simmering point. You don't want them to be complacent. You don't want them to be overwhelmed. But there's a point in between need to find for everyone where you get the maximum productivity and growth. Yep. Well, that actually evolved into a better conversation. It did. So anyway, all from Tesla. Saving lots of money for college. It's all about the we have the nice car now. It should last for a while. We're actually on the waiting list for the Model 3, which is the cheaper version. She was like like thirty thousand dollars. Probably. But then if you want tires, it's 60. That's a. So we're in a mark. So my wife's minivan is now over 100000. I haven't had a car reach 100000 miles in a long time. Well, our priest has like one hundred and forty right now. But she's she's complacent and I'm just waiting for that one big ticket item where I'm like, OK, that's it. Done. Done. Yeah, I don't know if electric cars going to be her thing, though. All right. Anyway, I dig it. It's fun. It's got the manly acceleration. It's got all the tech and stuff. So it's fun car drive. Cool. Cool. Shall we get on with the show? Yeah. Let's let's do it. Oh, never mind. Not getting on, not getting on with the show. One big thing for me, which is odd, is I now have an adult aged offspring and man. Did they just contact you from like? No, no, no. My oldest turned 18 just last week. Wow. I can't imagine. That transition is just odd. Like one one thing. Hot mail makes sense, right? But hot mail exactly at midnight, sent him a message saying he's been kicked out of the family, which, by the way, is a weird message. But I understand why it was saying that. They were saying the hot mail family feature he was kicked out because now that he's 18, Dad's Dad's rules don't matter as far as hot mail is concerned. Oh, he can sign up for his own mailing list. Yep. All right. Whatever. And who uses hot mail anymore? Besides your family. What do you use? Are you Gmail? I have my own domain. Oh, right. So now I've been telling my kids, like, look, until you're 18, you're off of Gmail because I know what that company does. I'm not going to be morally responsible for you. Screw it up. So I'm six years away from having an 18 year old, but counting down the days because that's when the second one turns 18 and it changed the locks and they're done. Yeah. Changed the locks. Start charging storage fees. Absolutely. I tell the kids that I think I'm joking. Six, seven more years. I told my parents this a couple of weeks ago. I said, yeah, if if Alex is still at home and not going to school a year from now, if he's at home and going to school, say, if he goes to UW, then then that's a different thing. But if he's at home and not going to school, yeah, I'm charging him rent. Yeah, my parents gave me a bill when I turned 18. Did they? Seriously? A joke one. But yeah, my dad said I figured out what it cost. Here's what you owe us. Yeah. All right. Let's get back to the podcast. Oh, really? You think it's time? Yeah. Hey, everybody, it's Al. And Brett, episode 47, blah, blah, blah, blah, blah. So we spent the last three episodes talking a lot about data. A ton. A ton. So let's talk about something else. Let's let's turn this conversation back on me because that's what's really important here, right? Yes, it's all about. I mean, you are the A. I am the A in A.B. testing. So I want to talk a little bit about what's going on with me and my team at Microsoft. We are getting ready to be known at some point around the world. In fact, maybe by the time of our next podcast, I have to look at the calendar. I can actually speak of our name. OK. So but in the meantime, that means we're getting ready. I thought it was Microsoft Juicy for Business. It is Juicy Microsoft Juicy for Business Enterprise Edition. It's been a fun transition. This is actually a lot of things I've wanted to do on the team for a long time. Now that we're about to, quote, ship and become much easier in some ways difficult than this, but much, much easier. So I want to go through those and talk about those a little bit and then also talk about what it means to air quote ship in a world where you're shipping a service or an app. Maybe I'll tackle that first, because there's been a cultural maybe mind shift sort of thing. And maybe you've gone through this, Brent, where we have a bunch of people on the team. The team is a large part of the team has grown up, grown up, but, you know, live their business life, shipping, shrink, rack products. We're well beyond the days of going down to Egghead to buy something. Some of the kids, some of the older listeners may remember Egghead Software, but it's really easy for people to think of shipping as this. Think of Office app. It ships and then you have to taper down like the bugs we take and have stabilization, then you get to the ship date and it ships. And then you wait and see what happens. Right. Very, very old school. I think verbally they get that we're going to ship. We're going to announce. We're going to ship. We're going to announce a couple of days later and then a couple of days later, we're going to ship again. Let me ask you a question. Yeah. Ask a question. The you said that your developer team, most of their experience with ship rack products. And as you were saying that I was thinking through the last time I was on a product like that and oh and or the last time I purchased a product like that. And don't even think of it as so. Ancient. But it's a it's a cultural transformation where it's not just developers, it's everybody. Dev PM management. They have this and they know logically that we ship and we ship like eight times a week now across because we have a bunch of microservices as well as a web front end. So we're shipping like eight times a week across these things to 10. So we're shipping all the time and that's not going to stop. So what's interesting is the transition of I mean, they get it like we're going to ship and then we're going to ship again later. But they haven't internalized it yet. They don't really get the muscle memories not there. Their muscle memory is still from the old days. So there's been a couple of things that have been interesting and I should have written them down so I get them in some sort of sensible order. Or if I was a really good podcast editor, I'd splice them into the right order. But none of that's going to happen. So I'm going to speak randomly about some of the things that I'm doing, which I feel like are getting us in the right direction. And then Brent will tell me how I'm completely wrong. And then we'll discuss and then move on to the next one. Okay. That's the plan. So one mindset shift in shipping a product is, Brent, you've been around the block. You remember shipping your products. Yep. And one of the things is, is you talk about raising the bar of bugs that you'll take. Don't laugh. Let me finish. Yep. Let me finish. There's this mindset of, well, that bugs too, that bugs too minor for the risk. We're not going to take that fix. It's too risky. So we got to cut down. We can't take, we can't, you got to cut down what bugs were taking. We're taking fewer and fewer bugs. We got to, where does convergence come? So my line there after a brief amount of thought is we're going to raise a bar. But the bar we raise, I mean, we're going to, cause we're going to be shipping all the time, if we were to raise that bar so high before our quote, ship date, our announced date, uh, what would happen after that? This flurry of getting out of bars up, you have to lower it at some point to let everything else in. I don't want that flurry of crap coming in all at once. I'll get back to the flurry of crap later. So the bar of what we take doesn't change. We take everything. The bar, I'll get back to that in a minute, what that checklist is, but the bar that changes is the bar of what you have to do before that code is checked in. And this has given me a lever to pull that hasn't, uh, I haven't made traction on until now before to check in. As long as your manager signed off, you're good. Check it in. Woo hoo. And we had in the Kia and we had instability. Um, oh, shocker instability in our branch and some didn't work. What? Some developers, of course, better than others at getting the right, doing the right due diligence before, but some people would then get in some bad code and screwed up for everyone else. So now that I'm re I can raise the bar of what goes in, what has to happen before code is checked in. So you may remember, uh, a thing at Microsoft called ask mode. Yes. Well, you have to ask to check things in. And so I got a question from, this is give people what they want versus what they need versus what they want. Yep. So I had our GPM and our VP come to me and say, when are we going into ask mode? We need to go into ask mode and lock things down. I thought, huh? Yeah, I guess we should go. Uh, thinking, thinking, thinking. I have a plan picture, the light bulb over my head. Ding. So we're in, uh, ask mode now. Yeah. Immediately. So, but we're going to ask mode, which ask mode means that, uh, one of the PM's not the GPM, one of the PM's that he trusts and I sit together twice a day. And we reviewed, we review things people want to check in and we either accept them or reject them. And I get to be in charge of determining what goes into the product. And also through this reject things saying, no, you can't check this in without writing tests for it or no, please test this across all browsers before it goes in. So all the things they should have been doing before, if they're not doing, I can just reject them. You are now the PO for the product. And you're doing this, what's done is the acceptance review. I'm the release engineer, acceptance review, or in the agile world, the PO. Product owner. Yeah. Yeah. So this is working. So what I'm like, and I can do through that is continue to raise that bar of what goes in and then stuff goes in better. And then something I stole from, uh, Chuck Rossi, his release engineer at Facebook. He has this idea of plenty of writing on the internet about this, about developer karma, and I know that on my devs listen to the podcast so I can talk about this is we took 300 changes last week. Congrats. Um, which is fine. I'm happy taking 300, 500, a thousand. It'll get less as the bar goes up. They'll have to do more work. The, that number will drop down. They also get, keep in mind, most of these are bug fixes. So I doubt, I think 300 will be our peak. Usually it'll be much far, far fewer, but there were one, two, three, four changes that we took out of those 300 that caused a product regression. Cause they didn't do the proper testing and I signed off anyway. I didn't recognize it. Okay. So Chuck Rossi does this thing called developer karma where in his case, it's a four star system. Everybody starts with four stars and you lose half a star. If you screw something up like that. Okay. So I'm going to, I will give the exact numbers, but I'm going to use a 10 point scale and people are going to start somewhere in the upper middle half of that and they'll lose or occasionally gain points that they're super awesome, like, like imagine, like I, I made this small change, but I noticed the unit tests were all screwed up. So I wrote another 50 to cover any further aggressions in this entire file. I might give them a point of developer karma. And then when things get really risky, I want to look at the change, the risk of the change match that with your developer karma and go, no, you're going to need to do more here or I can trust you. Yes, this is fine. Brent's rolling his eyes a little bit. Well, so I like, I like the, I definitely like the gamification aspect of, of this. I'm curious around the, the finger pointy or the rest of the risks aspect. So one of the things, and that's a good point and two things to keep in mind. One is I haven't done anything with this list yet. And two is this won't be a list I ever share. And I won't say, no, you can't check this in because your karma is too low, but it will give me, as I'm looking in the PO role, looking at these changes coming in, I might go, well, Fred has had a history of, of regressions. This is high risk and I don't feel like I've had the right people code review this. Let me push this back and get a little bit more information. I'm going to make his bar a little higher and hopefully make him a little bit through that, teach him a little bit more careful about his check-ins. Yep. So, but I'm never going to share that list and stack rank them. Uh, ever. Uh, I may bring the knowledge of those, not the list, but the knowledge of what I've learned to a people review. Gotcha. I think that's a given, but, but overall I want to teach the, uh, devs at the bar, they have to the developers, the bar, they have to meet to check in code. It's going to go way up over time. So once we become announced, I want to do two things. Uh, and I'm all over the board here, but it will make sense. One is that bar will be high enough. Like everything that goes in is well-tested and, or behind a feature flag. And for people not familiar with feature flag, that means that this feature is fully checked in, but there's no way for you to use it. Developers and dog food users can turn it on. And we have a flooding system where you can turn those things on for a select set of users. You can gather data about how that's working with a select set of users and get that information and Brent staring at his phone. Just turning off random. All right. Sure, sure, sure, sure. Anyway, uh, things behind feature flags, uh, should go in and it should not affect the rest of the product. And so I forgot where I was. No, the nice thing with feature flags as well is that if, if, um, you, do you release it and an undiscovered regression down that code path, it's relatively easy to say, okay, turn this off. Yeah. Right. The, um, the thing I like about what you just described, and actually when I am, when I'm in the role of a, of a PO, a biggest, the biggest, um, principle I get across is essentially, look, you guys can check in. Whatever you want, but the main build must always be RTM. Right. We, you can check in whatever you want, but we have to be able to ship it at any time you guys don't get to control the ship date. Like my favorite teams is where I get engineering out of the business of influence, the ship, the ship day. That should be a business team only decision. But the only way to do that is to make sure that that mean build, that mean tree is always ship a bull. So let me tell you another story about what we're doing and what's changing. Yep. So right now we are the canonical example of mini waterfall. So let me, let me describe what I mean by that. So we have our services are pretty good, but our front end is the most error prone part of our product. Uh, user facing more, at least more noticeable, more visible problems and also the largest. So what we do now we've done up to this point is once a week we take our develop branch, which is where all this churn was going on uncontrolled. And we take a snapshot of it to a pre-production branch and we test it and dog food it there for half a week, a week or so. And then release that rinse, lather repeat. What I wanted to do originally when I described this, I just wanted to go just get, I don't like that pre-production branch. I wanted our develop branch to be high enough quality. We could just take it to production. Uh, and have it be less of a moving target. That scared the crap out of people said, no, we need our pre-production branch. We have to, where do, where do we bake things? So, uh, the compromise I made is that this whole continuous deployment thing is such a long haul to, to get people to ship it is, but I feel like now I'm on the path there because I wanted to jump like skip a step, but mentally and psychologically they weren't ready to lose the safety net of pre-production. So, uh, I backed off a little bit and said, okay, we're going to keep doing. So no, actually I put it this way. I said, never, never mind. I miss print on my part. Of course we'll continue to have a pre-production branch. We will continue to snap that and test that. Uh, but the quality of our developer and should increase over time. Well, over time doing what we're doing. And what I expect to happen is, is I will do that. We will take a snap, but turns, but already seeing advances there and one week of this, but I imagine another few weeks to a month at the most and our develop branch will be of better quality than our pre-production branch ever was. And once we get to the point where develop is that good, I might just say, Oh, you know what? Gosh, this is actually good enough to ship. Let's go ahead and, and also because we have rings of deployment, let's go ahead and take what's in develop and we're just going to ship that to, uh, our first ring of deployment and see how things go. And we'll look at data. We'll look at bug reports and then we'll, and we'll just roll things out through rings and see how things go and roll back as we need to. So that, so that will happen. I think you'll still have the, the, the safety net discussion then. I think the safety net is what we call a ring zero. Yeah. No, no, I completely agree. Of course you know that, um, this isn't a technical problem anymore. This is, no, no, no, no, there are technical problems getting the rings, right, and getting deployment. And there is one technical part of the problem, but then get to next, but you're right, it's getting people used to the mindset of that or shipping and things like the bar we're moving is what has to be done before it goes in, that's part of it, the bar that, uh, we don't need that safety net. If we're using rings of deployment, which are also new as some of these people have worked on web products before, but they haven't, for some reason, they didn't do rings of deployment. They flipped a switch and it went to the world. There aren't, there aren't many teams that I'm aware of it at Microsoft, even today that are doing deployment rings. So it is my responsibility. And there are testers in the world that say testers go out of the QA business, you shouldn't be making the business decisions on when to ship, but I make the business decision on when to ship. It's my, it's my call from a quality perspective. And so I make that call. Uh, I am scared to death. Now, when we are shipping to a hundred people, 500 people, a thousand people flip the switch. I'm okay. Right now we have 10,000 daily active users and without rings of deployment, you want me to flip that switch and we're going to, we should be at a hundred thousand and probably up over a million in the next few months. And do I want to flip that switch for all of them at once? My blood pressure goes up just thinking about it. Yeah. No, you, you will, you will definitely need that to mitigate risk for sure. I was thinking through your other problem and I think the way I might try to approach that would be to, uh, Hey guys, here's my numbers on the dev branch. Here's my numbers on the pre prod branch. Um, here's the number. Does it go dev pre prod then prod? Yep. Okay. So here's the, the regressions that have this have been escaped. In other words, found in production. Um, here's the cost of the, of the pre prod and try to weave a story that says pre prod is or try to leave weave the analytics such that any brain dead monkey looking at this would say there is no ROI for pre prod, but then present it to your dev team and just simply say, all right, guys, here's a bunch of numbers. We're doing really effectively on this. Now what do what changes do we do to ship faster and try to, try to set the stage so that your, your dev managers are the ones that go, we don't need pre prod anymore. Yeah. Right. It'll be fun to get there. I I'm excited about, cause there's a few people that one by one, they kind of get it and there's an excitement that comes like, Oh, I call a cow. I've had people come to me. This is the biggest compliment I've ever gotten at Microsoft. I had one of our Ems come to me and says, I feel like we're shipping like 21st century software, which is rare at Microsoft. Yeah. Now, when I first experienced, um, continuous deployment, particularly in the Kanban model, like where, where each of my guys could be shipping. If you have a large enough team, at least one of your guys is, is quote unquote shipping something every day. Right. Um, when I realized how much risk was mitigated by being able to ship small things that continuously integrate. I would rather ship 20 times a day than once a week. Yes. Absolutely. Uh, I remember that moment like yesterday. I'm like, this is what this does. Yeah. And there's, it's funny. There's one developer on the team, one, a manager, one of my peer managers who has been, yeah, I want to get to CD. I want to get to CD. And then I gave him my original plan. Uh, and he goes, uh, this is a little scary. The team isn't going to buy onto this. So even he was a little hesitant and he was right. This is a, uh, definitely a case where boiled frog seems to be done. But I have a, I feel like I have a good plan in place. It's coming along. Couple of other things I wanted to talk about. Okay. One is our developers write two different kinds of tests. We have, um, some unit tests. Which, uh, running against a headless browser currently Phantom JS, but, um, I think we're going to switch to headless Chrome here shortly. Once it's officially available, those tests are great because they, they run super fast and they can, they find a lot of functional regressions, even in the web front end. But knowing that we can't find many issues through those unit tests, we also write some almost UI tests. You know, my, you know, my, uh, opinion on UI tests, but there's so many, there's selenium tests, which I know many people who've had very good success writing non flaky selenium tests, ours are not non flaky. There are, but they're not super flaky. They're slightly flaky selenium tests. And that's what we have pretty much right now for testing behavioral and functional correctness. So there's a couple, some EMs come to me and say, okay, after we ship again, after the ship bait, we want to double down on writing a lot more scenario tests and my answer to them. So my strategy here is sort of three pronged or one prong with three curves. I don't know. But at that level, you, I tested, you know, you saw my blog posts on not you didn't, but you did. Uh, you, the listeners eat it on gooey schmooly. I really leery of UI tests. And again, selenium tests work sort of at the object models. They're a little bit more reliable, but they're very difficult to get correct, but not impossible. So I would rather, uh, and I have one of the people on my team working on making sure that the scenario tests we have are just rock solid, not flaky. And also teaching the dev team how to write those tests. Certainly possible that's going to happen. But I think as far as writing those scenario level tests, that's the third thing I want to do. So the bottom thing I want to do is yeah, sure. We need more of these. We call them scenario tests, these selenium tests, these end to end tests. Sure. We need a few more of those covers, some gaps, and they need to be rock solid. That's the third level. But I wouldn't second level. I wouldn't double down on that is bottom. That is number three and the stack rank number two. Moving up is because I believe in that tight dev, what we'll call the inner loop at Microsoft. I want more unit tests, uh, great safety net against regression. Uh, you just sure you can't find everything there, but we'd need a lot more of those only mainly because they run super fast and they're. Generally super reliable. We've in fact, I can't think of a case in the last year where we've had a unit test fail that wasn't due to, uh, uh, faulty code, like the tests aren't flaky. So, so I want to, if we're going to double down, it's there, but I don't want to double down there either. What I want to do, this goes back to what we're talking about three episodes ago. I said, no, I want you guys. We have a lot of, now we have a lot of BI telemetry in the product. We can tell what users are doing. So what I want you to do now is use telemetry to tell me whether things are passing or failing. And then we're going to write selenium tests that don't, this is taken strictly from Brent that don't try and be the Oracle, which is very, very hard to do just exercise the product and use the telemetry to figure out whether things pass or failed. Yes. And when we get some of that in place, now I have even more confidence to roll through rings and look for failures. So they get there. They're on board with that suite. So that's going to happen. It will happen very slowly, but I'm pushing down like this emphasis on these end to end tests. I think putting more emphasis on the right, like diagnostic telemetry, and then the unit tests for that inner loop. And this is our test for some, for some frosting on top. Let me give you a, uh, a potential rallying cry. We we've, we've talked about rallying cries. We've talked about this in the past. Oh God, take a shot. Damn it. Um, um, rallying cries are critical to, to, or not critical, but extremely helpful in solving these in these, um, non-technical, but appear to be technical, but are actually people problem problems. Weinberg comes back again. It's always a people problem. Yes. Here's what I would suggest to you, right? We have these deployment rings. We have these feature on off switches. I would suggest that what you want, say in six months time is a system that automatically turns offer on features based off the telemetry being reported. I like that. We'll get to that, but yeah, automatic stuff. So right now, another part of this change is I make the column with it a ship. Yep. But when I make that call, I go to our SRE, our system reliability engineering team, I say, okay, go ahead and flip the switch. And they, they actually do the deployment of the deployment and watch for their monitoring dashboards and figure out when to roll back. Yeah. They actually do the deployment and watching a monitoring. So they're my automation right now. They are. But what I'm saying is if you use that as a rallying cry and say auto on off, then, um, so what, what you're at right now is where the DevOps, where the DevOps will progress next is, uh, if you let it go this way, six, nine months from now, that team's going to be flooded by a crappy TSG docs. They already are. And I don't remember what TSG stand. Troubleshooting guide. Right. For our three listeners. Um, so they're going to be flooded by that. And, uh, you run the risk of your developers, um, focused on now bugs and features, viewing, uh, instrumentation as a second class citizen and, and basically saying, Hey, I wrote that TSG jock. It's now DevOps problem. I did this whole idea of it's not my job. Um, unfortunately never dies. Um, but if you can begin the path of saying, Hey, we need to have this telemetry. You guys need to be accountable for making sure the telemetry is such that it is being used to correctly turn off or on features as it goes through these deployment rings, then these DevOps guys are just looking for this new, what just got turned on or off signal. Yeah. Definitely want to get there. Great rallying cry. And we have actually a good set of, uh, behags on my team about getting some of these things done. Behags. The behags are the big hairy audacious goals. What book is that from? That's from, uh, God, uh, I forget which book it's from a book. I read like 10 years ago. Okay. Sounds cool. Anyway, definitely want to get there, but it's fun because a lot of these things I've wanted to do for a long time, but the, the circle back to the beginning of this conversation is the process of becoming a public app and quote, shipping, whatever that means, uh, has allowed me to finally get over the edge on many of these things. It's like now people see the reason or I have a way to roll these things out. One last thing to talk about is, uh, a lot of this from some from a doc. I wrote on our branching strategy. People asked me in the traditional Microsoft world, what you do is you would create getting close to shipping. You create a release branch and then everybody would party on the old branch and then you try and merge them back together after your release. Hatred. What that would mean in a product like this is we would quote ship and we would never ship again or not for months. We'll try to get everything to merge back correctly. Right. So again, I said right off the bat, we ship out of develop. And so what do we do with our, what about the, our stuff? That's not going into our V one launch. I said, well, if it's behind a flag, check it in. If we really don't want it till later, uh, maybe it's a, for whatever reason, uh, do it in your branch. They go, well, how do I merge it? I teach them how to use get, so what I sat is another interesting thing here. I've, I've, you know, I've worked in windows-ish products for a lot of my career, so I'm, and I'm sort of a command line guy. My first automation ever was lots and lots of batch files. I've had to give multiple tutorials on the team on how to use the get command line because they use like visual studio. And my role with get is never trust the GUI tools. Just use the command line. There is a couple of good tools on top of get that are fantastic. I don't trust. Yeah. The command line, at least on get, so I'm usually a GUI guy, but when it comes, when it comes to source control management, um, I'm definitely a command line guy right now cause I need to be sure that I'm doing exactly what I think I'm doing and, uh, a lot of the GUI tools on particular get for me, it's confusing. I just want to make sure that they are, have a merge plan and pattern that will help them be successful in a branch. And one of the things that I worry about and they rightfully worry about is, well, how long do I keep the stuff in a branch? And I don't like long, long running branches, although with the right plan, you can keep things merged and in sync with the develop branch, so you're not. So when you have to merge back, it shouldn't be a problem. Those things are possible, but again, feature flags for merge to develop frequently behind a flag, get your code in there. If you're worried about things diverging too much, but get it behind a flag. But you're going through is risk retraining, right? The people above you know the rules for managing risk. And they're like, this is to the right. It, the concepts of ask mode and, well, I call it ask mode. It's just, it's just release management. No, but it's asked mode, right? I wouldn't be surprised if you, if someone above you recently has talked about bug jail or any of these bug jail hasn't come up. In fact, one thing that's come from this is I should talk about one of the thing is we have still, I believe in the popcorn, popper theory of shipping software mostly. So the popcorn, popper theory is you've made popcorn before. And whether it's the microwave or Jiffy pop, same metaphor works. The popcorn is popping like crazy. Where it's work coming in, pop, pop, pop, pop, pop, bugs coming in. We're going to fix those right away. Pop a pop and the end, it starts popping slower pop pop pop. And there's a fine line between getting the most popped kernels and burning your popcorn. Yep. That's when you ship. So we have an income. We're still popping, not super hard popping a reasonable amount, but we're, but our fixed rate is higher than our incoming rate. And it's all good. But one thing has come from this is for a long time. I've been trying to get to, I was close a little while back and then things went off the rails of, of how many old bugs we have. And right now we are almost on top of keeping our, basically our bugs older than three days at zero. We have like 15 right now. Good. So my goal and the book again, buy off on this as we get that to zero, we keep it to zero and the line I'm using to explain it is if as long as fixed rate exceeds accepted rate, that indicates, so the number of bugs are fixing is more than the number we're coming in. That indicates that we can take on more feature work. Yes. No, I, I would, I wouldn't approach it that way, but that's fine. The way I approach it is bugs take precedence and when the bugs are dead, yeah, then you use your available resources, potato potato works. Right. Um, it's been great though. The point is that getting to this point and trying to working with their definition of shipping versus my definition of shipping, uh, we've been able to get that number close to zero and, and with the goal of getting it to zero. So I feel good about that. And once, and then with the added dynamic of we're shipping all the time after that they understand the importance of keeping that at zero. Yes. You were talking about deployment models. Have you, did you ever go and look up? It's all public domain knowledge. Uh, the safe version of the deployment model. I read through that a long time ago, maybe a year, a year and a half ago, but I don't remember it. In a nutshell, version three, oh, a safe there's now a four. Oh, so I, I haven't reviewed the four content. And then they make big changes as they learn new things and learn better strategies. There's essentially three branches, maybe four, four, we'll go with four that there's the, the private dev branch on their machine. Then there's the official dev branch. Then there's the integration branch. And then there is the RTM branch. Okay. So devs continuously taking it from their, their personal machine branch and integrating into the dev branch man. In the safe model, um, you have two weeks sprints and then you have a system integration team, um, two weeks sprints, the dev team, uh, then demos at the end of that sprint. Uh, this is easily adaptable to more of a Kanban model. I'm just communicating it from a scrum model every two weeks, dev then demos, what they are checking into the dev branch. Okay. The system integration team, their job is to, um, the weeks where the dev team isn't demoing the system integration team is demoing the off weeks. So dev's going every two weeks. So then it would be dev demo system, demo, dev, demo system, demo. You follow? I get it. Okay. The system integration team is then accepting these check-ins. These change lists and they will take a change list at a time, integrate it into their integration and determine whether or not that gets rejected or moves up to the RTM branch. Anything that gets rejected, the integration branch gets reset to the current version of the RTM branch. And then the next change list is incorporated and quickly tested. So then what ends up happening in this case is your RTM branch is always RTM. And, um, this integration team, their purpose in life is to reject as fast as possible. So they're highly focused on proving that this didn't integrate correctly, but as fast as possible. So you don't see much like you were talking about with these scenario tests. You see these scenario tests, um, uh, trying to be lean, uh, highly focused, enabling this, this code to filter through. Um, you don't want to be overly pentak or pedantic on, on, um, blocking regressions, because then you just turn into a waterfall team with this. Yeah. This is, I get how it works. It seems a little waterfalling. Um, but I get, I get how it's not and how it maybe is. There's a lot more structure in up on the safe documentation in terms of how to, how to assure that this doesn't become a waterfolly process. Um, the role of this branch is primarily to, um, enforce Dev's behavior of what you expect from the lower branches. Okay. I get it. I'm going to read through it because I have a plan now that I like, but I'm always looking at adjustments as needed. This model, along with the idea of a feature keys, I think is a, is a good way of blocking risk. All right. So this is a nice segue. So we talked about everything from the Dev side, release engineering. We haven't talked about, uh, a little bit through the PM role in this. I want to jump to that. And then, and to kick that off, we'll do that from the mailbag. So on the Slack channel, one of the three dot slack.com. Yes. Let us know if you're not a member, let us know. And, and we'll add you to it. There's a lot of great content, a lot of great questions that don't appear on the air. We have a new member on the Slack channel, Marcus, welcome Marcus. And he asks, I'm working with a team that is totally on board with going to a more sustainable quality models, such as unified engineering, though the PMs are more conventional and want to know how much longer it will take for features. If devs are testing and prioritizing bugs over feature dev, they really want to be able to plan a soft launch and set expectations with leadership and are unfamiliar with continuous delivery and no shut down, uh, polished phase at the end. Do you have any experience advice on how to tackle this? I think we've probably both been through this. I'm still in it now. RPMs on my team still very much live in the must plan. Let's look at capacity and we'll plan for that. And they try and put in, and they do a reasonable job. They put in test work as part of the monthly backlog as along with the dev work. There's a couple of things wrong with that. And I'll let you have probably a lot better ideas here, but what's the quote predicting things as hard, especially about the future? Yes. So I think test estimates tend to be just as inaccurate as dev estimates. But unfortunately what happens if, uh, what I've seen is you, when the dev estimates go haywire, they just go, okay, we're not going to get the test work. Not always in some cases. So, um, the challenge in that transition to me is going from. So by the way, that was actually one thing that's interesting, right? Cause the PMs are saying, how much longer is it going to take to produce these features if dev owns the testing? Right. They, um, in the prior world, right? If tests on into testing, it's all, um, right. You're just shifting who's doing the work. Right. The same works happening. The same works happening, right? But now PM has this view it's going to take longer. And I think that's interesting because, um, it almost articulates a belief that I believe PMs have had. I don't need tests to ship. So now what what's happened is this, this hot path to ship has been eliminated from, from PMs repertoire. It's no longer in their toolbox. Yeah. My, all that's true. Right. And I don't know if you're going to, uh, to answer the question or try and answer it, I don't think without actually doing any of the testing or any of the development, I don't think you're going to know how much longer it takes. This is why we do iterations and learn from them. So pick a chunk of work that you think can fit into a two week iteration, you know, stack rank, because it gets done in order and which includes things being test complete and see how long it takes, see what your, what your throughput is for if things are to be completely developed and done. The completely agree. Right. Um, the, the, the first thing is to measure the, in Kanban, the, the thing I really like about Kanban is essentially once work starts in two weeks, once work starts in between now and two weeks from now, that work will be completed. That's that is a commitment that my team has made, but with PM engagement, they are often more concerned with. Well, right. But I want to know when this item that's 10, two weeks iterations from now is going to be done because I need to set commitments. With operating the, this is another one of those paradigm shift changes where people are, um, used to setting and resetting expectations on a six month cadence and what I found is once I get, can get them to trust my model, that the, the way I'm going to execute differently and realize that they can trust that that cadence, um, then PMs will turn over and find out that this model is actually more valuable to them. The challenge with their model is they want to set expectations for six months from now, but in one month from now, when we realize that there's this P two thing that we now have to do, um, because of the learnings of what we just shipped, their model doesn't account for really changing these downstream it expectations. It really creates the world where you're trying to compress features into a much tighter timeline than you should. Um, so another shift that happens. That's been interesting for me to observe is, uh, the traditional PM is, you know, they want to own the feature and the schedule and be, and then the coordination and all these things. There's much less of that to do in the new world. I just turned the corner now where, um, uh, our PMs, what I tell our PMs is you can make sure you understand what the features are based on cut, not what you think is cool or not with the VP. Thanks, but customer, you know, feedback, and then groom and re prioritize that backlog we can't, there's no way we can predict what we're going to do three months from now, but if that, you know, you basically can figure out our throughput and you can figure out, uh, the prioritize backlog and get an idea of when things will show up, but we need to, part of the shift is getting out of the habit of thinking you actually know what you're going to be doing three months from now. The challenges is a lot of these PMs have been making promises, right? And that's the thing that you got to, what they view is a commitment, a PM who owns delivering to your team feature requirements, um, who doesn't own the schedule can actually be more harmful, but you have to get rid of that. If you want to get out of the waterfall world, what I mean by more harmful is, okay, now I just deliver feature requirements. I have no accountability to the schedule. Therefore that's your problem. Figure it out. Right. Which is not, you want them invested in the overall team success, not just be the guy on the Hill, um, making demands. Yeah. Going back to say for the thing I found that works best for me in terms of getting them aboard on the journey is, uh, what's known as WSJF weighted shortest job first, and I basically say, Hey, we can adjust my schedule every week, once a week, we can adjust it. Um, but only on the work that my team hasn't started. So if they started it, that's going to go to completion in terms of the next stuff that's up, you can change that. How you feel with one condition. I want to make sure that we are in agreement that this next set of list is the highest ROI, which means business value that we predict over the estimated cost, right? So they bring, they bring the business value equation. There's a way to objectify this. I bring in the cost equation. We have a discussion and then we, um, we iterate and we try to do this on a weekly basis. Cool. Yeah. So I'll loop back to the question real quick. Uh, we're actually talking about the question. One blunt way to answer the question is going back to what you said is the same amount of work done by different people. So how much longer we'll take a ship it on one hand, it should take exactly as long because the same work is happening. On the other hand, it could take longer if developers are learning how to test. But on the other hand, the game of, of what I call bug ping pong where the developer says, here's my code test says, here's a bug developers says, here's a fix test that didn't work that ping pong game is very inefficient. And if you get rid of that, it should take less time to ship. So the, so it's all boils down to iterate, learn and repeat. I think in the long run, it's faster, but as things come up, as people learn things, there may be some time in the first few, uh, sprints where it takes longer. In the first few sprints, it will, it will take longer. Uh, the best advice I have in this particular situation, uh, particularly if you're going to go with a unified engineering model is essentially give many, I blogged about this. Maybe we, I could dig that up. You give the dev team a 75, 25% rule. You give the test team at 25, another 75, 25% rule. And then you give, uh, the, the new leadership teams in this unified engineering model, a timeline where you expect both the dev and test to, to come to a 50 50. Now, what the hell am I talking about? Dev. I wonder that every time we talk. Dev, your job is going to be 75% dev, 25% learning how to improve your testing from the get go test. Your job is going to be teaching dev how to do testing and 25% how to do coding. And the trick for a manager in, in this aspect is to figure out an aggressive, but achievable flow going back to a book ending our topic, such that these guys merge their skill set and their knowledge into one amorphous unified engineering blob, they both need to teach the other side how to grow and become a unified team. Perfect. I hope that answer is good, Marcus. Yes. All right. I'm still Alan. And I am Brent. We'll see you next time for episode 48. Bye guys. 
