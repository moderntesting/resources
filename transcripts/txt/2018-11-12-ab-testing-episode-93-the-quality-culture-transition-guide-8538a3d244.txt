The modern testing podcast join your hosts Alan and Brent I am mindless agile robot I must iterate as we talk about software engineering software quality leadership and whatever else comes to mind now on with the show hey Brent hi Alan it's good to be back yeah and thank you for listening yes been a rough week Alan I'm sorry I'm sorry we moved into a we at unity yeah the thing I saw you were in two headquarters oh so no no no no no no no so a test bash is going on this week shut out the test bashers in San Francisco and Philippe walked by the unity office probably the main one in San Francisco where test bash is and waved at it we currently have two different offices in San Francisco because we outgrew that one so we have one for ads and one for the rest of unity at some point I believe we'll reconsolidate in a larger space so that's that was my comment about two buildings but even better I currently now work in hands down the absolute nicest office I've ever been in in my life I visited Google and I visited Facebook and screw them our unity Bellevue office is sometimes you walk in the rooms you just laugh cuz they're over the top we have there it's really good it's really fun even our in a weird space before we were we were renting some just some random office space for a shoved in there until we could build something and we're in Lincoln Square those you know know the area the new Lincoln Square building which is four blocks away from the old Lincoln Square building where I used to work on Microsoft Teams but it is very good we still get lunch served every day and now we have our own kitchen on site so we have chefs and food staff that prepare that for us and it is fantastic I will say the time so there is a when when James worked at Google he invited me over several times to go do lunch there and the lunch experience at Google is just yeah there's is there's a choice there because there's so many people they can be there's different chef stations depending on what you want to do we get one lunch for everyone there's enough right of there it's very good so anyway office is good I missed the grand opening the week they moved in I was in Europe visiting with my team which was good Europe was good got I had meet with the group formerly known as my leads because only one of them still works for me anymore through the power of modern testing I still coach mentor helped them a lot all of them so that's going on but interesting conversations about what this means and and how that fits into how I guess at a meta level how what happens when modern testing takes off we already had a message from one listener who did work himself out of a role and a job we took care of we talked about in a mailbag a few episodes ago I have plenty of job and plenty of role left but I'm also used to things with larger scope so I'm trying to the thing we're working together on it's good to have this group people to work with is how do you if you're you imagine the visual I guess is is as I'm delegating more of this work away to developers and other people as we move towards something like modern testing what do I feel that void with that gap with and some of this just you know some of that scope continues but what happens is is more like it's delegated I do gain more capacity and it's good to have a plan as you gain capacity and ability to do more stuff you have a pipeline to fill those things I have a pipeline but the water is not on full blast it's trickling in some working on that that is those such the transitions can can definitely be challenging yeah I think and I was prepared for it it just what happens is again with the visual if it all of a sudden pours out faster than you expected yo wait I got to turn the water on over here so imagine you have a bucket and you have water pouring out one side you have water pouring it at the same speed your bucket stays full my water started pouring out of my bucket faster than my incoming stream yes so so the capacity went up as the water level went down not a huge issue but just something we talked a lot about like what do we do what are some options just trying to find the best things to do we is the group formerly known as my leads oh so we had our it's not just you they're even having no no no cuz they're there in no no it's mostly me okay mostly me all right so anyway we work together are there consequences to know of your leads express or your former leads expressed any sort of negative consequences absolutely not they're they're they feel supported by their new manager they do they do all right all is well oh yeah that is we done data science what yeah that's that's what you do next data science I should be doing more with data and I have a couple options there but probably not to be discussed here okay I don't know if I've ever mentioned this before one of the thing before we get into the meat of the topic of the day is I think my LinkedIn profile my advice is and I did this for a while at Microsoft is just don't put your title in your LinkedIn title don't just for when I did generic employee as my title as my job title the random recruiter and BS mail I got from people went remarkably down it all depends on where you are in terms of wanting to explore the the job market I well no because there's two things I get I don't just get random job recruitment things I got two different emails this week asking me if I wanted to be a contract s debt on Windows we looked at your profile we think you may be a good fit for this I said did you know did you did you actually respond no I didn't okay the thing is I don't want and and but what's worse than the random recruiting things is the amount of vendor spam I get both in LinkedIn and somehow they got they figured out my email address I don't know where but the amount I get sent to both my Alan angry weasel calm which listeners know and my my unity account on you let us help you revolutionize your QA testing business with our QA automation tools and and testers we can help you improve the reliability and stability of your testing process and I'm just making up crap but that's what their stuff sounds like too and then not only do some of this stuff that I delete or go straight straight to my spam folder some of these vendors actually get mad that I don't reply Alan you haven't replied to our mail what is wrong with you what the hell is what the hell are you doing why don't you care about quality not in those words but but follow up after follow up can I please have 30 minutes to tell you how stupid you're being by not contacting us and holy crap like non-stop I get 20 a week and now they're set up they all go to my spam folder so only see him I go empty out my spam make sure nothing good in there but it is absolutely over the top ridiculous like no I don't want to hire an army of vendors to test my web by website because 10% maybe 5% a tiny bit of what I do our websites and no I don't want to write a gazillion selenium tests just this morning I got a note I got a note over LinkedIn saying hey are you interested in selenium certification you know my answer is that I didn't lie yeah it's no trucking way so I yeah I that is and my title is I think this quality director and not QA director not test manager I want to direct quality I want to be in charge of quality which I which means I influence a lot of people and sometimes I don't remember when someone oh I signed up for a webinar and I accidentally put in my right phone number and they called me oh dude and I didn't what happened was is it was a Chrome autofill and normally I purposely delete out the phone number or I'll alter it if they require it and I must have missed it and they called and wanted to know what do testers do and said not what you expect what are testers you know what you expect leave me the hell alone yeah I know they're I know this is their business and but hell and then one last thing is every once in a while I will because I'll glance at some of these things I'll just kind of see what they're selling and go oh god no everyone's mostly something wow that's actually kind of cool and I won't give any names here but I will follow up a little bit and say well tell me more about this how does it work is there a demo cool or a video whatever and then I asked about pricing and it is a tools are a crazy market which is weird giving how many good tools are available open source because some of these tools are three thousand five thousand ten thousand dollars ahead subscription for fifty thousand dollars a year like wow that's a lot of money even in Microsoft dollars yeah there the but then again you balance what's only half an employee for a year to have that well the problem is is that is again these tool companies that are essentially targeting niche markets yes all right their license fees have to be through the roof yeah I know they had to make money I get it I get the business model but it's a tough place to be in it I mean you have only a certain level of business size that can support that cost yeah yeah it's it's not a business market that I would want to be in no no and a lot of times I have to shy it away there is this this one tool that that I really really really really love it really makes things simple but it's six grand for a single user and you have to renew it on an annual basis yeah and I'm like you know what don't love it that much and I could rewrite it with greater than six grand worth of satisfaction through Python or R for for my needs yeah the the frugality of I mean I'm sure it's the right price for the market but the frugality of it of me my frugalness makes you think God that's really tough to justify anyway but vendors if you're listening I know you're not please stop if I don't call me I'll call you yeah I the the vendor stuff even the people I get the same crap and the problem is it is there is good stuff out there but I know it's there what the good stuff I know it's there if I don't I'll find it so I got one just this week and it's it's one of the few I've gotten recently where where I like huh that might be interesting and it's Facebook reached out they they're looking to bolster their leadership team and what they call the data analytics space and I'm like okay that could potentially be interesting wait where's Facebook Oh Seattle yeah no I guess I'm not driving or working in Seattle you take a bus I take a bus nope do I do mailbags first or do the thing first let's do mailbags first because I think it feeds in okay hey we have a couple questions from the mailbag from Johan his question there have been a lot of discussions about how to get testers to change and adapt MT but in my work now I talk more to developers so I was wondering what parts have you found hard to get buy-in from developers and how do you get through to them as an example number five seems to be a big thing for testers but with developers I've not had an issue with a single number for me developers have liked the idea and bought into them almost from the start and the issues start to come after a while when they understand how much responsibilities they really have it's kind of sounds like he's figured it out already MT isn't about improving or adapting your testing as as an individual at least MT is about leadership and quality if you're able to lead the team towards those things and improve that quality culture then you are then you are doing the right thing read me the first sentence again before I think in his elaboration he answered it well so the here's the question what parts of modern testing have you found hard to get buy-in from developers and how do you get them it depends on the developer I think in my experience on some teams just getting him over the hump of like oh you can actually do testing is once they begin to understand that things go much quicker but if you have an old school like I can imagine developers at Microsoft you tell them to do testing they go screw you not my job I would say the the hardest part of it is is on that front right multiple folks have pushed back on MT making the statement but but dev doesn't want to do testing right and now number one I'm pretty sure I've said this here before right you don't build a whole test discipline just because some other discipline doesn't want to do that work okay that's number one number two once you've worked with the developers then this is where I would say is the hardest part when when I did unified engineering it was actually rather easy because I basically said you know what developer so if you recall I had a combined team some that came back from xdev some came from xtest when I stated this requirement it the the test was like oh sure makes sense no problem okay but what I found is as the developers who really didn't want to do the testing they would take shortcuts and they would ship the prod and then there was another process that I had where essentially bugs get funded by the whole team and so and on the board is fairly transparent so when when you hotshot dev specialist basically gaining the perception of the team has to prepare for an interrupt every time your thing ships the social behavior begins to to I get it I get it I think it's preparing there's a perceived perceived velocity drop when developers own quality and testing it's not perceived it is real no no it's perceived because I'm if because they don't count the rework time that will happen later after they find all their bugs that's why I mean perceived so the other thing that I did back in those days is I had the similar sign you know like you see a like construction sites a sign that says zero days without incident man so I had a similar thing and I said okay guys when we get to 30 days without anything lunch is on me not Microsoft me we're all gonna go to roost Chris it took them six months to get there and every time it got to like 28 and then one of those developers checked in something and didn't do enough testing right the social pressure kicked in the but also having that measure and that goal was something that helped positive behavior the last thing though because it's part of this where they have this theory right oh it's gonna delay time it's gonna do all it's gonna add time delays I don't want to do this work in the first place once I got through that hurdle once I got the 30 days bug-free we didn't have a we got to like 60 once we got the 30 because what happened is they kept on having to re-arc they had to re-discuss they they both they added on the right test cases and it turned that developer completely 180 degrees to a place where they were upset when I left because they're like holy crap what if my new manager forces me to go back to this old stupid world right so it's if you make it visible then the problem that you're talking about kind of goes away yeah but I guess maybe even the shorter answer is there may be some initial problems on some calm legacy dev teams but but I think in my experience beyond that developers are they see much less controversy in MT than testers do because again modern testing isn't about testing it's about building software in a way that is much more efficient and delivers customer value better and more frequently than traditional testing so it makes sense his experience makes sense I expect that would be the same for everyone will be less controversy with dev teams in fact I think it was I Michael Cross who showed the video of my test bash Brighton talk on modern testing which was the debut of Monty the modern tester and his dev team washed it and they said things like oh it's just common sense so I think it's gonna be typical on most dev teams and and the ones that freak out are the ones that either need a lot of work from you as a leader to get them there or teams just to run away from and let them die a slow miserable death of failure what's the next question on that bright note from Ryan Ryan the Ryanator for a team that is starting to practice the MT principles what would you recommend as the first steps how would you show MT's value to stakeholders managers that have a traditional testing mindset I see now why you thought this would be a good segue into the main topic of the day so let's answer this question for the next 25 minutes okay if you don't mind I don't okay good good to be clear and I mentioned this before but the lead-up here I'll say it again I have not once ever gone to anyone at unity anyone on my teams is saying here's this thing I call modern testing we're gonna do it here are my principles we should all follow them that's one it wouldn't work but two it's just not the way I do things I don't think anyone should do that well I'm just clear I don't so I don't want anyone to think that oh you can just say you're doing it and you'll show people the the video and put the principles on the wall and bam we are MT there are a lot of folks that have asked for like specific steps to do this and I'm honestly rather worried about being overly prescriptive because it's gonna be a tautology but leading people leading teams towards modern testing is a leadership challenge yes so one way but it's also not an intellectually lazy one correct so well let me tell you a little bit how this came about I the thing I'm about to talk about I gave a talk at the test leadership Congress in New York in May I believe keynote on leading a quality culture and I at that point I talked a lot about quality culture what it meant to me a lot about leadership test leadership conference Congress but I hadn't thought at least formally about what actually is how would you define at a more granular level what a quality culture is and then maybe just a few weeks later I was in a conversation at unity with my manager and a few of my peers and this idea of like I start I was I quality culture on the mind I was talking about quality culture and I said well what is it how would you define it and and I said let me I think I can do that let me write that down and I thought about it for a couple days and and thought and thought I said I don't know what to write down how do I how can I quantify in some way or what how do I describe a quality culture in a way that covers all the things that would that would lead a team towards quality I very much put a modern testing lens on it and that I looked at agile and lean and the modern testing principles I thought what what makes a team function in an empty way and all of a sudden at some point something clicked and I do so much work air-quilt work just driving around and walking the dog and thinking that when I spit this thing out originally it was like an hour of work and it's had some tweaking since then but not overhauled edits so what I built after that long diatribe is a quality grid it's I I'm pausing because it frequently gets referred to as a maturity model and I hate maturity models for many reasons one is just a basic allergic this to things like CMM CMMI how about the quality culture transition guide let's call it that quality culture transition guide if I had internet access I change it right now my original doc so what I did and the way this worked out and just do my thought process before we go through these is I listed the hard part was coming up with what were the attributes of a team really clicking on frequently delivering customer value accelerating the achievement of quality what does a good dev team a good engineering team look like delivering that as able to break it down into about I should count them eight attributes but I'll read them then we'll kind of go through them one by one I might have mentioned these on a previous podcast we'll dive a little bit deeper today quality and test ownership and I'll come back and go deeper into these like who owns quality technical debt and maintenance code quality and tools customer data analysis the development approach learning and improvement and leadership emphasis and Brent I'm gonna ask you to interrupt me whenever you want otherwise I'm just gonna talk a little bit about what I did those those headers are sort of horizontal aspects yes you think or expect teams to be in fact it's probably a good time to interject a partial answer to the question is I would look at how well the team is doing on each of those aspects each of those horizontals and some areas they may be more I'll put it in the accelerate way some teams may have more capabilities in those areas than other in some areas than others you can use this quality culture transition guide love it to figure out where one where you are but not to grade yourself in the in the old world of maturity model but to figure out where you may need to make improvement so let's talk about testing breadth wait before you continue on there's there's one thing I would say sure so first off with anything that's the one paradigm here you often hear it as you can think of it as a crawl walk run type model exactly right now generally my guidance when dealing with these type of things is first you go through an inventory where you're at and then you go okay how do we get to the next column don't try to skip columns generally is what I advise because a lot of times that creates more problems than it's worth I definitely agree and but even that even that approach sounds a little bit too much like the old maturity model approach to me so what I have had teams do is sort of assess themselves on where they are on the model sometimes just the the QA person on my team but more often with a with the dev lead with them and then not worry about necessarily about getting to the next box but okay we've gone through this now we've it's forced us to take a different kind of retrospective on overall on what the team is doing and how we approach software and delivery and building things and what are one or two or three areas we want to work on improving in this transition guide comes up a lot in retrospectives and in the incorporation of an experimental or experimenting culture where you say hey let's brainstorm come up with ideas around what what actions we should take let's take those actions let's also determine how we're going to determine if it's success succeeded or failed and if it failed no judgment call except if we you know try it again or continue trying to power through that's the biggest thing that I see let me I have a gazillion examples of how we've used this so let me just go ahead get through it but I gotta get a little bit more I think the listeners need a little bit more than just the headers so I'll talk a little bit about how I built the model and what's in there so I built a transition guide a model I call it the thing sometimes to avoid calling it any sort of maturity thing but there's a starting level where the thing basically isn't happening where there is no testing breath where people assume that doing some happy path tests is enough what horizontal you talking about I'm talking about testing breath okay this is testing breath so if you have a lack of almost complete lack of capability in testing breath you're probably focused almost entirely on functional testing and verification you may do some other things but they're not planned and sporadic whereas if you are super mature and the way I built this was to kind of describe what I thought like what is it if you're basically not doing this and what is it like if you are like rock stars kicking butt at this superstars and if you're at the top level building a multi-dimensional quality strategy is part of how the team builds software design includes that your testing approaches consistently cover all areas of like the agile quadrant you want to use that model you're thinking about all aspects of quality your continues to thinking about what are the different ways I mean the test is where do we need to do perf securities involved early as a specialty but also you're just thinking about all the different things and go wrong all the time and we've we've dealt with teams like this so there are teams that do operate at that level and of course there are levels in between where maybe you're you're not you're getting to learn things but you're not doing them consistently there's there's levels in between but the growth is from one end to the other on the testing breath you're saying that there's a multi-dimensional you say thinking I don't necessarily think you're referring to a you know a traditional test plan no I said a quality strategy how do we build this with quality meaning right I'm building a if I'm building YouTube probably not the best MVP to start with but if I'm building YouTube I'm thinking about scale and reliability and security and all those things from square one they're not like oh wow I guess I should think about scale so there's the old-school 60-page test plan no no I'm just saying this criteria though it does not okay because the old-school 60-page test plan was often not a strategy with often a list of things and even worse a list of test cases that would be done against these things I don't want that I this is about and you you're playing devil's advocate here but this is about a full-breath quality strategy as is planned and executed as part of building the thing you you and I have been on teams where illities any perf or security or scale testing that's what we did at the very end of the product when we knew we're gonna ship in two weeks anyway and we found a bunch of bugs that people weren't gonna fix because it was just too late because oh that's gonna be an architecture change we can't do that now yeah the the other thing I would say in there would be right adaptability is gonna be key in there right I think the biggest thing so I think you're trying to express an element of holistic aspect yeah I want you to recognize like all these things matter and we'll go a little faster through the rest so we can finish well let me know yeah cuz we're never gonna finish go ahead go ahead this number one I don't think you're saying anything around prescriptive or are reactive right as you know I don't want everyone anyone building the 80 page test plan what I'm saying is that all has to be done before we ship all aspects of quality are considered from day one to day in that's it that's at the top level and there's steps you can think about what you need to do to get there in between you again we can all think of the baby steps I'm not gonna list them out here yep quality and test ownership at level one is traditional testing I should even call it level one when you have lack of capability you're doing there's a test team that does all the testing because it's their job and it's not and developers do developing because it's their job okay but at the other end I could probably set up with the last line in this thing which I did not get any pushback even from people outside my team where you truly have whole team owned quality and one of my gripes with agile testing is even though Lisa and Janet Lisa Crispin Janet Gregory describe whole team testing is everyone owns testing and quality often what I see unfortunately on agile teams is even there is they iterate but the tester stills the tester on the team still does all the testing the agile tester yeah I don't think that's Lisa Janet no it's definitely not their intent they they sigh visibly or or with verbs every time this comes up but I'll read the end of this that the test specialist focuses on coaching the team and assisting quality efforts sounds like MT blah blah blah and then last sentence where I did not get any pushback because I've shared this across all of unity is teams at this level may not need a dedicated quality specialist nobody shit their pants nobody freaked out yeah I think we've talked about those things enough on here we don't need to go any deeper yeah technical debt and one thing on the last one that I'm tired of if everyone owns quality then nobody owns quality alright that's it okay so tech debt and maintenance this is the biggest thing here something talked about is just working from a zero bug backlog but we also need to recognize that bugs are not the only form of tech debt keep your debt paid off keep it zero team that that is very has zero or a little capability here has a huge bug backlog they have all kinds of to do's riddled through the code they have they don't even know what static analysis linter errors they have because they don't run those tools they have a huge both known and unknown mound of tech debt whereas teams on the most mature scale have little to zero leaning towards zero tech debt they just don't carry it forward they pay their bills on time something else we've also talked about in the context of empty a lot or they they cancel their subscription right to me a bug is not necessarily tech debt right as we've talked on multiple cases there's many a bugs that are never worth fixing right but I think just not even but I would say keeping those bugs around even if you're not going to fix them that is debt because you end up looking at those bugs over and over again that's waste is in my waste yeah fine and in between you can see like okay we're keeping things triage we have a we have a fairly low bug camp but we're happy with 20 and that's I guess it's a start but you can look at where you are in between and where you want to go and figure things out the team that when I started at unity had the highest bug count and was the crummiest quality is now down finally under 10 total bugs that they carry that they carry and there with the goal still to get to zero by the end of the year but in fact another one of my teams that was when that team got low there was another pair of teams that were then my new highest in the 30s and they just got to zero yesterday day before so slowly but surely almost all of the teams in my jurisdiction area care about are still on track to get to a zero bug backlog by the end of the calendar year and the teams that have gotten there and sustained it what's their feedback it's it's freeing right no I know that I'm yeah yeah that's how they feel yeah it's all like oh this is much better but they don't miss doing triage beans we look at the same bugs over and over and over no yeah I don't either yeah but the other phenomenon that I noticed is that once you get to that state and you've maintained that state it becomes a lot clearer that how bad feature development was for you and you were carrying that bug backlog right the thing I've noticed with all the teams I've put them through is essentially this model sort of encourages more scalable architectures and a scalable architecture allows you to produce features when you trying to figure out how to not fund the bug but string a feature through a minefield of a couple hundred bugs your estimates go slower in your release like for sure yep you are correct go next attribute is around code quality and tools and this means a team that does no capability here they compile their code and then there and you can see these things interact because if you're you're not going to be generally I have a hard time thinking of a team who had no capability in some areas but we're very very high in other areas so team they're not running they're probably compiling at a look not at the highest warning level these aren't independent attributes right exactly they will just like the modern testing principles yeah so they're not using any to any code correctness tools things like code coverage which is a wonderful tool in a horrible metric linters compiler warnings other static analysis tools security analysis tools teams that are very mature here their CI runs a crap ton of code correctness tools because that's where we can catch the bulk of those things and that's where they should be caught not by tests down the road this is like the level of tests that run before unit tests yeah and then goes with tech debt so you turn on these linters I see teams turn on linters and go oh this is bad I'm gonna have I'm gonna run the linter but we're gonna turn off all the warnings like I you I get what you're doing there but you you yeah teams that are very mature here they they are constantly trying to find holes or risk using code coverage they have linters and static analysis tools running on on every check-in to make sure that they have the highest code correctness they can and in the middle levels maybe you're starting to use things be to look at the results or you turn or you turn off a lot of the rules for our linters you're not I think teams at a mature level here are also not just running these tools but they're looking for additional tools my partner what they do is like oh what else do you define this looking for code correctness tools as part of maybe some of the investigation that comes out of a retro or an RCA analysis yeah the one thing I guess it's RC analysis or otherwise it's redundant release no no root cause analysis rather than saying RCA analysis is redundant right it's like an ATM machine anyway go on right yeah the one thing I was actually really fond of back in the day was measuring cyclo-matic complexity oh yeah yeah at the nice and even complexity metrics are a great thing for risk we had you and side to engineer unity had a hack week they had to have one every year I haven't been to one yet my travel is a little crazy this summer but I did make sure I took a half a day during hack week in the Seattle office and just do something random and the random thing I did was I wrote again using some helpers from the NPM library I wrote a little node app that would look at the files you had checked out run a complexity analysis tools around a bunch of different around cyclo-matic complexity Halsted metrics and some other complexity analysis and we give home with an overall number and I would flag files or functions that had in just your checked out files that have a high level level over and whatever N was of complexity because complexity doesn't mean the code is buggy it's a smoke alarm out of fire it means there is risk there yeah I mean that the one thing that I haven't observed yet is tooling that can analyze how you've put together your code and help to simplify it yeah hey if you if you incorporate this design pattern instead of the thing that you did you'd be able to reduce part of it is part of the maturity here is continuing to search for things like that yes chances are eventually they'll exist next thing near and dear to do you have a heart no okay near and dear to the cavity and branch chest where a heart would live is customer data analysis yay we're at a where you had low capability you don't do it you don't collect anything about higher products being used and then you can imagine we've talked about Brent's data maturity model in here before right but I think the lower lowest capability I would hope this doesn't exist but it would essentially be your entire team functions off of what's the founder syndrome which is essentially no founder of a startup has ever has ever understood why his idea isn't the hottest thing since pancakes yeah and I'm actually gonna read through the model here because I think it'll help explain it and I'll go quickly I'll skip so free in this transition guide I wrote I wrote a couple levels in between to help figure help teams like figure out where they were in the middle and figure out what kind of things they could do to improve and I have a whole accompanying doc I wrote internally it talks a little more deeply this will be in the twenty twenty eight release of the modern testing book I'm just making that twenty twenty eight yeah I figure it'll take that long it'll be obsolete like oh we're coming up on the ten year anniversary of how we test off right Microsoft by the way I'll need to write a blog post about that so anyway on data analysis I mentioned like it's data is untracked or ignored with a few more capabilities a little more higher along the transition guide you're gonna have some data track that may be used to understand quality prioritization data may be discarded if it does not match intuition or anecdotal feedback and we've seen this happen but you're starting to collect data you just don't trust it yet because it's it's yeah it's what do you call this data affirmed yeah that's similar to that level it was a Steve Rowe call it that but I've now stolen it all right yeah and I stole it from you yay me and then even before you get to the most you know optimal level you may be at a level where the team has at least a handful of metrics in place that help them understand feature quality and customer experience there's probably some holes in interpreting the data but those usually address quickly instrumentation and or analytics as part of the requirements are done definition and almost all and almost always done as part of feature development so at that point you're well on your way to becoming data centric but like all things that are like maturity models even if we don't like to call them that there's a level where that can be okay for a while for some teams you don't have to get to the highest level in everything no I like that it's a guide yes it's to help you read you read through and figure out okay here's something I can do more of this is actually the way I want it to be used is for I mean in a very immature quality culture you might think that okay once the test team plays with the buttons and things for 10 minutes or an hour or a day then we ship and it's good but looking at what are all the things that actually influence a quality culture two more rows to go through three more ways to get last one can you reread that very quickly again no because I paraphrased what I wrote so it'll be even different so the team has a handful of metrics in place help them understand feature quality customer experience although there may be some holes they're usually addressed quickly analytics as part of the requirements or done definition and almost always done as part of feature development okay okay because what I think you said was instrumentation before analytics is a much better word yeah I have I used both in here so but the one problem I also see and this by no means is a north star that we're trying to guide people towards and that is a lot of times you'll see in the traditional world you'll see a PM with their 60 page spec listing out requirements and then there's a three page section of all the instrumentation requirements and it's just a grab bag of random crap here I would say go back to what episode was it 62 the hypothesis episode where I I don't know remember the exercise I walked you through yeah I don't know it was in the I was in the 80s that's far more helpful all right really important thing is the development approach and this is where a lean and agile come in at the zero capability level you have no approach it's pure cowboy write it and compile it and ship it world we're at the end of course you have a system Brent and I both prefer Kanban but basically you have working in small batches flow is high you probably are using experimentation to deliver features or delivering things behind flags you have a development approach that allows the team to ship quickly and safely which is worse try to think through which is worse big design up front or cowboy equally bad that is a good question I like to tweet that well they do I want anarchy or over prescription and very quickly because we're a little tight on time yeah the last two are learning and improvement I mentioned earlier we're and we've been on teams that don't give a crap about improving there's no retros they don't try and get better at anything they're just happy to crank out their crummy software day after day where on the other end of the spectrum you probably have teams where you do have teams who retro they do recognize that retros are the most important things they can do every week the whole team is a learning organization people focus on learning and getting better and growing as part of the software development and that helps improve culture overall which reminds me to refer to the lens you only work that shows that organizational health which I think comes from this is direct as a direct correlation with product quality it does there is a absolute principle there that may be of what you just mentioned you're gonna post this up on MT at some point at some point I'm not sure if I want to share the whole grid yet but I will okay and then the last level is around leadership emphasis which I you gave me some feedback which I thought about and rejected I don't think that mandates of thou shalt have a quality culture work so the the maturity here the growth is a little interesting so we'll just cover it briefly and then you can send us a bunch of mail by questions we'll dive in deeper in the following weeks is at a at the lowest level here there is no leadership support zero because they did they just there's nothing that that supports sort of that cowboy culture we talked about in development approach and everything else and that can come from multiple different ways yeah whereas as you get a little bit more mature the leadership communicates quality is they like say quality is important it's part of what we do it's in our vision etc and at the most mature level it's you get to a level where leadership doesn't need to be involved because the team is internalized qualities what they do I mean it's still part of the rallying cry anyway we'll dive deeper later but that's sort of how that works and I didn't get to talk about the examples we'll do that why don't we plan on doing that next time yeah there's more I what would want to talk about for Ryan's let's figure out a good agenda of topics and things we want to dive into next time hope that was a good start to an answer for Ryan's question and we'll continue to answer it on the next time we talk on A-B testing okay goodbye everybody bye 
