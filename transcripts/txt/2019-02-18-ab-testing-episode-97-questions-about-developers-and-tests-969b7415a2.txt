The Modern Testing Podcast. Join your hosts, Alan and Brent. I am Mindless Agile Robot. I must iterate. As we talk about software engineering, software quality, leadership, and whatever else comes to mind. Now on with the show. Happy snow day, Brent. Happy snowpocalypse. Yeah, so we had a little bit of snow in our area. Yeah, my children were taking bets last night. My daughter said, Daddy, I bet you we won't go to school in February because mid winter break is starting next week. Yeah, my kids go two hours late today. So they're getting a little bit in. But what's worse is I went to the office. I went to my office yesterday, the first time since before I left for my trip to Europe. Because I got back, I was sick for a couple days, and the snow came, and then I was snowbound, and then I wanted to leave Wednesday, but my neighbor managed to get their car stuck in the snow at the end of our perfectly flat driveway. At the end of your driveway? We have a shared access road that goes to our driveway split off from each other. And they went to leave and they got stuck in the middle of the flat driveway. So that happened. So it was good to get out. I'm happy to be out. I was so happy with the snow day because, as you know, I drive a big ass truck, and I was able to get into work every single day, and no one else was. We had people come to the office on a few of the days, and there's only 20 people there out of normally 200, if everyone's there. It was quiet. The only way people could reach me was via teams, and if I didn't respond, they couldn't tell why. It was just fantastic. Yaa, yaa, yaa. I got stuff done. Anyway, good to be back. I think we've been a month since we've recorded, given my travel and being sick and snow. So I'm glad we got a recording in today. We're recording on Friday as usual. This will go out on Monday. And then while you're listening to this on Monday, because everyone listens to the show right when it comes out, I will be skiing in Whistler, making my annual pilgrimage up north to do things that I probably shouldn't be doing at my age on skis, but we'll see how it goes. So you're a skier? I'm a skier. Snowboard as well? I snowboarded last year with my daughter one day, and just thinking about it hurts. So I am going to ski with her this year. My daughter's a snowboarder. I definitely got better. I definitely got better, but I crashed a lot. A lot, a lot, a lot. My fascination with the snow right now stems from the fact that I'm a former Californian. I still think when it's snow-ween, it's magical. But I have pretty much done nothing with the snow this year. I don't even think I have thrown a snowball. Maybe we can do that after the podcast today. No, because all we have is slush. But on that front, my still-at-home son, he made an igloo in my front yard. That's cool. It was. We had that much snow. He actually, and the thing that was cool the day I, a couple days ago, I came home. He had strung through and buried electrical, and so his igloo lights up. His igloo's got power. That is. I'm impressed. That's my son. I'm impressed. I'm impressed. I thought if it was okay with you, we'd do a podcast, and then it would be an A-B testing podcast, and we would do mailbag questions. Sure. So what number episode are we? We're in the 90s. We are in 97. Counting down to that number 100, which I'm sure, what are we going to do to make, what are we going to get it up, whatever? What are we going to do to make it special? Do we want to plan that now? No. I think we wanted to do a mailbag episode. We are. We are. So that was a rhetorical question for you and a question for the listeners of the podcast. What should we do in episode 100? Should we bring back one of our former guests to talk about risk-based automation? I figure that's what you're going to do. We should do something. We'll figure something out. We have not too long to decide, but sometimes to decide, sometimes for you to offer your help. We should take calls into the show. At the very last minute for the end of the year show, I asked people to record things. It was too last minute. I wonder if now is early enough for people to... Actually, maybe we should do that. I'm going to throw this out there. If I don't get at least five, I'm not going to do it, but send me your 15-second or shorter greeting or thoughts on episode 100 looking back as a WAV or an MP3 file. If we get enough of those, I'm making this little montage. It'd be fun. For one idea. Is there any way we could just do it live? Just do it live as I shoot a call-in show? Yeah. Let me think about that. I know I could broadcast it with Periscope. Let me think, but we don't want video. We are not video people. What would it be like to do like... Let me think about that. I'm thinking something. We could do Skype. We could do... I'm sure Percy or Joel do something here. Yeah, I know how to do it. I think I can do this. Only a little bit of setup time. It'd be a little few extra pieces of equipment, but we could take calls during the show. Anyway, how about we do this show on... That would be fantastic. I'm sure it'll epically fail, which will make it a memorial or a memorable 100. Sure. Our 100th and last episode. Okay, on with the mailbag. First. Sorry. It's the only opportunity I have. Oh, yeah. It's plug time. I am doing no conferences in 2019. That's what you say every year. So far. I haven't done in so far. I have done no conferences so far in 2019. So yes, I think we can all agree that retroactively between now and the start of the year, you will commit to no conferences. However, I am doing one for AST, the Association of Software Testing. It will be on Thursday next week. So I guess by the time people get the podcast, it'll be Thursday of this week. So quickly go register. We'll put in the show notes the link. Alan will put in the show notes the link. As long as Brent sends me the links, I don't remember. It is on February 21st at 11 a.m. Pacific Standard Time. I'm going to be discussing... It'll be a modification of the Unity presentation. I'm going to be discussing how to sort of the approach or the journey around building a data-driven modern quality culture. I'm actually thinking I'm going to shift the content about a bunch this weekend and tie it to MMT. I'm thinking that obviously the data and the business principle are a key aspect of that. So I think I'm going to tell the story and tie it directly to those two principles. We'll see. Cool. I'm going to send my team there. I'll be skiing. I'll watch the recording. Your team's already seen the first version of it. I have new people since then. Fair enough. Okay. Can we start? We can. All right. Our first question. We have a bunch of them. I'm going to group a bunch of them into one question that we'll get to in a minute. But the first question is an email I received from Mierich Zalewski. I probably butchered that name. Best I can do. By the way, if you have questions, you can of course, if you're in our Slack channel, Slack team, you can post them there. One of the three.slack.com. You can go to moderntesting.org and find the link to join that team. Or you can just email me, Alan, A-L-A-N, at angryweasel.com. And if you're in transition, I highly recommend you go to the Slack channel. That community is super supportive now and it's thriving. Love it. Yeah. I love that. Somebody will ask a question. I really should answer that, but then I don't because I'm busy, but then everybody else does. Yeah. I love that scale part of it. Hi, Alan. In episode, I'm reading the mail. In episode 94, context-driven testing meets modern testing. One of you said that back when context-driven testing principles were created, there was a lot of unskilled testing. I probably said that. Presumably, as opposed to right now when testing is skilled. Could you elaborate on that part? What are some skills that testers have today they didn't have back then? What are the most important skills testers have today? What skills do they need to have? What are the skills we should hone to stay relevant in the future? That's a lot of questions. I think it's important to talk about the skilled versus unskilled, which is a, it's not a dichotomy. It's not a binary choice. I should have said testers had fewer skills or were less, often less skilled. Yeah. I'm actually hoping that it was you who said that and not me. I did. I did. Because I remember hiring testers in the 90s because they knew how to use a computer and they had some, in an interview, they demonstrated some aspects of critical thinking. So yeah, critical thinking, problem solving, those were all like on the interviews. We didn't care where you came from. So to finish the thought there, the idea was we had an army of these folks not paid a lot of money, but paid a good wage and we could use them to effectively test quality into the product. But what they couldn't do was scale or they couldn't find, once the bugs got harder to find, they became more or less, in many cases, useless. So as far as what skills they have today, they didn't have then, I think I just ranted about this on Twitter is we went from folks who verified a lot of functional attributes were correct, but we need now to be able to use tools to build tools or to use tools that can find a lot more difficult to find issues, to find the things that are impossible to find by hand. I think some of those skills are just technical skill. I mean, technical coding skills, some are technical skills and you knowing more tools of the craft to use and how to apply those. Of course, modern testing, having some data analysis skills, both in mindset and in coding practices, to be able to grok large amounts of data. Those skills are much more important today. But now I'm gonna let you jump in because I finished my original book. Yeah, I was, I was thinking about the day. Right, I'm thinking about the STEs, then they became SDets. Now sort of a more of a unified culture. This is the way I view the world. The STEs, the what, what I remember from them is, as you call out, they were cheap. We could hire a whole bunch of them. And the ones that that, and then just sort of deploy a natural selection process. People who just sort of came in and clicked on the product all day. Right. Sure, that the ROI was there, they would find a bug as long as they had the ability to notice that they found a bug. What I recall back in the day is that when I first came here, what we call, well, ad hoc testing was the dominant form. It's essentially click on the product until you find something. Right. And then the manager would mitigate an underperforming person by putting a kick ass bug count KPI. Right. And now, you know, begins the spiral that we're still trying to kill. As I read this question again, I'm wondering if the inventors of the context driven testing principles would be slightly pissed at me for saying unskilled. But I do believe, again, less skilled, definitely less skilled, less breath in their testing, testing knowledge, less breath in their knowledge of software definitely was occurring up to 2000 ish, maybe a few years after. Yeah, what what I believe was like 97 to me looking at sort of the difference between now and then. Right. We call them STE software test engineers, but really they were, as I mentioned, ad hoc button clickers. Now, for me, that's that was damn officially I have now been in the industry 25 years in January. I passed 25 years a long time ago. The like, wait, a year ago. So we gave them a common title, but it but the discipline wasn't any way, shape or form anything that I would have called a craft. Definitely not. And I think that was true at a lot of companies. I think what CDT did help a lot was take the people who are actually good at it and give them a rallying cry. I think much like yes, and which I hope we've done a lot with modern testing, take the testers that have moved beyond have evolved beyond just being the tester and the verifier. And and actually, one thing we've heard a lot enough to make this part up is people say modern. We're actually doing that. We just didn't have a name for it for modern testing. Oh, right. So I think I think there's some similarities there. What I think we've talked a lot about this recap on this quickly. But we talked about the differences. Testors are engineers are a little bit more more breadth in their knowledge. They have a little bit deeper, deeper knowledge of tools and or coding. They're able to do more things. It's much more of a definitely much more of a craft, definitely much more of there are definitely a test discipline still in many places. Although we have our thoughts on that. What are what are skills though that you think are different now versus say learned knowledge to me. To me, it's it's a lot of we need a lot more of the t-shaped persona today than we did back then. The game industry and I'm sure there's others but the game industry is still the only one that I am aware of that kind of still hires that same class of folks. And it's not even all game companies. I've talked to some game companies who are much more advanced in how they do testing then than the horror stories we hear out of some large game companies. Oh yeah and I think often of Jimbo a friend of Alan and I. One I haven't talked to him. I haven't talked to him in years. But within Microsoft in the game game space he was doing a lot on data driven stuff. Yes yes for a long long time. That was impressive work what he had done. Yeah the data driven stuff. I would say I am convinced that the theme around the new skills are around scale. Yeah that yeah test has to the the testing skill set you have to be able to get to the same amount of risk mitigation at a much higher scale without sacrificing time. So I'm always gonna fall back on data and and doing customer quality analysis. That's good but that's my wheelhouse in terms of tying directly to someone in test. Honestly I'm not certain that I would be a good mentor even on that privately or even on the podcast. I think the questions we ask a little I think that's right on the money. I think their comment about what we the technical skills we need to hone for the future are the skills that help software scale. I think the maybe the questions what questions do we ask back in the day like does this work? Is this automated? Would this work for and we'd look at I have a variety of computers in our lab ever having like a huge computer lab. Yep so they could test on different configurations. I was one of the people I had one of my laptops was the same as Bill Gates laptop at one point so I can make sure that we had a bunch of us had one to make sure we could dog food on the same build that he was dog fooding on to find harbor issues but stupid stuff right yeah but now we get all that stuff through data and the question we ask a lot now is okay that's great will that work for a million people that's great well that worked for 10 million people yes and like one of the questions I asked just recently one of my when people on my team was they said they were gonna do a B and C it's great so what happens if that's successful and you have 10,000 customers who want to do that and the answer was we can't handle that and it's a good question I've say I mean it's weird that's a turning point that's someone who's been in testing for a while getting them thinking about scale as one of the initial questions they ask I think is a really important thing to do and one of probably one of the best guiding things we can get people to start thinking about yeah in terms of a lot of a lot of my go-to examples are right get accustomed to proving and disproving risk on your product by using the the telemetry right that the the example I've given now a zillion times of change how you think about automation use your telemetry to build the oracles not how I even describe it the previous model where where you would right you would use automation to not only drive their product but then you would use automation to verify the product mm-hmm right that last bit is the thing I'm thinking needs to change and it takes it takes sort of comfort with data skills and it takes certainly both approaches take comfort with coding skills cool I think one of the other things testers need as far as skills and we've talked about this in the principles is this ability to coach this ability to help people understand to leverage to not take your testing expertise it's some special snowflakes skill that only you can master but to use your knowledge to make the entire team better at testing I will I even say it further it's always been the case there's an old book I read years and years and years ago that said testing is 50% politics and what they meant is in order to get your bug fixed you have to be good at negotiating and communicating to win people over now that was a world that was highly intuitive right it was a world where the first oftentimes we would be looking at bugs and the product still wasn't gonna ship for another year the but I don't think that's I don't think that aspect has changed the if you're still in a test role you also have to be able to communicate and influence others because last I heard unless you're in a unified engineering org you cannot test quality in right so you have to scale yeah I think that influence and leadership part has always been important and I think it becomes more important as we have fewer testers or no testers or people just with the testing that that expertise on influencing people which segues into the next question which is two questions I'll read because they're both kind of the same question okay first ones from Patrick Alexic says I don't know if it was in a previous podcast I don't recall it unfortunately what arguments did you use to convince developers to do testing as an activity because faster feedback loop if there's a problem could convince some but not all of them and then after shock 9 who I don't have the full name in front of me sorry I'm not they asked me these questions anger weasel a few times on the podcast you have mentioned that part of the quality role you played at Microsoft Teams was to teach developers how to write good and useful unit tests and integration tests and lots of other tests I added that part would you mind exploring what resources books courses that has aided you in developing the framework and approach you took I was speaking to one of the devs in my team and he said lots of times they don't know what unit tests to write I would like to work with them to explore and improve this so the questions are largely around and you can answer this first if you want or you can let me go your call is how do you get developers to write tests and especially how do you get them to write good tests I see two questions number one is how do you how do you convince them to start and then once you've convinced them what what are the training resources to get them going running my technique to get them to start was actually rather easy I own the test org you are responsible for the quality of this I will not be using my test resources for writing test cases any longer so I was able to get away with no I'm changing what my team what what I I'm changing the business case for what I use my my team's people for and then all I had to do was was say this is what I'm doing this is why I'm doing it and much of it is the main reason why we did this podcast right that I would have a more succinct version of explaining to my peers this is my rationale then I would go through and I said but the type of example we will be there to teach you to fish we just aren't gonna fish for you anymore so I was able to get away with it because I was when I was going through this I was in a management position and I own the decisions are why what my resources will do I don't know that that's going to be helpful for many of our I don't think so so I can give a couple stories how I've done it but I'll go back way before teams way back in shoot like 18 years ago working on Windows CE our dev team decided a big chunk of our dev team decided they were gonna start writing unit tests which is great and I even gave I remember I gave a talk to the team on how to write unit tests how to get started with our framework use it for unit tests and it's all going great and that's where I had a difficult and a very difficult conversation that right after that talk one was from a developer saying hey if we're writing all these unit tests what's the test team gonna do and I was able to explain that that's I could give them context then probably the it easier things that yeah yeah but then the more difficult question was when a tester came to me and said if devs are writing unit tests what are we gonna do same answer same answer but a little more a little more stern and strict yeah yeah there was another thing that I did as a there's another technique I did years ago that are that I recall and it was a the issue was is my test team was slowly but surely getting all of their resources sucked into maintenance costs on the automation because dev wasn't informing us about these changes before the check-in do you remember those problems I do yeah I do and so I basically laid out a plan for my team and I said hey guys tests will no longer do what did we used to call check-in tests smoke tests tests will no longer do smoke tests for every check-in for you we will we'll give you a per team for each of my leads will give you eight hours a week you can you can use it as you see fit you need to negotiate but before the entrance into that is you need to run the smoke test some dev leads did some dead leads didn't but every time a bvt failed or a key test failed I don't know if this maps to modern times but every time it tests failed I went back and I ran the smoke tests and then I was very public what dev lead guy had you run this smoke test you wouldn't be dealing with this so I just slowly but surely I did I did a I need to worry about the scales on my team I want to get back on the because I wasn't done yet and I'll get back on the right question you're kind of answering the question now of how do you get them to run tests how do you get them to test before check-in no I want to go back to so let me summarize the point of that story and then I'll let you go back the point of that story is that particular dev didn't realize that had he run this the smoke tests himself he wouldn't have gotten into this really messy bvt thing they got really political really fast so I was creating motivation and incentives for them to buy in all right so not everybody probably very few people in these days is going to have the leverage you had back then so let me tell a couple stories about how different techniques I've used to get developers to write tests what I joined actually I'll go back before teams on the the project that I refer to as stupid science project actually I can go back to see what the story I wanted to tell there and the way I got some of this tangent was when the developers wrote unit tests they wrote really crummy unit tests they weren't very good tests and at that time I was new enough on my career I didn't know how to coach them I didn't other than complain I didn't know what to do I think it's really easy for a less experienced software engineer regardless of discipline to know what to do when you see something you don't like and I see this frequently across in Twitter people I work with regularly people I've worked with before where they see a problem they don't know what to do that throw their hands up in the air and that's kind of what I did at the time I knew the tests were really bad I part of me was thankful they were writing them but I had other stuff I needed to do so I worked on that when I joined the science project we didn't have a test team we had a quality team have focused on data it was stupid it was windows they don't know what they're doing sorry Steve but one very introvert aware technique I used was code reviews I looked at it I was on the code review alias and the team was big enough I could look at every check-in and I could start by asking questions like where are the tests stuff on and what helps and to give some framework what helps and what helped in Windows CE one thing we did to get the developers write unit tests and that windows did in a much much better way at the time was make it so dirt simple to write a unit test that it was it was very little tax to write a test they would type a command line and it would figure a bunch of stuff out and create the whole framework for unit tests to start writing right away little command line script and you bam you're writing tests so one technique is make it so easy for them to write tests you may have to create a framework one thing I've done a lot over the years is created a dirt simple to use framework for the team to use to begin to write tests you do have to eliminate all excuses except for yeah up into test does it for you right so that part was taken care of they had a framework so I'd ask questions like where are the tests and they go yeah and someone usually you have enough allies someone jump in the yeah these need tests so I asked out for a while and then after a while I wouldn't need to ask because there was enough people that had seen me ask that enough people joined the bandwagon that they would start asking each other hey where are the tests so now we're getting tests in now the tests were kind of crummy way too much complexity odd bizarre asserts tests that didn't actually test anything tests were if it failed there was no indication other than a rerunning the test in the debugger to figure out what exactly failed all the test smells that we you and I have seen for years which even for the most experienced devs what I've learned is 90% of the devs regardless of experience when they begin to write tests will write really really bad tests and so I just started asking questions used to experience that no much less so I think well comes with experience I think these days developers I work with have been writing tests about as long as they've been writing code but back then remember that we had a lot of developers at Microsoft and maybe you still do today who coded for 10 15 20 years without ever writing a single test here I completely agree but here's one of the things that I would actually say is different between then and now particularly first time I thought about this in a while but the devs that I work with the sort of the these back then the spirit was no we needed testers because they saved my ass but today that sentence is still true except it's I need my tests because they've saved my ass yeah so yeah they're definitely better today so I asked questions like and remember people are gonna be at different places so again just via code review I would ask questions about test smells just all the classics wouldn't have to look at them that closely just all the stuff that I had seen wrong sometimes just asking what does this do and other people would chime in and guess what happened just like the last thing eventually enough people would pick up on the things that the test smells they would begin to ask each other questions and then I will continue to look at all the code coming in and a lot of it have pretty good tests I'd ask I would have to ask fewer questions and eventually I went through like a week of looking at code and thought these are all pretty good so no resources require just a lot of my experience just looking for test smells a lot of a lot of remote or virtual coaching as well some one-on-one things walking through some things people were confused it's taking leadership on teaching the fish asking yeah I'm teaching people to fish and then on teams largely the same when I got there they had written a lot of tests in the end the dev team wrote all the tests okay 95% of the automate automated tests and their unit tests were actually pretty good they knew what they were doing they tested one thing they ran quickly they ran exactly as I expect a set of unit tests to run they wrote a bunch of tests with Selenium with protractor and they were crap and again I think writing UI animation is very very very difficult and I hate it necessary sometimes it has no friggin place in a unit test suite no it was this is not in the unit test suite oh my god they wrote all the tests okay and they made the same mistakes a lot of junior testers and and maybe even intermediate testers make with writing UI they try and test too much through the UI they littered sleeps in their codes to deal with synchronization issues it was just a mess and we slowly cleaned that up it never got great it got better but they also fell into that trap of since I've written this automated test there's no reason I would ever want to get rid of it or not run it on every single build because I wrote it remember remember that trap from 15 years ago I think it's interesting to watch people new to test but not new to development fall into that same trap I am NOT certain that that phenomenon died 15 years ago or even died dying it's slowly dying way keep the hope alive my friend so that's certain that's true um I know you asked for resources but other than by the time I got to a stage where I was doing coaching of development teams writing tests I have been testing for long enough I was able to do it as a combination of work experience random test books I had read over the years and pains and tribulations from my life as a software testers so I don't have any I don't have any shortcuts I can think of her or bootstraps other than just leveraging experience and trying things and experimenting and seeing what works that's getting them to the end like in terms of a bootstrap I but my recommendation is still find a way to just get them started with with TDD right and even even if all you ask them to do is one test per check-in as with a TDD model what you're trying to do is just get them started right don't flood them with if you start truck talking to them and you go through and you and you unwind all the deep technical considerations that you as a two-decade long experience tester has done you're gonna scare them off you want to because their motivation is there the right but they also are motivated to not go back and have to fix the code they just right so just get him I would there's a lot of TDD resources on there if you can afford it find a local TD expert and bring them in if you can't I would recommend the dotted objective or dotnet objective guys they travel anywhere they may be outside your price tag but you just want to get them started the next thing you do is is modify your check-in automation and you just need two checks did the sweet pass did this contain a new test yeah one and one little bit to add that did help I've always said code coverage is a horrible metric but a wonderful tool measuring code coverage on your code is good and when the one thing I do with development teams I never give them a goal of number to shoot for I'll say your code coverage is this this say it's 80% that means 20% of your code doesn't have tests are you okay with that and they say no we should have a hundred I said a hundred it's really hard let's what do you think is right and they'll decide on their own goal which is fine but I'll remind them the goal is not important it's important understand what's not tested but then the piece that helps them with that sorry you just talked about is this happened on teams without me even suggesting it one of the dev teams followed by more of the dev teams and we've done this on several teams now at Unity as well have added a check-in gate where if the code coverage number drops from the previous build the check-in is rejected because that means that new code was added without tests sure so that helps that gets people to encourage people like well get a percentage yes so if you if you removed lines of code if you remove lines of code that were tested drop sure right you could that's the only negative thing on that one it is but I assume the team the team hasn't taken it that way they figured it's a little bit of a boy scout rule where they will add oh well I'll add here here's where some tests are missing I'll go add some tests it encourage it actually encourages the right behavior I love it and there is of course a way to bypass if it really is an issue but hasn't been an issue yet which is great I like that rule on code coverage what I found is the best thing to do is use it is this is on teaching the fish teach it as an analysis tool yeah like the first thing I would always do when I got a good coverage results I would bring in the dev and I would go for the height high level bits I'm like hey here's a whole class here that doesn't even have not touched yeah here's a function that's not touch what does that mean right and I my more of teaching them no for sure to use it what question wonderful tool a horrible metric there hasn't been a single time where I've kicked off a code coverage project like first time measure code coverage had that conversation ask that question about this this class isn't called by any tests oh yeah that's dead code we should remove that yes we should one last question I want to get to a little bit of overlap these all segue well because I'm a wonderful planner from Sean what are your thoughts on building out or structuring development teams as first QA person at a small startup that has no testing specialist do you see a place for hiring a test specialist to add missing skills to a team any advice on moving the team towards whole team ownership of testing if some might be expecting to push all or most testing tasks other than unit test this test specialist QA person so to paraphrase the way I hear this is a small startup or a small team doesn't you on one hand you want to hire someone with some testing expertise to help bring that to the team but there's also the worry that if you do that they become the testing bottleneck for the team yeah I was thinking a different B word so if it's a brand new startup and you're the the the first tester there like in that scenario like it is really best for you to to it as part of your interview set these expectations around what you're what you're going to do when you first arrive your your job if so you're you're coming to a team you're the first tester and because you're the first tester there is one thing that is phenomenal so far with that thing and that is the dysfunctional codependency loop has not started and the first thing I would do is go okay this is how we're gonna make sure it never starts so I can look at two directions one I'm the test person about to be hired onto this team remember I was my official my unofficial title on teams when I joined was the testing guy they had a team of note they had a large development when I joined about 50 or 60 developers and I was I was hired to make sure they actually thought about testing a little bit better so but I think you very quickly changed your your pseudo role name title thing yeah to quality guy not testing yeah for sure so if I have this small company a small team I want to bring in the testing guy I'm bringing in somebody to help coach testing expertise on the team thinking from the role of development director or development leader owner or whatever I want I have to look at it as not bringing in a bottleneck someone to test quality in I want to highlight efficiency and bring in someone that can help the team get better at delivering quality software from the other angle if I'm a tester looking to get started at this company I would definitely ask questions like if I see I'm interviewing some you know ACME startup co and they want me to be their their first tester their only tester I'm definitely gonna ask some questions to make sure that I am NOT hired to be the bottleneck there's a little bit of for some people I think there's a little bit of ego involved they'd want to be like I want you to dependent and depend entirely on me I will I will do all your testing for you and validate myself worth anything from shipping but you don't want that I again going back to modern testing we want to be the accelerant for the team right we want to add business value because we highlight risk in the appropriate places and we help the team deliver more efficiently and looking at all the different not just functional testing but all the different aspects of quality the team could be working on and making sure they're all on the radar which is a very difficult job but I think I don't know what stuff I think often what happens unfortunately is I'm this development director and I have a dev team I need a tester I hire a junior tester to come do a bunch of testing for the team and help me out and and that just sends you spiraling in the wrong direction yeah you do and that can that's a far too common dysfunction of leadership like I one of the things that we started seeing in the last six months people who never grew up in tests joining the slack channel yeah because they're like no this aspect the testing activity and that's again going that's the thing that I see is shifting is that the industry is viewing it again more as an activity that has to be done not necessarily by a particular discipline and they're seeing it more as a systemic problem which I think is absolutely the right thing so yeah could you a startup created by I'm thinking about actually a buddy of mine who joined multiple startups with rock star developers right the developer you know is often an inventor or founder of a concept wrote a bunch of code hired a bunch of people around them and trying to build a business out of it they may or may not have the business acumen necessary to make that thriver succeed yet yeah right they may not know that the fact that they you know are producing crap build after build is actually going to hurt them I think the specific answer to the question and this is not a great answer but it's because it requires a lot of nuance but in respect to time yes for any advice on moving the team towards whole team ownership of testing is the person you hire as the testing specialist is not is there to do very little of the testing yes so that's the advice both from the I think to the tester joining the team as well as the person hiring that testers you hire that person for their expertise not to do all of that task I would do the same thing of how I was hiring a person someone man I got I got a higher performance guru I am NOT going to hire him to go around through all the code and tweak it and optimize it I want him he's gonna do a chunk of that it definitely do some of that but I didn't help the whole team develop that performance culture that's the same thing I want to do with quality and testing there's so yeah a t-shaped person there on the performance stuff right I would hire somebody that is familiar with the tooling I would want to make sure when with these type of problems that the approach I always start thinking through is what system or tech can I put into place and then when I say system it could be a process but what can I put into place that will increase friction around this in this case dev doing the wrong thing even without that dev having knowledge of the right thing right the more you can just tell them what to do in an accurate fashion the better and the more you can automate telling them what to do even better right if you can if you have something that can run perf profiling automatically say part of your unit test suite and point out that there was a regression here and if it can somehow connect up to static analysis tools and tell you why fantastic yeah so we are about out of time one question not written down that we get a lot is what happens after modern testing say you've worked yourself you've got your team executing and the knowledge is all there on the team what happens to you and the answer is about 50 million different things but I've often talked at Unity how my goal has been to work myself out of a role but not a job and I got a little worried because recently I've pretty much worked myself out of a role what does that mean let's talk about it 98 
