Hello everybody! Howdy! I'm Alan. I'm Brent. Back for episode 39 of AB testing. Welcome back. I remember the number. Right? Yeah, it helps. Because Brent wrote it on the board. Yeah, it helps. It does help. It does help. So, ask me where I've been, Brent. Where have you been, Alan? I just got back last night. I flew back from Waterloo and boy, my arm's tired. Ha ha! Ba dum bum. I went to Waterloo. Do you know where Waterloo is? No. Canada. A? Is it Tim Hortons right next to it? Of course there is. Waterloo is about an hour drive west of Toronto. So I flew into Toronto, drove to Waterloo, parked my car where it stayed until I drove back to the airport. But in between there, I had dinner with the board of KWSQA and then I gave a talk to a sold out hundred-ish group of software quality professionals. Sold out! You raking in the testing cash! Yes. Yes, it's all on paper money. But it was a good time. Is that how you afforded all this fancy new equipment you got brought in today? So Brent just wants to change the subject and go. Happy 39th birthday to A.B. Testing. I bought us a new mixer. So whether you can actually hear us after this podcast is, we will find out. I don't know if that will work or not. Hey what's this button do, Alan? Don't push any buttons because normally when I get a new piece of audio equipment I will take time to learn it and make sure I understand what all the buttons do. And although I've had mixers similar to this in the past, let me make sure, yes I'm actually recording on. I just thought that's a brief nightmare. Like I had set it up to record and then like left the program recording off of the laptop microphone, but I didn't. So we're actually recording off these microphones. So anyway, the subject was, I was talking about Waterloo where I had a great time. I knew there was a lot of tech there. I know Microsoft has recruited a lot from University of Waterloo there because they have a great program where they do lots of internships, which is super valuable. And anyway, I didn't realize how much tech was there. They have like 200 startups there and all kinds of tech. There's this huge physics building next to the hotel where I stayed. Pretty cool town. I liked it. And I gave a talk that was similar to, I think I'm probably going to give an evolution of these talks I imagine over the next few years and it'll go into our topic today, but sort of what is the role of testers in this new world of software development, whether it's agile testing, whether it's testing without developers. Sometimes I feel really good about what I'm doing. Sometimes as you know, I'm frustrated with, I feel like our team could be more agile than it is. But then I look at it from the delivering frequent customer value at a sustainable pace and we managed to do that despite the fact that we do things that I don't feel very agile-ish about. So it depends a little bit how you look at it. But anyway, I'm sharing a bunch of stories about what I do, what's worked for me, what's done, what to worry about, what not to worry about. I asked a question at the beginning like how many of your testers, all the hands go up. How many of you are here because you're afraid, you think I'm going to tell you how your job is going to go away and all the hands go up. And by the end they're going, okay, I don't feel so bad. I kind of get where I fit in in this new world, which is I think a great gospel to share. Yeah, you, was that, that's not the same presentation. Was it the same presentation you did for what was the QA? No, I cannot give the same presentation in a row. So what I do is I wanted to give a variation of that talk. So I got, excuse me, I got rid of about half the slides, added another half to fill in, and let it evolve that way. I believe in evolution. I assume the, yeah. A lot of the same ideas come out, but I can't give the same talk, I've done it before, internally at Microsoft, when I used to teach things like at Neo and classes and things. But I don't like to give the same presentation twice because it gets stale for me fast. So I like to always change it and not just a little. I like to change it, you know, at least 25, if not 50% if I'm going to give something sort of in the same topic. And as I learn more and as I do more things. There's some valuing consistency. I think to me it's just like the same principles that apply to software work. I want to evolve. I want to iterate. I want to make, I want to throw out what didn't work and add what I think will work before and listen and learn from that. I agree. Of course you do because I'm right. There's an agile onboarding deck that I've been carrying around with me for the last five years. And every presentation I go through, I am happy to say that it's now at a point where I essentially do minor tweaks. The onboarding process is very similar to going through a class, right? You got to talk about the same things. You got to say the same reasons why essentially the only differences I do now with this deck is I change the stories. And we're always getting new stories. Right. There's new, and not even the stories, even experiences. And I like sharing those. So a funny thing happened on the way to the forum. What? With the forum being sort of me going to Waterloo and the reference to the musical. Are you catching on here? No. No. Someday I'll introduce you to culture. Good luck with that. Many have tried before. I'm still trying to work on getting into soccer. And thank you. That should be an easier one for you. We'll see you next time on People's Testing. God! Oh my, my, my. So I was, hey, don't you have another conference coming up? I do. I do. Oh, tell us about that. I'll be at Better Software in Las Vegas. Oh, sweet. Are you a gambler? No I'm not at all. Because you don't know the games? No, I know the games. I just like money. I don't like losing it. I don't like to pretend that I... What you need to do is go, you go buy chips. You're buying chips. Yeah. And then I give them to the guy with the cards. And then it's not money anymore. You're losing chips. No, I'm really not interested. I often won't gamble at all. Sometimes I'll play, I'll be very careful to walk up to the lowest wage blackjack table I can find and I'll play for like 20 minutes and walk away just a little poorer than I came. But I'm not really into gambling. I really like holding on to my money versus just giving it away to people for a very brief amount of entertainment. Yeah. I could have went and saw Deadpool again for that much money. Would have lasted longer. Hey, I finally seen Deadpool. Deadpool. Really? That was really funny. Okay. So anyway, yeah, I'm going to the Better Software Conference. That's like the first Monday in June. I'm giving a workshop on A-B testing or experimentation. I have some good information. I feel pretty good about that. About filling my time and having some good information. I'm not going to give away all the secrets today. Was the last time we did this a workshop format? No, last year, about a year ago, I got a call. It was less than a year ago because I got mail that said pretty much something, hey, are you free next Thursday to give a presentation in Las Vegas? This was on like Friday. I said, okay. So I went down and gave someone that canceled and I went down and filled in and gave a presentation on A-B testing. One thing about Seattle to Vegas, direct flights about 25 a day. Easy to get there and back. And apparently went well enough that Mr. Copeland called and said, hey, so next year, how about a workshop? Same topic. I said, sure. So here we are. All right. Shall we get to the topic of the day? We should. So remember when I remember like a half hour ago when I was about to go into a new subject and you distracted me? While I was there, I was checking out the Twitterverse. While I was in Waterloo, I was checking out the Twitterverse as I don't often do these days but do when I'm traveling to see what's going on. And there was a tweet and I'm going to get into, I was going to dance around for the beginning, I'll dance around context, but we'll have to get into it. There was a tweet from another small workshop conference. Wait, wait. First and foremost. Without explaining it, do you know the context? Yes, there was a conference on, a peer conference on reinventing testing by James Bach. Okay. I'm going to go ahead and use names up at, and I'll get into the rest later, up at, I think it was placed in Orchis Island and there was one slide that was controversial. So while it could have been, well, it could have been just contained within the workshop, Matt Hoiser for reasons, I think, to stir up controversy or to just share it with the world or to share his thoughts, took a picture of it and tweeted it. And I looked at it and I thought, what the front door is very interesting. So it was, I don't want to go into a lot of, I want to try and just look at the facts here and my experiences and how they relate to the bullet points versus I think there's a lot of psychology that I could go into why James put these bullet points on the slide. Because I think James is really smart and I like him. And the only thing I'm going to say is it's slide comes across as very defensive and without context in many cases. So again, not a slime on James. And thanks, Matt, for posting it. I'm sure, I'm not sure how James feels about that now that the controversy is rolling, but I do want to talk about the bullet points on the slide. So if you haven't seen it, you can go find it. Look for the, and what was really weird is the make testing great again tag. It's a little too Trump like and made things a little awkward for me. But actually, can we start with it? Sure. Sure. Make testing. Great again. When you read that literally make testing great again, right? I don't think there's anyone, well, at least in my mind, there's no one that's going to disagree with that when you look at it literally. Now I suspect that the intent behind that hashtag is make testers great again. I don't want to, I think it's unfair of us for to dissect the words and go into intent. No what I want to do is there's, so for me, this is relatively context free. All right. Okay. I'll let you continue. And what I want to really what I want to address is look at this sort of visually on its face. What is from our point of view, the most likely interpretation of the intent here as well as what is what would be the most respectful interpretation. Okay. So spit it out. That's so for me, making testing great again. I know most or the three will know that we are supportive of unified engineering. We are supportive of agile practices. We are not necessarily, I know I'm, I don't want to speak for you here, but I am definitely not supportive of a large dedicated testing, tester individuals that all they do. But the hashtag says test Dean and I am definitely supportive of testing improvements. But I believe that those efforts need to be moved up the stack. I need, I believe dev needs to be trained on these things. And that's how we achieve making testing great again. One of the things, uh, that was a lot of words to not say very much. I said a whole bunch of, okay. All right. So one of the things I tweeted in some tweets term about this was that I'm working with some of the best testers I've worked with in my 20 years, 25 years of testing. They're just not called that. Right. Yeah, it's true. The yeah, the, the, the other thing when I, when I first look at this, right, I like that line. Um, it reminds me of our presentation at redfin where, uh, one of the questions that got asked us is, is in my view, this sort of old school archaic, uh, question of, well, isn't it true that if devs test their own code, they can't maintain objectivity. Right. And I'm no, it's not true. That is actually, that's a myth. And uh, and some people would say that the op that, that the opposite is a myth. There's a big, that's a controversy. It's a disagreement. Software testing is not a field without controversy. Yeah. So for, for 22 years now, I guess I've been dealing with, um, even when I was in test, right? And dealing with the questions around is a great tester, uh, born or made. Whatever. Right. So I want to get past the make testing great tag. Go ahead. Actually talk about the slide. Go ahead. So I'm going to, uh, let's have a discussion on the title and the bullet points. Hopefully not too philosophical or long, but just kind of see what they mean to you, how they resonate with you. So the title of the slide, it says, this is the premise, the theme in the agile world. There's an ongoing and longstanding attack on the testing role. So you want to start? Yes. Go ahead. And no. So I look at that and I go, no, there's not. But in a way there is a little bit. There was one of the, uh, one of the books on agile had a chapter on manual testing and the chapter said, and I'm paraphrasing or could have been called, it was manual testing and it was just one page. It said, don't do it. And it was tongue in cheek and, and it, one thing and I'm paraphrasing some little correct me and it's fine, but you get the idea. Uh, the ads, any book on agile or any, actually this podcast, anything I say, anything you read in a book, anything you hear anyone say, it is not a blueprint to tell you how to do everything. Context always matters. Whether you're in the context driven community or not, you have to be driven by context. So, so when I read books on testing, I found plenty of stupid things. Didn't mean testing was stupid. It means there were some stupid things in there. Same things happens in all the literature on agile. Uh, so there have been jabs at not testing, not the testing activity, but little jabs that the tester role, maybe do we need a team dedicated to doing testing? So I can see a little bit where that's coming from. But for me, no, I think in my experience in agile, um, testing has been, ah, for the most part embraced, sometimes briefly forgotten, but then quickly remembered. To me, when I look at that, I, I think of other industries that have gone through transition, right? Um, in the auto manufacturing world, there has been a ongoing and longstanding attack on horse trainers, right? If you think back to the 1800s and when the automobile was introduced in, um, similar in in Detroit, when, when assembly lines, uh, started getting robots added to it. No, not automation. Automation will take our jobs away. Right. Exactly. Uh, and actually that, no, that's a very good point because that's, that leads us straight to manual versus automated testing. Right. Testing is not a world without controversy. Now it's the world. Any time there is a change in which the world, uh, is, is moving toward this is a better practice. Go ahead. One of the points I made in, uh, it reminds me that I'll continue to make, I made it up at Waterloo is I, before I said a minute ago, testing is not without controversy, whether it's manual versus automated, exploratory versus scripted testers versus no testers titles. Uh, you can do a couple of things with that. You can either deny it and tell the world that this change is stupid and it's, and it's confrontational, or you can figure out what it means for you. How does that change me? And anytime I look at a sufficiently complex problem, I will look at one technique I love is look at extremes. What would it look like if we automated everything? What would be the bay, the gains, the benefits, as well as the drawbacks and losses. And also what if we automated nothing? What if we did everything without automation? What would happen there? And the answer is somewhere in between, depending on the product and the context and how often you're shipping, those things are going to happen. That the, where that slider is between those two is going to be in a different spot. Yep. And it's the same thing here in the world with, you know, are we, what would it be if we had no testers versus a massive one to one or even larger test to dev ratio? Look at the pros and cons figure out where that line is. There are lots of inefficiencies there. So that's going back to my topic from Waterloo and away from the topic on the page here. But I think this first bullet point I'm going to go ahead and read because I think it's in the, you finished because it will, it will relate to the title. Yeah. It says agile was not created by testers or with testers. It's a programmer's utopian vision. So what's your takeaway on that? I agree with the first sentence. I don't necessarily agree with the second. Agile was, was around before the manifesto was around, right? It was a large number of people seeing similar practices working through similar things. And they said, Hey, let's get together and, and knowledge here. Now the, the, this entire slide is, is sort of filled with controversial terms meant to inspire emotion towards the point that the, the author is making the, the, just because agile was created by or not created with testers. We are to believe that that is sufficient to prove that it was a programmer's utopian vision. Right. And, and right. And you use the word utopia to sort of imply that this is a dreamlike state that's never achievable. And when I look at this slide, we talked about this on the podcast. And if I had realized that we now had the ability to bring in the third mic, I would have invited Jeffrey Weston to join us today so that we could, as we go through this slide, also have a brief lesson on fallacies. The, the, the thing that actually puzzles me about this slide is Bach is well known in the testing world as a grandiose systems thinker. Right. But this slide, this slide without any context now, and I want to say one thing, one thing very clearly, I don't suspect this happened, but if the slide that came after this just said the word not, well, then, then I'm like, okay, I get the point you're trying to make. That is a worthwhile comment to make. I don't know if you ever read the Lessons in Software Testing book. I have. Well, one of the things they didn't ask me to quote anything from it is they would have, they would say, blah is good on one page, next page, blah is bad. Just showing context. So that very well could have happened. So we don't know that we don't. We're out of context. All right. I don't think it's utopian. I think it was, you know, add the manifesto came about. There were some developers who were doing some lightweight development techniques who wanted to figure out, can we, they're just trying to get rid of inefficiencies. To me, anything that gets rid of inefficiencies, I'm a big fan of theory of constraints. I think Agile and theory of constraints work well together. It's about identifying what's the bottleneck. Let's mitigate it enough. We're not a bottleneck. Let's move forward. And Agile is about eliminating some of the bottlenecks and finding some of the things that work well and finding ways to make them better. It is not a playbook. It is not a, you know, I think one of the things that, you know, you're talking about utopian being a word that that makes it that as drama here, the fact that they call the the principles of the principles of the called the Agile manifesto. The principles are different. But the manifesto sort of mentally conjures some of those same images. It's easy to push back on something that's called the manifesto. Well, and I've talked about it on the podcast before. I'm not going to go deep, but as you well know, I am not a supporter of the manifesto. It encourages people to just go look at one page and go, oh, I get Agile. And Agile is far more complex than the waterfall model. It's a lot of moving parts. It's primarily a principle driven. Yes, absolutely. I don't even know if calling it a principle driven framework is even correct because how do you have a framework with principles? But as you call out correctly, it's about consistently identifying and eliminating waste. The other thing on this first bullet point, right, the why is it a problem? That's the thing that I ask myself upon reading this bullet point. So what? The one thing, and we talked about Ryneartson's book. If you go into look at Ryneartson's book and you want to understand the details about why they made that decision, this is trying to lead us to believe that a bunch of programmers got in a room and they said, how do we screw over test? No, that is not what they did. They said, how do we build better software faster to compete? They were looking at what is the better practices that get rid of waste that adds value. So it isn't, in my view, like if we want to talk about testing, it isn't about making testing great again. If we want to have individual tester roles, then what we need to do is make those roles valuable again. Sure. Okay, I'm done with that, Ryn. Go to the next one. They frequently said that Agile discourages specialists. A specialist tester, a specialist seems to be defined as anyone who does not specialize in programming. Agile definitely discourages specialists. So when I think of specialists, I guess when I see specialists, I think of the generalizing specialist or the specializing generalist, which is different than the specialist. You're correct. So I guess in that sense is correct, but I believe that. For the next sentence, I think I know where you're going, and I think I agree with you. So shoot it out. A specialist seems to be defined as anyone who does not specialize in programming. And that is not true. An Agile team is made up of these T-shaped personas, to use the term most often used in Agile, and fit together to make sure that the sum of everyone can do all the parts. A team full of specialists is very difficult to do that. Someone who is solely a testing specialist, you have to provide a lot of value. And generally someone who's smart enough to be a really good testing specialist also has the breadth they can fit in well with an Agile team. The other thing I'm going to call out, the thing I find wrong with this, is I don't think a traditional testing role is a specialist. I think they're a generalist. Now it's still correct in that, as we have said on the podcast repeatedly, we don't like either of these. We don't like pure generalists, and we don't like pure specialists. And as sort of hand-wavy proof of my point of view, I'll point to your deck. Any place where you have a role where the individual is responsible for doing the remainder of the stuff that no one else wants to do, that in my view is the definition of a generalist. And that's traditionally what test is done. Program management has defined what the project is, programmers write the code, and then the remainder is done by the test team. And that can be a lot of different things. There's definitely specialization when we talk about automation. Sure. Right. Dev. And there's over-specialization. Some people, I knew a lot of testers at Microsoft who wrote functional tests eight or nine hours a day, every day for their whole career. Is that testing? Ish, but it's a very, it's very de-specialization. Those people are either not here anymore or actually many of them turn into pretty good programmers, developers. One of the earliest works on Agile, the XP white book, claimed that no one likes to do testing. This set the tone ever since. So I'm going to go back to the comment I made earlier about the, again, every sentence starts with a truth and then ends with a huh. So two sentences. First sentence, yes, the XP white book said that, I can't dispute it. But just because it's written down doesn't mean you have to follow it. And then I disbelieve that it has set the tone ever since. There have been plenty of things that have happened all over in the Agile and outside of the Agile world that have set the tone for testing not being exciting. That is not the fault of Agile. We've talked about this on a, uh, I'm going to make you drink every time you say we've talked about this. I'm bringing in tequila shots for number 40. Okay. You have, okay. What's that point again? One of the earliest works on Agile, the XP white book claimed that no one likes to do testing this set the tone ever since. We've talked about it. I've blogged about it. The history of test. One of the, if we want to talk about the history lesson, then let's talk about how tests got developed. It's actually in your, uh, in some degree it's in your presentation. There's one aspect I think you're missing. Probably not. Maybe you usually write how did test get, how did the testing role get created at least as it relates to Microsoft, right? It's Hey, we can hire this cheap guy to do the crap we don't want to do. Yeah. Right. So pretty much it, it, um, this XP book did not invent this concept. This concept has been around ever since the, the dev test codependency loop began to get constructed. Correct. Um, now does, uh, so in, in one regard, you could say the agile community, if it is a community of programmers said, you know what? Yes, we created this role. We made a mistake. We going to take it back. Okay. Uh, that's one way of looking at it. Okay. The next one, um, I'm just going to read and move on because I wasn't there. So I can't comment. Uh, 2004 agile fusion conference collapsed in acrimony when Brian and Merrick claimed that testing is only reluctantly about finding bugs and Bock and chem can or vigorously objected. So I don't know if it collapsed again. I wasn't there. I don't know. Testing is only reluctantly about finding bugs. And I'm not sure I entirely disagree with that, but I'm not going to debate that. I've often said that finding bugs is sort of the side effect of doing the testing job. I'm not sure if that's the same thing or not. And then this event, this is like, then we kicked him out. This event marked the exit of Brian Merrick from the context driven testing community. Um, so it's, I think that was, uh, I'm not sure how to read that one. I just kind of want to move on. Do you want to add anything on that? Yeah. Uh, Brian's making a face complete non, you know, thanks for that information, but it's a complete non sequitur. Yeah. So moving on. Yeah. So the most popular book on agile testing by Crispin, actually it's by Crispin and Gregory, is not cited or thought of as a testing book among testing specialists. It barely discusses testing. Go ahead. So you're friends with Lisa. So I like to consider myself, um, one of my specialties to be testing. I wrote a book on it. Um, it's obsolete. I've mentioned before, but, uh, I wrote a book about it. I consider myself a specialist in testing and, um, I, I liked the books. I especially liked the second one. The second one has a lot more testing goodness in it. The second edition. Yeah. No, it's called more agile testing. Okay. Um, a lot of guest writers and there it's a, they're really good books. I consider them. I, I recommend them often. People will talk teens about having a no-chester role. I said, go read this book. See how it figures out. It's there's lots of great information there. I don't know why it depends on context because James may not consider me to be a testing specialist among his peers that are testing specialists. Maybe they don't know about the book or like it, but I think if I consider my peers who are testing specialists, most of them do know about it and do appreciate it. The, I don't mind. I have to drink. So I think this comes back to sort of, um, one of the discussions on CDT and their, their point of view of how the world turns and, and it kind of, for something that is context driven, uh, their view is some is incredibly static around is this testing or is this not right? The, and then the thing is, so I have read Lisa's book. Unfortunately, I don't recall much from it. Um, I read it years ago when I was going through my own self-training on Agile and I wanted to get a better sense of how Agile worked in multiple discipline, uh, scrum teams and Lisa's book, uh, does give great insights. Her point, as I recall, and please correct me, cause I'm sure you remember this better than I do. Even though the book is titled Agile testing and, uh, I'll go ahead and agree with that it barely discusses testing and I'll say that's not the point of her book. That's a good point. There's plenty of books on testing. The value add that Lisa brought into this is essentially, Hey, this Agile thing is a better way to go. And she's actually attempting to actually make testing great again, or to reduce the losses given Agile is an unstoppable force at this point in time. Right. The, the world is not going to go back to these long delivery cycles. The world is not going to go back to, to the, like the, the, if you want to talk about who's making the greatest attack on testing, it's data science and telemetry, right? We, we now can measure the ROI of things. We now can very rapidly get actual customer feedback. We don't need artificial advocates in the front of it. So yes, in many ways, yes. And I want to actually play devil's advocate for James and his community because again, I have nothing against James. I think it's important to talk about these in the context of AB testing, these bullet points on this slide and kind of what our testing world is. But if you think of our testing world, the reason we're opposed to these bullet points, because we live in a different testing world than James Bock and his peers. I think a lot of his projects, I have to assume, again, I'm not in, I, I, I don't get to look over his shoulder. Um, but I think he does work in a lot of, we get software at the end. If you think of you're working with companies where it's an IT company, you're getting software at the, you know, here's the software, make sure it works. Doing that rapid software testing. Like you have two days, let us know whether it's okay to go to customers. Um, the things he teaches in his world is really good at finding those key issues at that point. We just don't live in a world where we're going to do that. We live in a world of high daily quality versus let's, let's try and make sure quality is really good at the end. Here's, here's something we have talked about recently. One of the things that, um, now I'm super conscientious about having talked about that recently. Thanks for that. You're welcome. Yeah. I was trying to help my peers improve. Um, you and I have been talking about these sorts of topics for at least six years, and we have seen Microsoft go through a massive transformation. Uh, one that I'm very pleased with and we're not completely done. Um, and I know that you're happy with this trans, uh, transformation as well. But we also know, we also know that most of our, the, the people who are one of the three, but they, we know that for the most part, they don't live in that world, but one of the things that, that I have observed is when I talk to these guys or I tweet them or we, we chat on the slack channel, um, they're now what a place where we were three years ago. Where there's this sense that it is coming. It is real and it's hit their company. So there's this, um, right. Uh, we've had multiple conversations, uh, with other, other folks. Uh, I remember one time you, you pulled together an agile panel. You asked me to speak on it, uh, for tests and, uh, when tests was still here at Microsoft and there was a lot of anxiety around, this is a threat to my job. Hidden behind, this is a threat to quality, but when you, when you just scratched the surface and didn't take much to, to get there, it's really, this is the threat to my wellbeing. Yeah. And I remember as early as it's funny, I remember this and recalled this at, uh, in Waterloo, but as early as maybe 2005 or so, I was asked to come talk to a team, uh, I did a lot of that at that time, uh, where they said, Hey, we are, our team's doing agile and we're not sure what our test team should do. It wasn't, I hadn't done, I knew about agile then did I didn't, Lisa's book wasn't out and really having any ideas, but in talking to them, the, the answer emerged quickly. It's like one of the best things you can do is it helped define what done is and make sure that, make sure that done happens. So when we think of that testing role or that quality role within an agile team, it's, uh, there's a lot of coaching and training of developers on what testing needs to be done. And, and thinking about, well, what actually gets, cause when I get that highly daily quality, make sure things, things are done now versus having a coding milestone or stabilization milestone. It's like, what needs to happen to be done? And those things are really important. Like a great value for testers to bring to the table of the slides, like this, uh, of all these bullets, right? Uh, under the, the hypothesis of the context is, Hey, everybody hate agile. Cause it's coming to steal your jobs. This bullet is the one I find the single most offensive one because Lisa is not attacking testing. What Lisa is doing is recognizing testing is a set of outcomes and a set of activities. The world is shifting. We have a bunch of people who are trained and understand how to help make better software in this product. And she is teaching testers how to thrive in this new world. Yeah, I agree. I agree completely. She is the defender of making testing great again, way more than she is the attacker. All right. And to be clear, it's, it's they cause because Janet wrote the book too. Right. So I'm just, just to give credit, this slide calls out. Let's do the last bullet point, which is again, um, a slight non sequitur, but, uh, just goes into the whole theme of the slide. TDD and BDD are focused on excuses to be done rather than a sincere inquiry into the status of the product. Yet both are regularly confused with testing. I'm not confused, but I don't know anyone who actually has those anything other than the definition of TDD and BDD, who thinks they're, um, a substitute for a larger set of testing. Um, TDD is a design technique for writing unit tests that make sure you write simple testable code. Yeah. BDD, I love even more behavior driven development because it makes you think about what the outcomes are of the software, the behaviors of the software before you implement the code. Yes. Um, and I've said before drink, uh, maybe not on here, but to me, the biggest benefit of BDD, there's all kinds of, I'm a fan of gherkin and BDD frameworks, but the benefit to me, the, the majority or the vast majority of the benefit of behavior driven development comes from just thinking, what are the behaviors that need to happen? Cause it makes you, it's helps you scope your code again, write more testable and sensible code. If you want to automate that test, that's great. That's fine. That gives you a nice integration test, but really thinking about the behaviors before you implement the code and then writing the code to make those behaviors work. That is the win. The thing, and this is prevailing in this one, like this last bullet point just hits it hard. Okay. Both TDD and BDD are regularly confused with testing. That's the final point of this bullet point. And I have to say first and foremost, that's wrong. They are not regularly confused with testing. What they are is regularly confused with a better way to reduce risk to the product. The thing I find that troublesome with this last sentence is he's holding true that test testing is inherently valuable. He's holding true that a sincere inquiry into the status of the product is inherently valuable, which isn't to say that I'm disagreeing with it. I'm saying it is not black and white. The, we know from, uh, uh, many of these conversations and CDD sort of community, there's a point of view that testing's role is to provide information to the business leaders. Okay. If testing's role is to provide information to the business leaders, TDD and BDD is about prioritizing and identifying upfront what information is valuable and incorporating that into the strategy of writing code such that, you know, upfront and continuously. On development teams that practice TDD and BDD, uh, what you get out of them in my experience is code that works pretty well and beyond just the functional level at the integration level. And then instead of having the world where you give me code and I go, okay, here are the bugs, blah, blah, blah, I'm not even half thinking about it. You give me a product to test. It's like, okay. Now I take my serious, inquiring exploratory system thinking, testing mind, and I have to work hard to find out where the detractors, the customer value are and that, that is where we need that skilled specialist tester. But without using some doubt, putting effort and care into making and programming the software correctly, the testing job, it actually does become something that the moron out of junior high school can do because it's easy to find bugs. There's a quote. I, and I'm, it's, it's a quote from this guy named Alan page. So, but I forget and I'm going to misquote it, but I remember an event you did, or maybe it was a tweet is that bugs should not, should be hard to find. I say that all the time. Right. And even in the world where there's a mixed role, where you have tests and dev as distinct specializations within a team, TDD and BDD should be highlighted for this, I can't tell you how many years I've been dealing with these the testers in a room going, how do we move quality up the stream? How do we help, uh, dev not create all of these bugs that keep throwing crap across the thing? I'm like, you can't have it both ways. You can't simultaneously say, we want to move quality upstream. We shouldn't be finding these low hanging fruit, stupid bugs. And then also bash the key and extremely valuable techniques that does exactly the things that we've been complaining about as a community for decades. Yeah. And if you also, if you say that developers are not capable or they're not objective enough, test their own code BS, because those types of things, those easy to find those low hanging fruit bugs, things they should be finding. And they can use techniques like TDD and BDD to make sure those idiotic bugs, those brain dev bugs, those stupid bugs that a junior high schooler, that my kid in junior middle school sixth grade could find actually my daughter in fifth grade could find are found before they get to the specialist testers who can then go, ho, you know, when's the last time you had a product? You had to look at and go, it's hard for me to find bugs. That's the kind of stuff we need our skilled testers to do. We don't need, if you want to think of testers as this lower skilled, you know, this, what was the bullet above about setting the tone for no one likes to do testing, no one likes to do boring, repetitive testing. If you give me a testing activity that is hard and I have to mentally strain myself and I feel exhausted at the end, but happy with my work, that's the kind of testing I want to do. That's kind of testing, testing specialists should do. That's, that's reinventing or make testing great again. It's not about this other BS. It's not about setting up boundaries and looking for conflicts between communities or processes. It's about making the job challenging and rewarding. Now, I think of this and I think of the other James Whitaker six years ago, huge controversy test is dead. Right. And I look at this and I'm like, was it even six years ago? It was longer than that. Wasn't it? No longer. 10 years ago. And, and I look at this and he's going, uh, test is dead. Right. In, in, in, how do we go after agile? Like dude, you don't like this stuff. Again, it goes back to what does it mean for me? How does it impact me? It's not an attack. And, uh, I know, but the reason why I spawned this up and I should have actually tied the, or connected to before I gone into it, right. You, if you want to have this world where you have, um, you said Dev and tests and Dev can't test their code because they're, they're too subjective. Right. The thing is, as we've said over and over again, that world is increasingly shrinking and it is not the dominant part of the world today. You can't, the single most precious asset in software today is calendar time. You can't afford that world where you assume Dev is moronic. And that is the business reality. And it is ever increasingly becoming true in a world near you. All right. One last thing to say. I'm done. Good. Thank you for listening. Thanks. I'm Alan. I'm brain. We'll see you next time. Bye bye. 
