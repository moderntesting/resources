This is the AB Testing 343 podcast, a podcast where we ask one of the three listeners of the AB Testing podcast, three questions about almost anything. ABT 343 is a fun slice of what's going on in the world of modern testing. Let's get started. Welcome to episode one of the AB Testing 343 podcast, a new podcast from AB Testing, where we take one of our three listeners and we ask them three questions. And today I'm joined by the testing chef, Andrew Morton. Andrew, say hello to everybody. Hello everybody. Thanks for being the guinea pig on this inaugural episode. Glad to have you here and give our listeners and myself a chance to get to know you and your work a little bit better. Yeah, I'm very much looking forward to it. So before we start, maybe there's a pre-question. I know we're going to dive a lot into what you do, but tell us a little bit about the work you're doing. So for anyone who doesn't know, I work at the Ministry of Testing. I am their Dev Boss. So I essentially do their development for them on the website. That's at www.ministryoftesting.com. Please feel free to go and check it out. Obviously, there's a few good things on there. Alan's made a couple of appearances and we'll be having his own course on there soon about modern testing. So one of the advantages of being staff at Ministry of Testing is I'm going to get to see that before it goes live. So looking forward to checking that one out as well. Yeah, we run Ruby on Rails. I've always been a bit of a Rubyist at heart since I started really picking up coding, doing web UI automation a few years ago. So now I'm a tester-turned-developer, which will also come up later as to why. Super neat. Yeah, I'm just going to pause and say I'm really excited about that modern testing course coming out. And I hope everyone gets a Dojo membership and checks it out. All right, let's get into a question, a real question. You were someone, so when I first spoke about modern testing principles at Test Bash Brighton, you may have been in the audience. In fact, because I had a few people and you may have said, thanks for putting a name to something I've kind of already been doing. And I've heard that many, many times throughout the years. And like I said, you could have been one of the people that told me that because I know now that you were living at least some of the principles before they were codified. So I'm curious, as someone who has been moving towards those principles before they were before Brett and I stated them and made a proclamation, which ones were you living already? And which, if any, came as a revelation? So probably worth just going back a little bit in my history before I started with an initiative testing. I was working a company there beforehand and was one of the testing team there. And what I was finding was we obviously were moving to try and get developers testing better, getting more robust unit tests, testing in the correct places, rather than just passing it all over to the testing to a new automation. So that kind of part of the idea, the shifting left type thinking. We were doing the job there. And then it occurred to me at one point that I don't know how much of this was in my own head, but I always had the thought that it's all fine me being a tester trying to teach developers how to test. But it kind of occurred to me that they probably will listen to me more if I was a developer showing them how to test instead. So if I was actually practicing what I preached and living it. So I made the move there to move from testing role specifically to a development role. And that was a to basically build how I felt software should be built, which is your developer there will test stuff. And we'll talk through requirements. We'll make sure that our code is tested as much as we possibly can ourselves. And I always try to not fall into the trap that annoyed me when I used to be a tester of how could you even give this to over to testing when it clearly has never been done. So I was always not only testing through code, but I was still using my testing and exploratory testing skills to try and do stuff before, you know, before it got passed to other eyes. And obviously, the main reason for doing that is that we believe that or the company that believes and I certainly agreed with them that the faster feedback would be what would improve the business. So that that part of the principle number one, our priority is improving the business, we believe the business would be improved by developers testing better. And by testing better, we get faster feedback, we'd be able to react to changes quicker, and be able to put good quality software that our customers value in front of them as quickly as possible. What about a revelation? Did you have any revelations when you saw the principles? The main one that came as a bit of a revelation to me, and it will sound odd because it makes perfect sense, is the, it's obviously Brent's favorite phrase of data science. It's the idea of, yes, we should use, you know, we need to capture stuff for our customers to get the feedback to know what they're going to value. But it was never kind of, I never kind of realized that that could be scientific. It is always kind of expected to go through a product donut to do stuff. It never kind of occurred to me that, well, if you've got questions, you know, you're, as a developer, you kind of got control of the system. So you can put things in there to get those answers. So that was one of the things that just never occurred to me. It makes perfect sense as soon as you say it. I wish we could say that about all of the principles. As listeners know, some are a little bit more controversial, but I like to hear they make sense. Well, it's one of the interesting things because my view of principle seven and the reason why I'm seeing no longer a tester as a role, although I still identify as a tester rather than a developer, is because I'm not sure that the testing role as it was being performed was needed and I was giving better value by being able to develop. So, and that is the right revelation with that one. You can let me know later, but I'm pretty happy with the way I explained that in the upcoming modern testing course. And I did not make this podcast as a way to plug that course. I'm just excited about it. When you get to a point where you may not need dedicated testers on the team, it won't be anything less than completely obvious. Like in your case, I'll be more effective if I'm a developer. It's inefficient to have me focused just on testing. That's what happens in, if you're executing on the principles and that's what principle seven means. It means if you get to a point where you realize you don't need to have dedicated testers on the team, it's not a bad thing. It's just an evolution that may or may not happen. Well, a funny story that I like to tell people is that obviously at Ministry of Testing, we have probably the highest ratio of testers to developers or anyone because if you think about it, a lot of our staff came from testing backgrounds. On the flip side, we also have no testers, at least certainly not anyone whose job it is to come in day-to-day and test software in the sense you think about of a testing role. Whereas obviously I'm testing as part of development. Our CEO Richard does a lot of user testing for confirmation of what I built is actually what he asked for. So he does that. So yeah, it's just morally iconic in some ways. But on the other hand, that's not unfair because we're living that principle of testing needs to be done as soon as possible by the person best place to do it, not by farming out to a role just because. Yes, a million percent agree. My role is currently a director of program management and I still do a lot of testing. I do a lot of test coaching. Your story reminded me vaguely. It's a stand up for a feature being ready to be released and I took one of my many questions out of my quiver and I asked the team what's the worst. This is the way I was doing testing. I said, so let's say we release tomorrow. What's the worst? What are the worst things that could happen? And they did a nice job brainstorming and too nice of a job because 15 minutes later they had brainstormed a bullet list of things on the board and had assigned them to people to go investigate, which I think is a good thing. I was a little disappointed they haven't thought of those things earlier, but often it's the way we can scale testing across our team and teach the team the test is just ask questions about testing and it's not like they're unable to do it. You need to plant some seeds and get people thinking a little broader about how they're making their software. Yeah. So you're at the Ministry of Test, which is fascinating and very, very cool. How do you apply modern testing principles in your current role? So as I say, one of the way, basically how I like to work is test driven development. Start with, so I very much building testing from the start by having a hypothesis or trying to codify in a test how I want something to work and then running a test, having it fail, failing in the production side code and then refactoring as necessary. So TDD does seem to me to fall quite nicely into the modern testing principles from that perspective. Coming back to that data thing, we have a lot of things in there that we try to capture from the pages being visited, what lessons people are viewing. And the interesting problem with data is how do we get data that is useful without getting data that is not private, but not stuff that people want to share. So we have to think very carefully about what data we capture and when. So that we're not trying to just pull in everything that's either A, not useful and B, that people don't want to tell us about, but also having stuff that we can then act upon to improve the site so that the testers who use Ministry of Testing get more out of it. Any others? I think it's fair to say that because as I mentioned earlier, a lot of us come from testing backgrounds, so we quite often have conversations around things of how we can improve. We've all been in jobs where you have retrospectives and then nothing would happen as an example. So we make sure that we action stuff that we say we're going to action. So that's all kind of around principle four. So we do care about the quality culture. We want to make it better. We listen to feedback from users, testers, and ourselves and try and implement it. And not only when we try to implement it, make sure we fed back on whether it's worked or not. So constantly experimenting, constantly trying to improve. I can't see you, but I'm smiling. That's fantastic. I've probably already asked three questions, but two official questions. Let me ask one more. How did you discover the A.B. testing podcast? I came into it, I think it must have been about the early 20s. I know that I'd discovered it after it had been going for a bit. And I went back to episode one and listened all the way through. But then it was still early enough where that was actually not completely not insane thing to do, but not a difficult thing to do. Yeah, that's a brave endeavor. We tell most people... Yeah, that's right. We're doing it now, certainly. Now that's the famous traditional versus modern testing manager conversation. Yeah, which was good fun. Someone brought that up on the Slack group this week. And I thought, Brent was so convincing because he had did that job for a long time. I thought I totally lost and had the wrong points, but he played me right where we want. We played each other right where we wanted each other. So it was a lot of fun. Maybe we'll do it again. Yeah, it was all very good. There was one of those early episodes that I did particularly like, because when I first joined the Slack group, they asked, what was your favorite episode and why? And I definitely had an answer. Unfortunately, that answer was about four years ago. So I can't remember what I gave. But certainly if I was going to answer it now, one of my favorite episodes was the one that you did with... Well, it's actually a pair of episodes. So it was the one around Slany and Webdriver and then the follow up with Hugs. Yes. Yeah. It was really cool. He reached out on Twitter and asked if he could be on the podcast, said, heck yeah, let's do this. And it was fun. A lot of good fun. Yeah. It's one of those classic conversations where you end up going, yeah, we agree on that. We agree on that. We agree on that. And it turns out the Slack disagreement was not really that massive in the end. Right. And the main point there, and people should really go back and listen to that. But he tried to, it was a good, he tried to draw us in by asking, so should Selenium stop using selectors? Because that's my gripe because people use some really convoluted code to try and manipulate a webpage by doing these wild selectors. And of course, we said no, because we have millions of Selenium tests that need selectors. He can't go break them all. And he kind of agreed that things that I didn't like were ugly. So he built a heap, he finally grew into a bit of a monster. And I think in his soul, he realizes that a little bit. Yeah, I can slightly laugh at it because being in the position that I'm in, I pretty much get to create the selectors. I am in the thing. So I was doing automation and testing course earlier this week, again, with Richard and Mark, who are also MOT people. I'm not entirely certain why they sent me on that course, but my boss wants me to do it. That's what I did. Anyway, but in there, one of the things they say is like, you know, if you're having troubles, talk to developers, get stuff changed, or even better, learn to do it. That's great advice. And I'm lucky enough in that not only can I do it, I literally have control over it, being the developer. So I hopefully, fairly certain, think about my code base. I don't have any horrible selectors in there at the moment. But I have known some stuff in the past where only thing I could do was something, either rather whole BX path or that is the exception. Yes. Yes, I understand. All right. Well, that's kind of all there is to it. Be about a 20 minute podcast. I am so happy to have you as the first one. I will do an episode zero. By the time you hear this as a listener, there'll be an episode one. So maybe I shouldn't have said that, but there'll be episodes coming out of this where we talk to a lot of different listeners and practitioners of modern testing and kind of get an idea of how they operate in their worlds. Chance to plug anything. Anything else you want to plug? Anything other than the cool stuff you're doing in the ministry of testing? Unfortunately, outside of the cool stuff I do at ministry of testing, I'm rather boring, but I am at Testing Chef on Twitter. I'm also there on the ministry of testing Slack channel and the testers.chat slappers. So if anyone wants, oh, and of course, I am on the, one of the three Slack channels as well for the other three listeners, but most of those three know where to get hold of me. I was with two of them the other day. That's all the picture. That's fantastic. So I might have attested. Cool. Well, but yeah, that's pretty much it. Talk to me. I'm perfectly happy to talk testing whenever. So yeah, thanks for doing what you do. I'm, Brent and I are both huge fans of ministry of test. It's awesome to have you there and awesome to have you on this podcast. So yes, thank you very much. We'll cross paths again soon. I'm sure. Yeah, I hope so. Thank you very much. 
