Hi everyone, howdy, I'm Alan, I'm Brent, and we're back for another episode of AB testing. Yes we are. And Brent was, that was the face of, oh my god, what number are we? That's where you usually say the number. No, I had written it down. Oh, it's 83. Yeah. You notice the three looks kind of like an eight? It does. Is someone a race part of it? Yeah, I'm not good with numbers. Aren't you a data scientist? Yeah, yeah, yeah. Alright, what's new, what's up, what's going on? It's exciting times, it's review time at Microsoft. Yeah, I don't miss it. You know, you mentioned it last time and I completely forgot. Yeah, I wish I had the luxury of that. We even had, you know, I got a raise recently because I've been there a year and we actually have three times a year where we do merit increases, raises at Unity. And usually we don't do the first one for a year, unwritten rule but not official rule at all. And I didn't, I forgot. I knew I'd been there a year but I forgot that I would get it. It's so weird how much that's changed. I do not miss the Microsoft review season. No. I'm so sorry, my condolences? No, I mean, you got to take it in baby steps, right? Right now, Microsoft's regaining momentum, right? Sure. We're at all time highs. We're more capitalized than Google now. Again, there are folks thinking that we'll, there's actually discussion about Microsoft being a $1 trillion company in the next year. Which I, I mean, certainly I would love that. I was just going over, now total tangent, don't dive too deep. Yep. The big story is I was going over my savings and college expenses, figure out how long I'd work and had a couple weird realizations yesterday. One is that I have saved, as far as I know, more than most of my peers. So I'm very lucky to work at Microsoft for a long time. And I was just thinking about this because I have zero regret. I left a lot, a lot, now a lot, a lot more dollars of stock on the table when I left Microsoft. But I'm still 100% glad I left. But I realized that as much as I've saved, which is- As things says, money isn't even close to a primary motivator. It's enough for it's, and that's, I really, that really rings true. And that I lost sight of that at Microsoft because you're sort of chasing that, that, ooh, I wonder if I can get in this band of bonus. Oh. Yeah. I don't share that. I mean, I know a lot of people who are aggressively going after money. I don't share that. For me, I just want to not have to worry about it. So anyway, the point I realized is, first point I realized is how many people are planning to work pretty much until they die. Like this idea of retirement has faded. People kind of spend what they have. Lots of data showing that. And then with, here's a weird economic thing. And a coworker said they read an article on this. I don't want to find this, but I was thinking through it. If people work into their 60s and 70s and maybe 80s and life expectancy increases, we're going to have an odd, it's not, I was called odd, that's probably not the diverse way of putting this, but we're going to have a workforce of lots of people in their 60s, 70s, 80s working, which would mean fewer jobs for those in their 20s entering the job market. What happens then? It's a systems problem. It is a systems problem. The thing is, is that assumes that the market hasn't grown to require additional. And I imagine we'll move into a world where additional labor is needed. But anyway, interesting. Interesting. And I don't think about retiring as a point like, I don't want to work anymore, because I'll probably always work. And even when I quit a full-time job, probably do some consulting to make ends meet. But it was interesting looking. I don't think most people realize how much you need to save if you want to stop working even in your 60s. Yeah, you know, for me, so it's interesting you bring this up. I had lunch with a long time friend who's still at Microsoft today. I had lunch with him yesterday. And he shared that he's got some developer that is coming to him on a monthly basis, trying to get him to sell his house. And the developer is currently not offering the make me move money. But he's like, I kind of hope he does. Because he's intending, if he gets that, he already owns two condos in Maui. And he's found a bed and breakfast that if he got the make me move money, that would be enough for him to put a down on that bed and breakfast. And then he's out of here. Oh, and so he would have residual income from being being a landlord. You just need a plan. You just need a plan. And I worry that so many of my home friends, my people I interact with, so many of them, their plan is no plan. I'll work until I can't work anymore. And then I'll figure something out. So I'm in that camp. Like one of the things that I realized when talking with him. So something I know about me already. My cost of living goes up when I have too much idle time. Right. So if I'm going to retire, I need to have a sense of what I'm going to do. Right. If, for example, if I got hit by a layoff today, it's very clear what I would do. I would just take time off, go back to school. I have one class left in my master's. Oh, you haven't finished that yet? No, this class. So the classes that I got to do now are just not interesting. And I didn't go back to school to get a degree. I went back to school to learn the content, but I'm just like, no, I'm tortured. I'm like, uh, yeah, just why not. Might as well just finish it. At this stage, you may as well do it. But I would go back. But even then, right, that's sort of an activity, a promise of some future goal, which I haven't identified. Great. I'd go back to school for what? What am I going to learn? What do I want to do with it? Although I will say, going back to like a culinary art school. I've thought about that. I have thought about that myself. So reeling back on track, because I do have some topics today. Very quick, I'll be in New York next week at the Test Leadership Congress. Cool. Giving two workshops and a keynote. Busy, busy Alan. Managing the Modern Tester is one of the workshops. I'm sensing a theme. The other one is, I forgot the title. It's on building communities. And then the keynote is the Leaders Guide to Building Equality Culture. Which I want to talk about a little bit more afterwards. But this was probably the hardest keynote I've ever had to put together, because I had to think. Because most of the time when I give a keynote, I said, like, OK, I got the ideas in my hand. I got to organize them into a story below law. What's the title again? The Leaders Guide to Building Equality Culture. So I had to think a lot about this. And I worry a lot about telling a story as I go along. And I'll tell more about it afterwards. But I'm pretty happy with what I ended up with. I'll do some more tweaking on it before the presentation. Thank you, Test Leadership Congress, for not asking me to submit my slides. Three months in advance. I appreciate that. One thing I started to do at conferences now, that I'll continue to do, is I create a friendly URL bit.ly link to my presentation, like Google Slides. And I share those on the first slide of my presentation. So. Oh. So. So that people can follow. Yeah. So it gets rid of the inevitable, are your slides going to be available? And my slides are frickin' useless to anyone not telling the stories. But if people always ask, so I just make them available. Yeah. It's actually. No, you write slides for what slides are for. This is something I learned a long time ago. Do you know what the number one purpose of a presentation is? Convey information? Information sharing? Nope. What is it? To entertain. Oh, that's a much better thing. I do do that. I do try to do that. The secondary goal is to convey information that sticks. Yes. All right. I'm going to try and do both of those. Hey, one quick thing before we dive into the principles, which we promised to do and we will do is I want to thank you for episode 82. If you recall or you're back and listen right now, we'll wait. Welcome back. And I trust you hit pause in the right spot. I went through the exercise that Brent walked me through with some of my peers and worked out pretty well. People. It caused. It caused the right discussions to happen. I went through a bunch of other things as well, but I walk through that exercise as part of a larger presentation I was giving and it lots of proper conversation happened. And the one line I'll give you without diving too deep is we finished going over data or business value for a feature in data collection. And someone said, we should do another. So we'd get another hypothesis. Another hypothesis. Yeah. So we did it again. Yeah. The thing I think that's very valuable is it's a structured approach. It kind of creates it forces system thinking. So did you encounter a situation like we did on the air where you got to a particular point and then they realized, oh crap, this is the hypothesis. Yeah, I couldn't have planned it better. We came up with we struggled for our hypothesis. We came up, said, yep, that's the right one for that feature. We started going through and someone said, wait, wait, wait a minute. I think we have the wrong hypothesis. It was perfect. I couldn't have planned it any better. Yeah, that's great. It's a total improv works out great. And we will refer back to that and dive deeply into that when we get to principle number six. But today we're going to spend the rest of the podcast talking about principle number two, which I will read to you to get started. These are the modern testing principles on moderntesting.org. We accelerate the team and use models like lean thinking and the theory of constraints to help identify, prioritize and mitigate bottlenecks from the system. What the heck does that mean, Brent? One thing that that means is so what that is expressing is first, our goal is, is to accelerate the team. Okay. So it doesn't say we help the team go fast. It says we are a force multiplier. That's very, very important. It isn't people follow the trap. It just needs to go really, really fast. Right. Go fast and break things. Well, one way to say is that we're constantly making the team go faster. Okay. But then the other bit of it is, is using models like lean theory of constraints to identify how. So this principle is around, in my view, it's around adaptability, reaction and identifying the places. Now this is a modern testing principle, but it's adapted from Agile principle. So in this particular case, it's okay. Now that we have a sense of, you know, a much like your what you just described with your organization, we have a hypothesis around what creates quality. Okay. How do we accelerate towards that hypothesis? How do we validate it? And how do we do it faster by using Agile principles? Okay. I want to dive a little bit into just for those who may have only heard about these and not studied them a little bit into theory of constraints and lean thinking. Let me ask you a question. Why is who cares what I want to do? Right. Why is this the second principle? We talked about why it's important more than why it's the second principle. All right. So I'll ask you before I go back into the what, because you brought up the why and screwed up the whole flow. No, why? Okay, we'll come back to why. So what is there? I don't want to anymore. What is the theory of constraints? All right. What is the theory of constraints? I'll wait to turn that around. So theory of constraints is introduced in a book called the goal by what's his first name, goal threat. Dunno. Total preparation. Dunno, goal threat. We're so sorry. We'll remember later. My introduction to theory of constraints is through right. It's okay. So it's just a methodology for identifying the most important limiting factor, the constraint that's in the way of achieving whatever you want to get done. And then improving that constraint until it's no longer the limiting factor. Doesn't say eliminating the constraint, just improving it until it's not the limiting. It's no longer the worst bottleneck. So the goal is sort of is business novel that describes pretty much right. It sends how flow works where you don't have to solve all the problems. You just want to figure out where the bottlenecks are, make them not bottlenecks and things flow through the system much faster. It prioritizes improvement improvements. And in the top priority is always the current constraint. Yes. That's pretty much the summary of theory of constraints. There was a book about from an IT angle called Phoenix Project, which I liked. Some people didn't like. I thought it was a good, fun read. A lot of it rang true. And it's just a way to do rapid improvement. So the way it works, the way the constraint work is you, like I mentioned, is you figure out what the constraint is, you make it a priority, you mitigate it or work on it until it's no longer the biggest constraint. And then you reprioritize on what is now the biggest constraint. So from that thinking, that's sort of what theory of constraints is. Let's talk about, I want to go into lean a little bit because they cover each, they overlap each other. Both lean and the Kanban method, which is a specific... Well, Kanban comes out of lean. Kanban method, capital K, capital M, trademarked by David Anderson. Both of these are sort of grown out of the theory of constraints. I'm not certain around chronologically the theory of constraints. Kanban itself came out of this concept of Kaizen. And that's an old concept that Toyota developed. I'm not certain what came first, theory of constraints or Kaizen. Nevertheless, today's methods kind of combine both of these things together. Yes. Anyway, you were going to the place. You kind of already summarized lean, lean, just in a nutshell. There's seven lean principles that guide lean thinking. It's optimize the whole, system thinking, eliminate waste, create knowledge, build quality in, important, deliver fast by managing flow. This is pretty much the core of lean thinking, the idea that focus produces higher quality work. Defer commitment and respect to people. Yes. But in the thing is, so this is one of the things I think is most often forgotten. By managing flow. People all know Agile is all about delivering fast. And that's what seems to stick. But the other bit after that is critical. By managing flow. Now is the time. I think for those who have been waiting, now we dive into the why this is important. You've already started diving there. I'm just actually officially announcing the transition. Yes. So what I want to try to do in a time remaining is, so we're adapting. We got some feedback from 81. We want to try to cover what, why, and how. But I also want to make sure that we're not forgetting the modern test context. Because a lot of this discussion is going to be very easy to describe it from an Agilist only paradigm. Right. Why is this important? There's a couple of things. A couple of things why I think it's important. Number one, by focusing the modern tester on identifying their role as acceleration. We're choosing these models because quite honestly they're proven out. Right. These are great structural models to learn to how to accelerate in a positive fashion. The reason why I think this is an important principle is I think far too much of test is the reverse. They create the bottlenecks. What we want is tests to be recognized that being a bottleneck in the system is actually harmful. Not only for customer quality, but for the business. Work towards the exact other side. An example I constantly think of is the stabilization period just before release. Yeah. Well, why do you feel that way? It means you screwed up earlier. It means you have not built quality. It's a bottleneck. It's always faster to fix the things as you go along and build quality from the beginning versus try to test quality in at the end. And this is the way Office was built forever. They would have these minuscule coding milestones where people would shoving their code as fast as they could to meet the arbitrary deadline. Then there'd be an extensively long stabilization period. Yeah, those these drove me freaking nuts. I'm sure I mentioned it on here before, but it just makes my blood boil. There are these sort of timeline concepts that, like one of the worst concepts I've ever recalled. Now, when I was a test manager, I never had this milestone. But do you remember, have you ever worked on a team that had a test complete date? Yes. WTF. What is this concept intended to mean? Like I have tested everything I'm going to by this date? No, we when I was on a team that had it, there was a test complete date of they wanted to lock the source tree except for fixes. So we had test development was complete like one week after product development. Yeah, it was. Yeah, again, I'm not happy about it. No, it's I remember once I had a director get so pissed off at me, he called me and I didn't work in his org, but he was so pissed off. He called me. He's like, Brent, when are you? When is your test complete? And I'm like, there is no test complete. Oh, yes, there is. Okay, that's a date you set. I am choosing to not follow it. And he's like, but Brent, if you if you continue to test after test complete, you'll find bugs. This is a director test telling me this you'll find you'll find bugs and that will cause us to slip. Right. A director of tests is telling me that I'm going to obviously a Peter principal promotion. Yeah, he he longer story there. He and I worked together years later and he came to me. We were peers at that time. He came to me and there was an opening for another TM role and he asked me to if I would back him for that role and I looked him straight in the eyes. I said, not a chance in hell. So anyway, yeah, let's tie this back to accelerating. Well, so these are some of the the the pre existing. Right. It's that mantra is around completion and predictability. Right. It's not around value. Right. And in order to accelerate, you have to have a mechanism that that first identifies what the value is that you can iterate very rapidly on analyze and understand what's the next bottleneck. There's a nice tie in to principle number one here and improving the business versus versus being a cost. A part in my mind, a lot of the principles we've laid out are specifically intended to contrast with current practice. Right. We do not want testing anymore to be viewed as a cost as a as a bottleneck. Right. The we cannot win the battle around all of those testers. You know, they keep finding the bugs and are slowing down the release. Right. It and I'm like, yeah, you know what? I'm I'm with them. Let's stop that. Let's stop slowing down the release. Let's figure out what. Let's figure out how we get product out to the customer faster so that we can actually use the customer to determine whether or not we are delivering quality. As we've set out over and over again, quality is a problem solved to a human being. And a lot of our bottlenecks are around this theoretical champion of quality crap. And this is the the canonical bottleneck in a software team is you have an agile team as air quotes their agile team of eight developers and a tester. And the tester is overwhelmed and he's the bottleneck for the team or she's the bottleneck for the team. Hiring eight more developers for that team isn't going to make the team any faster. But it says you can view the theory of constraints go well, if I add eight more people surely will be faster. But no, you'll actually be slower. It's solving the wrong problem. So the modern tester, of course, recognizes that the modern tester is coaching his team on owning much more of that testing and making sure that they are not the bottleneck. But so even more so. So now in terms of like the behavior we're trying to remove, let's talk about the behavior we're trying to get. Why do we need this? Well, in a quality context, a customer quality context, getting that fast feedback loop is critical in terms of triangulating around what is quality. So getting smaller releases, determining, hey, creating that feedback loop, determining, okay, did we create a risk? Minimizing that risk, getting that loop adapting and accelerating is what we're saying this is all about. It's all about the fast feedback. And I want to reiterate, it isn't, and you mean this, I know, but it isn't just about fast. No. So there's a fine line. It's actually a thick line. There's the fallacy of now, as I call it, meaning I got to get it out now, even though it's not ready, but I got to get it out of it. They have to have it. And you have to balance that with failure to launch. Whereas Reeve says you don't get any value from your engineering effort until it's in the hands of customers. So you need to get... You don't get any value. And if you're in tests, you don't get any sense of the quality of what was released. You don't have any learning opportunities until it's out the door. Yeah. So you're trying to create the best possible learning opportunity. And then again, as we called out earlier, it's about going fast by managing the flow. Right. Yes. It's about reducing the friction so that you can get access to these things that are very valuable for you to learn from. I just wanted to underscore it isn't just about fast. No. That's it. So it's super important. It's worth underlining, if you can underline in a podcast. Rents thinking. Yeah, I don't know how to do that. I probably could figure it out, but it'd take too much time. Have you done this? So I'll say, as most are aware of, I'm a data scientist now. I still live this principle. However, my sense of quality is primarily around usage. So for me, a data scientist, hey, I'm producing things where people are supposed to be able to make decisions off of. Okay. So that's always the beginning phase. Until you have earned enough trust from the humans who are making the decisions currently, you build your models and you support the decision making until that trust is established. And then you just automate it. Okay. Now, if I spend months on a data set and an analysis and then a model and then release it and no one uses it, it's the same thing. It's no different than any other product. And a lot of the times, this is why it's really critical to get these things out sooner. There's something that I did very recently on this. And I realized shortly after my release of a new data set that my target customer was wrong. I very quickly figured out who it was. And it turned out I was able to shift over, create demand without having to change anything around my underpinning asset. I forget the name, but having recently studied the Eric Ries pivots from the Lean Startup, there's a name for that pivot. He names that one. That's a very common pivot. Yeah. No, and that kind of goes into 82 around our hypothesis, right? We spent a lot of time last time talking about customer segment, right? Maybe when we were talking about what was it, the hub and the landing, something or other, right? You had gotten this feedback, but one of the problems with feedback is, okay, is that the noisy 2% of your customers? Agree. So I want to talk... But one of the... Actually, where I was going... Nevermind. And no, I'll let you choose your topic next. Choose your own next adventure. I want to tie it to testing. Last time I was in dev, I did this model. It worked very successfully. And what I learned from that is, yeah, I don't need a separate testing. Now, in my case, I had a unified engineering team and I had testing talent on it. And I spent a good amount of time thinking, do I need to separate this stuff? And I'm like, no, actually, I don't. My actual, quote unquote, testers are my better developers. Yeah. Yeah. No, I fully agree. So I want to kind of transition this into the how, but do it by talking about something that... I just double checked. I don't think it's mentioned explicitly in the principles, which is systems thinking. Yes. And being able to see the whole picture of the system. One of the things I ask everyone on my team to do is... In my viewpoint, in order to accelerate the achievement of a quality, in order to provide acceleration, you need to understand the system. And you need to understand the system in order to understand where bottlenecks may exist. So what I ask people on my team to do is, for your features, you should understand everything from developer desktop to deployment, how that works. So whether it's, what are the tools that run as part of the local build? What... I can dive in there in a minute. What testing occurs for the check-in? What testing happens during the continuous integration pipeline? How are things deployed? Are they deployed all at once? Is there blue-green? What happens? How do we get feedback? What data is available? I know you know this. You probably know it by a different name. You're deployed to this server, server farm, and you have a new version. You deploy here, and you slowly route traffic from one to the other. Oh, got it. Okay. So there's lots of different names for it. I think blue-green's fairly popular. I'm surprised you hadn't heard of it. No. But you go from the blue, green, and then the green becomes the backup. So you always have the hot and the live. It makes it easy to roll back. If you have good traffic mapping, you can slowly route people over and look for errors in the new version, et cetera. So understand that whole system. You understand where are the bottlenecks? What's difficult for us to do? But you have to understand the system in order to do it. Yeah. And again, I want to – the bottlenecks here, because it's the modern testing principle, right? The other thing, too, is I think where tests should spend their time is on the delivery of quality. Mm-hmm. Right? Now, here, it's going to be harder, because every time I say quality, I am not referring to code correctness, right? And so if we have new listeners on the podcast today, to me, quality is not bugs. Quality is, did it satisfy a customer problem? Mm-hmm. Right? So how do we get – if we start off with the basis that in order for us to achieve quality, we need to get that fast feedback. What's slowing us down from getting that feedback? Right. So I will push back a little bit and understand that whole system, because I fully agree with that. But if we are blocked from being able to get that feedback because of code correctness, I'm not going to go do the work. I believe that belongs – well, it's not what I'm concerned with, but I'm going to make sure it's happening. Like, you know what, you should really run – I'm going to change CI, so unit tests run there, or I'm going to change the developer flow so that this linter or this other tool runs before – this static analysis tool runs before check-in. I may facilitate that. I may do that. But you're right. My concern is customer value. The thing I will say to push back on your pushback is – This is as close as we get to fighting on A-B testing. I don't think you're going to disagree with what I'm going to say. Dammit. While I agree with that, I think QA needs to temper way back or scale way back on this idea of how proactive we have to be. Come on, dude. Shift right or left. I forget which way. Yeah. I hate the term, so I don't remember how it works. So you can ship bad code, but you can't ship bad code without the ability to detect and revert it. I will say having the ability to ship bad code with detection and reversion, letting devs ship bad code into the wild is something QA should do. So you're saying – Which I think is counterproductive to everyone's instinct listening to it. Yes. Less proactive, more ability to be massively fast at reacting. Our job is to minimize harm overall. But the more proactive we are, the more we start adding bile next back in the system. What we are trying to do is not create that dysfunction loop. And the way you get devs to be accountable for code correctness is let them realize that they just harmed a customer. Now, at QA, we can't allow catastrophic events. You can't allow that sort of thing. But the number of tests that we need to cover proactively is much smaller. I want to push back on your pushback on my pushback. Okay. Okay. So let's say we have a system where we can go, oops, bad, roll back. Oops, bad, roll back. Super fast. We're great. We detect the stuff. It's great. But we can never get a deployment out because code correctness is so shit. Then, if you look at it as a system – No. Then it goes right back to principle two. Right? It's, again – Exactly. Exactly. Our job is to deliver quality, and quality is value delivery to the customer. So if there's – so first off – For unable to deliver value to the customer, and the root cause of that bottleneck is code correctness, we kind of have to go make sure something happens there. Right. But here, the thing that's – this is fantastic. The thing that is important about this principle is that the modern tester is disallowed to create significant bottlenecks back in the system. Yes. So once we do this and we realize, oh, code correctness, the answer is not bring back the one-month stabilization test pass. The answer is how do I coach these – how do I coach these – or these devs? What – one of the things I blogged about this years ago, one of the things that I did to resolve this problem is I put my strongest test automators into the dev team, and I said, all right, these guys – they're now your reports. These guys are responsible. They're going to be first responsible for teaching the rest of your dev how to do unit tests, how to do the automation that is necessary so that they can CYA and stop reverting. Right. The most positive thing is, in this particular case, when dev is constantly shipping and then that's having to be rolled back, it's not just QA. It's going to be concerned. It's going to be the business. We're not going to – now, but the thing at that point in time, and I love when we get to that bottleneck or that decision point, rather, because what you have to do if you're a modern tester is show a better way forward than falling back to the old ways. Which means that the big essence of this principle is that you constantly need to be looking at the system, take a step back. Yep. Because you may – it's very possible and very common you may be focusing on the wrong bottleneck. So, stop and ask yourself, is this the right bottleneck? Back up. Look, is this really the slowdown in the system? Does it exist somewhere else? Have I already mitigated this bottleneck? What is the largest one in the system? Dive back in. It's really easy to get stuck. What is creating risk to the system? That's something test is very good at, although they don't think of it that way. What is creating risk? I've talked about it a million times before. I hate Scrum. It doesn't take long going through Scrum to realize when all of the bugs are created. It's at 11 p.m. the night before the sprint in demo. Yes. Almost all of the time. And when you shift to a Kanban model – Which is optimized for flow. And one check-in gets absorbed into the system at a time. Then you go, hey, it's a lot easier to create a mechanism. Let's say you want to – some teams want to have a staging or a test environment before they go to prod. You create a system that says, okay, let's do one check-in at a time. Let's validate goodness. I think – and a little bit of a rant here, but it falls into the principle. I think too many teams use Scrum as – one, incorrectly, and they think they're doing Agile. But what they're – they're focusing on iteration versus adaptability. The other value add – so when people say we want a hybrid between waterfall and Agile, one of the learnings that I've done is I've actually realized that Scrum is not Agile. Scrum is actually that hybrid. Because what you want is – the problem with waterfall is – Scrum has turned into – the idea of Scrum is that if the item's not complete, it's fine. It goes back into the backlog at the end of the sprint. But people feel bad not completing their commitment, so they shove them in at the end and create waterfall out of Scrum. Scrum as designed, I don't think, is the hybrid. What Scrum has grown largely into on, I would say, most teams following Scrum is exactly that. And I disagree. Well, one of us is right. Oh, well, good. And one of us can edit out the I disagree part of the problem. But it's not – that is spawning – I mean, that can be episode 93. What else do you want to hit on this? What are some other things that you've done to support this principle, or that you've seen done to accelerate the team? The single most important thing is get folks moving up front. The second most important thing – so these are very tactical things that I've discovered work very well. Shift to a flow model, not a Scrum or a waterfall model. Do one check-in-a-time. Create a process where one check-in-a-time goes to stage, and then that gets validated and goes to production. Create a mechanism where you're using test and production to drive automatically your rollback process. One of the biggest issues that I've seen is a lot of teams, they're still heavy on the proactivity and have it invested in the ability to solidly roll back automatically. It's a forward only. And once you detect harm, you've got to roll it back. But what you'll find is that a lot of the situations – things that we've done in the past, the traditional testing methods – were a waste of time. Yes. One thing also to bring up here – and we've mentioned this on the podcast before – but an important aspect for understanding the system and figuring out where improvements can be made. It's part of agile. It's even part of Scrum that teams don't take advantage of properly, is the retrospective. Yes. It's a method for the team to discuss and discover and sometimes solve the bottlenecks in the system. The other thing that, again, that – I mean, you asked what have I done. One of the things that I've done is deeply invested in the telemetry and the data. Yes. Because one of the ways to really accelerate the team is to kill the theoretical discussions. More than hours, I would say – I'm old. At this point in time, it probably is, months of my time in my career has just been lost to theoretical triage discussions. Yes. Right? And you know what? It doesn't – it takes far less calendar time. Like, this is the thing I think that is critical to hear, is what this principle isn't just about – it actually isn't – we've talked about it being about acceleration and about moving faster. At the end of the day, what this is about is test has a responsibility in today's market to contribute to getting to the same goal and reducing the amount of calendar time it takes. Yes. We have not, as a society, figured out how to scale calendar time. In Principle 1, we talk about being a business value, and our focus is improving the business. And one of the primary ways we improve the business is by accelerating the team, by accelerating our ability to get feedback on what we're building. Yes. And you're right. Retrospectives is absolutely valuable, one of the most critical questions. Like, yes, you're right on something I said five minutes ago. That was awesome, Brent. Thank you. I was just tying it all back together. Book ending is what they call it in the business. I don't know the business. I don't know the business. Yeah, and you completely caused me to forget what the hell I was. That's because you're old. It is. Although chronologically, I'm older, you're older. Probably. It's all the – yeah. Okay, Brent is, I think, ready for his nap. Stunned. And I hope that all three listeners got an idea of why this principle is important, or why we think it's important, and things you can do to exercise that principle. I think one of the things that we may need to just already retrospectively thinking about this podcast, we may need to start calling them medium dives. It's not really a deep dive. Yeah. Okay. Well, there's no official title. We're going to dive into each one. I think the discussion is – Drill in. Drill in, yeah. Lean in, drill in. I don't know. Yeah. Anyway, we just did one. Okay, whatever it was, you tell us what to call it. I can't wait for the next one. It should be exciting. Okay. All right, everyone. We'll see you next time on AB Testing. Bye. 
