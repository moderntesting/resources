Welcome to AV testing podcast your modern testing podcast your hosts Alan and Brent will be here to guide you through Topics on testing leadership agile and anything else that comes to mind now on with the show boom Whoop there it is that was the sound of 134 episode 134 of the AV testing podcast hitting your podcast player Because I finally got almost Almost everyone switched over to the new feed for some reason of course if you're on the old feed you're not getting any new episodes, but I had like 11 or 15 or some small number of plays still last week from the old feed like they were catching up. I Like that as a as a model for the model for the podcast a be testing podcast where we almost get it right Sometimes maybe hey Perfect is the enemy of good right it it is have you ever heard of the 8080 rule the 8080 rule No, what is the 8080 rule? 8080 rule is 80% of the value comes from 80% of the effort the other 80% of the value comes from the remaining 20% of the effort I know you're a math guy And you're gonna think about that and it's gonna make sense someday What do you think I'm sticking by the 8080 rule all right? We're gonna go with that and that is not going to be anything. I call out in the show notes, which uh, so yeah We are here recording on a Friday afternoon on Friday Friday Friday Friday Freddowary the only thing I'm drinking is a tall can of cold brewed coffee Friday February 19th should be out on Monday next Wednesday Do it a webinar? Yeah Yeah, and I'm talking about a lot of you remember an article I posted on blog test project that I owe about a month ago on the developer versus a tester mindset and How I thought that was crap and we talked about that on a podcast probably 132. I Think and I'm giving a webinar talking about that. It's a real Multimedia experience of the article I wrote with more examples Of course, the audience is all going to be testers and I imagine the audience will all be there with pitchforks So, you know should be a good time. Yeah in here as a as a as a tease Alex or Alex that's my son's name Alan My god, I'm old Alan is is Finally going to show support for checking I'm not even that that was such a poorly baited hook. I'm not even gonna think of biting People are very subtle. I get direct messages on LinkedIn from folks saying your article is misleading Because it mentions the word testing when you really mean checking it's can and I am not Kidding they my latest article I just posted again on blog test project that I owe about Test automation which is pretty much the written version of our last podcast more or less with some Better grammar and spelling if you can misspell during a podcast. We would know how to do it anyway, the title was the title had the word test in it and They pinged me and said this article is not about testing. It's about test automation You should call that out and I did a quick little search and I replied back and I said Did you notice that the article has the word test automation or automated test? 40 does is not a made-up exaggerated podcast name. I counted 40 instances in a 1200 word article I think it's clear that the article was about test automation and the day I call it check automation Actually is never the only way that could happen is if I died and someone reanimated me as an evil robot So anyway, that's my life So I'm doing the webinar I will handle the pitchforks gracefully and again this goes back to episode one of the A B testing I'm not dictating That this is all going to change and neither is Brent We're here to help people navigate the change the webinar folks are really excited to have me do it There's good. It was their ideas to do the webinar and they said hey and be a little careful because our audience is testers And I will be of course, but it's about Letting just giving them information to help them navigate the change to itty bitty bits of information to share about the podcast One is the webinar None of this planned not in my notes One is that this is test project the test automation project Or program which I've used in the past. I did some blog posts on it a while back. It's super easy to use It's it's a nice platform I have subtly hinted both in my last article and in talking to these folks they should market these tools towards developers and not just testers and They are that is in their plans. They're gonna start marketing harder to developers. I think it's great I think tools like cypress and test cafe do already and I think all of the test tool Vendors in the industry should market a little more heavily Towards developers in fact, I don't know if I've mentioned I am good friends with the folks at autofie who make yet another Recorded test automation will make our test not flaky via via ML and AI Basically just to find out when it works pretty well It's it makes me much less afraid of UI automation, but they have companies come to them and Say they want to do. Oh, yeah, we want to do a whole bunch of automation They go these guys they get it because they're developers They're trying to market to developers and testers and teams say hold on hold on hold on No, no, just you you shouldn't do that You should write a whole bunch of tests that don't need web UI Verification and just use this for the things that can only be tested using web UI verification Anyway, we've been on that Hill before the other thing is test project was acquired a year ago six months ago by a larger company called Tricentis Not heard of it. Okay. Well, that is if you go look at I think the last James Buck post to web post from Roughly a year ago. He was going to work at Tricentis. I don't know if he's still there He's been pretty quiet and generally he gets quiet when he's busy working So he could be very much so still working there. I don't know if they'll show up at my Podcast a heckle, but I actually don't care if he does because I don't think he'll have anything to argue with them what I say But wanted to mention all that small world small world. Okay one more rant if you don't mind then we can do the topic for The day. Yeah, or do you actually want to say anything? Or so I didn't tag you on Twitter, but and we're not video cast haven't done that in a while Maybe we'll do it again sometime But I did I did send out an Instagram and a tweet Insta in a tweet right before we recorded and you guys can't see me but Brent I can't see his face because he's had his hand over his face the whole time but he is clean shaven and I in their hand have stopped shaving completely and I think if all goes well We kick Brent off of the podcast and the B and AB testing begins to stand for Alan's beard Let's be me and my beard. I'm practicing why I'm monopolizing the recording time Yeah, I I think that's a Potentially a great way to boost listenership right, I your beard is clearly very wise Clearly clearly makes me look older and smarter. Hey, I have a question for you. Yeah, this is a multiple choice question You're good at these. We've done this before. All right, here we go what false assumption should you be aware of when striving for continuous quality a Quality should be assured by tests conducted by a dedicated team B quality is primarily a marketing asset and yields few other benefits or See the more bugs that are found and fixed the better the quality. Oh my god Is is D none of the above wait say B again Quality is primarily a marketing asset and yields few other benefits and then a Quality should be assured by tests conducted by a dedicated team Well with I mean all of those options suck, but if I have to pick one I'll pick B All right. Well, you're your friends at Microsoft who made this little quiz Said that C is the correct answer that that's a fault that the more bugs that are found and fixed about other the quality is The false assumption about continuous quality therefore. Oh, therefore the others others must be true It's a very confusing question. I wanted to highlight that it gets gets the WTF of the day. Yeah It really is missing a all of the above option It is exactly right. Hey, so today on the podcast Did you where's the link to that? Where's the link to that thing? I just have the graphic and it's in One of the three dot slack comm you can join by going to modern test new or clicking on the link and it's in the Rance Channel where lots of folks post It's tough that pisses them off Okay, well Brent lives at go you guys this come out You won't you will have to talk to Yost? That's all I can say. That's all I know. I saw it today It was worth reading you need to do your research ahead of the podcast I have books all over my table at websites open. I have done my research I'm also lying Absolutely, you're lying. I'm like do the research before the podcast We we don't know the topics until five minutes after the podcast has started one of my favorite lines ever in comedy is from John Mulaney I Won't go it. I won't tell the whole story Blah blah blah blah blah blah blah blah blah. I said no You know like a liar Okay, some reason that line just I just love it sticks in my head all the time I lie which I guess is good Or it means I lie a lot So anyway topic and if you're gonna you're gonna be eating through the whole podcast or just like during part of the recording I think in the whole one is that is that I mean there are Seven days a week all of these like 20 One hour for one hour in two weeks of time I ask you to not be shoving crap in your face, but no I can't do a man It's too hard Further further evidence for for this whole beard program. Hey, so uh, we always we frequently we frequently use Stuff Alan's doing at work to talk about to delve into topics that are seem relevant for the three But I want to use talking about what you do at work to talk about what I do at work to benefit the three Because I don't think well, I think the three probably can describe what I do at least what my responsibilities are pretty well All they know is Brent sits in a desk and does math Like what is your role you manage a data science team? Is that correct? Yeah, and is it all top secret stuff? You can't talk about and that's fine But what does like what are the outputs of your team who consumes your stuff? Tell tell tell the three a little bit more Under the appropriate NDA on what you do So I have two key missions One is Essentially We have customers who are in pain. We have customers who have problems and That that second mission is around How do we apply? so my my portion of that mission is the is the application of data science with the goal of the match making solutions to problems as as soon as possible in the user's journey on the platform So is there a not is there a fair to share example of that you can share well So the other thing I was gonna say is so my team is a much further along on that mission than my second mission and We actually own and operate Microservices where that are ml powered that plug into particular elements of the portal of the Azure portal itself so one one aspect for example if you if you're on Azure and You go and and create a support ticket You begin the process to create a support ticket There's a system that will give you a recommendation as to What topic you're actually? should should move forward with the very very first pain in the wizard is sort of specifying the the topic that sort of encapsulates the problem space and That's a that that service is entirely my team There's there's another one that we operate that Helps so in the case. I'm actually trying to decide if this is an NDA thing Yeah, it is We have another service that when customers have a certain type of problem. We give them we give them a very concrete and direct alternative to them they they there's a specific problem that they could face and There's there's no way to move forward in their ideal scenario, so we are able to give them an alternative to what they were doing and That second one the first one is great because I ran a essentially a small little team and That one is the first one is a very tight scenario and But my team is very proud of it because we are operating at Microsoft scope and and helping to solve Microsoft level problems the second one Is a real customer bummer? It's it's it's in terms of Azure itself. It's a rather rare event but in terms But it does happen daily and This particular that one has actually helped to To get customers a faster solution and able to move forward and directly reduced The number of cases the support cases for that particular problem by 40% oh That's all that that's great. So yeah, most of your stuff it sounds like from you talking about you can correct me if I misinterpreted this but it is Not customer visible directly, but it's it's stuff that runs in production that actually runs behind the scenes to help other stuff work It's it's or is it internal that that was unclear to me So all of the services that we're operating right now and again It's the two and we have a couple more about to ship There they're behind highly secured rest API's. Okay, so so yeah, but the the user visible components Will directly show the results in a more user Friendly way, but it is a rest API. I'm not I'm not generating the UI or whatever API is accessible by customers as well as internal developers The rest API directly is not we're very tight on on Controlling who who gets to call it? All right, so you are and and the reason for my precision questioning is the topic I wanted to get to is talk about Orgs like test orgs like the org I run like the org you run that We exist to help other parts of the org be successful. Is that statement? Correct? Does that high level description of both of our orgs put us in the same part of the Venn diagram if you'd asked me two years ago That I would have immediately said yes, as you as you know Alan I think The denocides fad is at the beginning of the end. Mm-hmm. Okay, and As you also know when it comes to career chained events I tend to start I stand to start doing that shift much sooner than most others And in the coordinates, this is why I a data science team and operating to production services So I am I don't know if you would put a development organization as part of that support organization I guess if it were a tool developer, it's a little different. I'm stretching a little bit It's a little bit different than what an infrastructure or a site reliability engineering team do in my case Yeah, a non-trivial portion of my duties are in a supportive role. It's my job to generate insights That force other people to do things. Okay, so very close We have teams that aren't in my org that do similar sorts of things for our business as you could imagine Not not at Microsoft scale. They do it at unity scale Agreed, let me move on to my original topic. I think there'll be some relevance to what you're doing But of course you've of course you've run test teams in the past which I think very much fall into this bucket Your your goal as a test team isn't to find bugs It isn't to write a bunch of automated tests It isn't to run code coverage is to accelerate the achievement a shippable quality or accelerate the team's ability to ship or as principle one says Well cellophane correctly in the background or as principle one says Business value business first right, so I'm curious you've run test teams a lot and you've run orgs like this and of course as Probably as far back as Xbox one is when I first sort of fell into a role or a Purely support role where I wasn't testing. You know what? I realized for all the work I've done in testing. Do you know when the last time that my job was to do testing even? 70% of my day Windows windows. No, it was Windows 2000 yeah mine was it was in called NT 5 at the time but that was my last time I did full-time testing Yeah for me was schedule plus Right with ships with office 95 Right because I went from I see the manager relatively quickly in my career The but hindsight 2020 And I don't want to the given in the context And I've shared this over and over again, right? I've kind of always shied away from roles That were were too heavily focused on testing because because quite honestly the process of testing was Awful. Well, what happened with me and this is a little off-topic But I I enjoyed doing the testing but then after a while I enjoyed Helping others get better and faster at it. So even I gotta think where I went from there So I was testing full-time there and then I joined the windows and millennium team And I did debugger development just because it was hard and fun and worked on debug windows and ended up I don't think I wrote any tests. I was pretty much full-time debugging and Doing some of the kernel dev probably why it sucked so much and after that I Windows CE I was a test architect there I helped others get stuff done. I ended up running the tools team there I owe I managed some testers, but I just let them do their stuff. I mainly worked on tool development And of course, I went to engineering excellence and taught testing. I that's where I really studied testing That's where I learned testing as when I had to study it so I could teach it And then yeah, and then after that it was more test architecti kind of stuff on link and then Definitely running the internal tools project as I did in Xbox, etc, etc, etc And these days just running teams that support a larger part of the company or the organization Yeah hindsight 2020 like and I've said this on the podcast before Like I was never really into testing right? I was far more interested in quality and Yeah, hey, I said, yeah, I want to underscore that's the thing I think that that will end any argument on testing versus checking or so. I don't give a shit. I care about quality I don't care like the craft is exciting as long as it leads towards customer quality Right. And of course, of course There is the semantic, you know piggybacking off of episode one hundred and three therein lies the semantic problem right because In the camp that's pushing back on your article on the mindset discussion They don't see a world where quality and testing are anything other than synonyms and and I Don't know I used to have a great set of skills around this Right. I have the one blog post That actually raised a lot of eyebrows in and got people to surf source Basically rethink it where but and then I don't know if you remember but I had a mentor back in the day and I'm like Hey, why is it? that We don't see test people from tests back when we had the functional roles here at Microsoft. We see tests ascending to To the product unit manager role all that often and his answer was like, oh my god That's like one of the simplest questions ever It's it's simply because the cussed the test doesn't understand the customer and back in those days Thems were fighting words. Yeah. Yeah We are the customer man with a last line of defense Right. Exactly. We're the the customer advocate him, right and I go through that story and I sat back to him and I walked through that story and I and set back and you know I was getting ready to bit flip him as a mentor. This was actually our first meeting I won't tell it here Maybe we put a link into the blog post in the show notes But what resulted is I of course then had a huge community of peers that were also test managers And I'm like, you know what? I Realized this dude's fucking right. I've I've been having my head up my own ass on this for forever And then I would share the story with the other test manager and I'm like, look, this is my perspective now And I can't I can't unsee it tell me where I'm wrong, right? And this is why and I'm gonna go off here because as you all may recall Regardless of our seventh principle, which says you may not need testers and don't you mean checkers? No, the most controversial as far as angry feedback We've had on the principles is the one where we say only the customer knows how to evaluate the quality of our products Which is absolutely right and I get it the feedback we get when and again, we are not dictating this This is us and our love and our study of Eric Reese and seeing how it works to actually get feedback and ship incrementally and get feedback from from people actually using the product via data What we see of anyway common down Brent But the idea is we don't know we just don't know how they use our stuff until we can see them use it or study how they use it through data and the idea that test is there to act as the customer and be the customer and the subject matter expert for the feature is Just a bunch of crap and I can tell you because you and I can both probably think of software that We tested the shit out of it's very functionally correct and users can't figure out how to use it, right? because the problems we're trying to solve is Spec correctness as our friend Steve called out in his follow-up blog to the put to my post He's like yeah, we've been spending all over time Focusing on spec correctness and making sure the spec was implemented to the letter But right no one's no one's worried about Does the customer care so I gotta tell you once I wrote I? Wrote and for Windows 98 some network API tests that not only Created shares of every allowable length. I'm I use some equivalence classes, but also every character That was possible on a win 9x machine Japanese Korean Chinese, etc, etc, etc and I ran all those tests I found a couple bugs, but it was a huge huge huge huge suite It ran forever. It was super reliable because it was API level. It wasn't done through the UI and Does that mean those network APIs had no bugs? No, I I just ran a lot of tests I probably had good code coverage, but I in hindsight as dumb Yeah, there's a lot of things The other thing too though is I think back. What is that? Hold on. Hold on. Yeah, there's a lot of things What does that mean? I was trying to shift into an empathetic moment Where where you and I walked away feel more connected and bonded together. That's not gonna happen My beard's in the way I think through like those days and and I don't know about you but I'm Part of me is actively repressing those days and as a result I'm forgetting the other constraints right a lot of the things that we did back then We're due to the fact that we're shipping We we were shipping very slow. Yeah I remember Under a year was considered a fast release Right. We had no choice. We had no choice. I know I know it's a different world and we need to adapt. Oh I'm there Customers get quality We in support orgs test included. I think you know, what's really fun is I can tell you my team's mission and You might I might have to pay a copyright tax to accelerate the achievement of shippable quality No, it's better. So remember for me. I manage all of our infrastructure site reliability engineering documentation Quality coaches. Yes. We have quality coaches. Remember we used to measure ratio Well our ratio of quality coaches and developers is about one to a hundred your mileage may vary those are all on my team Some other stuff too. I'm sure I'm forgetting but all of the stuff that helps other parts of the company ship services and Mission to enable enable the success of developers at Unity and delivering high value products our customers love So we are they we are there to enable success It's not even enable success, right? Like don't fool you. It should be accelerate success Right, right. I mean by saying enable success like the thought exercise that you You can do the word enables there because there's a there's a division or organizational mission statement Which starts with the navel that I wanted to build on but you're correct Oh, all right I'll just say this I'll just finish the thought like if you use the word enable then you you Right it the implication is that if your organization wasn't there, right? You are correct that success wouldn't happen And that's probably false however Your job because you're there is is to accelerate that success. All right in this world where speed wins That's the reason to Get an orb like yours in-house. We want to make it easy fast and safe. Yes Easier faster safer. I'll work on that But so but that's very similar to what test did back at the day back before we had CICD Because you don't need it when you're shipping once every two years We did a lot of things we did testing of course, we tried the test quality in we played bug ping pong all the time But also we were doing we were involved in bug triage try and find the right bugs to fix trying to get rid of We did a lot of other little things and tools and Diagnostic things to help with that Yeah, I'm still You're a damn test harness Yeah, where you know it up you should have marketed that purely to developers and said testers don't write these here you go Yeah, that would actually have been smart Yeah Architected that got a patent on it. I just And then I wrote a right the way I deployed it usage actually Made that code dependency loop. We talked about so often Way more efficient man. Did we did that tool? Solidify codependency like anything else I've ever seen the lesson I've learned that helps with my org One get their job done and scale across the company But to just job satisfaction is nobody has ever put in a position where Another team or a person is dependent on them to get their job done Like everywhere from docs like we have developers are a lot of documentation. Of course, then we can polish it and edit it on the Deployment side everyone we have the you build that you run it We just make it easier for you to build it and run it easier built easier faster safer to build it and run it Yeah, the thing so winding back to the high-level topic and we kind of got there But the thing like I think in a support organization And you made a comment hey back in the day test tried to make it easier faster safer I May be safer like easier and faster No, we did not know we enjoyed being the bottleneck. It was part of the codependency We'll get this we have to sign off Yeah Yeah Remember Boyd Boyd on Xbox once sat me down. We're having a conversation. He told me, you know Yeah, he's doing is it kind of hippie thing What is the role of test and I fished around for some answers to accelerate the achievement of quality? No, that's not it to provide information to stakeholders. No, that's not it. The rule of that one is to sign off But well, that's a shitty answer Boyd Yeah Cool so if I sign off right now You know get can I just you know drink beer in my office? I gotta tell you just this week in one of my one-on-ones one of my employees were talking about the org I can't remember what we were talking about we I One of the things in just a tangent to the tangent and the one-on-ones there. I still have people who Want to talk about status what they did and I don't care Let's talk about let's talk about stuff that makes us think so usually usually I steer away pretty quickly and they kind of get it I've only once had to say in a one-on-one. I don't want to talk about status Usually they get it pretty quickly, which is great but we were talking about what's going on in the org and some strategic sort of stuff and This is a a person on my team and he said well, basically we're a cost center for the org Let's not think of it that way. Let's think of us as a business accelerant well, right and so once you once you realize rephrasing principle one because I think it applies to you a a DevOps or infra org just as much as it did test back in the day We're an accelerant for the org But one it's important that you you recognize that role like if you're in a support role In this particular case in your team It's not all support roles are gonna be an accelerant I think but in your case and in my prior test case Or test management career case and as we mentioned some degree even today My job is to accelerate this the achievement of shipable Quality and once you realize that you're an accelerant and that your whole value proposition is Acceleration then you can begin going down the path of defining for your organization What is the work you should be working on in some sort of return on investment? Oh, yeah, and and the answer the discussion that that we the subsequent conversation again faster better quick what I say faster Faster Better faster safer. Jeezus. I'm dumb easier faster safer I said, well, how long does it take for what's our pipeline time like and I know the answer It's super fast like our longest one if everything goes wrong is about 40 minutes But most most most the time emerged to emerge to Maine and it's live within 20 minutes. Okay. Yeah We can always tweak the bottle neck. He said yeah, we're already fine there. What can we do? So should we speed that up? I said no, but let me ask you this When we hire someone brand new person in the org how long until they're fully productive on the team? Oh, yeah, we could and right now. I don't know what the number is anecdotally. We can ask managers. It is not good Measured in months. I would say my guess is measured in months We know anecdotally at least it's we can do better there So this let's do that. You know, you and I could brainstorm and think of 20 things we could do today To make that better. Let's start measuring that get that faster Theory of constraints you have to which and systems thinking go together. You have to look at the system that figure out Okay, where's our biggest bottleneck? So if you look back like I mean, it's slow. Let's look at the whole process even beyond The systems is always a system within a system. So Today I have an open head count. It may take me some amount of time to get a job wreck in with recruiting and get that posted and go through resume feedback and interviews And then get them to quit their old job to start and that there's some time lag there That's all part of a larger system So I want to make that faster too But the first thing we can do is just make the whole on boarding faster But if you look at the system You're going to find other things that are slow. What are the things that don't make it? What are the things that make it more difficult to be? Easy fast and quick That's a key thing. That's a key thing for me. Like I'm still focusing on So I have two phases. The first thing is okay before they even started How do I reduce ramp up time to near zero? Yeah Yeah, that that's number one and my definition of ramp up time is essentially the idle period before they start doing something useful okay, am then the second phase is Is how do I get them to autonomy as quickly as possible? Autonomously capable would be better. Yeah I'm sure there are some some Good survey questions we can ask because our org does sort of an end-set survey twice a year to figure out How developers are doing but we could shove that in there, but I just thinking a perfect world imagine this imagine this Uh, we get our interview process streamlined enough that if we like somebody we can give them an offer at the end of the day And they are shipping meaningful code On their first day at work That's I mean, I like the idea the big hair audacious goal Just say that's the goal if you fall a little short you're still in pretty good shape, but that's what I want to do I just decide no, I I want off offers on the days of the day of the interview and I want them shipping meaningful code on their first day and and Like rallying cries are super effective. And if you just say look Offer by end of day. That's what I want offer by the end of the day Right, and if you don't set A clear simple goal like that obviously If you never start you're never going to get there Right. And so that's just setting deep deep. Right? I know right It's it's sadly a phrase I use at least once a week right, it's because there's a There's still a lot of push and not push but a lot of people uh in the company I work in uh that are still You know the big design up front is safer. Yeah. Yeah, it's the way it's it's the way it's always been it's easier It's what they're comfortable with. Yeah, and i'm just like So now I actually have a reputation So i'm out actually allowed I can do things I couldn't do even just took all the years ago. I'm like, okay Well, i'm not interested in investing in that then They're like what i'm gonna give you eight heads. Yeah, you can keep the heads. I don't I don't really care But but why it it well number one Uh, the work you want to do is not anything in this decade that is useful to build a career like like You're asking me. I mean higher vendors Is going to be my answer to that particular thing. Yeah. Yeah, um the the other one is um Where's the roi? I I I just don't i'm not seeing Given i'm not seeing any path to sort of a uh, a guaranteed roi And me as a data scientist now, which is just great because I have access to all sorts of data That says no matter. It does not matter how much big design and how much up front you do There is a huge degree of uncertainty In almost every scenario that i've talked talked through with folks recently that By the time even if it was a three-month project by the time that rolled out Still a degree of of so many variables that you can't even know That it's going to fubar the whole thing Oh that reminds me of the topic I wanted to pick for today Which was and I have another another tangent on top of that but the topic was shipping like something we're struggling with avoiding the what's alan doing at work is Helping teams figure out how to take a huge complex prog project And ship it incrementally Yeah, yeah. Well, and so now i'm at a point where uh And we were just for ourselves because you and I know how to do that It just it's right. It's so the one thing is the coaching and teaching of that to get people to get that Which is the challenge, of course In terms of me right now like the people who come and engage with me I have my team has built up such a positive relationship. I can skip over that I'm like look. Yeah, i'm not having that discussion A I have so much work to do i'm going to prioritize the folks that are Willing to join this particular party Now if it is something that I can clearly see a bunch of opportunity uh, and That will that will attract me first and if I can clearly see a bunch of opportunity then they engage me with this Then I just take over and I say no look here's the thing. That's not what we're going to do What we're going to do Is we're going to do this incrementally? And after we're going to break this down into smaller releases that can be done in in a in a two-week cycle And we're going to have a moment after those releases to judge the success and repivot I'm not spending three months with you to go through and come up with a perfect design I'm telling you I've tried to do this before and it's a waste of my team's time. Well, one of the things we've talked about in the way I run our programs in our org is the p50 estimate so that it gets rid of big design up front But it also gets rid of Running off like a like a scared panda in the wrong direction Or the or the ready fire aim We could just say no estimates, but let's give a Vague estimate based on a probability. It's not vague It's an estimate based on a probability and if you're wrong you'll discuss why in the retro and you'll get better And most teams get pretty good at this over time, but the p50 estimate keeps people from uh trying to over plan in fact We have it's a long story for Uh a few minutes for the podcast is ending but We have a very efficient way of keeping track of when projects are in planning too long And encouraging people not to over plan but to plan enough where they have 50 confidence in the date They choose and that's it and it works out very well Across the org we shipped like 400 we released 400 customer impacting 450 something like that Customer impacting projects last year some were late some were early a lot were on time But we made progress and and that that p50 estimate is a sweet spot for velocity Yeah, and you know, I was thinking through back in the day When I was engaging with pms Uh That came from the more waterfall model and they were working with me and they would come to me and say, okay So what's your commit date for this? I was doing a pure kanban and as you know in a pure kanban That's a question that doesn't make sense And I tried feebly to say sorry, that's not how we execute But in some regards And I got feedback on this p50 estimate saying, you know, I don't believe in estimates Don't give it just just work and things will work out like I my business says I got to give dates I work too closely with product managers and marketing people and they have to have an idea an idea and they get p50 They know there can be changes but an idea when things are going to be complete Right because other there there are downstream dependencies of course And what they're trying to do is is get those recent because it's a big system and Your team's system is an important system, but it's actually part of a larger system Yeah Unless you were able to do like I could when I started off unless you're able to own the sort of whole slice end-to-end um You you need to you need to give a a set of dates Because you have downstream dependencies And it's expensive to have them sitting waiting around being idle Right. It's it's much makes much more business sense than just simply Oh, they're making me commit to a date. So I cut corners or any other thing like that No, that's how it feels but that's not what is happening. Absolutely. Absolutely. So I feel like uh, we had a weaving river Of stream of thought that took us to this point and yet I still feel like we hit a few good points That may be irrelevant to some of our listeners. So next time I will talk about exploratory test automation Maybe awesome looking or whatever questions come in. You can always ask questions Um one of the three dot slack calm also a quick plug If you'd like to spend a half hour with me on a zoom call and have yourself recorded I haven't done an abt 343 in a long time. I'd love to have yawn If you just have a huge topic to share or something to discuss Uh, we're happy to have some people on the big podcast as well. Let us know for a small fee. Just kidding But especially some of the long time listeners be great to have yawn As we wind our way towards episode 200 I may not live that long. All right, everybody. I am Alan and Alan's beard and that's the ab testing podcast Why are you still listening? No, it's over. It's over. Goodbye. Goodbye 
