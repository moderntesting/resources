And, and Brent has no idea what I said because he was typing furiously. But what did you ask it? What did you ask? I actually did have what it is, but the second you challenged me on that, it did flush. Yes. Welcome to AB testing podcast, your modern testing podcast. Your hosts, Alan and Brent will be here to guide you through topics on testing, leadership, agile, and anything else that comes to mind. Now on with the show. Hello, everyone. It's Alan. And Brent. And we're here today to bring light to your life, like rays of sunshine sparkling into your living room or your car or wherever you listen to our wonderful podcast. Calm, motion, gently crash. This is the Pretty Little Things podcast where we talk about things that make us happy. No, we talk about things that make us mad and piss us off. This is AB testing, damn it. Yes. Who wants to listen to what makes us happy? So I think I may get the recording right the first time here. We will see what happens. I'm learning new stuff. Just had another problem. I accidentally unplugged my recording device. Hopefully I won't do that again. But how you been doing, Brent? Uh, it's review season. So yay. You didn't use that like a month ago. Is it, how long does review season last? Uh, this time it was three, three weeks. It's not too bad. That's not too bad. We have that coming up. We should probably talk about not specifics of that, but I have a lot of thoughts that are thought were ubiquitous, but are not around how to do fair employee reviews, but that is not on my bullet list for today. What a pain. And at Microsoft too, it's, it's, it's weird. Flip a coin, right? It's fair. 50 50. Just flip a coin. Throw darts. Nine boxes and darts. That's all we need. Have you gone through a review season at the current place? No. Okay. That should be a topic because I'm very curious as to, as to how much Microsoft and unity have influenced your style at the new place. Well, it's also, you have to do your style as much as you can within a confine of rules given to you by your context. Yes. So I will do what I can. My big value with me is fairness. I'll try and be fair, but sometimes the fair thing to do is to give one if someone's 0% merit, it's fair. What's critical is that we're fair all the time. Anyway, that is another topic. We're probably not going to get there in 2023. If we record in two weeks, we may get two more episodes in before the end of the year, we've got to coordinate calendars and figure that out to make sure we get the 2023 predictions and recap episode recorded properly. So let's spend a little bit of calendar time offline here, but that's coming up as a little preview. So one ninety one or one ninety two will be that the year end recap and predictions episode, it'll be fun to look back and look forward like we always do for the last million years we've been doing this podcast. So speak at a podcast. I've been slowly catching up on my backlog of podcasts. Do you listen? You listen to I know 99% invisible used to be on your radar. Do you listen to podcasts much anymore? Not as much. I still do like podcasts are still my favorite thing to do. Like when I'm mowing the lawn or chores, chore casts. Right. 99% visible is is still top. It's still it's listened to enough that it's still top in my little M.R.U. list on Spotify. Cool. The 60 songs I talked to you about this a while ago, the 60 songs. Yeah, I got to check that one out. 60 songs that explain the 90s episode. What episode are they on? Oh, dude, by the way, like he's gone way more than 60. No, I got to check that one out because I forgot I'm slowly getting caught up. I was literally a hundred podcasts behind a while back between the move and everything and I've been walking to the gym every day and I walk a lot living where I live, so slowly catching up and I want to add some new podcasts. I'm going to get to the end and there are I want to check this one out and my quick tangent there is speaking of the 90s and currently to today, even. Are you going to you don't do you leave your house much because the food fighters are playing next summer. Yeah, no, the are you inviting me to the food fighters? I only have one ticket. I'm asking for your. I'm not that guy that buys one ticket to a concert goes by himself. I'm that guy. Oh, are you? Yeah. Oh, my, my daughter would be upset as well as well. Actually my middle son who, who, I don't know if I talked about it, but he just got married and congratulations, but he's in Florida, so he's not going to make that trip. Well, I'm in Florida, so the food fighters. Yeah, that's, that's a, that's a good van and I really enjoyed the YouTube of the food fighters. Have you done much of that? Like Dave Grohl does a whole lot of like random songs and bringing people from it is just a good person. He's a good man. Fantastic person. He's a good guy. That's why I like the band. Their songs are kind of okay, but Dave Grohl's I'm a, I'm a Dave Grohl fan. I'm kidding. The songs are good too. So anyway, I wanted to mention that, but the real topic I wanted to mention is as I add new podcasts, there are two things. There's a quality of podcast as brand types, while I'm talking again, but I'll go ahead and tell my story anyway, cause I can edit that shit out. I looked for a couple of things in a podcast. One, of course, a topic I'm remotely interested in, but that's almost sub to two things are there. I don't know how to describe this, but I listened to a podcast where I loved the content, but the recording was so awful that I could not continue listening to it. It was recorded low. There was echo. It was just, I could not listen to it. That's on one end. Was that, was that our podcast last episode? No, shut up. Oh, we have top notch video and audio editors working on our podcast around the clock. And then, so that one was hard, but also I tried listening to, like I'm a big fan of, ah, crap, I'm forgetting names cause it's Friday. Who's the Netflix guy? Read what? Not the, not the Netflix guy, the, um, LinkedIn guy read, which one's Hoffman? Hastings Hoffman. I get him confused sometimes. Former LinkedIn guy. He wrote this great book called, um, the Alliance, which I love. I align well with the Alliance to book on, on managing people in the 21st century, but his podcast, good material. I can't listen to it because it's so overproduced. It has sound effects all over the place and weird music and weird places. It just, it's, it's too cheesy. It's too, too cheesy. It's like, it's like a podcast for an amusement park. I just need a subject that's remotely interesting, which is nothing you'll find on this podcast. And then a reasonably good recording, which you'll sometimes find on this podcast. This is not the podcast to compare against other ones. This is just your guilty pleasure to do while you're cleaning the bathroom. You've listened to 99% of visible. I have. Okay. Where did they fit? They're in the suites. But if I was going to put them on a spectrum from horribly recorded to overproduced, they're definitely a little bit more on the produced side, but they don't overdo it. They don't overdo it. And Roman Mars has the, his voice. I could just listen to forever. He does another podcast. If you know that it's multiple, but have you looked, my favorite is what Trump can teach us about constitutional law. I listened to that one. I don't. Yeah. It's mostly his neighbor, the lawyer talking, but she's really good as well. And again, the sounds good as production and I'm interested in the topic. It's great stuff. So if you want me to listen to your podcast, just do a decent job on sound. Don't add too many sound effects and things. Although I do add them sometimes to our podcast, not too many. Yeah. I haven't done a mail bag in forever. Yeah. Big. Yeah. Cause we can't read one podcast done by pretty sure it's the BBC. Maybe not. No. Cause it's, it's bashing the BBC. Have you heard of the podcast stuff? The British stole? No, I have not. Okay. It, the guy is the, the narrator, the primary person there is, um, Australian. Uh, so I think it's actually probably based out of Australia, but it's fascinating. Like, holy crap. The British stole a lot of crap over the years with the colonization. There is not for someone with a growth mindset, like AB testing, listeners, there is just not enough time in the world to acquire the knowledge we would like to acquire. Yeah. You know, for me, I, I, I like, okay, let's listen to stuff. The British stole. And for me, I'm like, you know what? Um, use me and teach me something and that's it. Like my bar that high, that high on that one, 99% invisible. Like I have a passion around design of all things. Like one of the things you, when I have shared his experience in the architecture role, right, we've had to design things and it's fun for me to learn the design. Of all random things, right? It's like, okay, why is that there? Like, um, I bought Roman Mars's book. Ooh. Right. Do you know what a love lock is? I would only get the audio book read by him. Oh, I don't know if that's, I don't know if that exists, but I love it. Have you ever heard of the term a love lock? No. Okay. I got the book. It was one of the first chapters I had read it. And then I went for a hike to the, um, snow call me falls. They added the very end of it. There is a chain link fence and there is a crap load of. Oh, okay. I know. I know what those are. I didn't know they had a name like that. I have seen thousands of those around the world. Yeah. Those are called love locks. And, and I've always wondered like, what the hell is all of these locks here? They throw the keys. They throw the keys into the waterfall. Right. They, they write, you know, they're locking their love. A plus B with a heart and then check the key into the thing. Chucking the key, you know, fish, that's probably bad, but you know, symbolic symbolism, planet money, free economics. These are all like freaking omics, especially. That's what got me into data science, but not necessarily for economics, but that topic. Right. So it's always fun to still connect with the data science and the customer behavior aspect. No, it's cool. We can talk more about new podcasts in our upcoming end of year episode, but I just, anime, um, new season of invincible is out. Not really anime, but close enough. It's I love that show. That one just completely turned me off. Like, yeah, that's just like dark. Yeah. My daughter, we're spending a lot of quality time together. Um, and she has been a fan of anime for a while and we just watched, uh, one called demon slayer and, oh my God, is it good? I got a couple topics to get through today and I forget what those are. No, they're right here. Uh, one I called out on my five for Friday and I shared with you. I don't know if you had a chance to look at it. Is our, our buddy front of the show, Jason Arbin did the thing you can do with chat GPT where you can give it a bunch more information and make your own little chat engine, which basically it's Chad GPT plus plus. And I've seen a few of these floating around. And I think you have to be on the paid plan to be able to use them to be able to get at it. So that's, that's what it is. But he sucked in a whole bunch of information from what he considers expert testers, so he included Brent and I, regardless of our status within the testing community. And then, uh, it just works like GPT and I'm going to tangent there. And I saw yet another post of like, I don't know what some luminaries hate about chat GPT, but they were mad that it couldn't alphabetize for them. And again, use it for what it's for. It's powerful, or you can, or you can find things that it won't do and get mad at your call. But anyway, Jason, uh, made this thing, pulling in information from expert testers all over the place. And I asked it, you know, we've talked about, and again, I'm not going to chuck James under the bus, James Bach under the bus, and it's not on the podcast. Uh, we have different approaches to quality and testing and that's fair. He can do his thing. We'll do ours. Uh, I think he's done some questionable things as a human. Again, not going to, that's not where the topic is going to be here today. But I was curious because we do kind of, we cross paths in a weird way. We have occasionally a sort of distant respect for each other where we leave each other alone, we chatted on the phone before we said, okay, blah, blah, blah. He'll do his thing. I'll do mine. That was many, many years ago. And then lately somebody brought up the modern testing principles and his reply was Alan, Alan's work is damaging the craft of testing. So I ignored that anyway. Drama aside, one thing I like to do as part of critical thinking is when I hear something somebody doesn't agree with is I want to try and do as empathetic humans is put ourselves in their shoes and wonder kind of where they're coming from. How can I see things from their side? So the way I did it with chat GPT was one simple question. Now I'm not going to read the whole answer, although I think it's very good. But I asked it, how would you compare the approach to quality between Alan Page and James Bach? And I kind of was unfair. I said quality and not testing, but so I probably led the witness, but chat GPT gave a very fair answer. Blah, blah, blah. I am not an expert. Alan known for his work at Microsoft. I wouldn't say that. I worked on let's list some of the products I've worked on a windows millennium. There's a lot of hate there and well, there's some, I will list things people like, but I was involved in the quality of both windows millennium and Microsoft teams. Please send your hate mail to Alan care of a B testing at the north bowl.com. In the answer talks about where I focus on business value and team responsibility, data-driven approaches, evolving the test to roll. All stuff you've heard here. Whereas James is again, context-driven testing, exploratory testing, critical thinking, craftsmanship, and a skeptical approach to automation. That that's all we know where we're coming from, but the comparison is actually pretty interesting. It is in perspective on quality. It says Alan, and this is actually, I have nothing to argue with here. I don't know if, I mean, the question was fair. I don't know if James would argue either of us. It's kind of worth bringing up and getting your thoughts. I read it. And just so you're aware, I read every one of these things. So I'll read it. Because I was just like, I was just like, yep, check. Yeah. Yeah. It's, it's really good. Nothing I, and I, again, I think it's fair and I love fair. And the summary, the summary I found fascinating as well. Alan is quality in a broader business and team context. True. Bock on the other hand, focus is more on the skill and judgment of the tester. It's really made me think, and in fairness to James, we are doing two different things. James wants better testing and I want better quality. And I could argue on my high horse that ultimately quality is what matters. And I think James wants better testing or does James want better testers? I think he wants people that do better testing. He's, I think he's, I would say he's involved in the craft of software testing. He wants testers who can have that, that deep critical thinking approach. I think that's fair. And I think quality comes out of that. I'm focusing on the outcome purely. He's focusing on a root cause that will get likely to the same outcome. Well, so again, I'm going to push back on that because I do think James is likely to write the critical distance concept. Like if he was focused on better testing, then why wouldn't he be supportive of our approach of whole team? Devs can test. I don't think that, well, the devs contest thing is that that's a whole, right? I don't want to, it's not fair for me to try and speak for him. I can look at the comments of chat GPT and interpret those. I don't want to try and speak for him. I think a lot of things, he just looks at what we do and says, you guys care about delivery. You're, you're, you're about something different. Developers being able to test. That's the thing he pushes back on. He thinks it requires he, his belief is in the specialist to do that, that deep work. And again, some other comparisons, but the summary I'll read to you the whole thing, which is, and then I'll get more comments from you, Brent. In summary, Alan's approach is more systemic, focusing on the role of testing within the broader context of software dev and business objectives. Well, James approaches more centered on the individual testers skills and the adaptability of testing practices to the context at hand. Both perspectives offer valuable insights in the different dimensions of software quality and testing, which is kind of what I said about two minutes ago. We're focused on different things. We don't, we don't do the same thing anymore. There was a time when James Bock and I were both testers. We're not, I don't want to talk a ton about him. I don't want to talk about James, but he's not here too. I don't want to say anything where I feel like James have to defend himself. It's not fair, but I feel like this is a pretty fair comparison of where we're coming from and where some, where some conflict may be. And honestly, I wonder if, you know, sometimes if I generate this conflict, because I am so adamant that the ultimate goal is quality, therefore discounting the craft of testing. I'm, I am on Jason's train. Oh, so you asked it something. I did. Duh, it will be edited out by the time you hear this listener. But as I was saying that last thing that, and, and Brent has no idea what I said, cause he was typing furiously. But what did you ask it? What did you ask? I actually did have what it is, but the second you challenged me on that, it did flush. Yes. I asked it, what are the key conflicts between Alan Page and James Bock? Oh, didn't ask that. Fill me in Jedi. Structure versus flexibility. Alan's approach involves more structured testing process. What? I, I, I wonder. I think that's backward. In contrast, James promotes a more flexible, less formal approach, emphasizing exploratory testing. Right. That part is true. And I'm wondering, actually, here's the thing. I'm wondering how much Jason train this or how much the training was based off of your book. Because. Oh, it does pull that in. It would pull that in. Yeah. My data is weird. If we were comparing the Alan Page of 10 years ago or 15 years ago, yeah, that might be true. Well, do this, do this. I'm going to take the time for you to type this, ask it to disregard the information from how we test software at Microsoft and make that same and asking the same question again. Rewrite, but disregard this. We regard the information from how we test Microsoft. Does it give the same answer? Previously was structure versus flexibility. Now it's structured versus adaptive and you're still structured. Weird. Like, yeah. Okay. All right. Anyway, I there's a. Don't you want to know the others? I do. I do. I guess. Already discarded. Everything else because the first answer was wrong. Yeah. And the third answer is also wrong. All right. So here's something that I did do. If you are ready for attention, we're always ready for a tangent on the EBT. I need a tangent sound effect. How would you compare the approach to quality between Alan Page and Brent Jensen? So what the world doesn't know is we're actually the same person. He did that fine. So on the background, known for his work at Microsoft and co-authoring the book, but the fact that it brings out the book, like, really makes me think it's like it's over. It might be over pivoting. Yeah. But you may have the same problem I do in terms of like the last decade. I've been pigeonholed. Yeah. Yeah. While Brent Jensen's specific approach to quality in software testing is less documented in public sources, based on industry trends and practices, one might infer that his approach would focus on pragmatism and efficiency. Okay. So it knows who I am. I think I haven't tested to see if it's... Yeah. It could be making it up. I wonder if I don't want to go too deep into this, but Jason, I know you're listening because you get mad when we don't have a podcast every two weeks. Make sure you feed it the transcribed, the transcriptions of our podcasts. I'm going to do... Here Jason, you didn't get paid for any of this, but do a bunch more work. I'm going to do Mickey Duck. I'm going to compare Alan Page to Mickey Duck, which I just made up. Of course you do. Because Mickey Mouse might be in here. Okay. Mickey Duck is not a recognized figure in a software testing group. Not part of the expert field. So he does have something... You know what though? Did you ask it about Gent Brinson? I didn't. I could do that. We are losing listeners. We are doubt for our three listeners in round one. So let me go back. Let me go back to our approaches. Alan's approach is likely to be more holistic and integrated into every stage of the software development process, focusing on the overall system quality. In contrast, and I'll tell you, I am already disturbed by the term contrast being used here. Brinson's approach as inferred might be more focused on immediate and practical outcomes, emphasizing quick feedback loops. Okay. Yeah. It's making crap up. It's fine. But you didn't do that, but it's guessing. So anyway... I do emphasize, but it's not really a contrast. Not really. Let me ask it. Let me do one last thing. No, we're done with questions. We're going to go on to the rest of the podcast. I have another topic to cover and we got like 20 minutes here. Main thing here is very cool stuff. Going to plug it. You can find the link to this little chat GPT wonder on my latest five for Friday. And you can ask questions and submit. Oh, we should get it to submit questions to the mail bank. What are good questions for Alan and Brent to answer on their podcast? We'll have to type that one. Okay. I'm not going to go into that row there. I wanted to follow up on something we started talking about briefly last time. Oh, sorry. This is bad. Are you still with Chashing? I am. So, so I, I, I, what are the key conflicts between you and me? Okay. You dude, you are old school according to this thing. Like even between you and me, I'm all about rapid agile and you are like structured. Systematic. Jason, stupid bot. Now pause this and go fix it. Okay. So anyway, on with the podcast. I want to talk about, so I'm on the podcast today with, with of course, Gent Brinson. I want to talk about a more famous Brent, a little bit more. Okay. Stop. No, I just want to do one more. One more. Is my podcast too well. The role of data and metrics pages likely you dude, I lost your audio. I hit mute. It's likely use of data metrics to drive testing decisions. My contrast with a more intuitive experience based approach, like someone like Jensen might favor assuming he leads towards a less data driven method. Okay. I don't know which one's better. So this GPT knows my name knows something about me, but not nearly enough. And has made a decision about you and it's wrong. Remember, it's just, no, I get it. Yeah. Remember how the, you know, how these things work. It's just you, a bunch of our work has been tokenized and it's trying to make up words, it doesn't know what the words mean. It's just making up words in an order that, that is grammatically correct. So anyway, I want to talk more about Brent Geller a little bit and lead that into a discussion of heroes. Do not ask Chad GPT who Brent Geller is. Brent Geller is Brent from the Phoenix. Thank you. I figured I'd like, okay. He's probably talking about that guy. Yeah. Heroes. So we talked, we talked about Brent a little last time. And I want to recap that whole thing, but Brent was the, he was the bottleneck because he was the expert. He was a knowledge silo. He kind of becomes the hero of the story as he, again, I hated him because he was fricking in the way. I want a root cause and see how we ever built a culture that got, got us to a place where one person was the bottleneck. One person was the bottleneck for all this stuff, but he did evolve and he was happy in the end. I think you could say he was both the victim and the hero at the same time, but definitely at the end, he becomes this agent of change. All good stuff. He grows up all good, happy ending. But it's made me think about heroes. The David Bowie song from the Berlin trilogy produced by Brian. No, heroes in the organization. You have, I don't know if you still believe this, but you in the past, you've said something like it's okay to have heroes if that's their job to be the hero. Is that true? Do I remember remembering? No, so that is true. And that is around the problem of heroes as sort of a knowledge expert. Brent and the Phoenix project, right? I don't think he started off his day intending to be a hero. What happened is, as you listen to the story, what happened is he was really passionate about his job. He was. And I think you're right about that. And when people discovered his passion, that began sort of the snowball that became the avalanche. And without anyone there to say, hey, this needs to be knowledge shared, then it very quickly becomes a situation where like someone like Brent, when you have a knowledge bottleneck, it's kind of like a person who, you know, fell off the ocean liner and has been treading water for five, six hours and is now struggling, right? Brent, I think we can agree. You know, I don't like how he got himself in this situation, but I think we agree that Brent from the Phoenix project, his intentions were good. He did not want to be the bottleneck. He did not want to work 80 hours a week. He didn't want to be the only person who knew that stuff. Just that happened to him within their culture. I was rereading that part of the Phoenix project and I thought of something I wanted to throw at you because there are sort of the Brent anti-hero. So there are, again, expertise is expertise, but someone who's the bottleneck who wants to be the bottleneck becomes a gatekeeper. Someone who's a knowledge silo will hoard their knowledge in order to provide value and be able to have, be able to be that hero. We've worked with these people in the past. Oh, yeah. I work with the people who refuse to share information because literally they would say out loud, that's the only reason I'm employed here. I need to be the only person that knows this for job security. I've heard that too. And for those type of people, like what, again, this is where I see, there's two things I say commonly, depending on where I'm at, either number one, then that needs to be their job. Like the type of hero who's essentially a firefighter, you know, critical and exceptional at diagnosing and putting out fires. In today's DevOps language, we might say that they're the DRI, or the designated responsibility. That should be their job. That's their job. Yeah. When there's a job is when there's a problem, they go in, or when there's a bottleneck or a problem, they go in and solve it or mitigate it until it's not a big problem anymore. I get that. Right. The type of hero that you describe, usually that's where I'll respond with, I want to remind everybody, hero is a four-letter word. Great. And this is where I want to get into. I want to get into the leadership aspect of this because I was reflecting back to earlier times at Microsoft, and this was definitely even better by the time I left. So I imagine it's even better now. But there were people who would hoard information or be a bottleneck or clean up their own mess so they could be recognized as the hero because they had leadership who would call out when heroes did things. I mean, you can remember stories like, I want to thank so-and-so for coming in and working all weekend to solve this problem that they created in the first place. So I want to talk about how as leaders in tech, how do we make sure we don't get that kind of hero? What are the preventative measures to make sure we, like I'm good with you. If you want to have somebody be the hero because their job is to be like the smoke jumper, I call them. That's fine. How do we prevent the people who want to be heroes because they think it's, they actually believe it's good for their career? How do we prevent them? So I think... I love the hero as a four-letter word thing. Maybe expand on that. Well, so I love, as you were saying, hey, maybe that's another place where Microsoft has softened over the years. And I'll say, yeah, it has. The hero of the type of, that we just described for Greg Keller, that's still there. That's still there. I think culturally that one may be easier to fix than the, I'll call them the anti-hero. It will be, no, actually, I think the other way is easier to fix. There has ever since, ever since, I was just thinking, a couple of things that come into play. Number one, a big portion of your review is not just on the stuff you've got done. It is also on how did you contribute to others and how did you incorporate others' feedback into your thing? And so as managers continue, as managers age out from the old school system and new managers are coming in more trained around this and things like the coaching habit. And here is one thing, if I were to do a big hypothesis that I had no proof on this, I would say hitting hard on growth versus fixed mindset was key here. Yeah. Because what you described as a hero, tell me how they can be more of a fixed mindset. No, I think you're 100% right. And this is really interesting. I was having a conversation when I think through these things, I have, when I think through things, I don't know answers to, I have conversations with chat GPT. And I told chat GPT, people who hoard information and are bottlenecks and want to be gatekeepers. Oh, no, actually I'll bring it up here. Dear chat GPT. I like to use dear and please and thank you with my computer counterparts. But I said, I'm discovering that I am hoarding information, gatekeeping people and overall slowing people down because I'm a jerk. What are some books I can read so I can improve? That's clever. That's clever. And of course, it led with How to Win Friends and Influence People, which I read a million years ago, but I wouldn't recommend. It's a good book. That Crucial Conversations, I think we've both read. Emotion Intelligence 2.0, which I read. I've read all of these so far. When I first learned I was an asshole, difficult conversations, how to discover what matters most. I've read that. The No Asshole Rule, which I'm rereading because it's actually very, very good. And then funny, you mentioned Growth Mindset, Mindset, the Carol Dweck book on the Growth Mindset. So those are the books I read to get better at this stuff. It did. ChatGPT, by the way, did congratulate me in my self-awareness. Very nice of it. Yeah, I just loaded up ChatGPT. I was going to ask it a question as well, but I forgot what it was. But as a quick tangent, this is asking ChatGPT to alphabetize your list of test case inputs, maybe not as good of an idea as it using it to think about, you know, help you become a little bit more self-aware than maybe you think you are. But anyway, I love it for stuff like this. And I said, you know what? There's a couple of these I'm going to go reread because even though I hope I don't do these things, I want to be able to make sure that I can navigate a world where I may run across some of these people. Yeah, and guide them. The biggest problem I've seen is that these folks, I remember the last person who told me straight to my face, yeah, I'm not going to mentor that person because then there'll be two people who know how to do what I do. And that will, oh my God. And I said, well, why not? And then it was a she, she then said, because this is my only value proposition. I'm like, well, learn, grow a new one. Oh, I can't. Like she had convinced herself that she had a secret sauce on how to test. And then her only option was learning how to code and that she couldn't do that. Yeah, there's something to that. And the growth mindset is huge. I was part of what triggered my thinking about this was everything. There's a soup in my head and ideas go and sometimes some ingredients clogged together. I was listening to a Pat Lencioni podcast and he was bringing up some ideas from his book called the ideal team player, which was originally titled the three signs of a miserable job. And he changed the title about five years after it was out because people would not leave a copy on their desk at work. But he talks about the ideal team player being three things, humble, hungry, and smart. Humble, meaning you're not a jerk. Hungry, meaning you love to learn and smart, meaning you make good decisions and you know, and you don't get like, you know, when to ask for help. You know how to, you know how to navigate the workplace. And it talks about like the people who are only have maybe two of those because of some labels for them. They said, if you are, if you are hungry and smart, but you don't have any humility, he calls that person the skillful politician. I think, I'm thinking, oh yeah, I've known some skillful politicians. I have known some skillful politicians. So that got me thinking about this whole, you know, and then thinking about Brent was in my head, Brent Geller from the Phoenix project. And that got me thinking about this whole hero slash anti-hero thing and just wanted to get your take. And then the books that I could like the brainstorming chat GPT, good stuff. So I forget what is your, as you're looking for chat, we should have chat GPT. If it could talk, it could be our third. We could be the ABC podcast. But anyway, can you please, how are we? I mean that directly. Can it, can it, can it love? I, I sure as hell hope. Can it give you a hug? No, no, but How do you, INTPs like us, like gross, right? My daughter has a shirt. She's very much like her father. Good. I'm glad. I'm glad you give clothes to your daughter. Yeah. And her shirt says at the very top, free hugs. And then in small letters, just kidding. Don't touch me. My, my insights report, somebody was asking about the disk report. I've never done the disk evaluation, but I'll do that sometime. But I remember my insights manual, which is not handy right now, but it has this little bullet point that says, do not get too close to Alan or touch him. And I love that. Okay. Very quickly here. Then I got to go. What are we doing about these people who hoard information? How did, what did you do with that woman who did not want to share information? What was your solution with her? How did you coach her? I was wired differently back then. I solved the problem that the business had without necessitating coaching her. You lazy. I, I basically said, I see. And started, I'd mentioned the snowball that rolled down the hill started the snowball that resulted in this person no longer being employed. I'm going to repeat something. I said this a lot, but I'm going to repeat it. Uh, cause I said it today to somebody over slack. Feedback has an incredibly short half life. Yes. And I think a lot of times we, we fail to give this feedback in timely enough manner and we go up. It's too late. Can't even give that feedback. Now I think if you were thinking that would happen today, you'd be able to give that person that coaching and that feedback in the moment. Yes. And well, absolutely. Right. And, and even more so like at Microsoft, like everyone's gone through and they've seen like what happened with tests. And there was this brief moment where everything was blamed off of the lack of testers, but now it, no one has that conversation. All right. So how do we, and did you ever answer, like you didn't have a good answer for this particular woman. So what's your general answer on how, how do we deal with these people? How do we, what would you do is my quest, you could do a whole other podcast on this, but in briefly, what do you do? Say you're working with someone and they are hoarding information and they are keeping everything to himself. They want to be the bottleneck or gatekeeper. What do you do? I put friction in that path. Number one, what do you mean? Uh, the first and foremost thing is I make it very clear that me as a business manager can't have that as a risk. I can't have one person on the team that is the only one that understands things like, and I'll do like the accidents happens in what's up, the bus factor. If the behavior continues, then, then I go down to, I will try to, to influence them that it's actually in their better interest, but I will go. So the, like, you know this from years ago, one of the books that really had a strong influence on me was titled influencer. So I try to use tricks from that and go, but actually what you're doing is harming yourself, not helping what you're doing. Now there's language on the fixed mindset. I, I would probably go and do some investigation on that one. Like I am firmly on the growth mindset aspect, but I would go through and I would try to get them to convince them. I would try to convince them that this is not, not a big behavior that's acceptable to them. I will say I have since adopted a strategy where I will do an earnest try to, to get them to understand this no more than four times, three times as typical, because at some point in time, I have to decide that, you know what? The ROI of continuing to have this conversation is quite low and, and if especially that the ROI of the behavior I'm asking for is high, then, then it's going to go down a similar route as the last person, just honest. I think the key thing here is you're just giving that feedback right away. Right. All right. Well, some good stuff in there, probably stuff we can lean into for next time, but we are out of time today. That was it. That was episode 190. Thanks everyone for listening and making it to the end. All right, everybody. Once again, A.B. testing. I'm Alan. I'm Brent. See you next time. Happy Thanksgiving. Yes. Happy Thanksgiving. 
