A.V. Testing, the modern testing podcast. Join your hosts, Alan and Brent. I am Mindless Agile Robot. I must iterate. As we talk about software engineering, software quality, leadership, and whatever else comes to mind. Now, on with the show. Hey, everybody. Howdy. It's episode 100. Three digits of A.V. Testing. I'm here with Brent and we have all three of our listeners on the line as well. And we will hear from each of them throughout this episode. So I say we... Do you have anything to say, Brent? Are you here? No, let's go. I'm very excited about today. Okay. I cannot believe it's been 100 episodes, but I would... I'm going to take some glory away from the three. And because this feels better for me to say it, but Brent, it is only your 99th episode. I hate you. Just for the record, the look of despair on his face was priceless. Real quick, before we get started, I want to give a quick shout out to today's sponsor, which is PractiTest, from Joel, who is one of the three who could not make it today. And PractiTest, triple dub dot practice test dot com. As you are aware, there is no one size fits all in testing. That's why they built PractiTest, to be a centralized solution that supports testing of different types and sizes. Scripted, exploratory, automated, whatever. They envision a place where all testing data will reside, so stakeholders can generate the information required for their needs. Another issue they're trying to solve is that as you create more and more tests and more types of tests, you end up having a lot of data in the system. And if you have too much data, it can be harmful because you may end up just not looking at it at all. That's why they introduced a revolutionary approach to data organization. Instead of burying the data in folders within folders within folders, they allow users to work with hierarchical filter trees that are based on the same data you are storing. This enables you to organize information in more flexible and even multiple ways, helping you to generate better reports and visibility into your product and process. They also believe that a tester's job is to not test for the sake of testing, as we believe on ABI testing, but to create visibility and provide information that will help the team release better products and do it faster. For that reason, having a platform that supports testing is not enough, and we put a lot of effort into the dashboard. They put a lot of effort into the dashboard and reporting metrics to make sure any stakeholders can get the relevant information they need, in the format they need it and when they need it. Brent and I got a tour of the product. We love it, and we think you should check it out. Again, it's triple dub dot practice test dot com. And now, on with the fun part of the show. Brent, you taking selfies? Yeah, yeah. I'm just going to post them to Slack. We have a couple of our three listeners on the line. It looks like a whole bunch of them are in chat. I'm not sure how to do this. I'm just going to call on people. Is that cool? If you don't have any, if you're just here to listen to everything to say, maybe that's cool and we can always come back to people. Maybe I'll follow chat after I kind of go through everyone in alphabetical order and just say if you have something you want to say, a question you have for us. If you have a question, we will try and be brief. As I stare at Brent, we'll try and be brief. We must be brief and I will jot down notes of anything that we should dive into later. And maybe we'll just go through it that way. As you can tell, we're carefully planned and meticulous. Actually in a perfect world, our A.B. testing assistant would be here to, in like a green room, like they have on the radio shows to kind of pre-screen the calls and bring them to us. So I'm going to go in alphabetical order, as I said, and we'll see if we can hear people and get them on the show. I pressed the total wrong button. Antonio, why don't you unmute and say something to Brent and I? I just want to thank you guys for everything you do for the community. You guys, between the five and five thing you do on your blog posts and all the podcasts you do, the talks you guys give at different conferences, you guys put a lot out there and you guys are trying to really make waves and evolve the testing community to be more as basically the technology evolves and as everything evolves around us. I'm not going to lie, I don't agree with everything you guys say, but I do love the fact that you guys are doing a lot for the community and I've learned a lot in these past, I'd say two years since I've been on the podcast listening to you guys. So thanks. Thank you, Tony. And after I heard you talk, I go, that's not on Tony. Oh, that's Tony. Thanks, man. That's really cool to hear. And then one thing Brent and I both brought in and for those not in the Slack channel and not in the big well planned out far in advance thing, we have postcards. We both thought to bring in today because a bunch of you send in postcards thanking us what we're doing. It's really, really cool. I tweeted a picture of one set that I received. So thank you everybody for that. That's super cool. Yeah, I really appreciate that. As Alan and I have said on multiple times, oh, we should have brought the tequila today. We do this for this. This list of postcards I have on the desk right now is the whole reason why I'm in this. Cool, man. It's not for dealing with you, which by the way has been five years. And we've known each other longer than that. I never thought it would be like this, man. No. It's not going to be like this. Alright, who's next? Cycling through. Andrew Morton. Hello. Hi, I'm Hi, Brent. How are you? Very well, Andrew. Thank you. Cool. So I'd just like to echo Antonio and thank you both for the podcast and especially for the modern testing principles. I certainly managed to distill a lot of my own thinking in a much better, more eloquent way than I ever could. So that's brilliant. Thank you very much. I don't know that everyone's ever called me eloquent before. Definitely not. I mean, people have called us charming, which we reject this notion. Yeah, actually, it's been an interditive process. We started, we went through it. Like I do like a lot of how the three have contributed. The MOT publish has really helped to simplify the language. That's Ministry of Test? Yep. Yeah, I should know. I work for them, which is a disclaimer. So I don't know how much credit is us versus the community because that's really been an iterative process. Yeah. And please reflect back on those of you that were around a year or a year and a half ago and we first started coming up with the idea of principles, the community helped vet the crap out of those. So a lot of the eloquence came out of a lot of debate and discussion, which I think is great. It's like the way I like to build software is the way we built the principles. Yeah. And it's interesting that it's viewed as its own thing now, given that a non-trivial portion of it was just blatantly stolen from people like Lisa and others. All right. Moving on down the list. Amanda. I wonder if you guys would get back to me. You disappeared down my list for a minute. I tend to be towards the top. Can you speak up? You're pretty quiet in our headsets. Okay. I just switched machines to a new Windows 10 machine, so I'm still figuring out. Yeah. I blame Windows, but anyway, go on. This is actually my first Zoom meeting with the new machine. So we're all testing here. I have been listening for quite a while. I don't think quite all 100 episodes, but it's definitely my favorite podcast. It even beats the West Wing weekly, as in the order of excitement when the new episodes drop. And disappointment after you listen for a while. Yeah, I'm thinking Amanda likes punishment. That's what it describes. Well, it's comforting to hear the rambling that my own brain rambles quite a bit, so it's nice to hear the stream of consciousness isn't just confined to me. But I really appreciate the conversations that have happened on the podcast. In the time since I've started listening, I've taken over as a manager of a QA team, and our previous manager had been managing since the 90s. So I really related, especially to the episode where we were doing the modern testing versus old school testing. Yeah, that was fun. Yeah, yeah. So I've that some of the things that were said in that episode in particular have really helped me articulate why we need to modernize in some areas. I guess the, not really a question, I guess, but the challenge I'm facing right now is how to have some of the tough conversations with my team who has been here since, not since the 90s exactly, but they're very comfortable with the old school way of doing things. And I think that's really the change or die. I think I'm having to get increasingly frank with some people on that. So that's the current challenge I am dealing with. So I'm willing to hear more from the three as to how they've dealt with that either now or online later on. It's interesting that you mentioned that because I've been talking... I've sent a few samples in our Slack group, but I send a weekly newsletter to my quality community. They're not even mine, the quality community at Unity. And one of the things I've been talking about quite a bit lately has been feedback and how to give good feedback. And the other thing I do is I consider part of my job is growing leaders. We talk a lot about, there's this line from a book by Heffetz, which I've mentioned 50 times on the podcast. I mentioned, again, leadership on the line, which is, leadership is disappointing people at a level they can absorb. And I love that line because you can't push them too hard or they freak out. But if you don't push them at all and they're complacent, you don't get any results. So it's just finding that right balance. We'll dive deep into that in an upcoming episode. But yeah, happy to help out there. Cool. Thanks for listening. Yeah. All right. Let's move on. Butch. Howdy. Happy 100th episode. Thank you. Yeah. Thanks for all that you'll do for the testing community. I do have a question. Awesome. I've got leaders in my organization, one in particular I had a conversation with. He's a developer lead. And how would you respond to someone who's in that role that says to me when I'm talking about testing, you know the old saying, the person who wrote the code shouldn't be the one to test their code. They've got their blinders on. How can I help drive a quality culture with that leader? The thing I do the most in that situation is one is I stop myself from rolling my eyes. I don't. But pairing, pairing, pairing. I think pair testing with someone like that is so advantageous for both of you. You as the test specialist learn more about the ideas, what's going on into the implementation of the code. But what I found 1000 times out of 1000 is that people are able to defocus, take those blinders off and actually test their code pretty darn well. There are things that a good testing specialist will find that that developer won't find. But boy, they can. I have found again, every single case, no exception. Through pairing, I have been able to convince developers that not only have they been able to test, but been able to test their own code. There are multiple techniques that I've seen that work very well. I'll say the ones when I'm in the management role, the one that I found the most effective is I just basically say you're going to own the quality and we're not going to we're going to my test resources are going to spend time on by resources. He means human beings. My test, Peter's, yes, are going to spend more of their time evaluating data in production. And so what we're going to do is grease the wheels for when they do check in, they go straight to production. So I try to create a little bit of a fire saying, hey, I'm tired of test being a bottleneck. That's going to be able to check straight in. Here's the mitigations that I know of that work very well, as Alan pointed out, pair programming. Although here, I would probably do a mob and have two devs pair programming with a tester looking behind them asking questions. Because what you're really trying to do is is make them realize that that objectivity or lack of objectivity mantra is baloney. Another great trick is just get a couple people going to and getting TDD training. TDD is absolutely my favorite way to start people into this. Alan's giving me the shut the hell up sign. I know how to recognize, oh, Brent's going to keep going, man. That's a start if that's not enough, ping us and we will talk more about that later. I want to make sure we don't skip the people whose name begins with Z. Awesome. Thank you all. Yeah, you're welcome, man. Thanks for listening. Chris Blaine. Hi. I'm happy 100th. I really enjoy the fact that I think you've been able to move the testing conversations forward that were probably stalled for a while in the testing community. That's something that I think is really important and it's fun to check in every week and hear your thinking of all, see how you're moving through your careers. I'm very interested if we can get more this week about the end of the transformation that you're doing, Alan, if you can talk about that yet. Oh, yeah. Yeah. One of the things I want to do is work on having that quality culture and building that and things like that. So I'm always very keen to hear that when you talk about that. In the podcast each week, it's been really valuable to me and I think it's a great way for the testing community at large to move forward. Alan, you're inspiring threes of people all over the world. I am. I am. So I finally officially start my new role at Unity on Monday. And I took job B, which is basically a director of delivery, working across our monetization organization, which is largely ads, just helping that team of 160 engineers work together better, increase velocity, increase quality. So obviously I have my quality slant in there. I've described this as an iceberg job, meaning I go in knowing what about 10% of the role is and as I start exploring that 10%, I'll discover eventually what the other 90% is. And I really like being in that situation, so I'm looking forward to that. But really that's all I know about it. I know I will spend the first couple weeks talking to a lot of people, figuring out what's up. And these are teams I work with before and people I work with before, so I have some pretty good ideas going in. But there'll be a lot of discovery, figuring out what's going on. And there was some bureaucracy and red tape in the way of getting it over. The Unity is a new enough company, a small enough company, that internal transfers are fairly rare. And internal transfers of senior roles are, I could be the first one ever. So there was some stuff involved in that. It's all taken care of finally, so I'm looking forward to get going. And I will be talking about that more and more as the episodes go on, so I'm looking forward to that. Well, congrats on the role change. Yeah, it'll be fun. I'm pretty excited about it. All right. The one and only Chris Canst. Chris! Wow, that's a great intro. Thank you. I want to know, I'm going to mess up so bad now that you said that. But no, I wanted to come on and say thanks to both of everything that you both are doing. I think the modern testing principles are great. I like that there's this North Star that people can use to understand what the future of modern testing looks like. Even though a lot of these aren't new, the fact that they're all combined and packaged makes a lot of sense. But my question is, have you seen from the people that you've talked to and the responses that you've got, are there certain industries that are actually better able to adopt the modern testing principles better than others? Are consumer internet companies able to make that transition better than say, healthcare companies or are mobile companies, that kind of thing? Are there specific industries where it's much easier for them to go, oh, this makes sense? Yes. All right. Next person? No. I'm kidding. I'll go first. I do think it's very tightly aligned and there's a lot of literature on this around even agile. Right. As you all know, modern testing principles has a strong foundation in agile and lean processes. I will definitely say if your product is something that's service-based, if you're not on something like modern testing, you're already behind the times. And then going to the final scaler where there's something that's very, has a long lead time. For example, I saw a message recently about automated airplanes. Doing reactionary stuff, there needs to be a QA department for something along that line. To assure you minimize what we've called here as sort of catastrophes in production. The way I would phrase that is that the larger the risk, the more likely you need a dedicated testing specialist or specialist. Yes. So that can be true in other aspects of software also. I will add to it in the larger the lead time. Yes. There is, I'll just throw another book reference out real quick. Steve Denning, I became a fan of his when he wrote a book called The Leader's Guide to Radical Management. He's a business author, writes for Forbes, but he had discovered agile and seen a lot of applications for it in business. So it was very early on, well fairly early on in the world of agile. So he didn't call out agile as much. But his latest book is called The Age of Agile or The Speed of Agile or something. You can look it up, Steve Denning. There's one profile of a team at Microsoft, but there's profiles of different industries applying agile. And of course, as Brett mentioned, we're built upon agile. We're built upon, I mean, if you've read the lean startup, you can see where we stole a lot of stuff from. And we also build a lot on what Lisa Crispin and Janet Gregory wrote in agile testing. Full, stealing, you know, steal like an artist. That's what that would be. Oh no, I mean, the people we've stole from is long. True, true, true. We're near to seeing pop and dikes. It's long list. Shall we go on? Yeah. Where am I? Connor. Hey guys. Hello, hello. Hi. Can you hear me okay? Yes. Perfect. Yeah, I just said it, John, because I'm enjoying the podcast and I want to thank you for it. I kind of got to a point in my career where I no longer wanted to be the bottleneck. I wanted to learn more about coaching teams. I started to use analytics to develop how customers are using the product and also getting more engaged with customers, getting on customer calls and getting involved more in beta. So at that point in my career, I saw the modern testing principle the first time, started listening to the podcast. So it was really good at that point to make sure that I found modern testing principles. So I want to thank you both. Oh, you're welcome. You're welcome. Brent's tearing up a little just so you guys know. I am. So I have to listen to everyone coming in and say, oh, I want to be just like you, Alan. I want to be a coach too. But I absolutely love it when I hear people saying, oh yeah, I'm moving into the data. I'm moving into the customer analytics. I haven't yet heard anyone saying, yeah, I've dropped it. I'm following, I'm going into a data science role yet, but I've still got my fingers crossed. Lisa's the closest one. But even then, I think what's her title? I'll ask her in a minute. Yes. Right. Where was I? Thank you very much, Connor. We're glad to have you on board. We'll grab our help once in a while. Emma. Hello, everyone. Hello. Can you hear me? Yes. Yes. Congratulations to this episode. This is my first time live with you. I'm very interested in modern testing. I'm following your video in YouTube and also in Slack channel. I have good news that I'll speak about modern testing in a conference, in IEEE DTS conference next. I'll talk about the transition from traditional agile and modern testing, also the role of a Gila coach. So, I'm very glad to be here and hope to, it's a challenge, modern testing, really a big challenge for me. And I'm learning a lot when following you. Thank you, everyone. I'm so excited to hear about, this is not the first time, but I'm loving that other people are talking about modern testing. It's exciting to me. It's fantastic. Grant, we made a thing. Yeah, I know, right? It's really cool. We're very excited. Please let us know how it goes. I'm both flattered and excited and all those things. Yeah, I'd love to, when you've done the presentation, I'd love to have the, to get the deck up on the Slack channel and as well as hear your sense of how it went. Awesome. Thank you, Emna. Glad to have you here. And then someone who gets name dropped on the show more than once, Lisa Crispin. It's so exciting to be here. Congratulations on number 100. Yeah. Thank you, Lisa. I'm trying to remember why I started listening to your podcast. I'm not going to say that. I'm not going to say that. I'm going to say that. But I happened to start listening right at episode 60, I think. And you did that. You did mention me and Janet in our book and I was like, wow, they have, they have found value in our book. And of course all the other people who contributed to our books. And so that was exciting. And of course, flattery gets you everywhere. So I started listening, but, but really truly, you know, I was listening to that justice. Like I had just heard Angie Jones on a different podcast talking about testing artificial intelligence and machine learning. And, you know, I was getting interested in data science. And hearing this hearing you talk about the next step after being an agile tester, you really need to learn this data science thing. You need to ramp up the coaching thing. And the coaching thing helped me right away in the job I was in because, you know, I was supporting up to 20 developers at one time and kind of switched over to that test consultant role there, which is something Janet and I always had promoted, but not to that extent. And that worked really well. And then just getting interested in the data science and machine learning led me into my current job. I was testing advocate for a vendor whose tool uses data science and machine learning. And I have not learned about enough about those things yet, but it's super fun. So thank you. You've like helped me transform my career, which is really exciting. Well, yeah. As you know, we stole a great deal from it. You know, in a lot of contexts, we do frame what we're talking about as sort of the next logical step from agile testing. Right. They're not mutually exclusive by any means. Exactly. And then one thing I wanted to mention, I mentioned this once before on the podcast. It's worth mentioning again because I mentioned my community, my quality community at Unity. And it was about maybe two or three months into my role there. I started there over two years ago when I realized, oh, I really have a community, this matrix organization. I'm big on building communities, as Brent knows, and that's helped connect people. But it was then like maybe three or four months later, I was rereading agile testing. And then right there, maybe it's chapter three, the book on managing teams talks about the manager runs a community. Totally paraphrased. I thought, yes, yes. And maybe, I don't know if it was something I'd read and forgot about, something that was like in my subconscious. But I love when I read a book and it reaches the same conclusions I reached on my own. It feels validating. Worth mentioning because I mentioned community earlier. Well, that is nice to hear. And it's nice to hear it works for other people. Yeah. That's exactly what we think about modern testing. Very cool. Thank you for listening, Lisa. It means a lot to us. Thank you. And Lisa, let me know how I can help you on understanding the data science part deeper. Awesome. Thank you. Yeah. We will. But happy to make that happen. Cool. Matt. Matt Dills. He might have fell asleep. Can I come back to Matt? He says he doesn't have a mic. Oh, that's cool. Cool. Thank you for listening. Thanks for being here. Thanks for listening in. If you have anything you want to say, you can check it in chat and someone can read it to me. But it looks like there's a Real Salt Lake fan on the podcast. And as you all know in our prediction episode, I predicted good things for the sounders who are doing very well as opposed to Real Salt Lake. But Michael Richards, what do you have to say? You had to bring that up, didn't you? Yeah. Long time listener, first time caller here. But not first time on the podcast. That's correct. Yeah. Yeah. Considering that, you know, happy 99th, Brent. Anyway. Yeah. So we're done. Long time listeners. We did like in the 40s. I was at Test Bash Philly and I recorded a whole episode of AB testing podcast without Brent. That just means I get to do this twice. So I'll do it next episode. Percy and Michael and Vernon joined me for a podcast recording. It was a lot of fun. Anyway, go on. At some point, Brent, you're going to be doing a test test. I'm going to be doing a test test. I'm going to be doing a test test. I'm going to be doing a test test. I'm going to be doing a test test. I'm going to be doing a test test. We're going to be doing a, a podcast recording. It was a lot of fun anyway, go on. At some point, you're going to have a deal. And without, without Alan somehow some way you can't figure out how to use the equipment. No, I can figure it out. I have a teenager and we started the equipment in my office. So maybe that's what I'll do. Is I'll just meet him, we'll just record one. Sure. Anyway, please go ahead. I really appreciate all the, the guidance on that. That's the best thing I can say. Alan, you specifically have been kind of a mentor to me, and I appreciate that because it's really helped drive the last three to five years of my experiences in the testing world and where I've come and where things are going. And I really vividly see how the industry is gonna change in the next five years, and it can't be stopped. And I really appreciate everything that you have done and how you kind of coalesce all the ideas that are out there into one central point. I love how he phrased that. One of the things that I think we've been trying to do for the last five years is just get people to see this and that it's not a negative thing. It is, in my humble opinion, just a matter of time. It really can't be stopped because it doesn't make business sense. There's context, as we covered with Chris's question, there's context where it makes sense and it doesn't today, but I think even then it's gonna change over time. And so hopefully we've inspired several people to, there's a phrase I use, you can either be the butterfly or you can be the wind. And I'm hoping we've inspired a lot of folks to be the wind instead of the butterfly. And I will say in my closing is, let's hope there's a hundred more. Here's 200 more episodes. Ooh, another five years with Alan. Another five years. Oh my God. Yeah. Luckily it's only once every two weeks. So we may be able to survive. As long as you don't die before then. Or you. All right, back on positive notes, Mohammed. Hi, I just wanted to say thank you for the hundredth episode. I've been hearing your podcasts since a while and has been amazing. And I just want to say to Alan that is article fear factor and the sentence for making the job obsolete and I just have like been an eye opener for myself. So thanks for that. And can you hear me by the way? Yeah, we gotcha. Awesome. And the modern testing principles, I mean, they're quite interesting because you know, we've never met and this is how somehow we drive our testing in the company I work for, which was like quite interesting. So thanks for that as well. Yeah, this is everything I have to say. Thanks. Hey, Mohammed, just making sure, I think I know who you are from the Slack channel. Are you a developer now? No, no, no, I don't think you know me. No, I work for a company called Acres Global. I'm a key principle guy there. Okay. All right. Wrong fellow, but thank you for listening. Glad we're able to help. On the podcast for the second time ever, along with Michael Richards, Percy. Hey, hey. Hey, Percy from New Jersey. Percy from Jersey. Thanks for getting that dad joke. Of course, takes one to know on, right? Yes, absolutely. Love dad jokes. All right, man. So I actually remember when I started listening to AB testing, I'm gonna give credit for, credit is due and that's to Michael Larson for putting up a blog post on, I think he wrote like an end of year blog post that says, these are the best podcasts that you need to be able to listen to for the incoming year. And on that list is AB testing. And I think you guys just put out the last episode of 2014. So that would be somewhere in the teens still. So that was the first time I actually- It wasn't even very good back then. Well, that was like, I got lucky with that episode because I think you guys were talking about, you know, the fundamental differences between generalizing specialists and specializing generalists. And then it kind of, my interest just kind of ballooned from there. Was that the one where Alan and I finally close on the debate between him and I on this one? It might have been. I mean, you guys were still both in Microsoft and well, of course, it kind of was a tangent fest too. So it was a typical episode. I must say, right? But yeah, I can't thank you guys enough for, you know, the amount of work that you guys have put in, you know, the fact that you guys listened to us or even take the time to listen to us with our really highly opinionated, you know, ideas sometimes completely canner against what you guys are thinking about. It did force me to think about a lot of stuff. And I've gone to apply specifically a lot within the data science stuff that Brent has been talking about, you know, how we were able to improve, you know, simplifying our regression strategy and looking into, you know, customer usage data as well as performance testing. Actually that did streamline a lot of the stuff that we work when it comes to performance test design and looking into how our customers actually use the product instead of just thinking, maybe this is how they will use our product. So we have, you know, very decent source of truth, you know, from there. Man, I can go on forever, but I'm going to yield the floor to whoever's next. Again, thank you so much for, you know, putting up with everyone else and making sure your ideas are being known to the rest of the world. I will say before Alan has a chance that of all the three, I actually think Percy has personally put more effort into the podcast than Alan or I have. He created the Slack channel. He actually even invented the hashtag one of the three. Thanks for being with us all this time, Percy, and thanks for being such an active participant. Yeah, thanks, thank you, thank you. And I would also say that, you know, you thank us for like listening to the community, but we can't do it without you. So we need, we rely on your feedback. We rely on your strong opinions. We rely on what you like and don't like. That's, it's principle number five. We, only you, our customer, are able to evaluate the quality of what we produce. So we want to take your feedback and use that to answer questions, to figure out topics we need to explain better, where we need to dive deeper. Which reminds me, I have to make an announcement later, I forgot, but remind me. Okay. It just popped up, that was a tangent. I didn't go down there, I shelved it. It's an A-B testing first. Yeah, this is hard. I was going to give an introduction, but I will wait till after he talks, and then I'll talk about some stuff that Rob's been doing. So Rob. Hello? Oh, you can hear me. Am I the only Rob? You're the only Rob. Oh, okay, yeah. So I love the podcast actually, guys. So I wanted to thank you, like everyone else. And weirdly enough, I think I was doing modern testing before I even knew what modern testing was. So I started hearing some interesting things around about modern testing, now rent and stuff. I think I'm doing color actually. I've introduced the modern testing podcast to me. You know, I've had huge interest in testability and a huge interest in quality coaching and test coaching. And I've been working as a test coach now probably for two years. Talk a lot about that. Connor as well works on that kind of stuff with me and quality engineering. And what we've been doing is working together to build a vision for the future of testing in our organization and the principles and your podcasts have influenced that greatly as well. So it's been a big, big factor for us. So I just really wanted to thank you for that. Really, really cool ideas, pushing the boundaries and there's so much in common with my own beliefs and thoughts around testing that I had to be on the call today to just say thanks as well. Totally appreciate that. Where are you in your business culture change? So yeah, so as I said, I'm head of testing and a quality coach. So I work with a team of testers and we're trying to influence the change and testing across the organization. So I actually work with the development teams to actually build testability into the product, identify quality goals and I'm more influenced to teams rather than actually test anymore. So I do very little testing anymore, unfortunately, but it's more around strategy and direction and developing, identifying goals and building good practices that allow our teams to deliver quality quicker. Awesome, love it. That's a such a. That mantra, I think is the single most important thing, what you just said is, right? So for so long, test has been accused of slowing things down or stopping ship and we need to change that direction. It needs to be quality and speed, not or. Yeah, yeah, so the maintenance. So what's great for us now is we've moved away from the area from focusing primarily on automation, maintaining debugging and automation. And we're going and doing the things that you're discussing like the looking at data analytics, driving our understanding the user using the data analytics but also things like ethnographic research, things like that. So we go and use the research talk directly to them. We were very big, I pushed user story mapping in a big way so we get different elements of the business involved in the conversation before we build anything and getting those diverse perspectives involved is hugely important to understanding quality, not just from a user's perspective but from the perspectives of everyone who interacts with the product. So there's also things around building skills across the teams in deep exploratory testing and risk analysis and a whole host of things. Very cool to hear. And the introduction I was going to add is like, I know from talks you've done, I think at Test Bash. Yeah. That you're doing that, you're into that coaching consulting world, which I think is at some point, maybe that's the next talk I give about modern testing is postmodern testing and talk about what roles people move into. I can talk about myself of course. There are other people like, I can talk about Brent moving into a data science role. I can talk about you moving into a coaching role. I think there may be something there. So I'm glad you're doing what we're doing. Yeah, it's very interesting because Test just have these critical thinking skills and analysis skills that can be applied in a fractal manner across businesses with different layers in different ways. So whether you start with hypothesis driven development and others just loads of stuff that we can use. I love everything you're saying, Rob. Everything. Brent's giggling. All right, man. Thanks a lot. Thank you very much. Is this so cool to hear? We should have 100th episode more often. We could do it next time. It'll be mine apparently. Yeah. There'll be one, we'll move on. We have the infamous and up. I guess it's not too late in Europe. As Brent refers to him, Pratrick. That is the rest of us calling him the test pappy himself, Patrick Prill. Hi guys. Hi Patrick. Or Pratrick. Pratrick. Hi, Pills. No. Cheers guys. No, thank you guys for 100 episodes. It's really great to be there from, I don't know. I think I started around episode 15 or so. So it's really great how you evolve the podcast. And I really have to say that the six little words of accelerate the achievement of show up with quality really changed my world. And these six little words really influenced my attitude and how to approach my daily work and my decisions. So thank you for those. You're welcome. I think that was a breakthrough for a lot of folks. Certainly was for me. Yeah, it definitely was a change in the discussions in the podcast. When you guys found that very short summary and you were, I remember that you were very happy when you found that. And I think that influenced all that modern testing principle idea. So that was really, really great. I was just, my mind was wandering back and of course you've been listening for a long time. You've kind of seen, just seeing it guys know, Brent and I rarely talk outside of the podcast recording, especially since I left Microsoft. Occasionally there'll be a message back and forth on Slack. Maybe I have something I want feedback on or an idea. But really everything we've, you've witnessed as listeners the development of everything we've done because we've done 99% of it recorded and then published to the internet. So I just kind of thinking back, I remember having the notion, I think I just read Ray Dalio's principles and having a notion that we should have modern, we've been talking about modern testing for a while, we should have principles. And then I wrote some out and Brent- Slaughtered them. Yeah, which I love. I think I really believe in good ideas coming from fierce debate. And then we brought them to the community and there was more debate. Then we talked about them and they got tweaked more. And we thought they would keep on changing and changing and changing, but they've been solid now for like a year? No, more than a year. As I get older, I refuse to stop, to look back in time and go, how long has it been since? No, I'm just, the reflection was not the time. It's just the... When you see something come as the evolution, it's like, how did these start? What's the origin story of these? And how did they evolve into this? I don't really recall all the details. I'd have to go back. But the cool thing is I could go back and listen to all of our episodes and figure it out. Yeah, and I still think it's a living document. For sure. The thing is, as mentioned, for a lot of folks, modern testing principles are the past already, but for a lot of folks, it is still very much sort of a North Star visionary statement. And so I think it'll probably still change as the world shifts towards, well duh, on where it stands. So for Patrick, one of my favorite things is, yeah, he joined the Slack channel early on. And if there was, I'll just put it this way, if there was something stupid, Alan and I said on the podcast, I could always count on Patrick to call us out. And then we could fix it, adjust it or clarify. Early on in the formative days, Patrick was super important to us. Thank you for that, Patrick. You're very welcome. I hope you stick around for the next 100 or 10 or one even. Of course. Cool. I'm gonna mispronounce his name, so please correct me. Is it Yuros? It's Yuros, but thanks for trying. Okay. First of all, I want to congratulate you guys on a 100 episode. Thank you. And I was introduced to ABA testing podcast by Patrick as a matter of speaking. So thank you, Patrick, for that. And it was right around when you started talking about modern testing. And what struck me most about it is that I felt like I was doing a lot of things already that you were already talking about, but you put it so nicely into the words. And to be honest, I'm still distilling all the principles and all the, let's say, important details that you are talking about them. And if you're okay, I would like to also contact you in the future about some things that I have in my mind. So maybe some details to discuss about. Of course, of course. Okay, thank you. And the last thing I wanted to say, I enjoy your banter at the beginning of the episodes. I learned some important stuff about cooking, about music and whatnot. So thank you for that as well. And I wish you many more episodes. Thank you very much. I do have to admit, sometimes they go on a little bit too long. Yeah. I do know there are listeners, probably none of you, but I do know there are listeners that kind of skip the first 10 minutes and wait for us to talk about something interesting. And that's fine. I will say, like one of the first reviews we ever got for A-B testing was something along the lines of, it's two guys babbling about, their vibe was two guys babbling about testing over beers. We've never actually had beers here, but I do like that spirit. I do think it's part of the charisma of the... That was Michael Larson. That was the post from Michael Larson. I was like, two guys having beers. Not knowing we recorded eight o'clock in the morning. No. Thank you. Thank you, Eros. And one thing I wanted to mention, and before, I'll make sure I haven't missed anybody, but it was Test Bash one year ago, almost exactly where I first gave a talk on modern testing. We haven't talked about it for a while, but we've been talking about it when I submitted, and I'm glad they accepted the talk. And it was fun to talk about, and this is on the dojo. It's their only, as far as I know, it's still the only ministry attest talk on their dojo with an explicit tag on it. I got excited. And when I gave that talk, the thing that really struck me, and people came up to me, they weren't freaked out, but I had people come up to me and say that, thank you for giving a label to the thing I've already been doing. I thought, oh my gosh, it's not, I'm not scaring the crap out of people. This is something they're actually, they see happening, something they're already doing. So that was really great. Then the one, actually, did I skip anybody? If I skipped you because I'm blind, please unmute and talk. Otherwise, I'll make a quick announcement. Okay, I'm good. I mentioned Ministry of Test for Big Fans, Ministry of Testing, Test Bash, big fans of that conference. I don't know if I've even mentioned this to you, Brent, but I am working with Ministry of Testing, literally as we speak. Sometime in 2019, Ministry of Testing will debut a nine-part course on modern testing. Whoa, cool. An introduction episode, one for each principle, and then a recap on post, or talk about post-modern testing, as we call it, what happens after modern testing. So there'll be, the plan is, each is only about five minutes long, and the idea is to give people a lot more. It'll be, I expect it will be, each course will be the super condensed version of the deep dives we did on the podcast, and I'll use those for resources. Lesson plans are done, that course is planned is done, working through those, it'll take a while to get the work done, but I'm pretty excited about that. Do you wanna send that to me? I will send you a link to the lesson plans, you can start giving me feedback. Okay, cause one of the things that I intend to do this weekend, and I'll do it just before we publish, I've decided to, that my penultimate blog post on Testastic will be this weekend. It will be the document we've been working on around modern testing. That will be, I will write up my final words on that one, post it as a blog post, and that I intend to be the last blog post I ever do on Testastic. When was the last blog post ever on Testastic? Wasn't that a long time ago? It's two or three years now. It's the, it doesn't, the brand is a great brand, but it's not who I am anymore. And your announcement? That was it. Oh, okay. That was it. And also one big shout out, not on the podcast today, but one thing, again, our community and you guys are just huge for us. And if you're not on the Slack group, you should really get on there, cause I'm gonna totally butcher this thing. It's Massiej Rodek, and that's probably wrong, but that's the best I can do. He listened to all of our principles episodes and the follow ups, and made a magnificent and huge and detailed mind map of modern testing. And that will get referenced and credited throughout this course I'm building, cause it's just a really nice, it's just a fantastic job. So thank you. As you listen to this, please accept my thanks, even though I probably pronounced your name horribly. It's really incredible. It did a fantastic job. I recently saw that he did a post on it as well. I haven't yet gotten Google to go and translate it, cause he wrote it in, I think he's Polish. Check out the Microsoft employees in Google. That's nice. Oh, we're a different company now, dude. It's all about what it takes to get it done. Yeah, yeah. We'll talk about other things later. This was fun. I just wanna thank all of you. You can unmute and yell stuff at us in a minute. But just for being a part of this and kind of taking this crazy idea to have a bunch of listeners talk to us on the show. And I would say this even if a lot of you didn't give us praise. Just, I'm glad it worked out. Hopefully the recording comes out. Otherwise, this is just a private show for about 20 people and we call it good. Or we can do it again next week on The Real 100. But really appreciate it. This is, it's, we never thought it would be, the podcast would be a thing. So it's just super exciting. And really, I just have a lot of gratitude for everyone who's even listened to one episode. So thank you. Yes, absolutely. All right, we're gonna call that good and I'll get this edited and published to the Slack channel hopefully tonight, but over the weekend for sure. And then out to the masses on Monday. Hopefully it includes all three of our voices, or 20, whatever they were. And we'll see you next time for 101. Do we wanna let the, you wanna unmute all of them? Let the three do the sign off. All right, three, sign on and give everyone a big goodbye. Good luck. Just letting my dog say goodbye. All right, goodbye everyone. Thanks. See you guys next week for The Real 100 and 101. 
