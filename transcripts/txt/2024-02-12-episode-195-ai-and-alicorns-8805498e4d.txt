I believe she said the Romans invented the unicorn and the Greeks invented the Pegasus. And then she's like, I have no idea who came up with the aliquot. Welcome to AB testing podcast, your modern testing podcast. Your hosts, Alan and Brent, will be here to guide you through topics on testing, leadership, agile and anything else that comes to mind. Now on with the show. Hello, everyone. It's Alan and Brent and nobody else except for my dog. We're here for episode 195 of the AB testing podcast. Welcome back. Thanks for listening. How you doing, Brent? I'm doing super. He's doing so super. He is wearing a San Francisco 49ers shirt and they are a sports ball team in the US. They play football, but not the good kind of football. The other kind that has gained massive popularity with the rise of the Taylor Swift Travis Kelsey relationship. I don't know how the Florida understand a chance. Tell me what your thoughts, Brent. I yeah, it was actually one of one of my employees had a one on one today. She's like, I never watched football, but I'm totally watching this time. I'm like, oh, really? Why? And she's like, because Taylor Swift. Because you can see like five seconds of Taylor Swift in the box being Swiftie. Yeah, it's wild. It's a wild time. I'm just like, okay. Right. The Niners have a pretty good chance against the Chiefs, but can the Niners also tackle Swiftism? I don't know. It's going to be wild. I will watch every year. I love watching all of the new commercials because there's like three times a year. I watch actual commercials for more than those little 30 second blurbs on on YouTube or now Amazon prime. That is the Oscars, the Grammys and the Superbowl. It's about it. Because soccer, there's no commercials during the match. And I use, I use halftime to go get food or make something or whatever. Cause I know how long it's going to be. It's very predictable sport. Great. Great. Your brakes are more predictable. Like I would say football is fairly predictable as well. No. Well, here's the deal. Like if I'm actually, I will watch the CX play sometime, but I have to have a project while I'm watching football because there's not very much football in the three and a half hour football game. Right. Right. It's, it's, it's a great social sport. I can see why, like when I was younger, I go, I watch like football games with friends and things. Cause it's, it's, it's a social sport because there's plenty of time to talk between plays and things. Oh, for sure. For sure. And I don't like people. So social sports are not for me. I, I, um, I once, uh, a buddy of mine years ago once actually used football as sort of a metaphor for waterfall. Interesting. It's like, oh yeah. Right. And NFL game, they plan for an hour. The game's only going to take an hour, but yet it consistently never does. That's interesting, uh, metaphor. And it's one of the reasons why. Right. With, with the variant of agile, I never gave it the name, anything related to NFL. Cause NFL is absolutely in comparison to soccer. NFL is way more command and control. So we are by ourselves. We've had a couple of guests, uh, over the last few weeks, uh, split up, uh, Jason into two, a big thing on AI. And then we had Brian before that. I want to do a little retro reflection on some of the things I learned there and go a little bit deeper into those thoughts I have, but then I was also thinking like, I like having guests on the podcast and it's fun. People, we get feedback that people like getting new ideas and, and all these things, and then my boss told me this week, he says, I skipped past your past episodes. I only want to hear you and Brent rant about things. I don't care about your guests. Your boss said that. And I thought he's a total AI geek and he's listening right now. Well, I mean, right now as the moment he hears us, but he would, didn't listen to Jason geek out about AI. So whatever I was, I don't, I don't know how I feel about that feedback. Well, whatever. Well, just, you know what? Here's the deal. Here is 195 episodes in and people know by now, look, we are the AB testing podcast. We do whatever the fuck we want. I ain't fucking men. And one thing that's really important that I think you just click me in on. So you're saying that there's like a 95% chance that your manager is going to listen to this episode. Yes, I think so. And he will tell me, in fact, he will send me a message the moment he gets to that part. It says, Hey, heard the call out sup. I don't know your manager well, but I, I'm going to think of, I'm going to think a bit about the chaos I might be able to cause you. So I'm going to read you a blog post and our blog post, a LinkedIn post from today. Okay. And I want you to hold your comments and any facial expression, actually facial expressions are fine because nobody could see them until I'm done. This is, uh, from a fellow named Mike Thornton. Developers shouldn't test their own code. Developers have a blind spot. Their focus is problem solving. They are so solution oriented that they can't see education. So they will only test the happy path. Only tester should test developers. Shouldn't design their own software. They will only design the happy path. Only designer should design developers should not Absolute deploy their own software. They will only deploy the happy path. Only deployers should deploy developers. Shouldn't code their own software. They will only code the happy path only Coders should code last line. Wait. I'm not done. Yup. Follow me for more career ending advice. Okay. Okay. I took Brent on a journey. That was a roller coaster. Oh my God. It started off bad and got more absurd and then got good. So I'm like, I'm like, what? Like the last one was like, what? What was cool is I saw this because Brian Finster commented on it and I follow Brian Finster on LinkedIn. So it showed up in my feed and it was really cool because what I'm finding is, and Brian was on episode 192 and there's a line from that or a concept from that podcast I've been talking about a lot lately where he says something to the effect of the way to really highlight where the problems are in your delivery is to try and do CD. And I have been thinking about that a lot because it's true. And it's really about we want to help people go super, super fast. I've been talking to my team a little bit about that. And there's a lot to that and see what breaks. So I want to reflect a little bit on that. I have, I want to tie that into a longer topic, but also that was it for the Brian thing. I thought that was pretty funny. And of course the comments don't in the internet never read the comments. The comments are like, actually I do want to finish this, this topic because the comments are you're an idiot. People said, I don't agree with you. These are wrongs. Like, oh my God. What I'm happy to see is we have people that don't even know what modern testing is doing modern testing principles, exactly what we knew was going on, but nobody believed us at first. And we're just seeing more and more examples of the fact that a whole lot of companies deliver. If there's anything we saw coming on that we, we pay attention to sort of trends that seem to be successful. Like we didn't cause this. We just observed it. And the momentum of that or the momentum of that sort of initiative, that just kept on going, but it, I think it's well beyond early a doctor phase. And that's the thing we and the thing I keep on reiterating, we didn't invent anything. We talked about what we were seeing. I put some labels on things just to try and explain it better. So interesting now, like getting just that one connection with Brian brought a little bit expanded my network a little bit. Into more people that get how modern software delivery works. So cool stuff. I'm actually wondering how well, send me that link later. I'm actually wondering how well that would fit on a t-shirt. It was like, just like that is the type of witty things that I would often get. T-shirts. It might be a little too verbal. Yeah, it's a lot on there. I also wanted to reflect a little bit on we had Jason and you and I geeked out a lot about AI. I know you've been thinking about that a little bit. You mentioned a little bit when we were first getting on the call and talking, but something about, please don't say AI ops. Tell me, tell me more where you were going. Like, what are you even thinking about since that about AI since that called, well, so one of the things, how do I do this without being. No, let me, let me do a brief version of it. A longer version of it might be worthwhile. So been thinking around, I'll just, I'll just invent a term and I'm not inventing it, a term cause this is a conversation I had with my manager just the other day, but let's just call it LLM ops. Yeah, I feel a little sick already, but go on. Right. It's essentially, so if we think about the progression and I, there's a couple phases in between that I'm, I'm forgetting the names of, right. There was start off with sort of a dedicated SRE team, then the idea of DevOps and then probably a couple more. Then there's AI ops where, well, so the big part of DevOps is now, now actually the developer owns their own life side operations. The idea behind DevOps was to get rid of the wall between the development team and the operations team or the development team and the deployers, the Devs and deployers never shall meet unicorn projects all around us. So cognitive distance. Yeah. Don't need it. So the idea is just get rid of the walls. It's faster. Get rid of the handoffs. Just get rid of the handoff. So to me, in a way, everything's DevOps. We're trying to get rid of handoffs between teams, but I'll let you go with your story. Right. Well, well, so AI ops is, is again, trying to speed things up, essentially get rid of the risk inherent in human decision making, right? Have the AI make the decisions. So we're not breaking down the wall between AI and ops. We're breaking down the wall between humans and their decisions. Well, so my absolute belief, AI, every AI, every AI, every AI I've encountered, and I think this is true period for all AI. AI's whole purpose in life is to automate decision making. That's what it does. It's certain AIs, certain AIs can only automate, you know, simple decision. Even very complex models can only automate certain decisions. But the thing around LLM that's attractive is it can, if you leverage it right, I suppose, hand wave, hand wave, it can make decisions of unstructured data of lots of forms. Obviously it can't, it has the weakness where it can't use numbers and the way, say, traditional AI, every number to an LLM is a strain. Everything is a strain. But to me, that's, that it kind of feels like the next logical progression of sort of speeding things up, of course, massive risk with it. I just wanted to flip that topic to see some of the invite, the potential for your brain serving there. Just to interject there, I like, and I've talked about the way I use chat GPT is to help me collaborate and really to make decisions like, if I do this or this, it's, it's, it is a form of decisions. But then I was thinking also like one of the things that's always, that attracts like the leaders I've liked in my, in my career, one attribute they all had was the, the ability for them to make a quick and confident decision, whether it was based on a little data or a lot of data, they just, they were good at decision making and their track record was super accurate. So if we can try to figure out if, if we use AI to help us make decisions or AI is there to make decisions for us or help us make decisions, I'll say. Does that accelerate? Does that improve leadership or replace leadership? Certainly the risk of it to do both is quite high. The, I think it's the former, by the way, at least for the short term, I think it's just like the thing we always say, AI isn't taking your job away. People who know how to use it effectively are not in the people who's here's my problem with, with the folks. Knowledge. We've, we've talked about knowledge and where ideas come from, et cetera. So we like knowledge. Yes. There's this concept of the adjacent possible. I think, I think I learned that from Johnson. Yep. You did learn that from Steven Johnson. Yeah. Okay. And so if everyone was to view like your personal knowledge as like a, it's like a literally like a bubble, like when you go blow bubbles with children, right, a bubble inside of your head, it's a sphere that has a surface area. And anytime you gain knowledge, you're basically blowing more air into that bubble. So it grows bigger. It has a better surface area. And so there are more things that are now possible just out of the reach of that bubble. The question is that I think about, okay, these, these AI is coming to, to, to take our jobs, they will, but will they take the portion of our job that we like or the portion of our job that we hate? Will, will it be able to, to what degree will it be able to go accelerate us such that each of us as human beings are, are able to access more of the adjacent possible, I think when I think about a couple of things like automation, why did we build automation, right? It's to get rid of sucky, repetitive things, the things that we kind of don't want to do. Right. And that's part of it. It's also to do things at scale that we don't really can't do. Like I do not have the ability to run manually a thousand test cases in parallel, like I'm pretty certain you don't either with automation. I can, but not manually. So there is that risk of anytime we automate because we can do it at parallel in that scale that, that we're creating the ability to do something that we can't do manually. That's certainly possible with, with AI. But a lot of it is, is going to be based off of, I don't need to make these decisions anymore. It can, like I'm perfectly fine with something else making those decisions. The lightweight ones, the ones where you're sitting with your wife and they're like, Hey, where do you want to go eat? Oh, I don't know. Where do you want to go eat? Like LLM tell us where to go eat. Great. For sure. So it's interesting you bring that up. I want to talk a little bit more about the adjacent possible here because I was talking to someone. I forget who it's a long story. Tech people, tech people I don't work with. I'll leave it there. And they asked the question. Every person asks me when we talk about tech, Alan, what do you think about AI? I said, really? Do we have all night? But what it boils down to is I brought up the adjacent possible. I think, you know, everybody's excited about AI and AI is now a buzzword. Do you remember when Microsoft put dot net on the, on the end of every project? I figured people were doing that with AI. Everything's AI. It's not probably 90% of the things out there now that says powered by AI are not powered by AI. It's dumb, but, uh, that wasn't my answer. My answer was all the stuff we've talked about. Chat GPT is a great example. I talked about how I collaborate with it, how it's enabling a lot of things. It's really, it's exciting as chat GPT is what it has done is brought us to. And what the adjacent possible is, I forget Steven's definition, Steven Johnson, but it's like the adjacent possible are the things that are possible to get done at our current evolution of tech biology, whatever, right? What chat GPT and LLMs and generative AI have done is it's, we've taken a step forward in what's possible, but I really believe the big inventions, the things that are really going to go, oh shit about and go, wow, this is amazing. This is accelerating or it's doing a, it's doing B it's doing C. They are things that are going, that we haven't thought of yet, but are now the new adjacent possible because of the existence of generative AI. Right. And then, and the new forms of AI coming out, there's something they say, well, what are you most excited about? I'm excited about the thing I haven't heard about yet that actually builds on this and takes us to a brand new place. Never been before. That's what I'm most excited about. I am. I'll, I'll, I'll share with you how I'm thinking about it in the AI world. Are you familiar with the concept of a center? Um, I, oh, we've talked about this briefly before. Yes. And old professor. So the term was invented by, and I forget the guy's name, the Greek mythology. Yeah. That term was, but in the context of AI and actually my daughter were here, she'd be able to confirm or deny it. It was actually the Greeks. Uh, that's what I said. I said the Greek, I said Greek mythology. Yeah. Anyway, they have taken, they have didn't invent the term. They've taken the term and applied it in a new way. In a new way. Right. Um, we are all about accuracy on the AB testing podcast. I learned from my daughter the other day, the following, and I may get it backwards. I don't care, but I learned that. I believe she said the Romans invented the unicorn and the Greeks invented the Pegasus, and then she's like, I have no idea who came up with the alicorn, right? But to your point, Steven Johnson, the Jason possible, no one was able to invent the alicorn until the unicorn and the Pegasus were invented. And for those on the call who have no idea WTF is an alicorn, it is a unicorn Pegasus. It is a unicorn with wings. No, it's a Pegasus with a horn in the middle of his head. The age old debate is a zebra black on white or white on black. Yeah. I clearly see where you stand on that to be. Um, whatever, whatever is the opposite of you, Brent. I yeah, like I said, I clearly see you wherever you stay. Okay. Where were you going? Where was I going? Tell me about the centaur. Oh, center. Thank you. Welcome to the ADHD podcast. I'm out. Hi, Brett. We'll see you next time. The center was invented. The context of use it in this context was invented by the guy who first, the chess brand master who got first to beat defeated by deep blue, but then came back and beat deep blue. Is that Kasparov? I think it is. And what he has discovered is that him with deep blue is basically undefeatable, right? He calls it a centaur because it's, it's literally man and machine working cooperatively together. Yeah. I I'm going to jump in. Is that if the man's leading it, it's a centaur, but if it's the other way around, it's just a mechanical Turk. I never quite understood what a Turk was in that. The idea was the mechanical Turk is that it's like, it's like the concierge MVP where you think there's a computer on the back end doing stuff, just a human doing it for them is I'm asking is the opposite of a centaur, a mechanical Turk where it's a machine on the front, but there's a human in the back making the decisions. It might be. Sorry, I like you on a tangent, but I was just thinking out loud. In this case, as we do. In this case, it's, it's, uh, yeah, the human making the final decision, but heavily augmented by the machine. Yeah. But anyway, I love the idea. This is the way I work. Generative AI helps me. It accelerates me in exactly the way you're describing with chess. Right. Now, one of the things that, and when I go on my full sort of philosophical talk around, oh, one of the things I bring out is. There are three personas that I've discovered that an LLM is, and I, and I have talked about this to some degree and I basically say a parent, number one, number two, a genie. And then the last one that's most important, which is an SME. Okay. And I find myself sharing this a lot, even with my own team who has now heard it multiple times, but it's with a data science team is, I find it's really important to share this so that they don't look at, at the LLM and go, Oh, it's magic. No, it's not magic. It's a bunch of cleverly strung together a set of probabilities. There's an example there that I might share later where one of my stronger data scientists, I walked them through a scenario and I said, and then I dropped the bomb on him. Like to help him understand LLMs better, right? I'm like, this is stateless. It is a parent, right? And then what that essentially means, it doesn't know anything. Anytime someone says, Oh, it learned this. No, it did not learn this. Are you familiar with the idea of a one-shot prompt? No, it makes sense in context, but go ahead and talk through it. Hey, let me try it a different way. So if you were to go to LLM and give it a prompt, what is one plus one? Okay. Now today, the LLM will do just fine. Uh, when it first came out, it didn't do numbers very well. Right. And all the people said, well, look, I don't believe in this stuff. You can't even do math. Right. And even though now you go, what is one plus one? It'll tell you the answer is two, but I will tell you it's not doing math. It is 100%. Like the model has improved and it knows that the correct character to output, given that initial stream of characters is with like five nines probability. The number two. However, what you can do, let's say you did what is, you know, and you, you pound seven random characters on your, your number strip on your keyboard. Plus do it again, different random characters. Okay. And then, uh, and then you hit enter. It'll probably get that wrong. Every time I do this example, I often have to come up with a different set of random numbers, but I can get it to get it wrong. However, if you do that same thing and then follow it up with the prompt example, one plus one equals two. By doing that extra string, you kind of prune down the probabilistic paths in the neural net that backs the LLM into one that is far more likely to be correct because there aren't so many, um, possibilities for it to spread out. Uh, even at those very small probabilities, it will get things wrong. And from our perspective or perception, but it's apparent, it doesn't know anything. It's just really good at simulating the correct response. Now, when I say a genie, a genie means a genie historically, like if, if you, if you found an Aladdin's bottle and you asked it to be, um, you asked to be a world-class swimmer, right? The problem is genies are historically evil and it will fulfill your wish by turning you into a shark, right? It you're a world-class swimmer. You know, I grew up watching reruns of I dream of genie and that genie was very nice. Uh, that was made for TV. Oh, yeah. What that wasn't real. No, no, no, not historically accurate. Okay. Yeah. All right. Go on. I just, I, I mind blown today. I learned. Yeah. So the way you, you battled the genie that this is like, if you, if you ever do encounter a, a, a, a genie in a lamp, the way to, the way to battle it, when you do your wishes, you need to make sure they are so specific. The genie has only the right way to grant your wish, like the way you want it to be granted. And that that's kind of the issue with, with LMS, like there is a risk. If you write a prompt and it is in any way, shape or form, ambiguous, there is a risk that's going to go sideways. Right. Uh, I'll give you an example for the, for the community here. You give it a scenario. Let's say you write up a narrative, a bug report or whatever, and you ask it, is this a bug or is it by design? Both of those are kind of philosophical. Right. And the definition of bug or by design is subjective and it will very often go sideways. And one of my favorite examples is, Hey, if the product, let's say it's a service fails to integrate with another service that only began its existence after the first service was released, is that a bug or is it by design? Well, it wasn't designed for it because the new service didn't exist. So it can't be by design, but then the product is still working as it was intended, so it's not a bug. And if you ask the LLM, you have to pick one of those, but it will roll the dice. You, you rerun it and it'll pick a different one each time. Um, I know this painfully from, from example. Now, assuming you can battle the parent and the L and the genie, the last person on the LLM is, is an SME. It's a subject matter expert or rather it can simulate the knowledge. I was going to say, yes, it can act like one. It isn't one. It knows nothing as we've discussed, but it can fake it super well. And it can, I would say, well, actually I don't need to say, cause when LLMs came out, there was all sorts of elements on it. Like LLMs can pass the freaking bar. Right. Right. LLHBS can at some point in time, it is so good at simulating as the being an SME. You might as well just call it an SME. Now the challenge is figuring out when it's gone sideways. Right. But I, I argue that's, that's an equivalent challenge, um, with a regular SME. Sure. Right. Uh, Alan has talked about on the podcast. Like I remember, like I enjoyed this story. Like you don't, you knew shit about A B testing. You were asked to write a presentation on it and I don't know, like three hours or something, I think it was like three weeks, but, and you're like, yeah, sure. You, you did your research enough to, to confidently fake that you were an expert on A B. Absolutely. And that's been the history of my career. I can, I am confident now after, you know, going through a hard way a few times, but there are a few limits on what I can do given enough time. Cause I, I can suck in knowledge and remember things. That's my super power. I somehow learn things quickly and find a way to conceptualize them. Now what Chad G Pajitas, it accelerates my ability to do that. Where before, like I have to make big batches of brain soup to learn things. I had to look at 30 articles on experimentation and statistical significance in order to understand how AB experiments work and understand just the gist behind them. And I got out Google analytics and learn how to implement that in, in Google analytics and, but I had to do all that and just kind of let it sit there for a while and then the soup came out. Okay. This is how I think it works. Well, now I can get a lot faster. I can go to chat GPT right now. It says, give me, give me three simple examples to explain, uh, statistical significance. Now I don't have to go like in the past 10 years ago when I gave that talk, I had to go read a whole bunch of stuff. Like they say the best way to learn something is try and teach it. Yep. And like now I can learn it faster. I focus on learning with the goal of teaching, uh, tell me stuff, chat, GPT, genie, parrot, SME, tell me stuff. So I can pretend like I know it. Right. Right. And of course, the one thing in that particular example, even, even if GPT is making things up, right, which is the risk, right? Cause you don't know you're asking it to teach you something. So you don't know if it's making shit up or not. Yeah, but I have ways of checking that. I trust, but verify. No, but even then, right. We we've talked about it before GPT is really good at bullshitting. Right. It would be really hard for, unless you are asking it, like if you're asking it, something's, uh, philosophical or subjective where you're, you're basically avoiding it, mentioning facts, things that can't be fact checked, right. It's going to be fine. Right. No, it's wonderful. It's better than fine. It's great. Right. So what you have realized is if we go back to my little knowledge bubble, it's inside of you, but you're like, Oh, my knowledge bubble, as you just called out is pretty awesome. You are able to puff air into your knowledge bubble really fast. Chat GPT is a supercharged air compressor blowing into my bubble. That's one thing, but it is also its own bubble. That's that you have direct access to. Like so many bubbles. When we talk about the centaur, right. And, and I forgot where you're talking about centaur. That's awesome. It, it, it, you actually forgot what we were really talking about, which is LLN ops. I'm tying it back. Oh my God. That's right. That was like a week ago. Keep going. All right. So if we, if we agree that AI plus humans outperform either of those components on their own, like AI plus you, okay. Nobody can disagree with that. Go on. And then we agree that in certain contexts, LLM is a, is a equivalent or perhaps better SME than the human. Then I go, okay, what can AI plus LLM be? Particularly in the application of ops because, you know, this is A-B testing. Is that a rhetorical question? Do you have an answer? No, it's, it's, it, that's, that's rhetorical. I'm going to me. That feels like an adjacent possible. Free inventions right here. I got to, we're almost out of time here. I got to tell you one thing going back. Half a story is one of my favorite moments in life. So Brit has like a master's degree in data bullshit. Right. That the actual degree. It's data data. The time when in the middle of a podcast, I pulled out a statistical term and used it correctly, the look on bread's face like, yeah, I can fake it till I'm in. I was just like, I don't, I don't remember my face. I remember, I remember the conversation. Um, I don't remember what my face that I'm like, okay, which one did I do? Was it the holy shit or yeah. I think it was just, just to wonder, just to wonder, like, where did he learn that word and how to use it? No, I've been aware of your superpower here for a long time. I was like, and I'm not going to confuse myself. It is absolutely one of Alan's superpowers. And the other one of yours that I'm jealous with is, is on writing. We're, we're both INTPs, but apparently that doesn't come, come with like the ability to actually just sit down and write shit and then be done in 20 minutes. Yeah, but it's different now. I sit down, it takes me more than 20, but I write, I have written a blog post every week for the last now I'm very last over a year now. And these days I write my post and then I paste it into a chat GPT and say, and ask it for feedback. And literally I say any feedback on, on this article and maybe I'll put some context, but not really paste it in. And it gives me like 10 bullet points. I usually ignore about eight of them and two of them are like, Oh, actually yeah, I could do a better segue there. It is a cheap and quick editor. I paste it in there. It's never, it never like hacks stuff. It read line stuff. It, it gives some basic, like some of the tips it gives are the same every single week, but it can say like it lets me know if I have, I always look for a mix between anecdotes and like, that's the way I write. I have stories I want to tell from experiences. I have books I want to refer to because I want people to know that I have no ideas of my own. I am really good. Again, it's using these superpowers are related because I use the brain soup. I get from reading like 50 gazillion books and I let them regurgitate and I go, Oh, wait a minute, this came up in a book and I figure out what it was. Anyway, yeah. Try GPT is my, is my quick and dirty editor. It makes me better. Going all the way back to the beginning of the episode. Oh my God. We're good. Yeah. I am, I am absolutely impressed at my hit rate of being able to remember the tangent, uh, usually I get lost and can't find my way back, but on CICD, right? I, I will actually fully argue that that was the main point of the Phoenix project, right? If you think about, if you read that story, you think about how the world frigging changed. It was because they deployed CICD. Yeah. Right. It, it, it isn't what they built, but how they built it. They tried to move faster. Uh, there's a whole other blog poster, a blog post, whole other podcast here. And we'll get to it next time. It's actually what I was going to get to. This was better, but it will be other one will be good next week. Just, just don't worry about it in two weeks. Going fast highlights where your bottlenecks are. If you go slow, you never see the bottlenecks. You'll never see them. They don't exist. Yeah. You don't even know you're, you're numb to them. They just don't happen. Move faster. Those little bumps get in the way. Well, but in any end, if you're, well, so one of the important lessons that I did back in the days when I was actively doing agile coaching back in the day, everyone thought it was purely about moving fast and moving fast is very important. But the correct statement is adapt fast. Absolutely. We've talked about that. There's a difference between iteration and adapting. A lot of teams who f**k up agile do it because they focus so much on iterating and not on adapting. And CICD is so important because you're not waiting to integrate with Maine. You're not waiting. Feedback loops. You get the feedback instantly and you're continuously improving Maine. Right. Um, which has a dramatic reduction in risk. Yeah. Um, one, one gazillion percent agreed. If that were possible. I think it is. Why not? Two Brazilian, two Brazilian percent. A Brazilian. Yeah. How much that that's like a law, right? Uh, well, no, that's like the person who lives in a country in South America. Oh, weird. Yeah. Yeah. Okay. Well, thanks. This has been the, um, the dad joke portion of the AB testing podcast. Really appreciate you coming by. We'll be here all week. Baaah, let's call it a day. I got all, this is cool because now I have a topic queued up for next time. When we talk in two weeks, Yippee-Kye mother. This is Alan. This is Brent. And we'll see you next time. 
