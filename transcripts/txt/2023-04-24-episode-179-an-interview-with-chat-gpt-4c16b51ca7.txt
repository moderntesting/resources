However, it is important to note that the principles do not suggest that testers are not necessary at all. Rather that expanding the team's abilities and know how may reduce the need for dedicated specialists, which is spot fricking on. Welcome to AB testing podcast, your modern testing podcast. Your hosts, Alan and Brent will be here to guide you through topics on testing. Brent's in a sample different these times. Not because Brent is going through any sort of life changing event. Just using his earbuds instead of his normal headset. There should be good news, far less breathing for me to edit out. Although I am getting really good at seeing the breathing in the audio formats. So that's good, but it doesn't sound as good. I'll see what I can tweak out. But welcome to the AB testing podcast, Brent. Thank you. I've been here quite a while. Wait, you're saying that you now know what my breathing looks like? I can recognize your breathing in its audio stream format, yes. Fun. I just, I don't even listen to it to make sure it's breathing before I delete it. I just, I just delete it. Hey, since we, since, uh, this is the AB testing podcast, I have, and I know you like using Dolly, right? Yep. I use Dolly every week. If you read, uh, shameless plug, angry weasel.substack.com. I've been doing a weekly post for the last several months and, uh, every week it is decorated with a picture generated by Dolly. I am sorry for the artists who I'm putting out of business by using AI to generate my cover art for my massively, not massively read. And this podcast has three listeners. My blog has two readers. And so they get a free picture. I'm sorry. I'll, I'll make up for it in a future life. Anyway, yes. I'm familiar with Dolly. So my, my, my daughter is quite an artist and they, she expressed a game with that her, her friends had made up. And it was a game of what does your artwork taste like? Okay. Right. It's in the art world. I did some other inspiring emotions. And so doing that literally went to your artwork. Like if you looked at the art and you like, okay, can you imagine what that might taste like? And then I responded, well, I knew what my artwork tastes like. And she's like, what I said, aluminum foil. She's never chewed aluminum foil. So she doesn't, hasn't yet learned the phenomenon around electrical conductivity and why it feels weird. But I spent a good hour trying to get Dolly to, to come up with its own expression of what, what a chewing aluminum foil might be in terms of an abstract art. And it just, how would you do it? What would be your prompt? I don't think it can. And anytime, one thing for us to remember, we're going to talk about this in a bit. I have a potentially lengthy chat GPT segment to go over today. As I once again, design the agenda, you have to keep in mind the data it was trained on. And it was trained on just a bunch of pictures with some metadata around them. So it gets an idea of what things are across hundreds of thousands, if not millions of different pieces of art and photos, et cetera. I'm going to guess millions and millions actually, now that I say it out loud. So I don't know what prompt I'd give it. I would, it wouldn't know the aluminum. So I would show, show me a picture of a man chewing with small sparks coming out of his mouth. No, I don't want an image of it. You want to know what Dolly thinks it's art tastes like? No, I want it to create an abstract. So imagine an abstract painting with the title, chewing aluminum. This is where Dolly is going to struggle because while it knows what abstract is, but unless it's going to be trained on the metadata around that abstraction. So if the abstract piece of art is called, if it's a white painting of two polar bears fighting in a snowstorm, it's not really going to get it. It it's very, as you know, generative AI is very, very logical. Yes. And you would have to not describe the aluminum. So one thing I learned in studying and what you were getting at earlier and what does your art taste like is art is the reaction to the medium that was created by the artist. I'm very adamant about this and I fight with my daughter about it sometimes too. So so what is your art tastes like is a totally reasonable question for how what does the art mean? What does your art mean to you? So if I'm going to prompt Dolly, there's no way I all I can do is prompt it for my reaction because I have to tell Dolly to generate something that is a representation of my interpretation. If I want to sort of reverse engineering art. So if I want my reaction, if I've already stated at the end, I'm working backward, it's kind of like TDD for art. My reaction is I want to feel like I'm chewing on aluminum. I have to give it a prompt. I have to think like what kind of art would make me feel that way. And you know that because you said it's your art. You could describe your art. But what's interesting in the general sense is I could decide my art tastes like sour lemon or no, I shouldn't say my art. I would I could start with this art that I haven't yet thought of tastes like sour lemon. And then I'd have to reverse engineer and go backward and think what medium, what sort of impression would have to be made on me for me to think of sour lemon. And then I would want to give Dolly some input to create that. So I would say, give me an abstract piece of art using lots of yellow and using lots of yellow and converging patterns. And then it would give that to me. And I could see if it had the if I had the reaction that it really is TDD. We're doing it backward. I could see if I had the reaction. I went out for it. They know it's not quite it. I could tweak it. I could try something else. But okay, that's the way I would approach that. Okay. Yep. There's a bunch of things like I think I don't know if I've ever shared this with you or on the podcast. So back in the day, are you familiar with the bird known as the American kestrel? I am not. Okay. But you are aware of birds. Yes. No. Well, maybe. So back in the day when I was not yet 18, I was a hacker and I went by the name, the kestrel. So if you were to go home and look up my gamer tag, you'll see kestrel was dominant. I do know that is your gamer tag. Yeah. I mean, it's other things. But kestrel is a big part of it. I also am a big fan of steampunk and I've been trying to get Dolly to create an image of a kestrel and dress it up in some some rad ass steampunk gear. Yeah, it incorporates the elements correctly, but it incorporates the elements, but never the way I want it. Yeah, I think what I was going to say is at some point you need to just commission an artist to do the thing. I think Dolly, one of the reasons I think Dolly does not put artists out of work is because it gets, I mean, you get what you pay for, right? Right. It's not going to get you what you want there. It's not going to get exact. One of the listeners posted on LinkedIn this week saying, hey, I tried to get Dolly. I tried for 20 minutes to get Dolly to put words into this picture and it wouldn't do it. And of course, the answer is Dolly wasn't trained on words. He doesn't know what they are. It has no concept of words. That's not true. It makes words. It knows words contain letters. That's right. Right. It has an abstract knowledge of words. Yeah. If you want something specific, go commission an artist. Feed an artist. They're great. If you're a listener of the podcast, we commissioned the art for the AB testing, the orange little box and the one of the three logo, all that stuff we paid for. And also what I was going to show you is if you go to angryweasel.com, you see the weasel logo I've had there for 10 years. Same artist did that for me. And I just made, you know, I don't, I have a couple unity hoodies. I probably shouldn't wear my unity hoodies, air quote, to work to my office. So I now have an angry weasel hoodie with a big angry weasel logo on the back and right over the heart. Cool. So, uh, yeah, it's a novelty thing. And then the other day at the gym, I'm walking out and some like 20, 20 something year old tapped me on the shoulder rather vigorously. I have a headphones and he goes, cool hoodie, man. And if I was quick, I should have handed him a card and said, here's where you go buy them in my shop. I don't have a shop. I yeah, I'm just not that together, but it'd be cool to start seeing people. Yeah. No angry weasel hoodies, angry weasel. Yeah. You're missing out on the hipster crowd. Yeah. I should. You do have a market there. I should just buy a bunch and give them away just for advertising. So I could go from two listeners to two readers to three readers and be as good as our podcast. Hey, speaking of LinkedIn, a couple of things happened. One, I didn't post this. I may post this on LinkedIn. It may become a blog post, but I think people would convince me of trolling. So LinkedIn is filled with a bunch of this checking versus testing stuff. And then also a lot of, and I'm gonna get to that in a second, but also still every week I know, sigh, sigh, sigh, but I had a thought about this one. This isn't a rehash the same stuff we get mad about all the time or to trigger brand. It is to talk about the fact that people still are triggered, I will say, over the term manual testing. They wouldn't, they say, I'm not going to make any mock voices right away, even though I just about did. Not manual. It's, it's, it's automated testing is checking or automated. How do I not do a tautology there? If it's automated, it's checking. And if I do it, it's just testing. And then I had a thought that came to me that was like, they don't call it manual programming and they're right. But I wonder. They also don't call it automatic programming. I know they don't either. And I, I think the thing is, I think if you look at it from a different angle, what if we lived in a world where I mean, it's about putting a label on something to show how it differs from the common. And if the common form of testing is automated testing, when we talk about testing, we're talking about some form of automation, you would have to use the modifier manual to let you know, typically testing is automated, but in this instance, I'm talking about doing it in a non-automated fashion. And I wonder if there's some of that from history, you know, and in the big scheme, I don't care, but I had a little fleeting thought. I was trying to figure it out. Something was there. I wanted to bring it up before I forgot, but I'm just going to leave that. I don't think, I don't think anyone automated versus manual. And it comes to this topic. No one's really disputing the meaning between automated and manual. What they're saying is manual testing is redundant, right? Yes, but it is, but it isn't. The modify, it's not redundant. The modifier is there to let you know, again, they see it, the people against it, see it as a attack on testing in some way. And I don't want to get into this because honestly, I don't really give a shit, but I just want, I just had this thought, like, I wonder if we put the manual modifier on for a reason, not to degrade. It's actually for a good reason. Also along those lines, I don't want to spend a bunch of time on this, but also along those lines, there was another, you know, someone posted, I'm not even going to go into names. Someone posted something on automated checking and our friend Jason who both loves us and hates us. Hi, Jason. I think he loves us more than he hates us. Sometimes he pissed him off though. He pushed back a little bit and something about, you know, he pushed back on the checking versus testing thing, but he took part in the conversation really well. And then at the very end, well, the law, the source of confusion is some people don't realize that automation isn't just for reproducing user flows. And we talked about this last time of the time before, when I got really mad about people just stop, stop writing automation to reproduce workflows. And Jason heard that and he liked it. I said, I described it well, and simply on the recent podcast. So thanks Jason for that call out. So you can go back and find that one. And then he also asked if there's any chance we can get Michael Bolton on the podcast and I'm going to go a hard no on that one. Yeah. With you. All right. Just, just don't have it. I mean, I'll do respect to what you do. You do you, but it's just not going to jive well with. I honestly think that I think the conversation around checking versus testing has exceeded its quota on our podcast probably years ago. Oh God. Yes. Oh God. Yes. So. Just to make it even worse, I think about, okay, a COVID test. Okay. It's not called a COVID check. It's called a COVID test. Right. And I would argue it is chemically automated. Right. So. Yeah. To me, it is just, it is nasal. It's semantic BS in, in, that's it. Okay. We're going to move on because we talked about that enough. Everybody knows our stance on that. You can go to one of the three dot slack.com. I need to update the link. If you, uh, cause there was a time when slack used to give you an in perpetuity, I can't pronounce that word, a forever working link for signing up for the slack group. They stopped doing that. I either, I didn't read the mail or they didn't tell me, but now it expires every month and I realized I forgot to update it. So it's like, it's currently broken. I'm going to wrap myself a note and I'm going to fix it after the podcast or tomorrow. There we go. Everything I remember to do, I write down in to do this. That's a free plug for to do is to do us. If you want to sponsor the podcast, that's great. Uh, so anyway, one of the three dot slack.com. You can ping us there, ask us questions, take part in the community, pretty vibrant community. There are lots of stuff going on. We love you. Brent, it is time to introduce our guest. We have a guest. We do have a guest. Someone we have talked about a lot on the podcast. Someone very influential in my life. Someone I talk with every single day is probably one of my strongest collaborators over the last month. Brent, I'd like to introduce you to my friend. Chat GPT. Yeah, I have. We haven't talked about your buddy in such a long time. So what I did this week, and I'm going to give you the highlights for this is actually going to be an interview with chat GPT, but we're going to comment on the interview. Because it's kind of interesting and worth talking about because again, I'm going to say this again. I think 90 plus person used to be 99 down to 90% of the people using chat GPT and similar bots are trying to use them wrong. Stop asking them questions that have a binary answer. Chat GPT is very, very bad at math, not even close bad at math. I even had it help me write a program, which generally it's good at. Logical programs, very good at. I tried to have it write me a program to help me with a math problem I was trying to solve. I'm going to go over that in a second and it failed completely. It is absolutely dumb at math. Do not ask it math questions. You could ask, but the kind of questions you can ask it like exploratory questions. There's that E word people love. Very, very good. Just real quick tangent. There's this new beta game out of the New York Times called digits. I do the New York Times crossword. Four to five days a week, depending on, I can't do any more than that. Cause I'm just not smart enough. I do Wordle. I do this new game called digits where you're given a set of six digits and you can use any of the basic for math. Jesus operators. Oh my God to come up with this target number and there's three a day or three or five a day and they get, they get harder as they go along. And I thought, you know what? This is fun, but it would be fun to try and write a solver. Okay. And so I asked chat GPT to help me and it was utterly hopeless. I tried to, like, I really tried to coach it to do it. It could not do it. I ended up writing it in Python. It's pretty cool, but I still try. I still try and do them by hand. Uh, but I wrote a little solver in Python. So, uh, but open ended questions are great. So what I did is I led, I said, here are a set of principles that I believe help with software development. And I gave it the modern testing principles, but the more recent version, which isn't, which takes out testing completely. So I'll read them real quick for context. Um, our priority is improving the business. We use models like lean thinking and theory of constraints to help identify prioritize and mitigate bottlenecks from the system. So far the same. We are a force for continuous improvement and adapt and optimize our practices in order to succeed rather than using safety nets to catch our failures. We believe that the customer, sorry, sorry, we care deeply about the quality culture of the team and we coach lead and nurture each other towards a more mature quality culture. We believe that the customer is the only one capable to judge and evaluate the quality of our product. We use data extensively to deeply understand customer usage and then close the gaps between product hypothesis and business impact. And finally, we expand abilities and know how across the team, understanding that this may reduce or eliminate the need for dedicated specialists. Those of you that have grown up with the principles over the last five or six years, we came out with them. You probably listened to those and go, are those different? They're slightly different. We've removed the word tester from them to make them more general. They're modern develop, modern delivery practices, what they are really. So I gave it those and it replied. It said, I didn't even ask. It just said, I hear a set of principles I believe help with software development paced. It said these principles are focused on continuous improvement, quality culture and customer satisfaction. The author, I'll put authors, the authors emphasizes the use of lean thinking and theory of constraints to identify bottlenecks and improve the business. The principles also stress the importance of using data to understand customer usage and the need to expand abilities and knowledge across the team. So in this case, all it's doing is summarizing, which chat GPT is very good at. One thing you can do, you can ask chat GPT, summarize this book, and it will give you too high level of a summary. Here's my hot tip. If you want a good summary of a book, ask chat GPT to give you a summary of each chapter of a book and you get a wonderful freaking walkthrough. Free tips, free tips, I'll charge for them later. So nothing, nothing exciting here, nothing for you to chime in on. In terms of writing style, the author's tone is confident and assertive with a focus on concise language and clear messaging. The principles are presented in a logical and organized manner with a strong emphasis on actionable steps for improving software development processes. Chat GPT thinks we know what we're doing. So I'm a little, a little against this. I'm like, I'm like actionable. All right, Brett, I want you to just hold on to your ego. Don't let it rise up because chat GPT will blow smoke up your ass like nobody else. I know. Oh yeah. Similar authors might include business and management writers such as Peter Drucker or Clayton Christensen, who also emphasized the importance of continuous improvement and adapting to change in order to achieve business success. We are not even in the same league who sees a league who sees a league that may see a league that knows those two. We're not even the parents of the little league kids. So that's, you know, that, that part's all kind of a bullshitty, but then I can ask it some questions and here's where we get a chance to comment. I asked, are there any improvements you would suggest? Okay. These principles seem like a good, and again, it's hard to get it to really have an opinion. You have to kind of work at it for a while. So it gets better as we go along. These principles seem like a good starting point for guiding software development. However, there are a few areas that could potentially be expanded upon or clarified priority. It might be useful to clarify what is meant by improving the business. Are there specific business goals or metrics that the team is working towards? Defining these can help ensure that everyone is aligned on working towards a common goal, which I kind of think is good freaking feedback. Yeah, that's right. We have had, we have seen certainly by feedback that people take sort of a different view. Like when, when, when I envisioned it, it was, it was essentially, no, I want these people to directly try to target revenue or profit. Yep. And then we've heard around like some, some, there was a podcast that people did about AB testing. Then we're talking about it. And they're like, Oh yeah, it tests, test can ignore this because as we know, test is there to reduce the cost. Therefore we're improving the business. And I almost pulled over the side of the road and cried because I'm like, Oh, okay. Not only were they misinterpreting it, they went 180 degrees wrong. Yeah. And you're actually hitting on something. So hold that thought. I want to get through as a little bit of feedback for each one, which is all actually pretty good. And I'll hold my next thought on that till I read the next one models. It would be helpful to provide more specific examples of how lean thinking and theory of constraints are used to identify and prioritize bottlenecks. This can help make the principles more concrete and actionable. I agree with that, but is it a goal of principles to be concrete? No, no, but what it leads to me is at some point there's in my head, these get misinterpreted and we're going to go more into that in a minute, but I wonder why we've never written an accompanying paper to probably something we should have done or should do at some point. I mean, I've talked about them at conferences so you can go a little bit deeper in the examples or there or some of them. I wrote a long ass blog post that, that accompanied it. I don't know what you're talking. Okay. Well, maybe it needs to be with them, but interesting. Interesting. I think it's good feedback. I'm not sure how to fit those into the principles, but it made me think. And again, chat GPT is my collaborator. If I can ask it questions and it can make me think that I'm winning. Yes. Continuous improvement. It might be helpful to clarify what is meant by safety nets. And I think again, examples would help, but I think our audience knows, but which actually GPT didn't know. Again, ask for more examples, quality culture. It might be useful to expand upon what a mature quality culture looks like, which we've done with the quality culture matrix. I'm going to pause for, get to the last three and just remind people who haven't been with us on the entire journey. Brent and I spent probably the first two or three years of the podcast, just talking about how software should be developed and what was happening with testers and vetting ideas and learning from each other. And then it just came to a point when, in trying to capture what we had been talking about for all that time, I sketched out a first draft of what eventually through lots of vetting became the modern testing principle. So it was, it wasn't like, we didn't set out to say we're going to write principles. It was like, you know what? We need to capture what we've been writing out in a set of principles. If I recall correctly, you were reading some book. Dalio, the principles by Dalio, which is a great freaking book. And you just connected the dots between the two. Yeah. And this is why I read a lot because I'm not that smart, but I'm really good at pattern matching. I'm really good at figuring out how to make stuff work together. That's my super power. By the way, INTP for the win, yo. Well, you know, I wrote last week about that INTP, but I do think I'm good at that connecting and putting stuff together. By the way, I redid strengths finders. I have new strengths. Talk about sometime soon. I'm going to save those for the later customer evaluation. While it's important to prioritize customer's perspective, also important to consider other stakeholders. We've got that feedback. Data usage, give examples and specialization. While it is true that cross functional teams can help reduce the need for dedicated specialists, it's important to recognize there may still be areas where specialized expertise is necessary. Add some clarification there, which is we've talked about. Like I think security will always need specialists. Is one example. No, if that's true anymore. Yeah. And this point, I've warmed up my friend chat GPT. Okay. So now I take it into, uh, I want to see what it'll do with a more introspective question. So I asked it, of course, which of these principles could be considered the most controversial? Oh, fun. The principles listed seem to be, it's, it can, I can almost predict its writing style. It makes like a, Hey, these are great, but so these principles listed seem to be generally accepted as good practices and software development. And there isn't necessarily one that stands out as being particularly controversial. It talent verbal italics. Mine. However, thank you, chat GPT. However, depending on the specific context and the organization's culture and values, some of these principles may be more challenging to implement than others. For example, principle number five, which states that the customer is the only one capable of judging and evaluating the quality of the product may be challenging for organizations that have a history of prioritizing internal metrics and goals over customer feedback. Yeah. Okay. Yeah. We agree. Yeah. That was pretty fantastic. But it pulled out that five was controversial. And when we wrote those, we didn't, we thought seven would be controversial and it went right for five. Yeah. But then it says similarly, principle seven, which suggests that the team should expand its abilities and knowledge across the board rather than, rather than relying on dedicated specialists may be difficult to implement an organization that have historically relied heavily on specialized roles. So I want to give props and a little props to chat GPT. It absolutely is. I mean, we didn't know me wrote them. We thought seven is the one people would freak out about. A lot of people like seven. Yeah, I get this. This makes sense. It doesn't mean get it. We're going to testers once they get over that, they kind of get it. But we didn't know five was going to be such a hot bed. It just went right for five and said, well, watch out here. Yeah. We knew about seven because that's what was the controversy when Microsoft was going through the transition. Right. We saw over and over. We didn't see anyone disagree that the customer, that one was purely because we were in a bubble. Yeah, we were. Oh, let me go back to LinkedIn for a minute before we go back to chat GPT. Chat GPT, hold on. Can be patient for a minute. I was tagged in a post on LinkedIn and I just got to read this. I wouldn't even say what company I don't know the company that tweeted it, tweeted it. I'm so caught up in the musk world. What's it called when you post on LinkedIn, leaded it, linked it, linked. I don't know. They said that the post is just this. Will we be able to live without software testers? Absolutely not. They make sure that the product being released is flawless. Without testers, all the tools would crash and burn. So follow these experts who share their experience and practices with the rest of us and they tagged me. Hyperbole. Hyperbole much? I replied and said something to the effect of, I don't know what it was. Like you tagged the wrong person. Like I don't know where it went. But yeah, that's, I think, I think I'm in the wrong. I think I got tagged in the wrong post. Well, maybe it's from like a millennial or something. And one of those terms, you know how like bad means good and, and, oh, yeah. Right. And maybe it's like, maybe we're just not up to date on like the new hip term. And now it's been reversed. I still, you know, I'm, I'm not anti testing. I don't know that testers should do it. I get asked a lot to write about testing or give talks on testing. And I just just, I'm not going to, it's, it's, I haven't done that in so long. I don't know. It's, I kind of view it as something that's going to be self-resolved. It's there are better ways to manage risk, right? Several of the statements listed out testers make your product flawless. That, that part's hyperbole. The fact they told me, the fact they told me in a post that said testers weren't going away, which I don't agree with. It's funny. Let's get back to our guest. Yeah. Let's play a little game and I'll call it test GPT. Okay. Mr. Chief, Mr. Jet GPT. What are some reasons that team should not adopt these principles? No. Probing questions while, and again, I'm so impressed with the, what it learned while there may, while there are many benefits to adopting these principles, there may be some reasons why teams might want to adopt them, including one organizational culture. Some orgs may have deeply entrenched cultures that are resistant to change and may not be receptive to adopting new principles and ways of working. That constitutes the entire, almost the entirety of the crowd that tell us we're dumb. What is your, what was your prompt again? What are some reasons that teams should not adopt these principles? Good. I think, I think it took it is that that won't. Yeah. Okay. Number two, short-term focus organizations that are focused solely on short-term gains and immediate profits may not see the long-term value in investing in continuous improvement, quality culture, or expanding the abilities of the team. And they're right. I focus so much on the people getting the work done. And that, you know, there's, it's not just me, a lot of people in our circle, in our bubble focused on, we want to get the team in a place where they can deliver quality at a nice velocity, a sustainable pace, all of that stuff. Yeah. If you don't care about that, if you just want to hurry up and get shit out to customers, I guess you wouldn't want to adopt them. I don't think it's new there. Number three, resource constraints. Some orgs may not have the resources to invest in the necessary training tools or personnel. And that goes a lot with number two. They only care about the short term. Number four, resistance from team members. Some team members may be resistant to change or may not want to expand their skill sets or take on new responsibilities. We've heard this from a lot of people. It goes with number one a lot, but that's, yeah, people are digging their heels in. They want to do what they've always been doing. My developers don't want to test. They shouldn't have to, because they're paid too much money to test. Right. And lack of understanding some team members or stakeholders may not fully understand the value of these principles or may not understand how they can be applied in practice. And these are, these all ring bells with me. So it's important for teams to carefully consider their unique context and constraints before deciding whether to adopt these principles and to be prepared to address any challenges or resistance that may arise. And I think you and I are, we like living in the world of being change agents. And I think there are a lot of folks who just don't want to deal with that. It's hard. It's easier just to do the thing they've done and not try and do that cultural change, which we, you and I kind of love a little. Well, yeah, it's the age old battle of if it ain't broke, don't fix it. That is not a perspective that I generally hold. There's a question I'm going to skip. I asked it on what tips you can think of for teams who want to adopt these principles. And it's just like, you know, pull your head out of your button before we're in a long paragraph. But so I got into two more questions because we do, we're down to like eight minutes here or seven. I didn't stop like a minute before four for our next meeting. What would a software tester think of these principles? Let's just get the embrace the elephant, hug the elephant, as they say. Yeah. A software tester may have mixed feelings about these principles. On one hand, they may appreciate the focus on quality culture and continuous improvement as those principles align with their role in ensuring the quality of software being developed. They may also agree, and there's a weird one after what it said before, they may also agree that the customer is the ultimate judge of quality of the product. And I know people who adamantly believe that that is false. They say number five is wrong. We ignore it. There's no way. And I'm blown away. Anyway, on the other hand, a tester may feel concerned about the principle that suggests the dedicated specialist may not be necessary. Testers may worry that their role is being diminished or eliminated, which could impact their job security. However, it is important to note that the principles do not suggest that testers are not necessary at all. Rather, that expanding the team's abilities and know how may reduce the need for dedicated specialists, which is spot freaking on. This is why I love chat. This is why it's my friend. And again, I'm asking an AI to interpret this stuff. It's like, yeah, I get it completely in the way we intended. Yet hundreds or thousands of testers read these things or developers read these things and go, whoop, that those are wrong. This is stupid. Overall, a software tester may appreciate the focus on quality, continuous improvement, but may have some concerns about their role in a team that adopts these principles. It's important for teams to communicate and collaborate to ensure that everyone's concerns are addressed, that the team may work together effectively towards a common goal. So what I think I may do is I may add some formatting to this and go ahead and post it in our Slack group, people to play with and react on, because it's interesting. I want to do one more. I'm going to skim over. I asked it what's missing. And I think it's okay. They mentioned that we don't explicitly mention any particular software development methodology, and that's on purpose. While the principals mentioned the importance of customer, they did not explicitly discuss the importance of designing software with user in mind. I think that's beyond the principles. They don't talk about security. And again, that's beyond what's in there or software architecture. So I'm okay with good callouts, but I'm okay with those not being there. I asked it, what do these principles tell you about the authors of the principles? And they said these two that the two authors are a couple of blowhards that couldn't tell their ass from a hole in the ground. No, it says they care about quality, blah, blah, blah. Without additional context, I can't tell you anything. That's fine. And the last one I asked it was this, can you think of a mission statement that would go well with these principles? Sure. Here's an example mission statement. Our mission is to continuously improve our software development practices to better serve our customers and improve our business. We prioritize lean thinking and theory of constraints to identify and mitigate bottlenecks in our systems. And we use data extensively to understand customer usage and close gaps between product hypothesis and business impact. We foster a quality culture among our team, nurturing each other towards greater maturity and coaching one another towards success. We believe that the customer is the ultimate judge of our quality of our products. And we expand abilities know how across the team to eliminate the need for dedicated specialists. My reply, that's a long fucking mission statement. Can you do it in 10 words or less? Sure. How about delivering quality software that drives business growth through continuous improvement? Say that again. Delivering quality software that drives business growth through continuous improvement. I like that. But then I said, what do you think of accelerate the achievement of shippable quality? Okay. I like that one too. It says it's a concise and effective mission statement that aligns well with the principles you mentioned earlier. It conveys a sense of urgency and focus and quality while emphasizing the importance of speed and efficiency in delivering software. Overall, it could serve as a good rallying cry for a team that is focused on improving its software development practices. Hey, so we're almost out of time. We are. I'm going to give you the last question. I'm not going to read the answers because I'll save these. I said the authors of the authors of the principles have a podcast called A B Testing based on the principles, what are topics they should cover in their discussions. And it gave me a nice list of 10, 10 things to talk about. Which is pretty nice. We should start going through the list. We should. You're going to say. All right. I just now. So my iteration, I don't know what version of GPT you use, but currently my favorite is the Bing bot. Which you told me to play with. I have not touched at all. Well, I could share screen, but I won't. That'll be a good podcast topic. Yes, I asked it. Read the book Accelerate and the following modern testing principles and propose changes to the principles that are supported by Accelerate. And then I copy pasted the principles and it said, Hello, this is Bing. I'm happy to help you with the task. Smiley face. First thing you did the Bing actually search for the Accelerate book summary. Okay. So this is the one thing that's interesting around the Bing bot because it can do with someone as info retrieval and incorporate that into the into response. Whereas open AI is is is only trained up to 2021. Correct. And only knows what it knows. Okay. And I'll just go through. I'm not going to read. So what it did is it modified the principles. And the first one, our priority is improving the business and then it added by delivering valuable software faster and more reliably. That's not horrible. Principle number two, we use blah, blah, blah, blah, blah, mitigate bottlenecks from the system and optimize our software delivery process. Okay. Okay. Principle three, we are a force of continuous improvements, etc. Rather than using safety nets to catch your failures. And we measure our success using the four key metrics of software delivery performance. Oh, okay. It's actually not a not a bad mashup. Now for we care deeply about the quality culture and nurture our team towards a more mature quality culture that embraces continuous delivery, the management and DevOps practice. I kind of don't like that one feels redundant to principle two. I does. Yeah. Principle five, we believe that the customer is the only one capable to judge and evaluate the quality of our products. And we use data extensively to deeply understand customer usage and feedback. And I'm like, okay, you just duplicated principle six, but what else? Principle six, we use data too. But this is one thing interesting. We use data extensively to deeply understand customer usage and close the gaps between product hypotheses and business impacts. And we deliver software in small batches and fast feedback loops. Those of us who don't go together. I mean, it's trying to shove the, that, that into all the principles. So the, well, it basically summarized, you can totally see how it's. Yeah. I see what it's doing and sometimes it works and sometimes it doesn't. And it's just trying to find the, uh, the way to, it's doing exactly what I asked it to do is they accelerate and approve it. All right. You should share that in the Slack channel as well. And I'll try and do mine as well. Did a little formatting on it, but I am, I am late for my next meeting. So we're going to call that a day. Thank you. Chat GPT for being on the podcast today. You are a wonderful guest. Yes. All right. I am chat GPT. I am not. And I'm Alan. We'll see you next time. 
