Hey everybody, I'm Alan. I'm Brent. And we're back for another episode of AAB Testing. Episode 89, ready to go. We are ready to go. AAB Testing is your podcast for all kinds of fun conversation between Alan on A and Brent. He's the B, among many other things. We talk about software development, software testing, software engineering, organizational change. Did I say agile already? I really need to write this down. All kinds of fun stuff. Thank you for listening. We shifted our schedule for a week, off by weeks, or a week late on this one. But that's cool. Life happens, stuff happens, holidays happen. But I think we're ready to go. Actually, before we dive in, what's been up, Brent? Anything new and exciting? How's Azure? Azure's great. My corporate slave drivers have dictated that is the correct answer. Awesome to hear. Awesome to hear. Yeah, it's an exciting time and place to be. Always good to have a little bit of excitement in your life once in a while. Yeah, outages. So there was a recent outage that's gotten a lot of press. That's what I'm indirectly teasing you about. It's cool. You don't have to talk about it. Yeah, I cannot talk about it. One thing I was going to ask you is, it's September now. Have all your employees survived, and you survived a Microsoft review season? We have, yes. You can put it behind you at slacking time at Microsoft, other than dealing with outages. And you guys can worry about ramping up that workload back in April or May for next year. That's always good to know. Right, it's now nine months of coasting. So none on my team, unfortunately. One of the things that we've successfully done. So my team's specialization is in customer analytics. And we spent the last six months diving into customer support problems. And it has garnered a lot of viral visibility, the good kind of visibility, not the bullshit kind that you see PMs do. So we're in high demand. And unfortunately, my team is still really itty bitty. I do have two positions opening. Not applying. Actually, I'm not qualified. And not applying. Oh, I would change the job description to hire you as an employee, Alex. Just for the week of morale boost, that would bring me. No, so I don't think if there's anyone who's interested in a data science position, I am looking for experienced folks. I'm not certain where our listeners are on that one. I think we mostly cater to the testing crowd, not the data science crowd. Oh, oh. Speaking of things I can't talk about, but I can talk about about. Gotcha. Following. I'm not sure if this person is a member of the three on Slack. I'm pretty sure they are not. But did hire a podcast listener. Did you? For her position in Austin. I'll make a big announcement. Oh, you got your. Yeah, got. Yeah, I'm very, very excited. Do I know the person? Maybe through Twitter. I'm not sure. Anyway, very excited. More information on that later, once it becomes, I mean, stuff's been signed, but I never talk about hires before. I guess that's common courtesy across the industry, right? When I was hired at Unity, they knew I was going there for a while, but they waited to make it, to tell people that I was going there before. No, so you don't know what this person has announced that they're asking. Right, right, it's their call to make. But I can say that someone who has listened to the podcast has accepted a position on my team at Unity, and I couldn't be more excited. This is somebody not only will make their development team better, but I think will make me better as well. So it's super exciting. Super. Sometimes crap just works out, and you get really excited about it. I don't remember, yeah, this is probably one of the most exciting hires I've made. For as far as like, what's going to happen? It's going to be great. Oh my god. Cool. So that happened. That's cool. Are they already in Texas? Yes. Oh. Yes, yes. I'll leave it at that. No, that's not enough for me to guess. Although it might be later. All right. There was something else I was going to share today, but. You got the P. Oh, a couple things, two things. One thing, PNSQC conference is coming up, Pacific Northwest Software Quality Conference in Oregon, as it's properly pronounced, in Portland, coming up beginning of October. Pretty reasonably priced conference. It's a lot of value there. Again, highly recommended. Also the last conference I'm planning on doing for some time. I have nothing else on the radar. I'll probably continue to do some webinars once in a while. Speaking of webinars, I did a webinar a few months ago with Aaron Kinsburger. But also from Aaron just finished editing and writing compilation for a book called Continuous Testing for DevOps Professionals. And I believe some of the three have contributed chapters to this book. Cool. So that book is coming out. I'm pretty excited about it. More information as it's out. But there's a launch coming up in conjunction with the conference. If I had my crap together, I could give you all the details. But keep an eye out for it. Very cool. I'm super excited about that book. I had the opportunity to review it all. I read about 75% of it. And it's all pretty good stuff. He gathered together some good writing, some great ideas. I'm pretty happy. So yeah, and that's pretty much it for me on the conference. Do you know? How much does it align with MT? I think it aligns quite a bit with modern testing. I think the main difference, it's something to talk about. Maybe in a future episode is there's a lot of really good things like Accelerate, the DevOps book. This book aligns a lot with modern testing. This book, I would say, the difference is it assumes that there's, which is fine, I guess, it assumes there's a testing and quality specialist on the team to drive a lot of these things. Not all, but a lot of these things where we think we don't, you know our stance. I do. That's OK as a transitionary. That's probably the right thing. It may be the right thing long term for in some cases. I'll leave an exception there. Let's start using differentiating language. Is it a test specialist or is it a testing coach? The way I read it, because I read everything through an MT lens now. I could see a lot of things as ideas for test coaches as well. It wasn't written that way, but I can read it that way pretty easily. Yeah, did you see the Ministry of Testing post I sent you? Yeah, I did. And actually that person, if I actually had internet in Microsoft, because they don't share their internet without filling out a form, I could bring up that person actually pinged me on Twitter a while back. God, we are so freaking unprepared. We didn't even write up the Kanban board today. No, that's your job. That is from Robert Meany. It was Robert Meany's thing, right? Right. So Robert Meany, there was a whole Twitter thing where he was pinging me. And he actually said, if you're interested in hearing about my experiences as a test coach, I did a talk at Test Bash Dublin recently. You should check out. There's a link. And I don't have a pro dojo account, so I haven't watched it yet. Yeah, why don't we have pro dojo accounts? I think we need, someone needs to sponsor pro dojo accounts for A-B testing. Absolutely. Like Ministry of Testing, guys, what up? Yeah, Test Bash is the official conference of A-B testing. We should probably bring, this is going to be eventually a mailbag episode, but for now an all tangent episode. One thing, I think we brought it up on the channel or in a private discussion with you is, I'll just throw this out here. This could be 2019. It could be 2020. It could be 2021. But there should be a Test Bash Seattle. Oh, I figured there were one or two places you were going to go. Well, that's one place. But no, it gets better. Test Bash Seattle. It gets better. The MT conference or the MT book. I wasn't certain which one you were talking about. Why don't you shut up and let me talk. Test Bash is usually Thursday. It's a Friday conference. Now I can't remember. But usually, yeah, I think it's a Friday conference. But there's always a day after thing. And when I was in Brighton, there was an unconference on Saturday where 30, 40 people? 30 people showed up. And we just unconference, like open space whiteboard thing. Right at Nia's, people vote with their feet. And you set it up as you get there. But that was fun. I liked those. Nothing wrong with those. But when you and I host Test Bash in Seattle, the following day is modern testing conference. Can it be a modern testing unconference? Yes, absolutely. I do love open space style. We should merge the two. You're right. So anyway, because we're doing that, we should get our sponsored pro accounts. Anyway, back on task. I don't disagree. But I actually think, yeah, I mean, I think. Maybe there aren't really. I think we've already satisfied that criteria. All right. But anyway, so Robert Meany will just do a free hawking for Ministry of Testing. Robert Meany is doing a meet up in Ireland, apparently, talking about the name of his talk is from tester to test coach, a voyage into the unknown. And I saw this, and I'm like, that is fantastic. I don't know if that's MT inspired. I'm guessing it is. But it's certainly MT aligned. It's MT aligned for sure. And I think it's more aligned than inspired. I think he, there's a whole long string of tweets I won't get into. But yeah, he gets it. He gets it. Brandt, look at you and I. We're not the most original thinkers in the world. Where do ideas come from? Other ideas coming together. But the thing is, it would be dumb of us to think that very similar, highly aligned ideas wouldn't develop separately in other places from us. And that's what we found out as we've been talking about modern testing in public. People go, oh, great, we do that. That's a name for what we do. And that's great to hear. I don't know. I mean, jeez, we've been talking about MT for, I don't even know how long, but since at least 60, episode 60, is that a year? I don't know. And we've stated all along, we're not inventing anything new. True. The only thing new, I guess, would be, we think these seven principles are the key guideposts. Yes. And interestingly, if I remember right, I think the evolution was, I thought we should have principles. And I made some crummy principles. So we iterated, and we iterated, et cetera, and telecubic that we have, which I really like. But what's interesting is that, I think I mentioned this before, is that the modern testing principles actually align really well with the three ways of DevOps. A lot of our stuff, we're not, we're dealing with the world as it is. I would say one of the most important things about MT is the rejection of traditional test methods in today's world. Yes, yes. The old ways don't work anymore. What got you here is not gonna get you there. No, what got you there is gonna get you unemployed. Yes. Yes. All right, shall we, anything else before we begin the show proper? No, let's dance. So we have questions, questions, questions from our listeners, and do you wanna go in the order I printed these out? No. Okay, so I printed some out some questions I've received in my email, as well as from Slack. If you've had a question that you've given us that we don't get to today, please follow up because we're horrible at organizing these things. We need to get better. Why? Which question do you wanna start with? I'll go ahead and read it. I stumbled across your podcast through the Ministry of Testing newsletter. Just finished listening to this episode. Not certain which episode. That's a couple ago. What you described resonates with my experience as a tester where I work. I joined the company as a testing specialist six years ago, primarily focused on process improvement and where required manual testing, progressively less over the years. Sadly, the terms I am leaving under are just as you described. There's no longer a need for me. Quality has been baked into the process well enough. Fortunately, I've managed to find a role with another company as a senior test engineer. I was wondering if you could elaborate on where you see individuals like myself gravitating towards. Do we need to consider a career change? Is management the only way forward? Is job hopping every few years all that's left? Curious to hear your thoughts. Yeah, it's a great question. This is from Rajiv Makhani. This is about episode 88. So thanks Rajiv for sending me a- Oh, literally last episode. Yeah. Well, yeah. Yeah. Great questions. You were able to read the question. I'm gonna let you start. There's a lot of, is the role of a modern tester just to be a coach to help one by one help every team in the world get there? On this one, I forget what we said in 88, but I don't think I'm gonna say anything that contradicts. In my view, one of the main reasons why we are doing MT is exactly that. We think everyone in test needs to begin the process of considering a career change. There are multiple options here. Career management is not the only way forward. To be clear, I'm gonna interrupt. I would, because it's not necessarily a career change, but it might be a career shift. I don't think it's a revolution. I do think it's more of a evolution. So let me talk about what, let's say I was at a much smaller company and I was doing what I do as an individual contributor. Okay, how much smaller? Like five, six people? No, let's say I'm comfortable doing this with 50 to 100. Okay, so I am helping this team accelerate the leadership quality. I'm helping them build that quality culture. I kind of dive in on hands-on stuff. So as they build this quality culture, there are things I've gravitated toward in my career. I do a lot of work with CI, a lot of static analysis, a lot of work with Gates, a lot of work with not as much as you, but with data. Those are gonna be my specialties. None of those things are testing. I'm there to help coach the team towards testing and quality. But I would assume that, and I've also done dev work and shipped code on almost every project I've worked on at Microsoft as a tester. So for me, and again, I'm going to follow, I'm just going to do more, if the quality culture is there and I don't need to do any more testing or test frameworks, because everybody else is taking care of that. I would naturally, this is just me, fall towards the other things I am good at that provide value to the product. And of course, I'm there to look, when things shift off the rails, I'm still around to maybe ask the right questions in a retrospective or make sure as new employees come on, they have the right mentoring and coaching, or make sure that that culture is not lost. But I think all testers who are, my guess is that all testers who are leading teams towards modern testing have a bunch of other skills that they can begin to leverage more as they begin to do less testing. Or adapting their skills towards a new mechanism. We talked about one poll survey, I don't know, about a year ago, that noticed that there was a shift in QA teams away from more dev-focused KPIs towards business-focused KPIs. The way I take this on in a mentoring relationship is I walk people through, like look, these are the strengths that a testing specialist brings to the table. And I almost never bring in the word testing. That's an activity, but they have customer empathy that is absolutely a strength, which is still valuable in different roles. Those that are fond of automation or shrinking time on that front. DevOps is a very suitable and growing role. Which is weird because DevOps is a culture, but anyway. It is a culture. So it's quality, it's all right. But it is very common for teams when they realize that they need that organization to hire in folks to bootstrap. The first thing you do when you need to incorporate this muscle is you hire in people who will do it for you and then you make the shift towards. Just like with testing. Just like with data. For sure. On the other hand, there could be, I could see a future where development teams, organizations, companies, whether they call it modern testing or not, see a need to be able to develop a quality culture. Like how do we build that? And then there's people that they hire to come in for one to three years and help them build that. So it could be, there is, I think for some people, it's a job hopping role. There is. It's harder right now because what you have is skills that will help a company do something they probably don't know they need. Yeah, and I think actually just traditional testing, I think there's still a lot of years left where job hopping will succeed in that, but I think it's gonna shrink. My best advice is not even mine. I don't remember my source, but there was a study that came out that basically detailed something Alan actually proselytizes quite often. I have never proselytized in public. That is unfair for you to say. Is this considered public? Sure. Okay. Wait, what does proselytize mean? Preach. Okay, yeah, I do that all the time. I should have just used preach in the first place. Yeah, why use a long word when a short one will do? You know, if I hear one more person use the word utilize, where they are supposed to use use, it's not even the synonym. I'm gonna blow up. It is absolutely synonym, lookupsynonym.com. Should I utilize synonyms.com? If you'd like. Oh God. Okay, back on track. You use short words. So what the study showed is in particular in the software industry, that there is rapid change occurring in terms of the skill sets. Five years from now, I think the standard developer is gonna have to have basic data science training because it's gonna be a key part of their job. Yeah. What is a key differentiator is constant relearning. In the software industry, that I think above anything else is going to be critical if you wanna build a career. Absolutely, and we've said that before talking about other things. Like what I'm hiring, I want ability to learn over random coding trivia. Always. Because the language you use today is probably gonna be, less it's JavaScript unfortunately, is probably gonna be a relic in five years. So I think I've shared with this, with you before. I treat my team like a startup. I run it like a fake startup. All right, I'm constantly thinking through the scenario of if me and this team were an actual startup, would my customers pay for an extended contract? Right, how do I constantly get that business? Now, I am now in one of the giant tech companies. So those consequences aren't necessarily something that I need to be concerned with. But in my particular world, credibility, there are other commodities that I can use to track how successful my team is doing. And one of the things I have to think about is the skill sets of my team. And are there opportunities that I cannot take on because I lack those skills? One thing that has happened to me lately, thankfully none of my team listened to this podcast, but one of the things that has happened to me lately. Unfortunately, for better or for worse, much of my team listened to this podcast. Well, one of the things that I've been thinking through is for example, I have some folks on my team that aren't there yet in terms of data science. And I'm thinking through, I probably have two years or so where I need to aggressively train those folks up or else it's going to actually be better for my business to let them go and hire new people because there will be new people who already have that training. So I want to balance being a people coach as well as a business leader. And when it comes to job hopping, I think actually I'm not alone in terms of how do I evaluate these things. If I went back to a peer dev position, I would not hire a test specialist. Now, part of that is because I'm sufficient as the testing coach on that team. But it's not hard to bring in people on new or retrained folks towards this culture. I just wouldn't do it. It's too expensive. We have a couple of milestones on the Slack channel. First and foremost in the last month, we've had people join the Slack channel that the one of the three listeners, but they aren't actually listeners. I still don't quite know what to do with that. But you may have seen it. So we have a peer dev who joined. I saw. Right, and one of the issues he had. Because modern testing isn't about testing. It's not, well. Right, not directly. Anyway, go on. Yeah, so there is a rising concern around traditional test methods being a bottleneck. And in his particular case, he couldn't get a security patch out because tests couldn't test it in time. And a security patch is something you gotta get out. And so he's going through, okay, how do I scale this activity? I think more and more and more that is on the way. If you're fond of the test traditional method, yep, I do think you're in for a good bit of job hopping. But there are, you don't have to take that choice. Right, what I would suggest, and I normally do this in a one-on-one situation, is introspect, think about what are your strengths. See if you can find sort of a technical career coach that can help you, guide you towards, hey, maybe you should think about the DevOps path. Maybe you should think about. One thing I should mention, interesting, is one of my former leads, quality leads, on our ads team where we no longer have QA, is now a DevOps lead. Nice. And what I've told him is, it's kind of the same thing. Same goal, same goal, work yourself out of a job. There's some work to do there, you gotta build the culture. But I think it's a great place for him to be. Because he can drive the quality culture from there as well. No, and actually, I actually think that those folks who work to just make the culture part of muscle memory, succeeding in that develops, my hypothesis is, succeeding in that develops within you a certain set of strengths and skills that make you immensely valuable. It might be another episode or two to decompose what those are. Yeah. But I've seen it over and over and over and over and over again. Sure. Okay, if there's probably more questions about that, they can come up for a future episode. But let's do another one. Answer another question. Or talk about stuff for a while in a way that in no way answers the actual question. It depends how you wanna interpret it. Which one do you wanna do now? Was there ever an episode talking about what reference skills are needed for a combined engineering team, which I will now state, we don't want combined engineering teams, we want unified engineering teams. All right, and this was from Percy on the Slack channel. Was it? Yep. Okay. And I asked him to clarify and he said, programming skills or testing skills or ops skills, what's the bar? Is there a must have and it can be taught learned section. And data science. Like what are the skills the team needs to be unified engineering? So I don't think we had an episode talking about it. We did not, which is why I left the question here for us to talk about. I did do. We're not gonna do a whole episode, we're gonna do the next one to 30 minutes. I did do a blog on that. I don't think it answers it though. And yeah, the answer in a nutshell is exactly from my experience, you should flesh it out. From my experience, it is programming, testing and ops skills. I think largely, yeah. You are making a jigsaw puzzle or soup. Yeah, so the one mistake I've seen people do when they shift to this though, is they re-interview testers to make sure that they are coders at the same level of dev. Yeah. And I think that's a mistake. I think it, no, to me it's infuriating when that happens. So the, what I propose is when you do this is what you wanna do is you wanna have a balanced team. So when you do a unified team, you're going to retrain that team. So this is another challenge. It's because every time I go do an Agile coaching session to a dev team, can you guess what the number one question is? Do we have to do Agile? No, it's- Who does the testing? I don't know. No, it's I'm a specialist in UI. So are you saying that I might have to work on database code? Really? Yeah. And I go- How are these people employed in 2018? You know, I tried to understand. I would never have guessed that cause I didn't know people like that still breathe. Oh, it's everywhere. Everyone is a special snowflake. I'm not. I am an unspecial muddy piece of slushy snow that people have stepped on. Yeah, one might argue that you are a special snowflake because you're not a special snowflake. That makes you special. Snowflake. Anyway. My sense on this one, or my guidance on this one is what you wanna do is you wanna get the right skills on the team as a balance. Even if it means you have four dev specialists and four test specialists, okay? As a team, it's balanced. Then what you need to do is spend the next six months forcing cross-pollination of knowledge. Actually, yeah, it's not a bad idea. Setting the examples I've done in the past, and this is one thing I did blog about, is so first and foremost, I am fond of in this new team putting the test manager as the one in charge, not the dev manager. The test manager, from my experience, is far more likely to understand how to execute that cross-pollination. And I do think that's far more valuable in the long term. The next thing, so what I've done in the past, for example, is I've offered up when we do these unified engineering, things I've done before is, all right, you guys can pick the two or three testers that come to your team. And you can pick whoever they want. And of course, they always pick the top two to three. But here's the criteria. You have six months, and in that six months, your job is to turn them into a dev, which means they need to be working on features, they need to be doing bug fixes, okay? Their job is to teach the rest of your dev how to get this test stuff done. And at the end of that six months, we are expecting that there is no difference between any of these teams except for that, which is where experience makes a difference, right? In terms of who does what activity, there's no difference. And then generally, I do a threat on that dev team. By the way, for the testers coming to your team, if they are not able to fulfill this bar, we're gonna take them from you and put them on a different team, and you will still be accountable for all the testing activity. This assumes you're starting from a place where you have separate dev and test teams. Separate teams and merging. I think, probably, I'm wondering if the, at this point, the majority of our teams are not necessarily combined engineering, but a lot of teams are set up in something resembling an agile testing model where they have a test specialist on the team, but they're like, they're managed by somebody else, it's a matrix organization. But the difference is, I think, is a lot of people I talk to, that tester, even though this was not the intent of describing an agile tester as Lisa and Janet did, that tester ends up doing all the testing. I think Percy's situation is he's still in the multi-discipline world. I just wanted to cross the bridge here for a few of our other listeners who are in a different world. Yeah, there's ways, there are ways that I've seen ripping the band-aid succeed. No, I haven't. Not with this change. This is a tourniquet change. Again, so there are ways where I've seen it succeed. The better way is boiling the frog. For example, ripping the band-aid, I've seen it succeed if you put the test guy in charge. Because they get it. Whereas the dev guy is trying to go, how do I manage these useless tester guys? And they do wacky things like hold a coding bar. I think the first thing you have to do to make this work, whether or not you boil the frog or rip the band-aid, is you have to realize that in order to succeed, you have to create a culture of knowledge across pollination. And the specialist culture can be rampant across both disciplines. Anything you wanna add to this? No, I think it's a good start if Percy has more questions. I guess the answer to the question was no, there was never an episode on this. So everything else is just lovely elaboration. Right. Let's do another. Okay, you can pick it. Tony G. when I was in New York asked this question. I said we get it on a mailbag eventually, and today's the day. Alan had a quick question regarding gathering data and being data obsessed. During the design phase, designers usually conduct mini user interviews and gather multiple data points. And as a tester, I try to be involved. This has not been explicitly mentioned in the podcasts or the Slack channels. From what I have gathered, the focus on data gathering has been largely once the item has been released into production. But I wonder how that compares to user data gathered during the design phase. It is evident that the design phase data is not actual data usage as in logs, but it is useful data for a feedback loop as nothing has been built yet. Just wondering if it's worth comparing this to in regards to value of also being something that adds to the definition of being data obsessed. My answer to him in mail was, short answer, yeah, data is valuable. With a caveat that those designer customer meetings often turn up what the customer wants versus needs. And it's in an area where our critical thinking and questioning skills can help. But it can get some, in other words, it can get some discussion started, but I'm not sure if it's how someone who does data for a career would view that. So, first and foremost, I'm thinking through, have we ever talked about it? And then, I don't recall. And I will tell you that I won't necessarily go to it. Because as a data scientist, that type of data is well known to be of very poor quality. Particularly for the reasons that Alan talks about. It's very well known phenomenon that if you ask survey data, or if you ask one on one questions, humans are wired to subconsciously or consciously sort of give the answer that the person wants to hear. And then recently we had a Twitter discussion where one of the listeners had reread the lean startup and noticed, did you see this? Yeah, yeah. And noticed, hey, there is a great alignment between the lean startup and modern testing. Well, there's another alignment. The number of times we've mentioned lean startup in this podcast. Yeah, right, so. I think I have quoted lean startup in probably every presentation I've given in the last five years. Yeah, it's, you know what, if there is like a, if there was a way to say, like look, you don't have to listen to us babble, just read the damn book. That's a big story. I think it's the same question. Like musicians get like asked, you know, like if you're, you join a band or you join a rock band and everyone in your band listens to Led Zeppelin 20 hours a day, your band's probably gonna sound a little bit like Led Zeppelin. Right, it's gonna be on the influences list for sure. Lean startup is on our influences list. So if you wind it back, so is this data useful? Yes. Is it everything you need? No. Right. I think Tony knows that much, but how, if you are data obsessed, is that data important to you? So from a data scientist, no. Right. From an Agilist, you bet. Well put. You really can't do anything with this data from a data science point of view. What you can do though is once you have both, from an Agilist point of view, one of the things, and even in NMT, where we talk about lean thinking, and one of the key things in lean thinking is, in this context is look, no matter how big your engineering team is, it's a limited resource. And it is a damn crime if you spend engineering hours on something that doesn't add value. The way I kind of look at these design phase discussions is preliminary hypothesis generation. Right, so you have these designers that go out and they talk to users and they're developing hypotheses. From a data science point of view, I'm like hey, a list of hypotheses that are already thought out for me, that's fantastic. That shrinks at least a day and a half of my time. But what we then would want to do, or what I would want to do is have, take those hypotheses, throw together a very quick prototype, an MVP as it were, get it out there, get it instrumented, and then see, all right, what does usage say about these hypotheses? And then do what's known as a pivot or persevere event and say hey, do we have actual data that aligns with the initial hypotheses that warrants further investment or should we change the direction we're going? Yeah, so I think that data does have its use. It is, designers unfortunately, their job is to pull together designs. So they don't have access to usage data because they're trying to design something that doesn't exist. But one thing that is good, and we haven't praised just the value of getting that early feedback from focus groups or customers to get an idea if you're heading in the right direction. He's already talking about it, he has, but I think that's really important. You and I have both seen many products of the what I call field of dream software development, build it and they will come. Yeah, the one thing around dealing with designers is along those lines. Right, a lot of these guys are very good at their craft. But again, a lot of the designers and a lot of program management, they're inflicted with Steve Jobs syndrome. And the key thing on this one is yeah, that is useful, but it's gonna be really useful when we get the prototypes run together and can validate your hypotheses. Yes. The thing that I think is critical in this case is to communicate what they've learned and reframe it as hypotheses if they aren't doing that already. That's the real challenge is a lot of these guys, they've been in the industry forever. And my trigger is at this point in time, anytime I have any conversation with anybody and they're defending the point of view with the phrase, I have been doing this for n years, sadly at this point in time, that is an almost immediate bit flip in my head. Yep, fully agree. Yeah, it is, there is no one that's perfect. Well, to me, it's to loop this back into something else we talked about, that ability to constantly learn and understand that you have to constantly learn new things. You realize the number of years you've been doing it doesn't matter because what you're doing has to be new all the time. Another thing we've talked about, like we reject the notion that predictive software lifecycle models are good in today's world. Correct. We want adaptive. Yes, yes. And that starts at the beginning, even with the designers. Right, and there was a big thing, Satya was hot about this a few years ago, but it's been around a lot, the fixed mindset versus the growth mindset. And we should all have the growth mindset. You absolutely have to have a growth mindset to be in modern testing. You know, I like growth mindset and I like growth hacking, but it's becoming buzzword. Yep, it's becoming, it's there. That ship is docked and boarded. I'm already working through, okay, how do I come up with this and then to explain the same concept? The buzzword, once a phrase gets the buzzword set as, you lose people attention on the message. Let's talk about shift right or not. I'll just throw that into the buzzword. No, we had a listener accuse us of, did you see this? We had a listener accuse that accelerate the achievement of shipable quality is likely on its way to buzzword set as. It's too long and verbi to do that and no one has shrunk it yet. Right, it's not there yet. Lots more I could throw in to talk about, but I think we're out of time. We should probably wrap it up for today. Thanks everyone if you've listened this far. Hopefully you found something helpful in here. Thank you, Perji, Perji. Thank you, Perji, Tony and Rajiv for your questions today. If we didn't get to yours today, we'll try and do it next time. Please re-ping us if needed. Always appreciated. I am once again still Alan. And I'm Britt. Or not Alan, have everyone with that. Okay. 
