This is the AB Testing 343 podcast, a podcast where we ask one of the three listeners of the AB Testing podcast three questions about almost anything. ABT 343 is a fun slice of what's going on in the world of modern testing. Let's get started. We're back again for another episode of ABT 343, and I'm here this time with Machi Zarek. Hi, thank you to be here. It's very exciting. And that was to see how it go. It's more exciting for me. I am excited about this series. I think they a lot of good insights from listeners of the podcast and people practicing modern testing. I'm also looking forward to maybe in the future, having people who don't agree with the principles, who have some conflicts, think that'll be fun thing to do. But I don't think that's going to be the case today, but we'll see how things go. Yeah, we'll see. Great. So I know that one of the things is you, I named dropped you in my recent Ministry of Testing course on modern testing because you took, Brent and I did in the eighties of our podcast, a lot of deeper dives into each of the principles and you created a mind map of that, which is super helpful. And just I want to thank you again for doing that work. And I think it's going to be continually valuable for people trying to get their head around how these principles can be applied and how they work with each other. So thanks again for that. My pleasure. I will admit I am, I really like to learn from mind maps. So that's why it was created. Well, I was trying to do article for one of the, let's call it a blog scene Paul, Paul and about modern testing. And I needed to, you know, sorry it's in my head. So I walking my dog, I was taking notes from your past episodes and I was complaining, giving that mind map. My only problem with it is that the current format is not very good for you know, contribution from other people. I'm trying to figure out some better ways for it to work in the future. But for now I don't have any ideas how to tackle that problem. That's interesting. We need a mind map diff tool. Yeah. You know, actually I found some way. I found recently that there is some plugin for the X mind to use Python to, you know, to make a different format from it. And I'm thinking if it's possible to, you know, to use it to start the mind map in getting some other format and shows, you know, auto-generated. But I haven't yet started looking at it. I would probably use it as one of my programming challenges in future months. That is super interesting. Speaking of, we're going to start right off with tangents here, but speaking with about programming challenges. Uh, in case I forget to mention on the podcast next week, it's almost time for the fact tomorrow, the advent of code programming challenge starts. I don't know if you've ever done that before. No, I was listening to when you were doing it last year or two years ago, but I haven't taken time to participate in it last, uh, last year. I am thinking about trying it this year, but I don't know if I will have time because I'm doing my own challenge in the meantime. So we do. I've never finished it. I've started it every year for about the last three years. And it's a lot of fun. It's, uh, in my current role about the, almost the only programming I get to do. But it's, it's fun. Last year I did it in JavaScript and which was both good and bad, but it worked. I might try. Why did you choose JavaScript for it? That would be challenging. Uh, I don't know exactly. It was convenient. I think it's, I don't recall my reasoning. I think it was convenient. I was on. Yeah, I don't know. JavaScript is popular. Maybe see what's going about it. And that means no, no, no. Why I didn't choose that. The advent of code always has two challenges. One that's kind of hard. There's always a follow-up that if you're lucky, your initial solution is, it's easy to bolt on, but if you're unlucky and you solve the first problem in a weird way, you have to basically rewrite something. And there was one where you had to figure out where someone would be on the thousandth iteration of some complex maze or a thousandth step. So did the code to figure that out. And I say, now imagine the character has gone. It was like 10 million steps or no, it's more than it's like, it's like 10 billion steps. Okay. If I was in a type, a strongly typed language, I would have to change my integer types and redo a whole bunch of stuff with large ints, et cetera. But JavaScript doesn't care. I just added a bunch of zeros and ran it again. And it took, took three minutes or so, but I still got the right answer. Yeah. And that is the power of the soft typed languages that you can do lots of that kind of stuff. I'm not saying it was a good thing. I'm just saying it worked. Yeah. I am currently playing with the JavaScript because we are taking look into the puppeteer and other solutions. And my biggest pain is that the bug fortunately, Visual Studio Code is giving some good options, but it's still not on the level that other languages and other IDs have for that. I definitely hate JavaScript more than I love it, but let's have a three for three podcast. And, uh, I'm not going to edit any of that out because I think it's all super valuable and interesting, but ABT three, four three is a podcast for people who have at least some knowledge of modern testing. And I know you have, as we've spoken of before, uh, more than above average knowledge. So for the first question, can you talk a little bit about two part question about how you've seen modern testing work and how you can maybe some ways that you've got teams to where you've snuck it into the job, where you've got teams to adopt some of the modern testing principles without knowing they're doing it. Okay. So, um, I will start with the second part because he's much more a recent situation for me. Um, there is currently a new project starting. Well, it's not exactly new project. The old project is returning for another release and they had few problems. Basically regression was taking five hours. And since this would be the probably the last release for that customer, you wanted to know, to improve it, to leave him with some better positions in the future. And the plan was to try to put automation there. And I wasn't too keen on that because well, since this is a rest release, I wasn't seeing the proper value of, you know, giving the end to end tests there and after lots of discussions, we came to conclusion that actually the biggest issue for the customer is that basically, um, the process when they find the bugs because due to the fact that the lots is dependent on the data and we don't have that data and we can't have that data is found in the production by them and they have to report to their representative. He has to do quite a lot of checking and then, you know, it has to go to our support, our support is reserving the issue. So my proposition was to change an approach. Let's look into, you know, improving our logs to create some alerts. So when we see some suspicious situation in production. So our customer support will know about it before the customer representative even will know about it. And maybe we even be able to go with it so fast that they will be able to fix it before anybody contacts us. Interesting. Interesting. Yeah. We will see how it will work out because you know, um, I was introduced to the project last week and the project is starting in the Monday. So we will see how it goes. But so far I was talking with the architect and he says that it's quite possible to fix the logs because right now the information is that in them are not enough to even reconstruct the situation to see what happened. So, you know, there is a lot of discussion. So what did you do? What happened? That's etc, etc. So, you know, shorten the feedback loop by making the logs better. The whole situation can be resolved faster, which means the client would be able to make more money and it means customer would be happy, which means he will stay with us and we can make more money because our support instead of the fixing the issue in let's say five hours, they can fix it probably maybe our. That sounds like principle number one, your, uh, your priorities improving the business. Exactly. Nice. Do you have other examples of how you've got teams to adopt modern testing or? This is maybe not exactly modern testing, but something very connected. Uh, I am community leader of the test automation in the objectivity company I work for, which means I have a lot of contact with testers that wants to learn automation. And what I am trying to show them is learn how to code this ability will be helpful for you in much more aspects. You can write some small programs that will help you with your testing will enhance your testing will, will allow you for the faster feedback. We allow you to better communicate with developers to better understand what's going there and make you pretty much more productive. The automation, the end to end tests is not a way to go, especially that I agree with you that in my opinion, this is the stuff that should sooner or later go back completely to developers because let's be honest, this is the hardest code that you will ever write. Yeah, I've made that comment before. In fact, there was, uh, and I'm going to, we're going to dive in here a little bit, but I remember talking to, when I was writing a chapter in, I was asked to write a chapter in Dorothy Graham's book, experiences and test automation. And I am always of the camp that focusing on writing automation is the wrong goal. You're trying to make it easier to do your job well and automation can help there, but that's, that's what it does. And the story I wrote, I was interviewing a former tester who was an architect on the windows team at Microsoft. And he talked about a, um, sort of a mock driver framework. They wrote that allowed companies like Intel and these people making hardware that was going to be available, uh, much after the release of the OS, uh, being able to test that hardware through a pretty sophisticated mock driver framework. I forget what it was called time was escaped me, but that was a good example of accelerating the achievement of a book quality and it's just much more valuable. My experience has been writing tools to help me test has been much more valuable and serendipitously to this conversation. I just, I, I saw a few more tweets this weekend about testers focusing on automation and that's so weird testers. It's odd to me. It's not big. You look at the state of the industry. It's not odd, but testers, as you've seen, they go, Oh, I want to make themselves more valuable. I want to learn automation. And what they really want to do is they want to make themselves more valuable. And there's a, they're focusing on the wrong goal. I'm to be honest, I'm not entirely sure because from perspective of value for the customer, I agree with you, but we are also in the let's call it corporate world when you are just a number in the table. And let's say, let's be honest, having that automation in front of your title quite often means you earn much more money. It doesn't matter that probably as you know, manual tester of human tester, you are much better. You can do much more, but for the payer, you are just the number and you may hit the glass ceiling very far, very fast for the tester, but you know, this is the problem of the industry that also needs to be tackled sooner or later. Yes. Any other examples of applying modern testing principles in your, in your roles and actually answer that question and doing that, I'm not exactly sure what your role is. Sounds like you're in a sort of a consultant role, but I'd like to hear more about what your, what your day to day job is. My title is simple. I am senior automation quality engineer at objectivity, but my role is, I would say automation expert. It would be the easiest way to describe. I am responsible for this automation community in the company. So I am responsible for helping with their equipment, with sharing knowledge, with trainings, and I am also, you know, expert. So when there is some situation that requires someone much more knowledgeable, I am the one that is called for to, you know, to help preserve the situation. We, for example, had a situation when we were passed the, you know, asking question if we should be doing, but if we were in the point, we have to do it. Basically there was platform that we couldn't do performance testing using the JMeter or the gut link because the like was, they were messed up and we had to do something that is completely against the books, you know, use Selenium for the performance test, but actually it wasn't completely another option. And for example, I was the one that has to design some solution, how we can even tackle this problem. I was screaming in my heart that I have that we are in situation when we have to do it, but you know, client needs some information about how the application is performing and we haven't another option to provide him that information. Cool. Cool. Before we go on, but were there any other examples of modern testing worth sharing today? To be honest, I think for now we can stop with this because I haven't answered the first part of your question, which I can't remember. That's right. Which was how have you seen modern testing work in software houses? Some success stories. To be honest, this is the place when I see the most problem, because when I look at the DevOps, when I look at the software houses, the problem is the DevOps, even if you read the Phonics project, they are saying that the most core business you should keep in hand, you should keep at your site so you can develop fast, you can release it to production often. And this is the problem I see, because usually when you outsource something, you need to have some kind of contract, some kind of working with the organization to be able to, you know, to have to trust them. And usually most software houses I see are not at this level of trust, because they are either working in the bottle using model, in which case, you know, they don't care because all management is on the side of the customer. But in case of time and material or fixed price, which are, I think the two most popular models, there is the problem how to actually implement properly DevOps, because you are still you still are very dependent on the customer and how they are willing to trust you with, you know, the access to production, that kind of stuff. And it's additional barrier that needs to be broken. I essentially read that there is another model of cooperation with the customers, which is called, I may, I may screw it up. I think it's outcome based model when customer is basically paying depending on the outcomes that you are achieving. And I think this is the only way for the software house system forward to be able to work in the DevOps and hands also apply mother testing principles, because we need to build that trust. And I think that's the point of the first principle, we have to improve business. And when we improve the business, we are able to build the trust, you know, to be able to even improve the business even more due to the other principles. Thank you for that. In that you mentioned the Phoenix project. And I know from our conversation that you recently read the unicorn project still on my list. Uh, tell me just curious on your take on that and what would be the interest of that, of that book for people who are listeners of this podcast. And to end the preface, while you think about that Phoenix project is all about the theory of constraints, which is a big part of accelerating the achievement of customer quality or customer value. So I'm curious where the unicorn project takes over and what sort of the main lesson and gist of that book is. That would be quite a tangent because I must admit, I don't like this book. I read it and I think this is still got a book, but it's the weakest book about the DevOps from Gen Kim Eats. It has its problem. Uh, I think for starter, we need to start with the goal because Dr. Goldratt, one of his ideas for the goal was to share that stories are good material to even about hard concepts in the management of other stuff. And the phonics project took much of that. It completely ran with the idea of the, uh, story as the method of presenting the information. Unicorn project is also making the same way. It's also the story. And here is the problem. The book starts with disclaimer that you have to leave your so that you will have to use your suspension of disbelief. And this is the big problem for me because at this point you are basically saying you screwed up as the storyteller that you need me to completely use my suspension of disbelief because the book is happening at the same time as the unicorn project. It's, I would say as the unicorn as phonics project is about the bridge crew with the managers and how they are dealing with the situation. The unicorn is about the, as they calling here, red shirts, the normal people down in the system, the teams that are actually dealing with the problems. And here I have quite a lot of problems because, uh, the model I'm trying to look at the characters. I see, for example, the time is completely made from the rubber because I cannot imagine how the original characters would have also time to participate in this events. And I think my biggest issue is I cannot say for whom is that book, because at first I thought it's the book for the, you know, for the laggards, for the late majority, for the developers, how they can learn about new technologies and how to use them. Because basically every popular technology right now, Kubernetes, Docker, et cetera, is named and explained in the book. So it's kind of seemed to me like it was addressed to those people. But then I came back, can see it because those people won't probably have contact with this book since they are in the laggards, they are still quite far away from the DevOps. And even if they hear about DevOps, probably they will hear about the other books first. And my problem is also what this book tries to teach because the only worth, I think, that was the how it called the five ideas for them of the work. And the ideas itself were great. Oh, yeah, local localities simplicity, that was one focus flow and joy was the second. Third was improvement of daily work for was psychological safety and five was customer focus, which the five is very similar to first principle of the modern testing. And they were a great idea, but the way they were introduced in this book, there was too much noise to actually see them in the work. The authors were tried to put them in the spotlight. But I kind of didn't feel like the spotlight was put on them properly. I'm still building my my final opinion of the book as I'm writing the review for it. But at this point, I cannot say for whom I would recommend that book. I don't see, you know, the targeted audience for it. Fair enough. It's something I think because I like business fables, I've read all the Lynch, Yoni books and the Phoenix Project and the goal, of course, I liked actually I like the goal the best because it wasn't about software. Yes, I agree. Because I could I could form the metaphors and the patterns myself. And I think that makes it a lot easier to adopt. Plus, I was listening to go recently as the audio book. And what was impressive for me, it was proper audio play. I think there was something like 12 voice actors there and white array of sounds. So it was a joy to even listen to it. It was treated as the proper audio play. And that was also interesting. I've never had an audio book experience like that. So I might have to check that one out just so I can I think it sounds great. So it's like, yeah, I do a plan, especially when you hear the doctor, how it was just what, John, and he's speaking with heavy accent. He's really just showing to listen to him. I'm going to check that out. I'm going to definitely check that out. One last question while we're kind of on and thank you for that. I'm like I said, I'm still going to read it. But yeah, I want to form my own opinion. But I think it's I was a little worried about it earlier on. But I will form my own opinion and probably share it on the podcast. Yeah, I'm looking forward to hearing your opinion about it. All right. One last question for today. And I'm going to give you an option to rant a little bit and I'll probably join in. But you had mentioned to me on Slack that you read an article in Polish today on the state of testing. And can you talk about what you read there and your reaction and we can both I'll help you tie it into modern testing if and where needed. Yeah, basically, there was an article called State of the Testing. And I started reading the article and basically it was about testers, testers, testers, testers, testers, and even more. It was about traditional testers. Then it starts going into different things that are happening in the market. Outer himself is stating that the market is not satisfied with traditional testers and they are doing other things like monitoring DevOps and this whole little of things which I could see their testing. And he said that the testers are staying behind. And he ended basically his essay with saying that testing is in the defensive right now, which kind of triggered me because looking at even things that he has mentioned from my perspective, adding to it even the test of smother testing, I think testing wasn't ever better than it's now. The teams see the value of actual testing. The teams are going forward with quality. What I'm seeing is that actually the traditional testing is in the defensive. And as I've already said, the fact that he put equality mark between tester and testing was the thing that pissed me off the most. And you know what Brenton I say and more and more and I have to continue a little Twitter battle after our talk here today, but I'm caring less and less about testing and more and more about quality. Testing is one method to reduce risk. That's a very good method and good testing reduces a lot of risk, but it's not the only way to reduce risk and improve the business. Exactly. Yeah, this is something I'm kind of mentally not ready because I'm still putting the equality mark when it's not between quality and testing. I'm trying to disconnect this, but you know, the years of the training makes it hard to remove that quality mark there, but I am seeing it as less connected lately. I agree about you can achieve quality. When we talk about accelerating the achievement of a more quality, it's definitely, I'm figuring out more and more. Brenton, I've been saying that phrase for years. I think Brent just reposted his blog post re-coin that phrase maybe 10 years ago. Over time, I'm realizing more and more what that means is less about testing, more about the other ways to reduce risk. And you look at testing and testability are one way and the traditional way we did it when we were shipping things every couple of years, but operability and the ability to deploy safely and monitor and learn are just as big, if not more, actually more important, I would argue, in some businesses. Yeah. Plus the thing that was actually in the goal, because one of them, well, that will be a mouthful, the goals of the goal was not only to present the theory of constraint and show how the stories can be used as teaching method, but the culture also wanted to show people that the science is not only what the scientists are doing, that everybody can experiment, every can learn from the experiments. And here is the R-set value. We, you don't have to be tested to experiment and to check the results of these experiments. And lots of quality is coming from that fast experimentation. Yes. Yes. I love it. I love it. I love it. All right. Well, that's, that's it for today. So any, actually before we finish any blog sites or Twitter handles or anything else you'd like to share with listeners? Yeah, I am on the blog. I'll talk on the blog on the Twitter as much ever attack. I have blog called the broken test where I recently went on quite a long essay around for dedicated for the people that wants to go into the testing where I'm talking about different myths connected to that because I'm thinking that we are sending too much snake or to them lately. Yeah. And, uh, I nodded my head so hard. I almost hit the microphone. Yeah, exactly. And, um, basically I am lately happy. You can see me on a lot of conferences in Europe. I am, my plan for the next year is to finally tackle the West of Europe because on the East I have no problem of getting into the conferences on the West, I have a little problem. And again, I will try to go with some subject topics connected to more than testing on our sub developer conferences. We'll see how it will go. Sounds awesome. Let me know if I can help at all. Try and grease some wheels somewhere. If I know the people. Yeah, I would probably ask the free way to help with the, um, abstracts for the call for papers. But today I am lazy and I'm not writing and I will be doing something tomorrow. Well, thank you, Mashi. It's been fantastic talking to you today. I know we both have to go take our dogs for a walk, so I'll try and edit out mine crying in the background earlier. I'm sure that'll work out. All right. I don't know if you could hear that or not. She had a little wine. Hey, okay. Okay. Good. Good. We'll see what happens. All right. Thank you again. Have a wonderful rest of your weekend and, uh, we'll talk again soon. Thank you for having me here. Bye. 
