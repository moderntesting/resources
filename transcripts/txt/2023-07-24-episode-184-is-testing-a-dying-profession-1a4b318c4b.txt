to deliver with fast feedback loops and count on fast feedback loops and rely and use those as part of the way you deliver. That's a big, that's a, that's a jump. That's a, that's a lock step jump in your maturity and your capability and your quality. Welcome to AB testing podcast, your modern testing podcast. Your hosts, Alan and Brent will be here to guide you through topics on testing leadership, agile, and anything else that comes to mind. Now on with the show. Oh, Hey, Oh, Hey, uh, yeah, I'm Alan. I'm Brent and that was the AB testing podcast. Thanks everybody. All right. No, no, I got it backwards. I got it backward. I'm confused. This is welcome. Welcome to the AB testing podcast. Oh, I thought we were just doing one really short this time. Actually, I liked the shorter podcast, but that may be a little bit too short, a little bit too short. It is, I'm going to touch on something. I have so many things to talk about and share with our audience. I promise as usual by 10 minutes in, we're going to get to the regular topics, but, uh, so I will time box that, but how have you been, Brent? What's going on with you? Anything new and exciting in your world? We're just a few weeks away from reward release. Wait, is Microsoft doing rewards this year? I thought there was something like they weren't. Well, uh, they claim they are. I mean, no one's getting a raise. Oh, but you get like the normal Microsoft bonuses and et cetera. Well, that's the question. Or maybe. So maybe, yeah. Um, should hunger games. Just put a pile of money and let people fight it out. Being old and that is shape. I'm, I'm certain I don't like that idea. No, you could do it like do it a Microsoft way, do it like a elite code competition to see who, no, don't even do that. That would be done. All right. Well, that's always exciting. That is always the fun part, you know, peak in May, as they say, as I've said. Right. We are in the middle of July. It has been Seattle warm here in the eighties. Yeah. Do you have AC? I do. I, well, I do. And I don't, and I'll get to that in a minute. No, don't, don't, don't, don't. Hey, it is. But before I get to that, are you ready for this weekend? Yes. No, maybe. Why do you ask? So I have seen the meme around how F up this weekend's going to be. Yeah. If you live or intend to go to Seattle. I, along with five teenagers will be at the Taylor Swift concert tomorrow. Oh, okay. So are you, are you leaving right after this podcast? No, I, no, I actually was cheapest way to do it was to book a flight from Seattle, which is the airport south of Seattle up to Vancouver, Canada, and jump out of the plane partway through and parachute to the stadium. Cause there's no other way to get downtown because there's a Mariners game at the same time. Oh no, you do not understand. I'm going to load up. I'm saying we don't, while Brent is bringing up his, his webpage of information for me. Yeah. It's going to be a wild weekend in Seattle. It's going to be hot. It's going to be, I don't know how well I do know how we're going to get to the stadium, but I feel like, Oh, it'll be after the show by the time people hear this. So, uh, going to get on the light rail somewhere, not sure where, but somewhere, cause they're running extra trains. That's going to be the way in, uh, and likely from the south. Because I think I normally do light rail from, from Northgate mall. Yeah. That's an option. I just feel like 30,000 people going to the concert who live anywhere on the North end of Seattle and, and nor a North from there will be taking light rail from the North gate mall. And this is, uh, Brent's ceiling of his office. Okay. He's showing there's a thing. There's a little map cartoon drawing thing that shows that there are 87,000 different events going on. One of the bridges is closed. It's going to be wild. I'm going to be part of that wildness. I will let you know how it goes. I'll let you know in two weeks when we record again, I will let you know. What happened as I brought five teenagers to a Taylor Swift concert and survived. Or, or, or this is the last podcast ever. You're doing this Saturday, Saturday. Yeah. Okay. So Taylor Swift Saturday, uh, Mariner's game, Saturday bite of Seattle all weekend, the Seattle storm Saturday. Uh, the bridges out to see what else. Yeah. For the first time since 2019, Seattle will look like it's an actual city where people are. And apparently Capitol Hill's having a block party on Saturday. Yeah. Yep. So, uh, speaking of Capitol Hill, uh, I have mentioned many times before segue, uh, on this podcast that once, uh, and, and probably to you more times that the plan has always been to get the hell out of suburbia as soon as the youngest child goes off to college. Yes. Getting out of, uh, getting out of the burbs, uh, bought a house on Capitol Hill. Oh, okay. You did the new, so we're going from a 20, a house built in 2018 to a house built in 1904. I was going to say 1820. So no, no AC currently in the new house, but by the time we move in, which will be September, we're kind of past the major heat, so I'll deal with that. Later. But, uh, excited going to be, going to be fun. It just kind of happened. We're doing kind of the casual looking and maybe this house, no, maybe this house. No. Well, this one, if we can, well, we'll put it off right now. What the heck? And it worked out. So we're good to go and, uh, closing like August, middle of August, end of August sometime. We're going to plan. I got a, I got to move in before September 13th or so, because I'm going on that walk around Mount Rainier in September. I want to get it done before then. Yeah. So that's exciting and new. That is exciting and new. I mean, it's, it's not a goal I share. No, a lot of people don't want to be in Seattle. You know, I spent so much of my life there. I want to go back and I, and here's the deal. We originally thought we'd move back downtown and this was the plan back in the 20 teens when people actually lived in downtown and it just, this is don't, it's a ghost town except for this weekend. So maybe someday, maybe someday still. So, uh, for those that don't know the geography Capitol Hill is, you know, it's a 20 minute walk from downtown, but it's just up one of the hills and it's doing okay, recovering from the pandemic. Few places have closed down, but there are still a good number of excellent restaurants and bars and cool places to what gyms and grocery stores that are, that are walkable parks, et cetera. So should be pretty good. No, that's it. And we're, we're only about eight and a half minutes in. So should we go ahead and, uh, talk about subjects people care about or anything else you want to cover? Uh, yeah, we can do that. I mean, that that'll be fun and new. Oh, uh, to do like a podcast about stuff about A's and B's and testings. Exactly. All right. Well, I, an article title caught my eye this week. It was called is software testing a dying profession. And we have different answers and we've talked about our answer a lot. Right. Right. The article didn't really go into that. It said it's going away because of codeless automation and DevOps and agile development. How old is agile now? Uh, it's, it's, it's old. They can buy a, they can buy a beer, right? We could be, yeah, absolutely. We could be its father. Again, to argue against this article. Agile development, agile development around for a long time. And this is what you and I saw. So it's interesting that you and I saw 15 years ago, Hey, this is going to make the need for a dedicated testing specialist and less so we began AB testing and modern testing. And we wanted to talk about this transition for a lot of people, but we haven't seen that change happen in the last 15 years and it could be happening, but it's not happening at a pace. Well, at any pace it's happening, but not at a pace is impacting testers because so many companies are again, maybe based on context, maybe based on legacy. They're happy to test the old way. I don't want to work that way anymore, but I think testing will continue to exist. AI and machine learning and testing. And again, my line is AI isn't taking away anyone's job. People that know how to use AI are. Yes. Again, when we started this podcast, I could do it now. Uh, monster.com. When we started this podcast, one of the things I noted was, uh, there were still club all jobs. Um, I bet there still are. And just a quick search shows that there still are. I was right. Yeah. Mainframe developer. It was just opened one day ago. I may or may not know someone on the podcast who's working in a company that has AS 400s just, um, as an aside. Well, you and I have worked on AS 400s and, or at least I have the question is, I think of it kind of like, you remember limits in math class? Yes, I do. Holy cow. Right. It limits. Like I, I forgotten most of math, but I remember those. Limits. Right. It's this concept that it never actually reaches this number, but, um, we might as well call it it's that value. Yes. Yes. Testing will never actually be dead, but do I think it will be at a point where we might as well just call it that? Probably. I think that it's interesting. And I think, well, on one hand, that would be my belief based on what we've seen, I think it's slow. I think it will ebb and flow and the people that, so I want to talk about the article first and the reaction to it. And then the article is a little bit straw manage and that's fine. I'm glad to see it brought up. I also feel like it's a little click baby because it's almost written to get the reactions from people who make their living, not just being testers, but being trainers and workshoppers and people who make their money off of people who do software testing full time every day and only software testing. So it hits them right in the pocket book. So they made, and what I saw, and I'm not going to recap names or comments, but what I was interesting, I thought it was a straw man article. And the comments to the article I saw were largely straw man reactions. And that could never be true because of this thing. That's only true for me. Right. Not, uh, or, or, well, what about medical devices and finance? I got it. What about NASA? What about airplanes and all this stuff? Like if someone's going to die, you know, blah, blah, blah. So let me bring up, this is hot off, not the agenda. There's another Slack I'm in. I don't know if anybody on that Slack listens to this podcast, but there's a testing channel there that I usually ignore. And then someone brought up. So it started with a comment on how Cyprus may not be in, I'm not sure if it's true or not, but may not be in business long-term because, uh, they're just, they're model and Cyprus is one of the UI automation tools. It's, I like it certainly better than Selenium, but they may not be actually creating enough revenue to keep it going. I'm not quite sure what, how much truth is there, whether it was opinion or whatever, but the, uh, the Twitter post was around like Cyprus is closing down and that kick off a discussion that I ignored until it got into a conversation around the absolute necessity of UI automation. And again, we've talked about this forever, but I made my point. I've been saying, I looked this up for 15 years, 15 years. I've been saying the following thing and people agree with me when I say it, but it does not change. Our industry has an unhealthy infatuation with UI automation. Oh, well, I, I, I, I'm preaching to the AB testing choir right now. Right. I was just like, no. So, so let me add some drama and push back. Like, what did you say? Unhealthy, unhealthy infatuation with the UI automation. Yeah. I think that's bullshit. I think it's like a way, tragic, tragic sickness. Okay. Fine. Right. Something on those lines. And maybe 15 years ago is an unhealthy infatuation today. Maybe it is a tragic sickness. Yeah. Of UI automation and unhealthy. I think the difference is like the person who's been told he's dying from cancer in six months versus the person who eats a little bit more sweets than they're supposed to, right? No. So it's funny. And I brought this up before and I want to move on to the, uh, to some more stuff about the article, but I remember I posted that on LinkedIn once in response again, I don't 99% of the, of the posts I see on LinkedIn that I want to jump in on because I think they're just blatantly wrong. I don't bother because I just don't want to deal with it. There's no reason for me to fight that fight anymore. I am so moved on, but sometimes I go, you know what? I want to share my thoughts here. Once I shared this exact same comment and then, uh, or yeah, I think it's probably the exact same thing. And again, I got some folks on the other side, the folks that believe in that there will always be a massive number. Cause it needs to be for their livelihood. Uh, uh, armies of dedicated testing specialists agree with that because again, they're also anti, yeah, it's a big generalization. This particular person, anti-automation in general. But again, we agreed on that point. And an argument I got was one is, you know, it's two, it depends on business. It's the whole depends on business context thing. And well, maybe you have to test the UI because of blah, blah, blah. And you know, my argument against it is, well, if you, if you really, if you have to test through the UI, you have other stuff to fix, but they say, we can't fix that. So people, they dig a hole, dig an excuse. No, no, but to be clear, you do have to test through the UI. You don't automate test through UI. That's frigging stupid for sure. But there was another thing I wanted to throw at you. Well, actually, actually with one exception, which you have recently talked about and they talk about in this article, right? Which is the codeless automation, which, which, which is a bizarre concept, right? And it's really just a fancy term. I believe it's a fancy term for record and playback. Yes. Which I think today's record and playback is so much different than the horrid record and playback from the future. In fact, I'm going to read the whole comment I wrote. I wrote two lines. I will take this moment to restate something I've been saying for the last 15 years, our industry has an unhealthy infatuation with the UI animation. Second sentence. In my opinion, the record and playback of today is more than sufficient for any web UI testing and that any need for extensive UI tests written in Selenium Cypress Cafe could probably benefit more from a rearchitecture than a bunch of fragile tests. Amen, brother. Not surprising, but I want, I want to throw a comment at you for, uh, someone who I respect a lot said, personally, I feel like the infatuation with UI tests, these, my words is great, is a manifestation of Conway's law. Conway's law is what it says your organization will match your architecture. So when you hire a bunch of S debts, you end up people who will write them because they own them. Which becomes status-cool overall, because people associate QA testing with rights tests and the most common ones that anyone with a QA title write up end up being UI tests. So it's a going back to, this brings us back to the article because we have testers and because testers don't want to do bullshit testing, they end up writing a bunch of UI automation because it's almost what that's what they're expected to do. We have this maybe I'll hypothesize here. We have a self-fulfilling prophecy where we have a bunch of these fragile UI tests cause that's what the testers are supposed to, these testers are supposed to write and it circles and it's one of the circles of hell. Right. It's essentially, we have to do this. Like if you boil it down, it's like we have to do this because we've always done it. Yes. Right. Which is wrong. One of the software's, uh, wonderful tautologies. So what makes this whole thing more interesting, rewinding the stack is someone on our Slack channel group, which you can go to modern testing.org and find the link. It works for at least 25 more days. Cause I just updated it. And thank you to those who remind me when it's, I don't know why my reminders aren't working, but remind me to update the link from Slack, et cetera. So someone posted a link from the U S Bureau of labor statistics, which I found fascinating and contrary to something you Brent said five minutes ago, where you said that eventually software testing will be at a point where there's so few, we can consider it dead, what they're showing with what the U S Bureau of labor statistics shows is that software testing as an occupation, as a dedicated occupation will grow by 25% between 2021 and 2031. Okay. Now what's missing from that is software development overall growing by, you know, a hundred percent and it's growing by 25% or is, uh, you know, I don't have that, the full context of that number, but what this says is we're going to have another 400,000 testers in the U S that we have right now in 10 years. Um, will we see, I think that the thing that's interesting is the prevailing assumption in, and this is, this is the thing I guess I would question is that when, when that article tracks that trend, right. To what degree are these testers actually doing the work that, uh, we are accustomed to them doing, right? Um, it's like, even the article you sent, uh, talks about, right. We're going to be less software testers and more quality engineers. Actually, I'm going to backtrack this whole thing. I'm going to leave this part in the podcast, but I just looked closer here. And nevermind as Rose, as Roseanne, Rosanna, Dan may have said at one point, the article actually shows the page is actually showing statistics for, they've grouped software developers, quality assurance analysts and testers into one group, saying that entire group's growing 25%. So maybe, maybe it's wrong. I don't, we don't, I don't have the breakdown to get it right. Got it. So we'll continue looking at this data. I think it's interesting. I think if you look at the industry, you know, maybe it's, I don't know, I don't know what to think here, but worth looking at, look worth doing research. Again, I don't think testing is going away immediately. I don't think any organization should fire their testers because they've heard that not having testers makes you faster. And I know you don't believe that for it either, but we do believe that as teams get better at delivery, that the need for that dedicated testing specialist, uh, decreases and in some cases it is not needed. And that's something that was saying forever, no new information. Let's go on. Okay. Fair enough. Yeah. Fair enough. All right. Anything else to add on that, Brent? Yeah. Let's just look at the article, right? And just to go through it quickly, they're saying recording playback, DevOps and agile development. Wait. Uh, the one important thing I think that is missing from here is fast feedback loops. They talk about agile developments, but they're specifically talking about testing early and often making it something continuous or discrete, right? But the thing is the real secret about agile development is adaptability. You don't waste your time on things that don't matter. Like there's, there's, there is one exercise I just did recently with, with my own team where, uh, we're building a whole new product and I put them in a room, created a basically very much, um, Eric Ries style, right? We, we designed an MVP. We created, uh, we identified early adopters, started putting them in a room and getting their feedback. And now I just sit back and, and my team doesn't argue with me anymore around, Oh, we got to do this. Right. Because they're hearing it from the customer directly. As we've, as we've set in the, in the MTP principles, the customer is the only one qualified and I can see it from my own team's behavior that they realize that cause everything else has been theory. Let's, let's drill in on that a bit. Sure. I have been, I have kept my Eric Ries book on my desk a lot recently because I've been quoting it a lot and holding it up and showing pictures of it. I hate even talking about agile as a thing because it's just been so bastardized and, and screwed up, but it's hard. I want to talk about fast feedback loops and being adaptive being lean and being lean and learning and being the, the value of the engineering effort being in learning and having some discussions around, you know, what that means there is some fear sometimes to deliver something that is not perfect. And then I just happened to read an article today. I didn't link to it anywhere, but it talked about perfect being, didn't say perfect being the enemy of good, but you're never going to be perfect release now and learn. And someone said to me, which is, well, I'll tell you what I said in a second. But I talk, I was talking about doing a release with just to a couple teams. Didn't have a lot of oomph, but would generate a lot of organizational learning via the onboarding process via via a whole bunch of things. And the comment I heard in a discussion was you only get one chance to make a good first impression. And I'm curious, I'll tell you what I said in a second. While I agree with the statement in its original context, I do not think it applies to software. Oh, no. Uh, okay. Is it my turn to do to reply? Go ahead, Brett. Yeah. So yeah, you're right. You only get a good, you only get one chance to make a good first impression. Okay. But my counter would be, all right. Uh, what's your evidence that the second impression isn't good enough or the third or the fourth or the fifth. When, when I see that, right. I remember back in the day and I pretty certain I've talked about this. When, when Google's first came out and was before I went to Bing, right. People were like, ah, Google's getting into the OS. Like what a bunch of idiots. Like we have 40 quadrillion lines of code and you know, uh, we have more man hours baked into windows and T that have ever existed in the planet history. Right. They were just saying like, that's an impossible task. Why would, why would Google do that? And I remember my manager specifically talking about the search engine and they're like, it's buggy AF. Why the quality is just awful. People are going to abandon it. And I remember talking to him and I'm like, yeah, you're full of crap, dude. You do not understand what you're talking about. Cause if that were true, the stock price would be tanking. And what ended up happening is Google, uh, because they were, did a very good job on their telemetry, they've did a very good job on fast feedback, the experience that customers had the first time through, yeah, it was buggy. But you know what? The second time through, all of those bugs were gone. And the second time through a lot harder to find a new bug. And that second time through was not that long after the first time through. It wasn't, it was just like two weeks later. And so what ended up happening is those customers did not walk away with a view of this product, this shit. They walked away with a view. The quality is visibly improving in front of their eyes, right? They walked away with a net positive, not a net negative, but the secret is the fast feedback loop. Yes. If the bug stays there for three years. Yeah. And even the bug, it's like, this would be great if you could do X. Yeah. And then all of a sudden it does X in a week and then it does right. Some Y and two weeks and X and Y and Z in three weeks. Like, Oh my God, this just gets better and better. I want to keep going back and using this. It is so hard from my experience. I have not yet, maybe you have. I have not yet found a way to convince people that, that what they are proposing is significantly more risky than what I am proposing, but it's really hard to convince them of that without them experiencing it from my ex from. Right. I could send them to Ryan, uh, Ryan Irnsons book, right? But even then it's, it's so challenging to battle. Well, yeah, that's a great thing, but it's all theoretically, or, you know, my products, the snowflake or, or those types of things. Those arguments are difficult to push back on. Yeah. So when I heard someone say you only get in regarding a software release, you only get one chance to make a first impression, my immediate answer is that phrase can go, I agree with the sentiment reps, not it's okay. It was a conversation with someone, uh, who took it. They didn't, they weren't offended. Ah, got it. The, the, the, the answer was something like done that phrase as and then we had a discussion around why. So there is, and this is really a learning. This is a gap like in crossing the chasm sort of gap or a learning curve. You see the same thing come up and people argue against us when we say only the customer can evaluate quality. It is difficult if you haven't done it yet to make the jump from we got to get this right to we got to learn as fast as we can. We got to have that fast feedback loop. It's a jump teams have to make like we have to get this as they can think back in the old days. We would test the crap. We would do the bug count coming in as less. Okay. We can ship shipping that way now is irresponsible. And, but it takes like, look at the argument we get against that. Like it's important for me as the tester to evaluate product risk for my stakeholders and make sure I'm making the best. They will do a crap ton of work and the customers will get a product. And as Eric Reese would say, and I don't know if I'm a disciple, a follower or a fan or a reader or a believer in Eric Reese, but what he would say, he would say, should, and he has said, show me a product with no bugs and I'll show you a product that shipped too late. Yes. Or still hasn't shipped. No. So it's a jump to make, right? You go from, okay, I, this has to be, I have to do, I have to do all this work to make sure I do my due diligence to, we have the ability to, if we, if something's wrong, I can change it in 10 minutes in a, in an hour. Versus and just making that jump and being able to say the focus is on fixing forward versus fixing ahead. That's a big jump that a lot of teams need to make. I think it's probably the most, maybe one of the most difficult jumps to make in, I hate to use the word agile in adaptive delivery. I'm going to call adaptive delivery with the capital A and probably also the one blocking the most teams and the one that gives teams the most benefit. When you learn as a software organization to deliver, we do, man. When you learn as a software organization to deliver with fast feedback loops and count on fast feedback loops and rely and use those as part of the way you deliver. That's a big, that's a, that's a jump. That's a, that's a lock step jump in your maturity and your capability and your quality. Okay. Given that you just said that hold on to hold on to that thought because a well known living expert in testing, uh, did a comment in that same thread. I wish to share that comment. Testing is not quality engineering, right? Again, this is a well-known testing expert. Okay. True. Testing is learning about the product so that the people designing, developing, and managing it can decide whether the product they've got is the product they want. Okay. Yeah. I just hate that because I don't, I don't want to go into. No, no, no, no, no, no. I want you to remember what you just said about Eric Reese. My point isn't around where you and I agree on tests as the people who provide information. Yeah. Right. You and I agree that that's bullshit. That's total crap. But this well-known testing expert is claiming that testing is learning about the product so that people, the people designing it, developing and management, managing it can, can decide whether the product they got is the product they want. Okay. Okay. Given what you said about Eric Reese and in my view, the testing experts own definition of testing is testing jobs going away. God, I sure as hell hope so. Well, no, they should be the proper kind of testing. They should be modern testing. They should be experimentation testing. The way you do what that person described is analytics, data analysis, fast feedback loops. You don't do it by holding onto the product and, and, and making sure it gets your once over for your stakeholders to make the decision on whether it releases or not. But my, my, apply what he said to the actual real type of testing as tests, real testing from an experimentation and metrics point of view. And I actually think it's kind of accurate. I don't know. Okay. It's so depends on how you stretch it. That cause my view, my view is the Eric Reese model, right? That migrates over to the, to the product manager's job or, or it's a portion of the developer's job. Sure. It's like having it, having an in-house person who, who again is not the customer. It's the ad, not even the champion of the customer as, as your, um, meamish slide details. It, I'm like, why would I ever hire such a person described on that one? I would rather have my people have direct connection with the customer and not have some, some in between like the product. The product I want is not the one on paper. The product I want is the one that actually adds a value stream that I can make a stable business plan off of. It's it, that is an anti-modern testing comment. Unless you squint and stretch it to be, uh, testing as experimentation. And then of course, this, um, because only the customer can tell you if it's the product they want your stakeholders can't. Right. And, and certainly having, having someone in house and unless they're the ones going out and talking to, to the customer, they're not going to be able to do that. But I'm going to tell you that job has traditionally been viewed as marketing, not testing. So, so this is the same thing. And again, this is, and sorry, and listeners actually not sorry, but this is where we're at. This is a conversation we've had the people who want to be doing the testing like Brent and I used to do in the nineties. Want, they don't want to do anything different. They want to test like it's 1997 and that's fine. They're very good testers for 1997. The world needed those in 1997 software, most software, much software is delivered differently today and no longer benefits from that kind of tester. Yes. Yes. I mean, we're not here. Well, as we've said many times before, we're not here to kill testing. We're basically saying the motor, like that's the way the wind's blowing. What's rough here is that Brent and I getting going back to Myers Briggs part horoscope part science, mostly horoscope, but INTPs we hate inefficiency. And when we see that we see this again, fast feedback loops. We love them because they're super efficient. When we see little blockers come into that feedback loop, why am I waiting for this? We get really, really mad. Yes. No need for it. What the hell are we waiting on? I told, I have told my team, done is my second favorite four letter word and wait is absolutely my least favorite four letter word. I like that. I like that. We weaved around that and got some good segues back and forth, repeated a lot of the stuff, but honestly, it's good stuff to repeat. You know, every podcast isn't about the same stuff. We talk about stuff differently, hoping that some of this will stick for those that maybe haven't got it yet. At least one person someday. One person someday. Yeah. I, it's tough. We're not, we're just trying to tell stories and get people to understand why we think the way we do. And here we are. Testing is maybe a dying profession. Maybe not. We may never know. There may be testers, like as you called out in 25% growth in tech field, there was right. The AI bit is interesting. Well, if I could hypothesize on growth in general, and again, the, the paper was everyone. I think tech is going to grow quickly. I think, you know, that original statistical study was 21. We're seeing generative AI become a very interesting thing. Interesting thing to many companies. We are, I think there's, like I've said before, we are on the edge of some significant advances in software. I'm not going to give away spoilers. I listened to an, listen to the audio book of The Origin on my hike a few weeks ago. And there's an AI in that book and it's, I'm not going to give away anything. The book is the audio book. The book is not great, but fun, but there's an AI in there. It makes you think about things AIs could do. And then I watched the Mission Impossible movie, which has an AI in it last night. And it's, it's funny. I think we're going to look back in 10 years and look at what AI actually is then. And just laugh at what fiction made it out to be here in 2023. That'll be interesting. But like I said, AI isn't taking jobs away. So people that use AIR, I think it's going to be a lot of people. Please don't call them prompt engineers, but there's a lot of people building generative AI models to help solve significant customer problems or new problems we haven't thought about. But maybe with fewer engineers than we would today. So it's, I think there's a shift. Not only is there a growth of tech, but there's a shift in what people are doing in order to deliver value that solves customer problems in the next 10 years. I don't know. 10 years ago, we could not have imagined what's going on now, nor will. So these, these predictions on growth are, they're, they're our best guess. I do predict right now that there will be churn in the industry. You know what? I'm, I'm slightly less pessimistic on this than I was a little while ago. Like, um, my team, we are a few weeks away from shipping our first actual, uh, in the end product that is heavily reliant on LOM. And, and I will tell you, like there's language I shared a little while ago, right? That LLM is kind of a schizophrenic. It's some part, it's a genie one part, it's a parrot and another part is an SME. And so now there's like, so even language, like I would call up when my ICs and I'm like, Oh my God, the genie is pissing me off. It's, it's like you, you add. I changed the sentence from is something, something to our something, something, right? It was grammatically incorrect, but just that one tense change completely changed the output. It's fascinating, but I will absolutely agree. Those who don't join or understand this, this, this change and have, have the ability to quickly learn. If they get behind, I don't see how they will ever catch up. I see the way the industry is going forward. The people who are, I think the next most at risk of being laid off are those who have not figured out how to learn and execute off of those learnings quickly. Absolutely. And one thing I talk about a lot, even in, I talk about a lot, I won't give examples is the need to be a generalist in software is just becoming more and more important. I've been talking to a lot of new and career are about to be new and career folks. And I bring up the fact that I spent the first five, seven, eight years of my career writing in C only. Just wrote C code and eventually added some assembly. That was about it for the first, you know, seven years of my career, maybe more today, working on software today, writing in one language all day, probably getting rare. And then in addition to that, you're not just writing code, you're gluing technologies together, your, your configuring web services and, and, you know, yaml and gluing this to that and doing an API here to compress this to there. It's changing. And I think with generative AI and, you know, who knows what other tools coming on that the ability to be able to do a bunch of different things comfortably is going to be a key in being successful in the long term. Yeah. Agree. You're making a face. I know that maybe I'm, maybe I'm way wrong. No, you're, you're, you are totally correct. Cool, man. Well, let's do the mailbag next time. If we get it, unless something else comes up. I don't know, but I think, uh, we talked a lot about it. Lots to think about. I think we talked about some old stuff and got some new ideas in there. Uh, we'll see how good it ends up when I finished editing, but probably pretty good. Probably this is the bed best podcast from AB testing. You listened to, um, one of the best AB testing podcasts of today. Right. If let me do, actually we just, we have it just a few more minutes. bonus material. I'm trying to find the article. I lost it. One more thing that the test expert mentioned. I would question if test experts, something that someone has a title, someone assigns to themselves, something that's assigned by a community or like, where does, how does one become a test expert? Well, in this particular case, I'm, I'm leveraging the fact that by the, by the, the people who invoke quotes of the test expert, I'm a short answer. Community is, is the one I'm using. Sure. Feed me the quote. All right. So they quoted something from the article. Quality engineers will need to ensure business factor quality into every aspect of the SDLC and increasingly the value stream management process. And the expert came back with three substances. That's not what testers do. That's what management does. Testing is not a dying profession. Okay. Again, straw, man's against straw, man's. It's fine. I'm just like, okay. If testing isn't going to care about the, the, the value stream management or the impact of the business, right. Principle number one and, and testing's job is essentially to be the internal expert that the team has gotten the product they want it honestly, I don't see how, how they can conclude test is not a dying profession. Well, right. Because there are so matter, so many better ways in today's world to achieve those goals. Well, this is the thing that, and again, we're going to end here, but this is what bugs me the most about some of the experts is they pride themselves on critical thinking, yet they can't take a step back and say, what are some ways which this may or may not be true? What are some, is this, is this thing I'm talking about is the execution of this, the only way this statement can be true. And that's the statement that's being made here. And you and I are saying, Hey, there are other ways that may be more efficient. And that comes up a lot when we talk about these things, they say, nope, that won't work for me. And I, like when I say teams are shipping software without writing UI tests or teams are shipping software without having dedicated testers, they go, nope, that won't work. I take a step back. Look, teams are doing this. Can you imagine a scenario? This is true because it is. So check your bias, check your teals digging in. Think about a scenario. This could be true and apply some fricking critical thinking and figure out if you need to adjust the way you're thinking, can you, what they're really saying in my context, which I refuse to change any views on this statement is true or false, right? This is from people who say they, they're driven by context and they're critical thinkers, but they're not applying those things when talking about subjects like this, because if this were true, if software testing was a dying profession, and this is the end, it's one, it's worse. Like it's bad. If you are, if you think the only thing you could ever do is software testing, you see this article, you go, well, that can't be true. And I refuse to believe it because my livelihood is on this. And now think you're in a position where you're an expert and your livelihood is based on people being in this profession that cannot die. Otherwise you don't, you can't make any money because you refuse to do anything else, of course you're going to dig your heels in, of course you're not going to use a critical thinking. Of course you're not going to apply any context or perspective. Well, it was a Mark Twain quote, I forget it. It was something around a man's opinion. Uh, it's more wittier than what I'm doing, but a man's opinion is directly related to their incentive, right? It's essentially something new comes out. Their opinion of that new thing is going to be directly related to how well that enables them to continue to do their job. Right. That was, that was delirally quoted. But I would say, you know, behavior, my quote is, uh, behavior comes from motivation. I was going to work with that motivation. This one, it's crystal clear what that is. I don't know the Mark Twain quilt, but one of our listeners can find it and post it on our Slack group. Yes. All right. Okay. That has been episode 184. Believe it or not. The countdown to 200 continues. I'm Mr. Weasel. And I am. 
