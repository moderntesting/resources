Welcome to AB testing podcast your modern testing podcast your hosts Alan and Brent will be here to guide you through Topics on testing leadership agile and anything else that comes to mind now on with the show Hello everyone and welcome to another morning edition of the AB testing podcast Yeah, how about that for or like getting back to the old days? Yeah, I had a conflict this afternoon with which has been our new time for the last several months or so, but as Some of you longtime listeners may recall by the way I'm Alan he's Brent and he's the one whose microphone still is picking up his no sounds and We'll figure out what to do there, but we are recording in the morning now You listen to this whenever you want to it could be the midnight show, but we're recording in the morning So what that means is I haven't finished my second cup of coffee yet Brent probably has he looks like he's been up. He has his McDonald's coffee the big one the cafe How you doing, man? How I think our listeners want to know most of all How did that second shot and the aftermath go? I'm pleased to report. I think I was one of the lucky few That literally got nothing That's fantastic. I'm hoping I'm one of those two Yeah, I have I have blocked off my schedule for the following day just in case Yeah, I both times for the shot I Went in for it in the afternoon and took the rest of the day off went straight home and I'd scheduled it on Friday just in case The only thing I could say every so I Physiologically react negatively to strong Pressure changes in the environment. So this last weekend it went from like super sunny to really crappy so on Monday, I was feeling like complete crap But that's close to three days after the shot and there was a huge pressure change. So I'm I'm far more likely to attribute it to to that aspect of my bad genetics than to the shot Cool enough. Cool enough. Well, I'm glad to hear that. I don't know if I have much else To share tonight. I mentioned last time that I'm I did I will be giving an AMA Oh, this will go good into our some of our topics today, but I'm giving an AMA ask me anything For those who don't like it when I speak in acronyms The future of test automation, it should be a lot of fun Yeah Because I of course I have I have a different view of the future than a lot of folks do it's It's interesting because to my perception you've actually done that talk I don't know feels like three or four times in the I've done a future of testing and you know pretty Predicting things is hard, especially about the future I think this is just a chance they know That given this topic in my opinions people and given the How many people I've pissed off on the internet? About my opinions that this will bring I think this is to bring in lots of questions and viewers So we'll see it might might be might be just the three our three listeners there in the AMA Saying yeah, you're right. Now you go. This is boring, but we'll find out anyway That's the only upcoming a thing. I have coming up. There's another conference this summer Someone just asked me over LinkedIn and and in this day of these days of pandemic and everyone's at home I'm saying yes to a lot more of these than I Probably would if we were in a different global situation, but I'm doing another one this summer I'll talk more about that when we get closer Nice. Okay. All right, man. You want to get into our Our A B testing podcast topics. Sure. Yes. And by the way, this is episode 141 Counting down to 150. Should we do something special for 150 when we get there? Sure. Okay. Yeah, that's Up to our three listeners if you would like to want maybe to segue into our first topic We have a slacker group one of the three dot slack calm You go to modern testing org and find a sign up link where you can join our slack and drop in and ask us questions or Ask questions to the the other two listeners who are there this week We had someone drop into the slack and ask us some questions about some of our stances which we can get into or not I'll leave that up to bread. The thing I want to call out is We welcome everybody if you're listening to this podcast and you think we are crazy Create maybe crazy. It's not the right word. If you think we are our ideas are invalid or if you think That we're just dumb old guys who don't know anything. You're partially right all questions are welcome You don't have to just come in and be a be a fan. You can come in and challenge us. We like it we Stand by the fact that we're we believe that we aren't inventing anything new that was never our intent But that we are just trying to identify And explain what's already happening happening happening happening in many parts of the industry So those are the discussions we have and if you don't get it Or if you don't get how it works Or if you don't get how it works for you or again, if you think that you need to explain to us Where we're right and where we're wrong all that's cool and welcome. The community is there For the open Objective Conversation on these on this front like in in my view and I'm fairly certain Alan shares this view There's a lot of places in what we talk about where Honestly, we kind of know we're right Science backs it up a good portion of it experience backs up the rest But it is context sensitive The we want that conversation To be happening within the test community. That is the absolute Even if we're wrong in your context We think the single most important thing is to Get the conversation going it one of the things that a term that I don't It was a term that I'm fighting against this sort of intellectual laziness within the test community this prevailing belief that It ain't broke. But Brent we're the only ones with critical thinking Yeah Walk that talk buddy. Yeah, I don't think we can make that statement because and I forget Because we're we're we're lacking serious study and something I forget. Yeah social sciences Yeah, oh Can we um, maybe one topic not on the list of yours? Can we do one thing I wanted to talk to you about that isn't on our list? I'm gonna do it Actually, I'll do it now cuz I already brought it up along those lines something This wasn't in that now moving on from the one of the three you can discuss this more with me explain it to me You're welcome to come to our slack community talk to me there or just message me on Twitter So you've heard us rant about checking versus testing how we don't really care. There's another Pair a false dichotomy coming around that I'm seeing more and more in tweets and articles This is an idea of shallow versus deep testing Okay It's from the look on your face and the sound of your voice you haven't seen this argument before no It goes back to my developer mindset thing Which a lot of people versus a tester mindset versus BS which a lot of people disagree with my stance on that and that's fun I I call it like I see it and if I see it differently from you, that's a discussion we can have I'm not trying to prescribe anything just trying to describe what I see so the shallow versus deep The idea is yeah sure developers contest think Oh compromise But they can only do shallow testing because they don't care about deep testing and you need to do deep testing to have high quality That's the statement What's the evidence of that? Study of the social sciences and Sure because the study of the social sciences is going to address the question or rather around whether Software products are better with or without deep testing. I would like to understand that Well deep touch Brent we could do devil's advocate on this and I yeah, maybe there's a whole Modern versus we still have to do a rehash of a modern versus traditional on some of these topics but the argument is that deep testing Defends the customer against risk or those are words I made up not not the actual words But deep testing is where we find the issues that that impact the customer all these edge cases and things like that Part of me when I when I hear this around shallow versus deep Right part of me feels like it's code words for the checking versus testing conversation. Well, it's not I mean It's a different it's a different conversation But my arg I don't want to go deeply into this but it's often described as shallow versus deep and I think There is no dichotomy there You do deep enough testing for the context of the software that you're shipping if I'm shipping 50 times a day I'm my deep testing is my analytics and monitoring The dichotomy of shallow versus deep I think it's Constructing and a needless argument Its purpose to me it feels is to sort of create a Foundation for an argument or a debate That's that is So purpose is to say only test can do it right? So if if you agree to that point Then to me, it's a debate argument. It's not really much to do with with technicality because the reality is You should test Exactly the amount of things that you should test And it doesn't actually it in my in my experience. It doesn't actually split around deep versus shallow right it more splits around customers Customers need customers value that doesn't mean you should be intellectually lazy when you go through it. Obviously Deep versus shallow is something that you should Think about but when I think about deep I tend to think of it more along the lines of Systems thinking type of things that we've been talking about before You gotta know how the dots are connected together and and how it may Have those integration points. Yeah, maybe again Have to let the context dictate the depth of your testing I think there's an argument that all and Well, it's not stated correctly. So someone will correct me and say that's not what they're saying I will say that there's an assumption that I've read about it and maybe you're right I think it's there as a point of controversy and to justify kicking your heels in and saying the way we've always done it is the way we are and one way I've described it recently is If you want to compare Proponents of people in checking versus testing and shallow versus deep versus what Brent and I I think our intent is the same We want to help testers cope with the changes going on around them Our approach is to help people navigate the change and be successful in flowing forward with the change Whereas I feel like a lot of these Discussions around deep versus shallow and checking versus testing and tester mindset, etc. Are a lot about helping testers Continue to justify the need not to change while the world changes around them. Yeah the Completely agree the one thing I was thinking of piggybacking and I don't know if this is something that you find interesting to think about how might the modern testing principles In your view Alan be used for evil Let's imagine. Let's imagine some some executive Happens upon it and says oh my god These guys are completely Justifying me doing this and the this is bad Like what's your thought? I I love that question, especially since You know some of the crowd likes to blame the challenges in testing on Management and executive management. So let's go ahead and assume that all managers don't know what they're doing I think very easily you look at number seven and go. Okay, let's get rid of our test team We look at number six and we use that to collect a whole crap ton of data We don't know what to do with this not strategically planned That's what says we use data extensively So you have a so you now you have no testers and a crap ton of data With no one who knows how to look at it And even if they did they would go this is crap data in believing the customer is the only one capable judge quality I'm working backward that is you don't do any testing. You don't ask your developers to do testing You just ship stuff trade out to customers No matter what regardless of the context and you hope that this massive dump of data that no one knows how to look at Will help you solve your quality problems So how's that for a start? Yes so far though the path you're going If a company I don't think a company would do that strategy for too long because I think that that company would fail Oh, of course they would they would massively fail. So you know, so you're asking like How could an executive use what we're proposing? To do evil but still succeed. Oh, I don't I don't know. I don't I I don't see a way to do evil without success here You could you can be dumb and implement them and egg and this is the my last statements We're all about the continuous barrage of straw man's that come up in the world and especially software development Agile doesn't work because I tried it. I did a really poor job and it didn't work X does it work for anyone because we tried it and used everything did everything wrong about didn't work You could you could straw man through you can find straw man arguments against all these but there's no As far as I can tell unless you are thinking it's something I can't I don't know how you use these force For evil and success at the same time you can be dumb and dumb can be evil, but you can't I Don't see a way to use these and be evil. Am I missing something? No, I was I I struggle with that as well. Right? It's it's the like the the one argument I've seen waged against us on this one is essentially an executive could use it to justify the removal of their test departments it sort of the Sort of we're feeding the automation argument, right? We're encouraging the industry to kill this Discipline, but that falls into the dumb and not evil though, right? Well, it depends it depends right it depends on where you stand right if you're if if if you view testing or being a tester as As essentially you're a member of an important craft Towards the software development lifecycle like you and I both were in in in strong in testing back in the day, we both had many arguments around Defensive I would argue defensive arguments around the importance of our role, right? We were always kind of defending the the value of of tests through a variety of means like actually back in the day You when you were running the big The big tlt meeting, uh, it was a test leadership team test leaders and execs from around the company right definition overdub Alan Alan played a a central role in sort of Evaluating salary equivalency between tests and in development as an example. Yeah, we had a lot of Yeah, a lot of emphasis was put on protecting and value and valuing test as a discipline across the company and this is You know, there was a time microsoft had just short or just just right around 10,000 dedicated testing specialists right and even as we we made We we gained wins Around sort of salary equivalency like the the defensiveness of the arguments that we would make defending how important we were In my view, maybe your experience was different never really stopped Right, and that was because part of part of it It's still i've made a statement before like the number one value proposition of a test team from those not within the test team and again defined by actions not by verbiage is uh Where the organization scapegoat when when shit goes out the door So I think part of what modern testing is trying to do is say hey Look, there's a these are a set of people with with very strong critical thinking skills And they can bring way more value Than just simply the team to blame when when the sky falls and a lot of the activities that that We see that that we're honestly very important in In the world where with on-prem products or shrink wrap products And that world is not yet dead There are lots of products going out the door that aren't aren't updated or shipped via via the cloud or or you know app updates But in the service world, there are are better techniques and and again pivoting off of accelerate Which is one of my favorite content sources, but you combine ryan Of everyone i've spoken to and i'm not aware of any formal study on this but literally a hundred percent of those folks who who claim agile doesn't work It doesn't take much to realize that that team Never got to a point where agile was adaptive Adaptive right right. It was still iterative. So they never They never actually got to yeah, of course, of course, and I think Rewind the stack here a little bit a lot of the arguments against what we're doing are Based on I just don't get what you're talking about. We don't do it that way or But the arguments are based on just That hasn't worked for me. I haven't tried that even I do want to Rewind that stack so shallow versus deep and the whole Set of tangents they're worth talking about but that makes me in real time because we are an adaptive Not predictive podcast I'm gonna change the order because I think that makes me want to go into You're talking about traditional testing Let's talk about this link You sent me and why you sent it to me and the point you want to make there because I think it's I think it's Relevant most relevant to this conversation we're having right now. And while brent if i'll if i'm a good Podcast editor i'll put the link in the show notes, but you know how good I am at that but brent sent me this thing of Well, actually why don't you describe what the web page is? And the point you want to talk about yeah so There is a company called own net online And I sent this to alan late last night. So I will Admit that there is A good deal of research on on this That I have not done um so listeners should definitely not walk away with Uh, at least brent's opinion is that this is hardcore facts. Okay. I don't know who this company is. I don't know who funds them however They do seem to be Tracking summaries around various occupations and there is a thing Uh Down below and for those who wish to Follow along ideally not drive me add some missing context So brent described what onet online is and what we're looking at the page. He specifically sent me Was a summary report for software quality assurance analysts and testers. That's a mouthful for testers Right, so we're talking about it So it has like the typical tasks they do the skills they require what knowledge they need etc, etc So the thing now brent is scrolling to the bottom or talks a little bit about where uh Where jobs are going, right? Yeah. Yeah. Yeah. Yeah, so it's very interesting in terms of Like the activities and the sort of things that they talk about right. I look at skills and tasks Right the tasks very much align with sort of You know the old what we call traditional testing, but you look at skills. You can definitely see uh, there is a lot of Technology that is viewed as important to this like I if you look at the technology skills, they have a thing They have a little fire symbol that flags hot technology the technological requirement technological requirement And you look at it and you go, okay There are a lot of things here that are a little bit more technical than say what we what we see in the traditional test roll right, um Although it does humor me because cobalt is listed in in uh software Don't quite understand that connection but at the very bottom it talks about They they're doing some sort of predictive analysis And they have projected growth from 2019 to 2029 and it says much faster than average eight percent or higher so they are absolutely Uh, this site is absolutely predicting. Uh a growth in this space Now, uh, one of the things I wanted to talk to to alan about is okay What's that mean alan? What do you think like are we are we? Are are we on the side of of wrong here is all of the the uh, Mtp opponents correct in their thinking that that essentially our bubble is It is basically just in uh unity and microsoft in seattle Well, you know, it's at many more companies than that. So that's that that's that's that's a Real straw man. So I think you could look at that and go that eight percent is based on one point Projected 1.5 million current people in software testing and a growth of whatever eight percent of that is So yeah, you could say oh there's lots of growth here testing testing is not dead So you could say that and of course that data is in a nutshell. Uh I went to look at the reason i'm pausing here Is I went to look at software developers to compare is testing growing? As fast more or less quickly than software development and now i'm questioning the data on this site Because their numbers for software developers are exactly the same as they are for software quality assurance and testers So there's some weird rounding and bucketing. I I now have questions about the data entirely Well, okay, so yeah, maybe But but overall let's assume these numbers are correct. Uh, it's fine. I think If we look at that cost of innovation curve that we've the Bell curve of where people are on moving towards things that sound like what we're talking about with modern testing We there's a growing number of people Adopting things that are like modern testing whether they know the name of it or not teams are It's really just agile and lean and we're thinking more about again modern testing isn't that modern. It's not about testing It's the reaction to our reaction to what we call traditional testing where testing is done often by a siloed test team or even by a air quote agile team where a tester is Where a dedicated tester does all of the testing for that team? We're talking about how teams move to being able to ship multiple times a day and Base their changes on customer feedback And use data in order to make sure that the customer is always first in how Crap is getting done so The fact that a chunk of the industry is still going to live in the world They've lived in for the last 20 years i'm not surprised at all Uh, but of course predicting things is hard, especially about the future I definitely see more and more teams, especially as more and more software moves to the cloud Doing things more like modern testing and needing Not zero necessarily but fewer testers going forward again. It's a data. It's a One piece of data amidst a system of changes. So it's hard to tell what it really means but actually Yeah, I dove in deeper because I noticed when you went to dev which was a very interesting idea Like when you went to dev at the very bottom of it it it warns that data collection is underway But then I started thinking through and going for example, I just looked at program manager and they don't have that listed Now i'm actually thinking they they might actually be combining Devops roles Because there's no position for that as well. Well devops is a culture not a role it's From the context of this database. It's both alan Yeah, and i'll give you another interesting thing because they they need to find the right equivalence classes or find a way for us to group those Because if I look under computer programmer The trend there is well one It's wrong because the the median wages are completely wrong But they say the trend there because I think because nobody's using that title anymore Here's the challenge. I think that title's going away because that one's declining by 1 percent and they say there's only 214,000 of those employed That might actually I mean that last fact might actually be true Like I I haven't met anyone that went by that title. Yeah, so what I think here is there's there's something here But that you need to actually apply some data analysis to all the data here to tell a story That's my take So sure someone could take this and I have a book usually on my desk. It's on the floor. So I could go grab a called How to lie with statistics and i'm sure I could find some quotes to use from that with this data But i'm not so Let's uh drop this and move on to a mailbag question. I found the mailbag Wave file by the way, so we're saved. I don't have to make a I've been purposely making bad ones to force myself to Find the original slightly better one slightly less bad. So we'll use that this time But The question essentially is if you want to ask a mailbag question, by the way, you can ping me on twitter you can You can send me an email the easiest way is to Go to one of the three dot slack.com and ask a mailbag question Or you can ask a question and you just tag it with the mailbag emoji And it'll show up in our mailbag channel and we'll remember to talk about it Ringo aka, richard starkie asks Could you discuss in the next episode on what to automate? How to coach devs and testers on defining criteria on which tests to automate and we all know the answer That's what we're going to answer and the answer is obvious You should automate All of the tests that should be automated and Not one more or one less. That's exactly it. So we're done with that. So the next topic We should probably go a little bit deeper because that's the challenge That's the challenge in test designers is of course figuring out which of those tests are to be automated If you are in the oh my god, I love selenium. It's my life camp Your tests to automate are everything I can possibly do in the web ui of my application Which uh probably isn't right? This goes back to and i'm going to get up on a soapbox And I don't think it's this one people won't argue with the manual versus automated and Teams that have separate automation teams and one one thing worse than having a separate isolated dedicated test team Is to have a dedicated test team that split into manual testers and automated testers recipe for disaster I think when you think about how you're going to test something you need to think about it holistically And then you automate the tests that would be too difficult Or too time consuming to conduct with your own hands In fact, I can't even use the word manual anymore because someone will jump down my throat telling me It's not manual programming. So I call it manual testing Uh, because I because I use the words that are commonly known across a million people in the industry. That's why wait wait But it is manual programming It of course it is but we don't use that label. So anyway testing Uh, and really it goes back to the original problem. I said is that testing is testing Wow, that's even more of a tautology than you should automate all of the tests that should be automated But it's true testing is testing and we're going to use the computer to help us do some of the hard parts So we're going to do this real time Give me a feature brant This has not been pre-planned. He's going to really make it hard for me go on Feature like give me something something you want me to test uh calculator Oh, that's a lot of stuff in there. So do I have Maybe the first thing I do so say i'm a tester at a company and say we're making a calculate yet another calculator app How are you going to test it? There's a whole bunch of stuff. I want to know I want to know If it's accurate I want to know if it has different modes they have to display. Let's just say it's a plain Standard calculator with no extra modes for right now. We can add those later. So I want to know if it's accurate I'm probably not going to do a bunch of accuracy tests through the ui. In fact, there's very little I want to automate through the ui On this but i'm going to assume it has a model where I can pass numbers to it do the calculation compare it to an oracle this is a case where The test may duplicate The actual code so maybe i'm going to sit down with the programmer if i'm not the programmer of it and look through it and see Is my idea for an automated test just re-implementing the code? Which i'll have to tell a story about the time I had working on uh, I tested gdi the graphics device interface And and user interface which was all the user interface elements on windows 98 Lots of automated tests and some little bit a little bit of exploratory testing that I won't go into right now But uh had a late night discussion with a programmer and maybe I don't know a couple people in the org on whether Whether or not we could use get pixel to test Set pixel set pixel would set the color of a pixel on the screen and get pixel retrieve that color absolutely not alan because Well, well what happened in that discussion was We dug into it. I was like, okay, what I can do Is I can go query the memory of the device of the graphics device driver get that same bit of information Pull that out and then compare that to the result of get pixel And do the same thing on set pixel Well set pixel and to use it i'll go query that memory on the graphics driver and see what it's pointing at which was 100 duplicating the work that get pixel and set pixel did So the answer so the question is can you use get pixel to test set pixel? The answer is of course who cares? Because if the pixels on your screen are wrong, everybody in the world is going to notice i'm not going to write any tests there Rewinding that back to the calculator. Yeah. No and the other one is it's like on this one like i've had these discussions in the past and the the thing is is Is you don't know how it's implemented it could call right? Is it the the reason why you wouldn't use? Get pixel to test set pixel or whichever one that you just mentioned is Because assumption could be applied To both sides and there was a preference to view it as a black box, right and to me The the answer is Okay, let's just go look at how it's implemented I think more often than not it's going to be some stupid property That that isn't manipulated within the class. It's just a set and get part of the answer to Automating all the tests that should be automated is to understand How the feature is implemented? There's some investigation work to do there to figure out how i'm going to test to make sure calculations are correct one way to do it is Something that the excel team used to do a long time ago is they had some custom hand crafted assembly that that did all the calculations in excel What they did on the debug version of that there's one way to do testing is to don't do testing just have a debug version that Checks the crap out of stuff the debug version had a much easier to read c if you can imagine c being easier to read But a much easier to read c version of all of those calculations that ran in parallel And if those two calculation engines ever disagreed you hit an assert One thing maybe not done enough as I think about it Is testing on debug versions that have massive amounts of diagnostics in place. Let me even back up that observability Maybe I don't want to write tests because I have a way to turn on some diagnostics and see the state of the calculator And see what's going on see if anything's corrupted its memory, etc, etc All those things go into consideration when i'm figuring out what to automate so let's say Calculation is fine. I probably want to test that Two plus two great three divided by one. Oh, I know i'll divide by zero You did you can check all those things quickly manually and they're probably never going to break again but One thing where I maybe would do automation finally in here, of course in addition to just I would probably write a series of Common like a sanity check like a unit test that ran against the model super fast that ram A thousand different calculations made sure they work that would make sure I didn't break anything as i'm iterating on this But also I want to know if and where I may even use a ui test Is not to automate that two plus two, but what happens if I have that calculator? Oh, say i'm doing my taxes or some extensive calculation and I have it open for hours and hours doing calculation after calculation That may be something I may brute force automate i'm not looking for results because I I trust the engine i'm looking for After I do thousands of operations, maybe even I might write a smart monkey That's what i'm getting at to see if I could get the calculator in a state where Again using diagnostics as my oracle not using a result of the calculation Can I see if the calculator gets in a state where it is either? Some of the internal diagnostics are incorrect or maybe just monitoring memory usage Right now. I was actually I was actually thinking, you know memory leaks Is this implemented like do we see that as we keep adding operations? It did the dev essentially implemented as every time you add a new operation It remembers the whole history and the way it produces the results is it recalculates the whole thing every time So yeah, so as you kept on adding operations, right? You need to perform it slow down But here's actually something I think is really important that you didn't address in this particular example Pinned that for one second because I realized I went way into solution mode, but my answer to that question on what to automate is Take time up front to think about all of the testing you want to do Or all the testing that could be done and think about the most optimum way to do that and some of that is automated The ui maybe some is automated at a lower level and some you decide not to automate But that's that's really my that's the short version of that whole answer But what's something we're still going back into solution mode? You're saying and you're probably right in this brainstorming of what sorts of things I could test or write automated tests for I missed something big. So what is that? Well, um, well, I don't know that I said that you Did something big i'm trying to put words in your mouth and add drama to our podcast right play along Sorry next time on yeah, you'll never believe what happens next In the example test the calculator Right you went into a place where? All right. What i'm trying to do is test the calculations But nowadays if I ask you alan to implement a calculator What would you do? like would you actually If you were to go and implement a calculator to me with all the libraries we have now GitHub and find someone's to fork That npm install calculator, right? It's that's That's true But if you were to build a new calculator today More than likely all that work is is ui Uh connecting to well known Well tested well established Libraries like you wouldn't even write the library. You're the one who gave me this example. No, I know uh, but I did it kind of purposefully because in this case the the You really don't need to test. Uh a good deal of the underlying library except for maybe a handful of regression tests to be used for acceptance like because For example, I deal with python and python libraries update all of the damn time So, how do you make sure that it's righteous to integrate the the library update into your project? It's so by the way, I gotta mention it's so cool to hear About someone at microsoft using a programming language invented in this century. That's great Yeah, thanks for that I don't I mean, I don't know that Actually every language i've used since my career here c was in bit. Oh this century, I guess. Yeah. Okay. Got it um But here is the thing I think that is Is valuable around automation because we also you kind of You kind of didn't talk about the cicb aspect of this for me a decision to automate Is essentially how repetitive is this work? And that's it if it's not repetitive don't automate it if if if it's not going to be part of your Check-in suite or necessary for cicd. Don't automate it The other thing I I think is great to automate which doesn't lend itself to this calculator example unless it has some sort of way to pass it a file of calculations is I automate a lot of data generation repetitive Right because it's repetitive and and also you can randomize it. I love the idea of Data-driven tests where maybe am I maybe it's a a messaging app I want to see how many contacts it can handle I would bet that somewhere there's a tester I noticed I didn't say manual tester, but a tester who Would by hand careful with my words create 10 000 contacts to see if it would it would wreck the app but something like that again repetitive I would write an engine to create me You know using the big list of naughty strings all kinds of fun, which is a cool project You should look up if you haven't on github All kinds of cool inputs for everything For everything that now I I literally in my career have done that test case Yeah, yeah Those are great things to automate that if you I don't know if you recall. Do you remember what my very first project was? Oh is the answer. I don't know the answer and and It's the only one of these things that I have still kept Oh my god Brandt is showing a copy of schedule plus for windows 95 Which was the cali which was the original calendar app from microsoft right calendar and contacts and um And we used to have a thing that every every time you ship something you Everyone it it was even a verb for a long time even after we moved to exchange calorim People would say could you sked plus me? uh It's much rarer now uh, but people hope but people still Still actually say can you s plus me but it's significantly rarer now. Um I and I forgot about that verb until you showed me Uh, so you showed me that box. Yeah, so that was that was my first product of I've I've I've gotten rid of all of the other shrink graft products that that i've gotten over the years But that was the first one I kept it to me What you test The the traditional aspect of of testing Right. It's around risk control and as a result Uh, there's an uncertain amount of value back to the business with this work and it definitely is An ever increasing cost to the business. So I think like allen's Totology is actually quite Wise it is essentially you should Automate what you should automate, but the way I would suggest driving that Is essentially automate those cases where they're over the lifetime of the product you're expecting a high return Right. You do not want a developer or or any human being that have to go through Uh manually say a an hour long Integration test for sure for sure If it's valuable, then you should automate it, right? Yes, the point I want to get to and now I want to close this and do our last topic and then close out today is I think a lot of folks just approach the the automation process wrong. They go. What can I automate? Which is the wrong thing wrong way to start that it's What is the testing we need to do for this product? period And it's it's highly contextual and then once you brainstorm that testing you should look at that Okay These are the things of the overall testing need to be automated and very likely in many cases could be all of it But at least you thought through it in some cases. It may not be all of it. That's okay, too but There is a problem I see in a lot of testing especially again from these test automation engineers who they focus purely on i'm gonna automate everything I can figure out how to automate instead of thinking about What's the best way for us to test this what actually or like I said before What needs to be tested in order for us to reduce the amount of risk we need to in order to get this thing out to Customers I was just about to push back on that right because we don't the goal isn't to test something The goal is to reduce Business slash customer risk, right? The goal the goal is never testing And yeah, and that gets lost, right? And and we didn't talk about it this time Unless we can get to the other one, but again, I remain a huge proponent particularly in in today's environment around leveraging the data and Optimizing, you know flight control rings of exposure And and doing a react in services. There's all kinds of safe deployment techniques You can use to reduce risk because again, that's the goal not testing one last thing I want to mention so we can close on time here because I have a hard hard stop in like a minute and a half is Modern test con or as it's been suggested. We call it test of this I think we should do this. I don't know how to host a conference and But we've had a number of requests for we talked in the past about having like a test bash seattle But I think we're still and and do a follow-up day, which still may happen someday But I think we're all still working virtually for a while Maybe we can start brainstorming this on our slack channel. I think we could get Several of the three there We could get several of the three. I'm not even sure what it would look like how we do if it would even be I don't know I It's worth thinking about i'm not sold on it. I don't want to do it just as a Oh, look at us. We have a conference. I want to actually provide some value to the overall testing community I do too and and honestly and I struggle with the same thing right with with test bash uh and online test conference Right my perception with those two, you know, there's a good deal of modern testing There are most conferences These days there's some one member of the three seems to show up talking about something Modern testing ish if not modern testing directly So that may be the better avenue, but i'm just wondering if there's a one day Uh thing I don't know yet, but I love to brainstorm that more So if you're not in our slack community, you have some ideas, please join in or you can tweet me or whatever But something for us to think about no plans, but I want to plant the seed and see if it grows Yeah, it'd be if if if there's if the three have great suggestions on what sort of is the Distinct value prop i'd love to hear it. Yeah, we'll get that going. All right Uh, this was fun Thanks for getting up early. It sounds like you've been up for a while, but uh, good job I did finish my second cup of coffee during this podcast. That's a good thing also. Yeah mine's halfway I still have halfway to go. All right, probably might need to go put that in the microwave for a minute It might be a little cold by now Okay, everybody. I am still the a in ab testing And I am not and brent's a big old b See you everyone Bye 
