Welcome to AV testing podcast your modern testing podcast your hosts Alan and Brent will be here to guide you through topics on testing leadership agile and anything else that comes to mind now on with the show. Hey Brent! Howdy Alan! We're back it's been a while. It has. I traveled and then I was so tired from traveling I forgot to show up for a podcast. And I traveled first somewhere in there right? We're back and we're glad to be back for episode 7. Yes 7. Episode 1900. You know there's a thing in podcast now sort of inspired by all the NBR podcasts podcast in seasons. Season 4 of the HSC podcast which is way too hard for me because I don't know if we were like really had our act together had a theme on season 7 of AV testing we'll be talking about UI automation. It just doesn't work out that way. We are pretty certain season 7 we will be talking about UI automation. We fail to have that level of organization. So we're like a hundred and you know. A hundred and seven. Yes. It's on the board. The board is behind me because Brent is in charge of the show. Oh wow. OK. I went to London. I caught not even a cold. I started coughing and now I've been coughing this like this cough since forever. How long ago were you. You've been out of London two weeks. Yeah. Yeah it's been. I'm going to San Francisco next week for work back for a month going to Montreal Montreal for a couple of days in October November. It's all leading somewhere. I'm doing my one and only conference speaking parents of 2019. If you want to come here we talk about something related to modern testing. I haven't done my slides yet and I don't quite remember my abstract. I'll be in Malmo Sweden for or dev in November. What is or dev. It's a conference software conference. Is that a DevOps type of conference. It's more of a dev. There's a testing track. They're going to regret putting me on. Yeah well we'll just say you wanted to get into the dev conferences. So I think that's the right way to sort of maybe. And I said why in one of the first conferences that said no to last year. What am I hated. So I promise I might come back to following here. So I'm doing it. I'm sure they will. Do you have if you stock it with. M.O.T. folks and. There's a large number of people in Europe that are fans. Yep. We got some M.O.T. years in Europe Ministry of Test fans. Oh speaking of which and then I'll shut up. You can get on the show or whatever you want to talk about. I am putting the finishing touches that all the main recordings in the first round of edits for minutes. Modern testing course on that will be available only to club members in their club. They yell at me all the time about confusing ministry testing the dojo and the club. And I'm sorry because I'm never going to get them right. But I managed to edit in the proper names for the. Yeah. OK. A couple of days ago you and I received a tweet. So there's two gentlemen Aaron Hodder and Luke Liu who sat down and. You sure they were sitting. I am not sure that that that may in fact be. particular for details correct. That in fact may be an exaggeration but in my imagining they were sitting but they were together. That is a true fact and they sat and stared at three sets of principles and came up with their own. And on Twitter they asked a whole bunch of people if we could provide some feedback. They generated. So the title of the blog is software testing principles. It's on Alan or Aaron. Sorry. Hodder's blog. But in the section down below they referred to it as Aaron and Luke's software beliefs. And what they did is they took the I.S.T. Q.B. principles the CDT principles and the M.T.P. I think Aaron titled it software testing principles because he collected three sets of software testing principles and then they in their own words since they're synthesized them add it and added their own beliefs and experiences and came up with a set of beliefs. Where they're referencing where possible they're referencing principles from the other three sets. They asked for our feedback. One set of principles to rule them off. I don't think it's a set of principles. It's our set of beliefs. They asked for our feedback and what a better form feedback than a podcast that goes to three people. Absolutely. And not only that because we care deeply about the quality culture of our team and we coach lead and nurture the team towards a more mature quality culture. That sounds like principle number four of the modern. It's almost exactly verbatim. I thought you know what let's do that and let's knock off an episode as well. How about that two for one. So what do you want. You want to look at their go through their principles. I'll go through their principles. They have one by one. Let's do one by if we can. We'll probably have to go quick. They have 12 beliefs and they're not they're not principles. They're beliefs. OK. And I guess number one. All right. Number one is testing is information gathering and reporting. Thoughts. Have you read these yet. Yes I read them. I read them a couple times. OK. I don't I know this comes from I think the context driven testing. They do not reference any principle. I thought I read one which they referenced. So yeah I have to think about the reporting. Of course testing is your gathering information. Your order to mitigate risk. Understand more about the product. But I haven't I haven't thought about not totally against it but I haven't thought about how or why reporting is nothing could be part. I think they're part of the six out there. But other than that I don't have really a problem with it. So I do. Information gathering and reporting. They're important for a large number of things. I was going to say that's a very general thing. Reading a book is information gathering report. Right. I just did a quick search on Google and I think this is closer. Right. There's a couple of definitions here of testing. First off I think the thing I think that they're calling out is testing is an activity and certainly information gathering and reporting is a key output. But like here's an example definition testing is the process of evaluating a system or its components with the intent to find whether it satisfies the specified requirements or not. I think we've all heard that one. We can. Let's do that one a little bit. Or testing is executing a system in order to identify any gaps errors or missing requirements. So I don't it tells me where they're coming from which I think is a fine set of beliefs. But from a modern testing I actually think that set of beliefs is what if we rephrased it instead of testing is information gathering and reporting. What if we said we perform the testing activity in order to gather information and report on it. That's better. I think it turns more into a principle. It I think that's better. Testing. Yeah anyway I think that's enough on. OK. One. OK. Not triggered. Kind of like I get where they're coming from. I get where they're coming from. The only issue again from from a belief system. The only issue I have is is I do think people who view information gathering and reporting as the actual goal of testing. That's kind of one of the reasons why we built empty in my humble. Yeah. Yeah it's kind of. Yeah I agree because I think that point of view is actually going to harm. And even my statement that says we do testing in order to do X and Y X and Y are two of the twenty six other things you do as part of that you can do as part of testing. Our principle number one is business value is critical and that's actually why you do testing. Yeah. And the thing I like about of course I'm I hurt my arm patting myself on the back about the modern testing principles is I joke about they're not being about testing and not being all that modern. But the you do you perform the testing activity in many cases to help promote those principles. Anyway. All right. Next one. Yes please. Test coverage is always relative to some model and then they refer to I. ST QB principle number two. I have to which is exhaustive testing is not possible. The nice thing about the I. ST QB principle is not a single like they're the longest one has looks like nine words. Sure. So their their belief is test coverage is always relative to some model. So that's a true statement. It's also not that profound or interesting to me. Now the interesting part of that statement would be model. So if it's relative to some some model how do you select that model that's going to be the thing you compare against. Right. You could abstract this to a larger form of testing and say testing. But it says test coverage is related to some model. Testing is related to some model. Sure. Sure. So but I know where I again I know where they're coming from because there is a lot of emphasis from the traditional world on coverage not just code coverage but feature coverage requirement coverage other kinds of coverage. It's important to a lot of pointy haired bean counters. So it isn't I see why they're calling that out because test coverage by itself is dumb. But but in the context of a model where you can communicate use it to communicate risk or or progress or something then it becomes more viable. And I think the point that they're trying to state is the relativity right. You you are there is always more testing that can be done no matter how far you've gotten. There's always more that can be done. Right. So you you can never claim completeness. May May I tangent as size briefly just on a conversation I had yesterday and I have to abstract this out because I pushed back on my boss and and he didn't get what I was saying. But I'm big on models. So there's we're having a not going to say heated a passionate discussion about some model one model we're building and someone brought up a model that I had suggested a while back which I just got from the Internet. And and they said what about a model like this. And my manager said I agree with what's in that model but we won't use that model. And then my again my semantic asshole ism. I said if we do what's in the model just because we refuse to acknowledge we're using that model doesn't mean we're not using the model. You follow me probably not. I do. The model is more than the drawing on paper or the diagram or the word. The model is the is the framework and even if you're not following the framework directly if you're doing the things in the framework you're sort of following the model anyway. It would like be saying no we don't do scrum scrum stupid but then everything that you actually do. Just because you don't call it scrum doesn't mean you're not following the scrum model. Right. And and by putting your foot in the stand saying no we're not doing that we're not following that model but doing it anyway is a little weird but anyway not not not a point to lose my job over anything but. But anyway now you have a little bit of insight in the way I work and I will never be employed again. And so going on how about the next one. Okay. Thank you for riding along on our tangent for down to two listeners. Yeah. Now I'm thinking about vanilla ice right. And don't think about ice. No he added another beat. It has nothing to do with the Bowie queen. Yeah anyway what we test and how much we test should be based on models of risk. Now this one's interesting because they refer to empty number seven. Huh. What we test how much we test should be based on models of risk. And just for listeners who may be joining soon that's Alan am I's principle and it is we expand the testing abilities and know how across the team understanding that this may reduce or eliminate the need for a dedicated testing specialist. Now I can tie a connection there but I am fine. I failed to see the connection. I have to go through a very convoluted process to get there. So let's let's not worry about that. We can disagree that it that we don't we can agree we don't see the connection. Maybe the intended to refer to number five. So we don't talk about which which modern testing principle if any do you think talks about risk based testing or risk based approach software development. Quality culture. I would if it I would do number one and five for that. Oh actually yeah I would do one. The quality culture. No it's one. It's definitely one. It's improving the business. Well again one of five is where I'm going to go with on that one. So we agree. Yeah. But we test and how much we test should be based on models of risk. Yeah that I don't disagree with. Now here what I think the where they may go to number seven is number one what we test and how much we test. Right. Because a lot of people interpret number seven wrongly. Yes as the second sentence not the first. Yeah. And I I think and we'll wait and see when it comes out and what the what the observations are. I think I did a really I'm going to pat myself on the back again of all of the things that I walk through and I I hope people get through the whole modern testing course on history testing because I get better at explaining as I go along. I think I did a really nice job explaining how principal seven works and put some exercises in that got people thinking about what it would how how that looks in execution. So again get your club membership for that course because that's going to be hot hot hot. I'd like to see that before it releases. You're not changing anything. It's perfect. I'm sure it is but I'd like to see it before it releases. But have your people talk to my people. Every time we've re explained like the the blog post that I did on modern testing principles. Yeah that that I felt was the clearest I've ever explained it right. It is around me number seven and is around. I should read that. Do the right thing even though it's scary. Well yeah yeah. That's true as well going on. All right. Number four. So again for number three what we test and how much we test. I don't think there's a lot of disagreement there. None except for we don't get why it's empty seven. Correct. And that number four it is often better to perform a variety of tests than repeat tests. True often nearly always. And they're not to IST QB number five. Breath breath over depth in most cases. Beware the pesticide paradox. Oh Borthweiser. True. And the difference is now we talk about. No I think it's true. What I. Isn't that it. Is that an insider is that a tautology. That's what I'm trying to judge in my head. It's neither it's a principle about the testing activity. The reason it's sitting wrong with you is because our principles and our beliefs do not focus on the testing activity they focus on delivering quality software. The testing activity falls out of that if you're doing it right. So I'm going to wholly agree with it because one of the things that drives me nuts and this is not a modern testing principle but certainly influence a great deal of my part is that I cannot stand the test zombies. My job is to run the same suite over and over and over and over and over and over and over and over and over. And also let me. I'm going to chuck someone under the bus here but I'll do it vaguely. So you want to know who I'm talking about. I had a I'll just say I was talking to some. People recently and we were talking about. Doing a deeper breath or broader set of tests do broader types of testing and they made a statement roughly equivalent to well we already do all the testing. There's no more testing to do. I think another way I may phrase this principle from Aaron and who do you run them with. I'm sorry. Luke for Aaron and Luke is always there's always there's always more testing to do and it's not the same testing you did before. Meaning always strive for different ways to test things and get that broader sense of that broader approach or scope to your testing. That's that's my takeaway from that. I think there's always there's always testing you haven't thought of yet. Well it says it's often better. And so when I think of better like to me when it comes to testing I always judge better by the business value. Right. Hey I can I can spend a week doing an exhaustive performance test or we can ship this thing and start making money on it tomorrow. Right. Right. Or if it's or we can ship this thing and make our customers super happy and and love us tomorrow. Right. Exactly. Business value doesn't have to be about money. It doesn't. It doesn't. It is generally about money or growth though. The one thing people people will go it's not all about money man. And I'm like look a business's job is to serve its customers and a business needs money to continue to do that. Yes. Okay. So while it could be in a lot of times people will do money is the root of all evil blah blah blah. No money. It is how it is used that defines if it's evil or good. Sure. And I'd like to know how many of our listeners and maybe one of the three does this but if you do your testing activities for free in the company asked me I don't need to pay you but but I want to make the point is when it isn't always a direct line between improving the business between making money like the customer is giving me cash. It could be that customers love you. So because you're adapt to their needs so that investors love the company and then put money into the company that way. Anyway. Again another tangent. Are we back on track. How many are to go. We're we're on number five now. OK cool. Out of twelve. We'll get there. Hold on time. We got plenty of time. We can't ever be certain that there are no problems. OK. Yep. True. Yeah. Amor's order of ignorance. Yeah. We don't know. We don't know. His name is his name is just armor. I like Amor. Philip armor. OK fine. If he's one of our three lists a product can meet all its stated requirements and still be useless true product can fail to meet all of its stated requirements and still be useful. True. True. And to me that is the difference between quality and testing. It's also principle number one if you focus just on making sure the requirements are met but it doesn't improve the business value you have failed right. You have not improved the business. No I mean if we go back to the definition I read earlier where testing is essentially the the activity to validate the stated requirements as well as look for gaps in the requirements. Right. Then the act of testing as as Whitaker said so long ago all that testing is getting in the way of quality. Oh you know you piss more people off down to no listeners. We'll get them back. Seven. Oh and by the way the references for that was CDT 5 and MT 5 testing can happen at any stage of any software development lifecycle and it is usually better to begin testing early rather than later. I STQB number three. I I would even get rid of the word can testing must happen or testing happens at all stages of software development. Yes completely agree with that. How do you feel about the second sentence. It is usually better to begin testing early rather than later. Usually sure. I'm okay with that. Yeah that to me is some words in here that makes the least I mean difficult to disagree with. I am going to say I can add certain weaselly words but I'm not certain I agree with that. Do you think is it because I think there's certain tests I think there's a lot of tests that must be done in an early and preventative manner. I agree. I think a large number of tests can be done post ship. I agree there as well. And I think it's the word it's the word usually that I can't that makes it inarguable. Yeah. See that's that's the one I want to argue with. Principle and I would have site I would cite principle number six. Yeah right. As as no. Well if we talk about testing right. MT is not about testing is about quality. All right. Next one shorter periods of testing that happen more often are better than longer periods of testing that happen less often. No disagreement there. They did not cite a principle but I would have cited modern testing principle number two or number three. Are they sort of saying that it's sort of a roundabout way that testing continuously is better than testing at the end. Yes. OK. I would have said it that way. Right. And so I think we have a modern testing principle that covers that or at least two of them right. What did this is basically saying doing things continuously getting continuous feedback is more valuable. Alan has just given me a thumbs up as he was gently chugging coffee. I was chugging coffee. There are no best practices only good practices in context. CDT number two as someone who just made some semantic arguments earlier in the episode. Now I'm having a hard time semantically arguing this. This has been number one from the CDT world forever is that best practices the horrible term because there is no very best. There's only there dependent on context. I totally agree with that. So I'm a little tainted because of the of the massive amount of emphasis on getting rid of the phrase best practices. I am from it's a model. Anyway I get it. Yes true practices all practices are good in context calling something best is just something someone invented a while back and stuck and now pisses people off. But I get both sides. My version my version of this statement and I do agree with it is that there is no such thing as the best way to do anything. Once we have established the best way it's just a matter of time before a new best way pops up. You're absolutely right. But there is such a thing as the best thing to do right now with the currently known information which is another way of saying practice for context. Let me let me ask you a question. OK. Is trying to think of a good example here is you are using tools to compile your code to best practice or should you compile it by hand with an assembler with an assembler. Sure. So the best the best current best current practice that you use a a compiler to compile your code. Who the hell would be compiling with an assembler. All right. Anyway that was a horrible example which may get edited out or I'll see how drunk I am when I edit this. But let's try it. But you know so. So I have a con. I mean that without the assembler bit that's a problem I have in my team right now. So we're we're producing a bunch of awesome models initially did not make sense to build up a CDC pipeline to produce the models right. Turns out we did some search. It's not exhaustive. We don't see much around how to do pipelines for producing Python models. If anyone anyone's a listener and they know of one please tweet me that tool. Pie pipeline. I just made that up. Don't write it down. It if if it exists it might be called pie pipeline that the the Python community likes putting PY in front of everything or just pipeline with Bell PY PE L.A. Any you know what if that one doesn't exist I will build that one. Here to help. There's three things difficult in computer software naming things and off by one errors. But it's expensive to put together the pipeline. It only makes sense if we know that we have enough of a value proposition to continue to do this and continue to provide updates to our models which we have gotten past but initially there's no way. Yeah. Because if someone said the best practice you have to have a CICD pipeline and you would but you don't have a system that needs that yet it'd be stupid to do it and it is a best practice. It's an accelerate our favorite book on the podcast accelerate by Nicole Forres-Gren. Just humbled you just called it a celebrate. It's all great. Which is what it is. Absolutely accelerate is accelerate. Okay. It's a hell of great. Come on man. You're stalling. Let's go on. Did I already do 10. No I don't think we. Wait wait wait. Yeah we just did nine. Do I thought we just did seven. Nine. There are no practices. OK. Did we skip it. Number 10. Eight. No we didn't skip eight. OK good. All right. Let's go. Ten change happens and that's a good thing. Therefore our practices should be as responsible as possible. Here they referred to empty number two. Could you read empty two for the for the readers. Yes listeners. Are those reading the transcript that doesn't exist. Empty two we accelerate the team and use models like theme thinking and theory of constraints to identify prioritize and mitigate bottlenecks from the system. Which I guess yeah that does align. It's about being adaptive which we fully agree with. But not modernism. Crystal number two Aaron and Luke principal number 10. We should we should change as needed in order to support the business. Yeah. I guess the only feedback I would say is sort of I would I would tweak their language like change happens and that's a good thing. Still has an element of being punitive. I think I think what they're getting at is the thing we've talked about. I care about it for sure on air or off or people are resistant to change. People are afraid of change that we talked about on there as well. Principle number seven. If change happens it's a good thing. Figure out why it's happening and how you write like oh wait you can be the butterfly or you can be the wind. I like that one. Yeah. I think of it as the discussions we've had around software development. Models prescriptive iterative or adaptive. I would say a little bit stronger insane adaptive development models are known today to be not only more successful but significantly so quit fearing it. It it boosts everything good. All right. Anyway yep. Number 11 testing is a testing is a performance not a procedure and certainly not an artifact. So I think it was Chris McMahon who was the first person I heard called testing a performance. No he called and actually Chris is going to yell at me now because it was he said this is interesting because he gave a talk on this that was really good. He said a agile team making software is a performance and Chris being a very good musician made some really good parallels to a performance because you're adapting on stage to each other and delivering software. But I haven't heard testing is a performance before by itself. So is that based on somebody's principle. Yeah. Where does that come from. Uh it's CDT six and seven and CDT six and seven. Good software testing is a challenging intellectual process. True. True. So is good software development. Actually any knowledge work is a challenging intellectual process. It should be. Yep. If it isn't you're doing it wrong. Yes. Uh C prior comment around test zombies. Uh only in number seven is only through judgment of skill exercise cooperatively throughout the entire project. Are we able to do the right things at the right time to effectively test our products. So I would re I brief rates went a little bit in the Chris McMahon frame and I would say delivering quality software as a performance and with the parallel being it is a team and not an individual effort to do so. Yeah. So when it says testing is a performance I don't have the music theory background that you do. So I was thinking of this as not the way you interpreted it. I was like, Oh, this is a grammatical error and they're talking about performance testing, but still weird. Maybe I'm talking, no, I don't have a clue what the hell they're saying here. Um, that's almost literally how it happened. It is certainly not a procedure. It is certainly not an artifact, but you, they don't reference empty seven here, right? Cause the closest thing to sort of testing is a whole team problem in empty is number seven. Right. And if, if that's how you interpret it, I agree. I don't understand what they're saying here. And then their last principle, I value healthy teams of people building useful products for people consistent with my ethical beliefs in a way that minimizes waste. My focus is on reporting threats to that value and the values of my stakeholders. And they refer to empty number one. And their last sentence, their last sentence. Their last sentence came across to me as the opposite or, or at least in conflict with our first principle. Uh, the way when you and I were wordsmithing principle number one, I was thinking around how do I get people to stop thinking of testing as reporting. Activity. Yes. And here is an example of someone who's actually using empty one to, to justify it. Um, now, could you read that second sentence again? My focus is triggered me a little bit. So my focus is on reporting threats to that value and the values of my stakeholders. So reporting, but this is the first one where I see testing referred to as a community of people, not a practice or an activity, right? My focus, I, yeah, it, my focus is on reporting threats. Right. My focus and, and, and the reason it triggered me is the focus is on improving the business. One thing you may do as part of improving the business is highlighting threats for the team, highlighting routing, call it threats, highlighting risk. Uh, we shine the spotlight as needed in order to improve the business. Uh, the focus here is I think opposite is too strong. To me, it conflicts. Uh, I would say strongly with our, our intention of our first principle. Uh, for sure. The way I'm, I'm, I'm trying to talk and read at the same time. I probably should not do that. Just so that everyone is aware, uh, if you're a new listener, I do think if you're in a test role, I do think you improve your career by moving more to a position of defining the actions based off of, uh, the decisions that your information is informing, meaning a lot of testers go, our job is to just inform the decision makers and I'm saying, why aren't you the decision maker? That's even well, years before we thought of formalizing, at least modern testing. I've heard that statement and it's again triggered me. It's like, that's ridiculous. It's, it's very passive. Uh, this is, this came out of the context driven testing book is the role of testing is to provide information period. Um, I'm probably paraphrasing and someone can come yell at me. And I thought that's a very passive approach. I think our role is like, get that information and then go make something happen with it. And that's what I've always done. And probably, uh, why I'm still employed and paid too much, uh, is because it isn't just about providing information. It's about figuring out what's the best way. So I kind of see, can I use best? I'll use best there. Uh, by using principle number two, what's the best known way to mitigate that risk bottleneck or that risk, uh, and often do it myself or make sure it gets done. Part of principle number seven is bringing that leadership aspect and attribute out of whoever is driving modern testing principles on the team. And, and I want to pause for a second because some of these I've, I've pushed back on a lot and, and said, uh, wrong. And I don't like it that way. Uh, I do want to commend, uh, Aaron and Luke for their, their work on this and looking at one of the things I love about testers is we like to look at systems and systems of systems. And they took these three sets of principles that exist in the internet and, and figured out what they meant to them as individuals and their work and made a nice summary of things that they believe in that drive the way they work. That's a hard thing to do. And overall it's, it's not like it doesn't make my blood boil or, or, or make me think, oh, these are stupid. You should use modern testing principles instead. I don't feel that way at all. I think they, that would be dumb too. Yeah. Again, I, I encourage all of our listeners to go read these and form your own opinions, but they asked for ours. And, uh, and if, if either one are listening and joining, if we have five listeners this month, uh, please take this, uh, this, any critique we've given as just our opinions and their opinions about the principles and in our practices and what we believe, uh, and what we feel drives us, what our principles are. And if there's conflict conflict is good. If they're not, I mean, you would, I think a lot worse feedback for us or anyone to give is yeah, these look good. Keep on doing what you do. LGTM. I hate LGTM. Now the, and likewise, um, Alan and I on an MT, like we're not married to it. When something better comes along, we'll, we'll be the first to drop kick it. We haven't, we haven't found something that resonates as well. Um, yet, but it's just a matter of time. Uh, I firmly believe that it is, it, it is a best practice now, but it will not be the best practice in the future. Like we said, they're not particularly modern. We just, we just grasp the things that were already there. These aren't forward looking. Uh, we just took some things that we saw that we're working and tried to formalize them into some principles. And again, I've seen this on the podcast before, but when I first started talking about modern testing principles in public, I got so many comments to the flavor of thank you for putting a label on something I'm already doing. So we're not like inventing some North star people are migrating towards. No, it's like, Oh yeah, this describes what we do. Cool. Thanks. You know what the single most important thing that we're doing is. Um, breathing, forcing the conversation. Yes, we are forcing a conversation. And, and Aaron and Luke, they've, they've joined the conversation. Yes, they have. Welcome to our conversation. And I, I think it's fantastic. Uh, I hope that their conversation inspires other. Yeah. And we have seen, we haven't talked about it directly on the podcast, but there are people speaking out sort of passive aggressively against modern testing principles in a few cases. And I like that too. Welcome to the conversation. It makes us think it makes others think. Uh, I, I am thrilled when anyone even mentioned them. So there've been a few conference talks, not by us on modern testing, which is great. Uh, they come up in blog posts, uh, other forums online, which I think is great. So let's keep the conversation going. We're, we're not here to say follow our principles or you're wrong. That's not who we are or why we believe in them. We believe in our context. But we've, but everything we've done over the last couple of years, these principles guide our decisions the way we work. I want to actually say it even stronger. Go for it. Don't follow any set of principles. Use them, think on them, be critical, come up with your own and act in that direction until you find a better sets of principles to guide you, your career, whatever you define success. Even stronger, blind faith in anything will wreck you. I can't go stronger. Sorry. All right. I would internet points are showering down on me. Hi, can you see like the, uh, the things floating down? No. Okay. If Brent, I'm closing my eyes. I'll be like a listener. Then nobody else can see them. Uh, all right. So thanks. Uh, thank you very much, Aaron and Luke for giving us that, uh, conversation topic for the podcast. Hope it was helpful, not just to you if you're listening, but to any other listeners as well. Uh, anything else that you want to talk about before we close today, Brent? No, we're over time. You don't have to tell them that they don't know. Cause when I edit this 50 minutes down, it's going to be like 12 minutes. Hey, it's good to be back. It is. It is. It is. It is. All right. Hopefully we'll be back again for one Oh eight and two weeks. That is the plan. All right. I am Alan. I'm Brent and we'll see you next time. 
