Brent, can you beat box? No. Welcome to AB testing podcast, your modern testing podcast. Your hosts, Alan and Brent will be here to guide you through topics on testing leadership, agile, and anything else that comes to mind. Now on with the show. Welcome to two guys drinking beer, talking bullshit. This is your modern testing podcast. I'm Alan. Hi, Brent. And here we are yet again to drink beer. I didn't make a drink. I was chatting with Molly. This is like the second podcast in a row. Call out to Molly where I thought about drinking ahead of or during the podcast. There's, um, I'll say I'm going to, I'm going to say this job's great. I'm fine. I'm at the stage now. I'm actually getting stuff done, which is fun. I haven't done that yet. So that's good. Good. Not a lot of stuff, a little stuff, but you know how it is when you got a drag people from one belief system to another. Uh, yeah. Yeah. So I'm doing some of that and it's essential. Welcome to the, if it was easy, it wouldn't be fun. Exactly. And I was going to say, welcome to the AB testing podcast. Oh, yeah. Yeah. This is what we do here. Right. Yeah. So anyway, how are you doing? What's, what's new in your world? Uh, review season. That's, I got so lucky. I joined NBCU right after their review season. So I don't have to do it for like 10 months. Oh yeah. That's you did get lucky and even better. You almost got really unlucky because, Oh, and by the way, it's review season. And you got to get all your feedback in by Friday. You know, I did a review season right before I left unity, not right before, but recently. And I was working with my HR business partner who had just come to unity from a different company and unfortunately due to cycles, he had, cause this is the painful, it's just a painful process for HR and, and managers it's essential. And if you do it right, it's essential because it puts a framework around having some good career discussions for folks. All that's great, but it's a lot of work and it's a lot of work for HR. Anyway, the story, I probably shouldn't have bothered telling when I've already started, I suppose, we'll finish it is he ended up doing back to back reviews, re seasons, because he did one of his old company, changed jobs, immediately had to do another one at unity. So, uh, and that's from the HR side, a little bit different, but still, it's a lot of coordination they do to get every stuff, everything together. But it would be equally as bad, if not worse for like a manager to do a review season, get a new job and then go right back into it again. Also, it would be hard to do as a new manager. Anyway, review season at the big M. Yes. Yes. You may have heard that there are some changes to cycle around. It was public news. Oh, there, there are no merit increases, correct? Right. I did hear that. And honestly, I think that's a smart move. I wish, I think it's a reasonable move. If you're not doing any more layoffs. Yes. I think, I think it sends a pretty mixed message on the negative side. If you continue to do layoffs while doing that. Well, so the thing is, is that hopefully it constructs some form of insulation layoffs are going to be very tightly bound to whether or not we get out of the recession or, you know, anytime soon or not. You're already overpaid anyway. Give it up. Uh, wait, we all are. Uh, and yes, definitely. And no, I worked hard to get, to get it, but there's several other things that are potentially interesting around what they're doing there. We can talk about it later in the, in the, in the show if necessary, but yeah, like, like that'll just tell right into our seamless agenda a little bit later. Yeah. The, well, it will actually, but like a great salary normalization. It is probably on its way, whether it be through things like AI, whether it be through things like, uh, inflation, there's big things, big things of foot in my humble of view. And I think, I think the more we make things simpler than the more you can get things done with less qualified people, less qualified people required less salary, which then might do to market forces changes the demand for that salary. Potentially. And we talked about this last time in that while that is true, you can look at it, that as being absolutely true. And that's one possible outcome or timeline. Another one is, is that we use AI smart people who should be compensated. Well, can use AI to enhance what they get done. So they actually are getting more done. So there's a couple of different ways this plays out, but really it's like, it's, there's a lot of forces all competing at the same time with the recession, the economy with AI and the advances that are put us into the adjacent possible, Steven Johnson called us plus world situations and American shit show of politics, all sorts of things are playing off each other, affecting all affecting everything else. Yeah. Yeah. And they're all fighting everything else. Uh, and it's like, it's a system. It is a system, but all the different, it's like a system and they've taken out too many parts and replaced them with two new with different parts that look fundamentally different and do different things and right. I, I wonder how long it's going to take for this, for this system to sort of restabilize so that we understand it. That's number one. And number two, I guess, will it, will it ever stabilize? Cause certainly on the pace of AI, that's accelerating faster and faster and faster. By the way, by the way, um, because we have a, we have a AI packed show today. I believe, although again, long time listeners will know we used to have agendas, but now we don't, but we do. We just don't write them down. We're that much in sync. Is your middle name, Ian, or anything is more than I, uh, my, my, could you change it? Cause I think maybe we can be the AI testing podcast. Oh, I'll consider it. All right. All right. I'm not going to go. I'm not going to go with you have to take advantage of what's popular. There is, I put this on my five for Friday, which you didn't read, but some of the listeners have. I religiously, wait, wait, wait, wait. F F U I religiously read your five for today. No, I, I read it when I get home. So you're, you're just, you're not really okay. We need home. You know what? I'm going to give you a number five. It's this tea shop in India called chai GPT. Oh, that's funny. That's right. I thought it was really, really funny. Really funny. It's funny. I mean, except for the fact chai is gross. Well, I actually, I do like chai. I drink chai tea without any of the milk, just the tea, you know, chai, chai tea with milk, but without the chai is pretty good. Actually worth calling out here in our random bit from two guys drinking beer without any beer is that I. During the pandemic, I went through fate. Well, they can't call it the pandemic because I work from home all the time. Now this is my office, but somewhere like when it first started, my first all went home because my good, like work has crappy coffee at home has good coffee, my coffee consumption initially skyrocketed. I was drinking so much coffee, like so much. So I stopped, I've tapered, I didn't cold turkey. I stopped. I tapered off. I never stopped drinking coffee. I stopped drinking as much coffee. I stopped having coffee every morning. I kind of got into tea for a while and now I drink tea probably as often as I drink coffee. I've become, I went from all the way coffee backed off, went all the way tea, and now I just do either whatever feels right. It's kind of like what am I drinking tonight? Is it gin? Is it wine? Is it beer? It could be anything I can, I'm, I can do it all. I too have had a, a bio rhythm of sorts on my preferred caffeine beverage. Uh, I am definitely at coffee right now, but like 10 years ago, uh, you would never see me with coffee. You would see me walking around with a cup of Earl gray, which was my, my go-to tea. That's just because of, of TNG, right? Of what? TNG? TNG. Next generation, Captain Picard always drink Earl gray, hot dude, hand in your geek card, hand it in. Uh, you know, no, I was trying to answer your question. I'm like, you know, I, it might've been. I don't, you are a geek, but you're too old and forgetful to remember it. Yeah. That's correct. Well, that's for sure. All right. Hey, do we have any topics to talk about that you had something you wanted to talk about and I riffed on that and that gave me some stuff. We have not discussed these in advance, but I thought, you know, 10 minutes in. We should almost do it. But the great thing is we started a little bit late and we're going to end just before the top of the hour. Like we usually do listeners. I want to hear from you because I listened to a lot, a lot of podcasts. And my favorite ones actually are the half hour ones. I don't know if we could do a half hour podcast because we'd be closing right now. Uh, but lately because we've been starting a little bit after the hour and then I edit out all, believe it or not, out of all the boring parts in our podcast, there is a chunk more that ends up on the virtual cutting room floor. So this will end up being about 40, 45 minutes, which I think is a pretty good length for an ABI testing podcast. You play that at 1.25 speed. You can still understand me when I'm hopped up on caffeine. And later when I rap, you want to slow that down. It sounds, but it'll sound better sped up. Don't slow it down. Shorter podcast, rewind the stack stuff. We're going to talk about Brent Europe. All right. On the one of the, bring some energy, Brent, come on in on the one of the three slack channel. Yeah. Yeah. Yeah. Um, there was a thought that, that came by recently. Right. And I was thinking about, I'll share the, the thought shortly. I was thinking about what started us down this podcast. Right. It was, it was, um, agile. Agile is, is not so much agile. I was buzzword term used far too often wrong in the industry. That would agile is. Uh, that is, uh, one of the many definitions. Yes. The invention and rollout eventually of agile and eventually people started to observe successful deployments, right. And as well as, as service, uh, services coming on where, where agile really makes sense, right? The ability to quickly adapt, which really couldn't do in the ship product world. Right. That in my view is what started the domino chain where not only do we see testing becoming less relevant, uh, but becoming. Under threat and eventually causing you and I to start going through doing some studies, I did some experimentation and going, Oh, if we view testing as his job is to reduce risk. Um, yeah. Uh, actually agile succeeds way better than anything I've ever done. It does. And this is a little bit of a riff on the agile being the buzzword thing, you don't see agile. What we really started seeing was a massive reduction in cycle time, even from teams doing poor cycle time and feedback time. Yes. Yes. Feedback feedback loops massively improved to the point where it was obvious to you and I that a traditional testing role or traditional testing process would just get in the way of the goodness that came from that feedback cycle. Correct. And then we wondered, well, crud, what do we do next? And we like, what does that mean for us? What does that mean? What do we do next? And what does everybody else do next? So the podcast started because we wanted to explore that along with everybody else experiencing that so they could have an idea what does come next. And man, we have seen it. I, to continue on, what I'm beginning to see, and I did a quick search, but the comment we saw on the stock channel was essentially doing a comparison and I'll call it the traditional test methods, which is there's several bodies of knowledge around traditional test methods that are still active today. Um, and, and certain consultant firms that are referred to quite often, um, on this topic, uh, and I'm getting the sense that they're feeling under threat by AI now and things like GPT, uh, even further. And I did a test this morning. I wrote a little piece of code and then I gave it to GPT and I said, write me a unit test suite for this. Yeah. It's actually pretty good at that. Uh, it's fantastic. It went through and automatically did, did all of the obvious ones. And I said, ah, okay. Then I start started, you know, as, as, um, let's just say the, the proponents of, of traditional test methods will say testing is a thinking thing, not a checking thing, right? So I said, okay, great. I got those, those done. Now let's think up another one. Oh, you know what? You didn't cover the case where this was null add that boom. There it is. Well, you're thinking. Yeah. Yeah. So I've done the same thing. I I've been writing, you know, my son's been in computer science class and I've been just for fun, I've been doing his homework alongside of him. And then when he asked questions, I can say, Oh, you probably, you probably did this, or I could say, have you thought of this, but I would write the code for these assignments and then I would use chat GPT to help me write the unit test because I'm lazy and I knew, I knew it would do a good job. So I would give it the code. I say, give me a set of basic unit tests for this. Then I would ask, what risks do you see here? And it would identify some, I'd say, okay, of those write the unit tests for one, two, and four. And I would say, what about the case where this happens? Can you write a test for that? And it would do that. And it was, it, I think my experience with chat GPT is it's okay at writing implementation code, but writing unit tests has been very, very, very good. So there's two kinds of code. I have it right. One that's in Python and another one in an internal Microsoft's language. Actually, it's not internal. It's shipped. It's Azure data Explorer. Internally it's called Cousteau, right? It's sort of a query language. It almost never screws up on Python. Even I've gotten, I've, I've gotten clear on what I ask it for, but it almost never screws up. Well, I told you, I tried to have it write a Python program that needed to do some math and it failed because it's just bad at math even when coding. Yeah, I suppose it could do all right. But this is really related to our initial conversation earlier on the podcast is you can either look to AI to replace you or look to AI to enhance what you do. And you're saying as a tester, putting your, putting your tester hat on, as they say, you can apply, be the thinking tester, use your brain. And I want to put a pin in that and talk about that. Cause it's going to be my, my article tomorrow for my sub stack. You are using your brain for the creative part and using AI to accelerate what you're doing with your brain. So, right. So now I have two questions for you. First question. Are we at a phase in software development, the current place we are in the world? So not a phase, but a timeline. Are we at a place right now where the manual tester versus automated tester no longer makes sense? Well, I believe that for, I mean, look, we live in a bubble where people do things in sensible ways, but there are many, many organizations that have a dedicated manual testing team and a dedicated automation team. And not, not, and, and, and dedicated development team. It's, it's a horrible way to make software. It's extremely inefficient yet it exists. So that is, it still exists in plenty of places, but I, No, but I'm actually thinking it's a non we're very rapidly heading to a place where that's a nonsensical distinction. Right. And doesn't matter if I'm, if I'm an S dead or an STE, if I can communicate a concept to something like GPT and get it the right information. Tell it what I'm looking for. Right. I own the thinking and it generates the output. Why wouldn't I do that? Right. That's you should, you should double that more than doubles my value proposition as an STE. Let me, let me come back to my pin and get on my soapbox for it. I've been on this soapbox before. Like I said, I'm going to write about this tomorrow, but I saw on LinkedIn, these kind of ball the time again, I go to LinkedIn to try and help out my friends who have are all getting laid off from their jobs. And someone posts something about how testers need to use their brain and like using your brain, like using your brain and being creative and curious is something unique to software testing, which blows my mind. Yeah. So it's knowledge work, the knowledge work that you and I do the knowledge work that isn't just putting widgets, you know, buttons onto a jacket and a factory, it requires those things. It requires critical thinking. It requires curiosity. It's just true for all knowledge work testing isn't special there. So I think any knowledge worker, I put it this way, every knowledge worker or every kind of knowledge worker could have some fear that AI was going to take their job at the same time, every knowledge worker can enhance and accelerate what they do by using AI effectively. Also. Yes. Yeah. Of course. Cause I'm absolutely right. And my, I'm, my arguments are infallible. And, and even further, it allows you to enter into an arena. We've already talked about like recorded scripts in the past. Previously, what we would do in the old days with STEs, right? We had them run through scripts as they thought through their tests. Right. So we could preserve that and check it in. Okay. But the quality of the test cases out of GPT is much better, just much better. And I'm like, Oh, so I was just thinking around, I see evidence right now. Again, the traditional crowd is acting defensive as if, ah, hell, like we, we survived the agile phase, which in my view, they didn't because you can see that the momentum against anything other than the dev owning their own tests is dramatically slipping. So, and I think we've talked about this before and, and I am just about, I think, if not done, almost not almost done completely done talking about the other bubble, when we first started this podcast, we talked about how teams could adapt to agile and faster feedback cycles, et cetera, because they were afraid it was going to screw up their job. Right. And as you were getting at earlier lately and today, especially we're doing the same thing, talking about like everybody's thinking, Oh, is AI going to take my job? And the answer is only if you let it know, you're right. I'd actually, you're right that I'm wrong there. That, that part was definitely fallible. So it is, what do I mean to say? So here, let me try. All right. AI will take your job. You will only be unemployed if you let it. That, that, that's a better version. AI is a motivator to, for you to start thinking around. It's a creative partner. And I don't get why people like, and I know what you're talking about. People are either, they're, they're trying to be dismissive of it saying, Oh, it can't do this, but you can't do a, but you know what? It can do B C D E and F. So don't use it for a idiot. Yeah. So here's the thing. With the way it's accelerating, do you know what an AGI is? I, isn't that like the emeritus? Um, I don't know what it is. I had a joke answer, but I can't remember what it was. Adjusted gross income is your, your poor joke. That's what I was trying to think of. AGI stands for artificial general intelligence. Okay. What that means. So an AI is nothing more than a simulator. Can't think, can't do anything. And AGI has the ability to independently rationalize. So it can make the decision to go and train itself on something new. It can learn by itself. Cool. Okay. Uh, no, that's not Skynet. Skynet is an ASI. That's a, now you're just making shit up. No, I'm not. You can look these up. That is an artificial super intelligence. And I will absolutely tell you if, if human society ever creates an ASI, it's over. Uh, just straight up over, but they predict that an AGI will exist, uh, within three to five years. Very cool. Very cool. All right. So I think that the, I don't know if there's more for this part because of other stuff I want to cover, but we can stay here if you want to. But the moral is the AI testing podcast, which we now may be called that we are, we're once again here to help teams navigate this, to help people navigate this change and understand what it means. We made new principles. Now, every time there's no, I think the principles are fine. Honestly, the, I was joking, but I do want to talk about the principles. So anyway, go on this one up for me. Okay. So that was an unannounced segue. Sorry. You're absolutely right. Like we're at a, we're at an interesting change. Okay. And it is in my experience, those who freak out about the potential of the change are the ones that are doomed. Well, yeah. Those, those who look around and say, anytime there's change, there is always an opportunity that, that no one's looking at cause they're too busy freaking out. Agile was a disruptor. AI is a disruptor. It's probably other things in between I've missed. Yep. When these disruptors happen, it's a pattern. Some people try and dismiss it, say it'll go away. Some people let it freak them out and some people embrace it and ride the wave. Yes. There's going to be more of these, man. This is what I love about work about knowledge work in general is I get to ride the wave, these disruptors and see where they take them. They keep me from being bored. All right. You want to talk more AI, you want to talk more chat GPT. No, I was just, I was just thinking around. I got to talk about it. Keep on going though. All right. I'll get to my stuff later. I'm summing up you son of a person. I thought we already summed up. All right. Fine. Go. No, do you want to sum up again? No, I'm done. I'm done. I'm done. You're done. Yeah. So, um, I got a couple of things I want to do from my friend chat GPT for you. Okay. And this is a play along at home. I want everybody to get out your pens and papers and break. You don't have to. And this is technically a multiple choice quiz, but I'm going to see if you can get it, uh, without the choices, because with the choices, I think you'll do really well because I would regard you as an expert in the area. Okay. So you know, I had that conversation with chat GPT. We talked about a couple episodes ago where we talked all about the modern testing principles, got some ideas. So that's all in the buffer of this chat session I have with chat GPT. Okay. And I had a little, little more conversation with it today. I keep that, that chat handy. I hope you, I hope you didn't ask GPT to create a modern testing certification. Ladies and gentlemen, it's the modern testing certification quiz. 10 questions. I hope you're still joking. Oh my God. Brent can be certified in modern testing. Are you ready? And please play at home. 10 questions. I probably won't read all the choices unless they're funny, but are you ready? Probably not. What is the primary, if you need all four choices, by the way, just ask for them all given to you, but I want to give you a chance to answer without them first. All right. What is the primary focus of the modern testing principles? To accelerate the achievement of sip of equality. Let me give you the choices here. Oh, fine. A maximizing profits. B enhancing customer satisfaction. C increasing test coverage or D minimizing development time. Oh, uh, except for C they're all pretty good. I don't like maximizing profits, but that's what I'm going to go with. No. It's increasing test coverage. No, it's enhancing customer satisfaction. All right. You have nine left. No. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. You can still get 90%. All right. I feel horrible. You can do this. This one's easy. Which models can be used to identify and mitigate bottlenecks in the software development process, according to the modern testing principles, which models it's multiple choice. Sure. A waterfall and agile. Wait, waterfall and agile is one option. Yeah. For redo read the question again, what models can be used to identify and mitigate bottlenecks in the software development process, according to the MTP. It's agile. A waterfall and agile B lean thinking and theory of constraints. Okay. Scrum and Kanban D spiral and rad. There's a couple of models I haven't heard of it a long time. Yeah. So it's interesting because I still view lean as a superset. I know. Look, it's it's, these are from AI. I get it. It's B. Here's one maybe you can do. But, but waterfall and agile as, as, as, as a top answer, I'm like, uh, that hurts my head. Yeah. Yeah. Okay. According to the modern testing principles, who is the ultimate judge of software quality? The customer. Yeah, that's correct. What were the choices? The developers, the project manager or the testers. Oh, okay. Those are all reasonable answers. Which I mean, if you gave this to someone who thought we were full of crap, which are there are many out there, they would give different answers. Yeah. Number four, how should teams approach? Can I'll give you a close to this one. How should teams approach continuous improvement? A by relying on safety nets to catch failures. B by prioritizing process compliance over adaptability. C by actively seeking ways to optimize practices and succeed or D by relying on predefined best practices. That was a pretty good list, but the obvious it's doing, it does a pretty good job on the other answers. Yeah. The problem is they're all kind of synonyms, but C on that one. Is it C all the way down the path? No. Okay. No. All right. Um, what is the role of testers in modern testing principles? A to write code and develop software B to advocate for the customer and ensure functional correctness C to, uh, manage project timelines and budgets or D to document requirement specifications. And the answer is none of the above because chat GPT said B to advocate for the customer and ensure functional. Correct. I'm like, um, tell me answer again. What was it? It's AA to write code and develop software. That one's actually closer. That was a say that was closer. Uh, halfway done. It was a weird way, but I agree with that. It does. Um, how should teams gather insights about customer usage and bridge the gap between product hypothesis and business impact data? Uh, yeah, whatever, whatever answer data is by using data extensively. There was, that's a dumb one. What is the benefit of expanding abilities and know-how across the team? A to increase team specialization and efficiency B to reduce the need for dedicated specialists C to create silos and minimize cross team collaboration or D to delegate testing activities to non-technical team members. Actually say those again, cause none of them feel right to me. B to reduce the need for dedicated specialists. That's what it says. Yeah. No, no, no. I mean, that's horrible. That's that's not the goal of increasing it. It may, it may result in that, but it's not the goal. Right. And we've always said that the goal isn't to get rid of testers. The goal is to improve enough and go fast enough where you end up where there's enough quality culture on the team, we end up not needing them. It's a side effect. Again, AI, according to the modern testing principles, what is the responsibility of software developers? Everything. Everything. Yep. Uh, is that an option? Well, no, they're all because it's all of the above chat. GPT just blows it. What is it? The choices are ensure customer satisfaction. Yes. Write code and develop software. Yes. Conduct thorough testing activities. Yes. Document test cases and scenarios. Maybe man, but a through C are all absolutely. Yeah, absolutely. Like what roles do telemetry and fast feedback loops play in the MTP? A they help in monitoring project timelines and budgets. They assist in regulatory compliance and audits. Both of these are true. They well, we don't talk about them ever. They provide real time insights into customer usage and satisfaction. That's the primary reason. Yep. They automate the entire testing process and well, no, but entire no. No, to limit. I mean, there's a lot more work than we've talked about using on this podcast before many telemetry for testing. You absolutely can use it, but the way the phrases, no, that's. Yeah, it's not great. It needs a massaging. I did not touch these at all, but a number 10, before I give you your certificate. Oh, which it cause it's free. Just like the modern testing principles, just like joining our Slack group, just like this in this podcast, just like reading my blog posts. It's all free. We don't care about the money. No, if we cared about the money, we'd take a whole different tact. We'd be into sensationalism and hyperbole and puppies and all those things. Which of the following statements. I am into puppies. Yeah, me too. Uh, which of the following statements aligns with the modern testing principles? Hey, testers are responsible for achieving maximum test coverage. No, I think we can eliminate that one. Yeah. B quality is determined by adherence to predefined standards. Oh my God. No. We're going to go. No. Oh my God. It's all the above. It's like this one feels like it's echoing back that previous question. Yeah. See development team should adapt and optimize practices to succeed. I agree with that. D safety nets and catch all error handling are the key to quality insurance. Uh, no. Well, actually, actually they are. If you want to keep quality assurance teams around, they're absolutely key. Completely agree with that statement. It's kind of, it's contradictory to modern testing, but yeah. One more thing. I may have to just read this without trying. It is not rehearsed, not rehearsed at all. Not even read yet. All right. But, uh, we're too old white dudes, but saw, I feel weird asking this question, but Brent, can you beat box? No. Fine. Fine. There will be no AI generated modern testing rap today. Why don't we go ahead and end it there and we'll see you next time on the AB testing podcast. Yo, let me drop some knowledge about the empty principles of rap. You make your thinking challenge your residual, enhancing customer satisfaction. That's the goal. Put their needs first and let the quality unfold. Modern testing breaks the mold. Customer satisfaction. Let it be told. Lean thinking, theory of constraints, continuous improvement. No time to relent. No safety nets. No catching all the flaws. Adapt and optimize. Find the root cause. Testers advocate for customers with pride. Functional correctness. That's the stride. Modern tests to break the mold. Customer satisfaction. Let it be told. Lean thinking, theory of constraints, continuous improvement. No time to relent. One more time. Data driven insights. The key to success. Telemetry and feedback. We're never second guess. Expand abilities. Don't need to special roles. Bridge the gaps. Let's reach our goals. Yeah. 
