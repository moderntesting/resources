Welcome to AV testing podcast, your modern testing podcast, your host, Alan and Brent. That's me. He here to guide you through topics on testing, leadership, agile, and anything else that comes to mind. Including AI. On with the show. Hey, Britt. Hey, Alan. We're now putting annotations into the intro. People know our secrets. Yeah. All right. Well, here we are. Our dreams. A water. No, your name. All right. Here we are. Thank you. Episode something. 219. Is that right? Do we know? I actually. I'm going to call it 219. I had it up and then I closed it. AB testing. Oh, what if we were the AB testing? Like for getting a six pack. Yeah. What if we're all about like. Whatever it is. Okay. So this is episode 2018. Oh, hold on a second. Brad's taking his shirt off. Hold on a second. No, those don't count as a six pack. That's that's. But it's a damn solid one pack. It's a keg. Yeah. If we were about AB testing. I am definitely the wrong co-host for this show. Oh yeah. Same. Same, same, same. How are things. Again, episode 218. Episode 218. Don't get it right. Don't skip over. Yeah. How are things going? Hey, I will tell you like sometimes it happens. Like we've been together now forever. I know half as long as my marriage. Yeah. And I have to say like the advice you gave for me on 217. Man, is that working out? One is, is it skills? It's adding joy to my life. Tell us more about that so I can stroke my ego and you people know what you're talking about. Yeah. So last, last time, uh, Ellen, I asked, Hey, Ellen, how I'm paraphrasing. I don't know what the hell I asked. But Hey, uh, how do you shrink the distance between teams in the remote world? And I brought up like the water cooler chat was really important because it helped construct interpersonal relationships, which is just a pain in the ass to do. Um, in the remote, particularly the remote async world, I am in Allen, amongst other things suggested, Hey, I did this thing called question of the day. Right after we recorded that episode on Monday, I created a channel, um, on teams. Uh, and the channel's name was simply, uh, my, my, my team's alias, a dash in QOTD. And I didn't even explain QOTD. I just started putting a date and a question and that's it. I didn't explain what I was doing, why I was doing it, what's going on. Why isn't this an evil trap for management? Just it. And then I always answer the question and, uh, first, because I don't know, you, you didn't describe when you asked the question. When did you answer yourself? Um, good question. Uh, sometimes right away, sometimes later, sometimes not at all. I see. Okay. Eventually not at all. Um, yeah. Yeah. And I've been doing it and the team engagement on it is, is just super active. Um, so let me ask, are there, when people answer the question, people follow up in threads or whatever with, with, uh, a clarifying questions or me to use or things like that. Oh yeah. Like we, that's the best part. That's the best part. And when people do follow up questions and engage, like I'll say, for example, today, my question of the day is if you could invent a holiday, what would it celebrate? That's a great question. And Alan on the spot, if you could invent a holiday, what would it celebrate? April 4th. It's the anniversary of the AB testing podcast. Okay. That is an entirely perfect response. Yes. I answered, um, benign chaos. That was my first thing. I'm like folks would celebrate it by performing random acts of randomness spelled R a O R, but pronounced roar being non harmful would be required. But within that constraint, do your part to maximize entropy for a day. And um, What a weirdo. Yeah. Uh, I am definitely, I don't know if you ever played D and D, but I would 100% as a character, I would 100% be a chaotic good alignment. Um, and one of my, one of my employees, they wrote, I have always loved the appearance and an emergence of randomness when you least expect it. The most harmful kind of course, it plays a key role in humor. And they said on a related note, a person once selling a lamp on a college buy and sell Facebook group. I wondered what if the lamp could reply to the owner's post? What if it was surprised and taken aback that was being sold like this without its knowledge. So a few account creation hops later, wallah, the lamp had its own Facebook account managed to join the page and reply to its owner's posts, expressing shock. That's really funny. That's really fun. And I'm like, yes, that's freaking benign chaos day. Right? And he was saying, yeah, he would support it as being a world holiday. If he could, that is good. Right. It serves no purpose. It is not positive or negative. It is just random. Right. Am I like it? Yeah. I play it for many years. I played this chaotic, good rogue. Uh, and he was, yeah, I, I played him. I played him to the alignment. It was fun. He was, you know, yeah, you know, D&D. I like playing. I like the alignment aspect, not just that go kill everything. Like, let's make this kind of fun. So anyway, the number of times the rest of my party went, oh, no, not again. Yeah, see, that's the fun thing about chaotic good. Everyone knows, okay, that you're going to be good, but yeah, you may, you know, rules are guidance, really, not rules. Anyway. Yeah. You know, yeah. Yeah. What would Hans Solo do? All right. Shoot first. Anything else from your end? He obviously shot first. Right. Anyway. No. All right. So as we discussed on the last time on the AB testing last time on AB testing, I recorded a couple of days before I told my team, but I am leaving my job. I do not have another job. I'm going to be professionally homeless. Nope. Professionally, I get paid. I'm going to be broken homeless and walk from Mexico to Canada on some stupid trail with about a thousand other people, but it's going to be fun. I'm all prepared. I've weighed everything. It's all ready to go. I let my team know last week. And what's interesting, what happened is as I let people know there was surprise. I had some really, really good feedback from my team coming out. I have tried to set them up in a way where they can just, I told my manager to give my head count away to another org or to not backfill because the team can kind of run on their own. I need somebody with a fancy title to yell at somebody with another fancy title. But that's really what my role has been reduced to. But anyway, going well, got a couple of great pieces of feedback. Somebody told me today, they appreciated me trying to challenge the system, which is like not surprised you do. That's what I do. You don't hire a change agent to stick with the system. I know. I know. Actually, the best feedback I got is somebody said, well, there was two parts of it. Oh, said thank you for your unconventional approach. It was a breath of fresh air. And what happened is... Okay, I'm good, baby. My breath of fresh air was a big fat fart to some people, I think. But it was air. It was air coming from somewhere. So yeah, wrapping things up. What's happened is my calendar has taken a massive nose dive. People have already started scheduling meetings, not with me with my directs or other people. So I have my one on ones left for the next... I guess through next week, April 4th is my last day. It always makes sense for everyone to do this. But I got to say, it's the saddest part of leaving a team. Suddenly, you yourself, all this energy and then the last two weeks, it's just like crickets. It's like quiet quitting. But instead of me stopping, slowing my work, the team has quit on me. The organization has quit on me. And I'm not mad about it. I've talked to people about it and they said, use the time to relax. So I'm doing a lot of steps at the Stairmaster. I may just do one... May just work from there, work from the gym next week and just do Stairs in between meetings. I'm not quite sure. We will figure it out. So anyway, good feedback from the folks, but they know they're in good shape. Transition stuff is done. Yeah. So I want one last thing and one last... I'm trying to push some promotions through before I'm gone. So we'll see how that goes. See what I can do in five days. I'm semi-confident. I believe in you. And I believe in me too. That's my challenge and problem. Well, all right. I think that's it for the... That's the work stuff, the trail stuff. Do we want to talk about the... This is the penultimate episode of A.B. Testing for a while. Right. And we're going to do a recording next week that will come out on April 4th, which is now a national, I think a world holiday. Right. The A.B. Testing anniversary, 11th anniversary special. There won't be any guests. It will be us reflecting on our time together and talking about what's next. I can... If you want to ask me questions about my trail gear, you can throw them in one of the three.slack.com. You can go to moderntosny.org to get a link to that invitation. I've been clicking the renew button every 30 days on this, on that link forever. But Brent and Perzi will take care of that going forward. And hopefully I hope to return to the slack in mid-September after that. So to segue into a topic that Brent and I talked about briefly before, I looked at my LinkedIn notifications as I do once in a while. Not very often. Sometimes I missed... I talked to... Remember Lena? Lena Zubit, a guest on the podcast? I talked to Lena about... This is actually my kind of tangent here. We talked about... She had some questions about like the history of the bug bash. And the internet says that the bug bash was invented at Microsoft. And it was there when I joined in 95. But I couldn't really find any documentation on how it came about. There may be somebody like Tierney or someone who was there in the late 80s and 90s and testing who may remember how that came about. If anyone knows, it would be Tierney. But maybe nobody ever knows. So we talked about that for a while, some of the bug bashes we did. It was an interesting conversation. But I messed up... I missed a meeting with her because I never checked LinkedIn and she sent me a message and I said I'd be there. But I didn't put it on my calendar. And then she went to check in. Didn't hear back from me for like five days. So anyway, that happened. Sorry, Lena. I went to LinkedIn and checked my messages, took my notifications today. And we are number two on some list of software testing podcasts. OK. What's interesting is I don't remember the last time we talked very much about software testing. But who's number one? What the hell? Oh, dude, dude, I was on this podcast once, the performance guy, Joe Colantoneo. Oh, OK. So somebody better than us, that's why. We shouldn't even... Honestly, we shouldn't even be number two. Double honest. It was on... We probably shouldn't be on a testing podcast. It was on a list of software testing podcasts. Dude, I'll bring up my link. Trying to cue you up here before you get distracted. The idea is, I'm going to go ahead and cue this up. We started A-B testing because we were coming from the testing world. I think I was still in it. And we were seeing changes happening. And we wanted to talk to people about what those changes meant and how to navigate those. By and large, despite the deniers, those changes that we predicted have happened. They're common. There are people that don't believe in them still, but they're... I mean, I can deny that the sky is blue also. But that's how we started the podcast. But then Brent had some ideas on sort of building on that. Brent's still reading. I'm trying to like get... You ready to go here? Ready to take over? Yeah. All right. I'm passing the speaking baton to Brent. I've cued you up. Talk about what you talked about before and we'll go on from there. Okay. And I found the list. And actually, I will re-cue even though you cued. I found the list. It was published two days ago. Yeah. Just came. I linked in notifications. Yeah. I wonder how they do. Okay. So as Alan cued up, why did we start this podcast? Well, if you guys remember, did we do that in 199 where we went back and listened to episode one? Yeah, 198 to 199. We went back and listened to episode one. Right. And we did it so you don't have to. It was a reminder that why did we do this? At that point in time, Agile was threatening to change everything. And Alan and I had observed through our own practice and through first observing other companies and then observing and leading that type of change internally that said, oh, well, if you care about testing, like we learned. If you care about testing this new world that we're clearly heading into is not going to be for you. But if you care about quality, this new world is fantastic. And we said, okay, there's going to be some set of people who are interested in knowing whether or not the grass is greener on the other side of the hill, how to get there and how to thrive. So we started this up and said, okay, let's just share our experience and see what happens. And avid listeners along the way, we ended up developing what we call the modern testing principles. And I thought that maybe today what we talk about is not AI, but the AI phenomenon. I don't, unlike back then where there were numerous examples of people making the shift and how to succeed and how to fail. And in this particular time, Alan and I also began to execute this shift. I got to the point where I was directly coaching people and teaching people how to shift. We're in a phase in the software industry where AI is beginning to take a tangible hold. And I see a lot of parallels to back then as to now, right? A lot of people holding on with white knuckles, oh, AI is going to take my job. Oh, AI. Like who's going to watch the AI? No one has yet said what would be the equivalent in the AI world? What would be the equivalent of, oh no, we got to keep tests around because dev doesn't want to do testing. Like we got to keep dev around because who doesn't want to do development? I don't know. But I thought maybe today we talk about what we think, not what we think, because again, what I'm stating here is we're still too early. Alan and I are still too early to really go and say, oh, this is the path for success. This is how you begin to migrate from the skill set that you had to the skill set that you need. We've talked about many times similar things. I am absolutely convinced that the jobs of the future are going to be human and AI working together. But what does that tangibly mean? How do we produce product? How do we ship product? Do we do either of these? What is that? Like there's not enough, to my visibility, there aren't enough early adopters where it is clear the direction to go. So I thought even given that ambiguity, maybe it would be worthwhile based on what Alan and I know today to go and revisit the modern testing principles. Oh, I see where you're going. And go based on what we know today, what if this is still valid? What are these should be removed? What should be tweaked? Thoughts? God, yeah. MT principles 3.0, discussion begins. Well, I mean, I guess we could just call it a brand now. Again, yeah, it's a brand name. Just like AB testing isn't really about, not that modern and not that much about testing. Right. But you could argue it's becoming a lot more like a slash B testing. Right? It is. I'm going to, I know you have a thought here because I'm honestly glancing at the principles having a hard time. So I'm going to let you start and then I'll probably figure it out and we can jump in. So please continue. You're having a hard time. All right. Applying to figure out how you want to apply what you just said. I don't want to like, so do you remember? Maybe they just all go away. Maybe you remember centuries ago where you had the idea of, Hey, Brent, I just read this nifty book on round principles. How about we sit right down. That's what I'm proposing. Okay. All right. Given that we actually do not know enough about how, how this AI phenomenon is going to change things, right? That's the problem because we're putting our finger in the air and predicting. Like we already heard from Jason Arbonne, right? Everything we're all going to be testers, but that's, that's his prediction. Right. But you know, it's funny. Yeah. I come back from my trip and, and because I work in a country where I have to have a job to have healthcare and I pay out the nose for it while I'm gone. What if I, I mean, there's probably a non-zero chance I go back into a testing job. Just are there, are there any testing jobs? Maybe there aren't any, I was going to say, maybe I go back into a testing job and Jason's prediction comes true, but there may not be any left by the time I'm back. So don't worry about that. Go on. All right. No. AGI, despite AGI still has a ways to go. Okay. That's not going to happen while I'm gone. I'm not worried. It's not going to happen while you're gone, but I do think multiple, I don't know if it would be globally or just within my company. But I do think things are going to change at least two times over by the time you get back. Right. Can we? The, let me just make sure the sky is not falling based on. It's a text saying AGIs are out the world is ending. No. Okay. So let's do it this way. Let's go principle by principle and then say based on what we know, does the AI, does the new AI driven business, how does that impact the principle? How is that the AI driven? I don't know. Even the term to say here, imagine the company, the new early adopting company, and they are all in on, they're not providing AI. They are using AI to provide their goods and or services. Okay. And they're successful. How do we do it? Now, number one. I think that's an easy one. Does principle number one change in that world? Who, let me just for context, when we started these our who said we and our and those pronouns are referred to testers originally and then the people of the develop people of people's people, the development team. So our is the people delivering the software, right? It's still the people delivering the software. I think so. Yeah. Who is we? Okay. People who just like back then we were we presented this like our were like the people under threat. Okay. Right. So I'm going to say it doesn't change the priority should be the same on any software development team. The priority is improving the business. Okay. Actually of any member of a company, your priority is improving the company. Okay. Done. One down, six to go. We use models like lean thinking theory of constraints to help identify prioritize and mitigate bottlenecks from the system. So I should probably not answer all of these first. I'm into this one because those things are still important for software, but I would change this one to apply system thinking and critical thinking in order to make sure that our phrase it differently than our AI overlords are contributing adequately appropriately to our business. What do you think? I thought we had one where we covered systems thinking. No, system thinking. I absolutely think is true. And then when I think about AI, right? I'm like, okay, if we have a, if we in a true AI agent world, we definitely will need system thinking. Okay. And we will probably still need lean thinking in some regards because lean thinking is all about producing the max number of widgets at the, at reducing waste, reducing waste and cost. Right. And, um, and the theory of constraints I still feel is like, if we have all these AI agents, who's identifying prioritizing mitigating bottlenecks? Like I don't see something I think still needs to do that unless these agents are so cheap, um, we don't need to prioritize. So what I see happen, again, I imagine this business where AI is helping us improve the business, which is great. I think that there are, like we need people, you know, overseers in a way to make sure just, just to help people not willy nilly accept code or to examine the code. It reminds me, you know, 15 months ago in our prediction episode, whatever year that was, I remember predicting and I'm going to pat myself on the back for this because the longer the time goes by, the more strongly I feel this is true. A key skill of an engineering team with the feature is the ability to read and evaluate code. And I'm not sure how we model that here, but you like, I think reading and comprehending and critiquing code is becoming, and it has already become more important than the ability to write it. I actually now disagree. Oh, Tommy Moore. Um, where I see the AI agent, um, movement going, uh, if I take it to the ultimate degree, uh, I see a world where except for two important exceptions, um, all code is throw away. Oh, tell me more. Okay. So I'll try to connect the dots. Um, so as we know, uh, I will tell you more. Where do ideas come from? Other ideas. Everybody knows this. Great. Um, now quickly summarize for our audience. This term called the adjacent possible. Oh, to me, I mean, this is relevant here because the adjacent possible is that's what AI has done. Adjacent possible is when you, there's a technology that exists. It's maybe it's new, likely it's new, but what it enables the things that are now possible to it cause they're adjacent to this become where the true innovations come from. That's what I've always believed. I believed. Gen AI was always the enabler of the adjacent possible and you know, 90% of the companies made bullshit applications with it, but we're starting to see companies actually solve real problems using gen AI and that's the adjacent possible, right? Uh, the way I would actually summer, that's actually not the adjacent possible because it's now solved. The adjacent possible is the, the thing, the ideas that haven't been created yet, but now can be because we have advanced the tech tree to go back to like geeky video games, right? We have gen AI and so that there's a now a whole new set of things that are now possible, uh, that weren't possible before gen AI. Okay. Now what Jenny, I does enable today is near instant disruption. Cause the other problem with the other phenomenon around adjacent possible that is really important here is, and I love Steven Johnson's explanation here. When new things become adjacent possible, it's terribly common for the same idea to be invented near, um, the same timeline, but entirely different times of the world. Yep. Absolutely. We're seeing, and we see that. And we see that. And what AI is doing is actually encouraging that adjacent possible. Like there's a piece of tech that my team owns. Okay. And just internally within Microsoft, I am knocking down a competitor like every month. Right. And now I'm not actually knocking down competitors. Whereas originally I was like inviting collaboration and all that, but I'm finding, Oh, some new team has this idea and now they're two years behind me. I'm like, look, I need to keep advancing. I don't have time to pause and ramp you up. Sorry. Um, and that is mostly because I have no idea how to quickly bring in these people. Um, and get them up to speed. Now, what that leads me to believe is that eventually we're going to get to a point where an all new dis disruption is going to happen monthly, weekly, daily. Okay. Now, the other thing I did is the other day is I went to open AI. I have a subscription and I typed in the following prompt. What is the sign of three, four, five, six, seven, eight, nine. And it wasn't actually those cause I specifically did random numbers. I kind of pounded my number key. Okay. And not only did it get it right, which surprised me, um, because I'm like, LLM is nothing more than a parrot. It is outputting mem, memorize things. But now open AI has sort of opened up the black box a little bit. And you can open up a dropdown and go, okay, how did you figure this out? And then I've seen those. Yeah. And then I looked at it and I'm like, Oh, that's fricking brilliant. And what they did is the, this part of it is still the black box to me, but they had something in there that figured out that leveraging the model directly, answering the question is not what it should do. What it should do is generate how to answer the question. And in this particular case, it generated a Python script and immediately executed it and that's what it outputted. Interesting. Are you doing the example right now? I am, but mine didn't give me the code. But anyway, I had to look. Okay. It asked if I wanted the answer in radians or degrees. Okay. Um, the, and I'm like, Oh yeah, that's exactly right. Because like I think about if I were asking you interview questions, if you came to me and my team and I asked you a bunch of interview questions to some degree, I care about what you know. Okay. But when it comes to specifics, I care more about, do you know, do you know how to figure it out? Yes. That is what the current model on open AI can do. It can switch between answering versus no, answering is a bad result. I should instead generate a Python script and even Python script is fantastic because it's an interpretive language. It doesn't have to be compiled. It can be immediately executed. Okay. As that continues, right. Disruption is going to continue to happen. There's no point in me starting a project that's going to take two months. If the technology is advancing such that, um, some other random team, because of the adjacent, the possible, there's no way for me to know that this team was coming, but if the, if the technology advances, let's say I have a project that takes two months, but the technology advances in one month, such that that project can be done in a week, I'm still three weeks away from finishing my solution. They now disrupted me. They have a solution before me. Um, which of course I will look into and then I will be the, the disrupt them tomorrow. I have a product idea. Yeah. Uh, it comes from, uh, I don't think, I don't think they do this anymore, but years and years ago, decades ago, Google, uh, would at the end of every week, employees could optionally submit a status report. Yes. And, but that status report was searchable and it could tell you like, Hey, somebody else working on the same stuff. Do you want to talk to them? Now my proposal is, uh, uh, open AI enterprise where if you choose privacy aside, uh, it would keep track of what sorts of questions everyone in the, everyone in the company is asking and pair people who seem to be working on solving the same problem. That's a fantastic idea. It's not bad, huh? Yeah, that's a good idea. I have been trying. I mean, I don't know how my story fired those synapses, but, um, that is a good idea because I, I too had learned around how Google, Google. And the, yeah. And the adjacent possible doesn't confine to a company, but if you want to optimize a company and make sure, at least across a corporation, you aren't solving the same problem. Why not, why not have the, have the AI figure out if you are doing that. Yeah. Yeah. All right. Just, just thinking about that. No, no, no, no. I mean, you're not convincing me. I'm wrong on the fact that reading code is critically important. No, no, no. So here's the thing as so in here, I have also thought through. So if we take what I just said, Yep. Um, to the nth degree, then in, so I'll, I'll, I'll circle back to my three things, all code, except two things, two types of code becomes throwaway code. Okay. Okay. So you need to do a query against the database. Actually, you don't need a query against the database. You need an answer to something. Yeah. Database is an input to my question. Go ahead. Great. It's Hey, how, how, how many widgets did Alan Page by last month? Right. Um, it realizes it doesn't have that answer memorized, but it knows how to derive the answer generates, um, Python code to authenticate, to connect, writes out the query, executes the query, summarize it, returns an answer. Okay. Today. Well, even a year ago, that would have sounded like fiction today. It would still be work, but that's entirely viable. Now the two types of code. So that code would be throwaway. It's generate execute, generate execute. Like, so in that world, Jason's 100% right. We're not doing QA testing for that code. That code lives three seconds. Right. Oh yeah. In that world, we're like, okay, let's make sure these agents are, um, doing the right thing. Uh, but the code that doesn't become throwaway would be the language platform. Like I've been talking about Python, right? Because Python's critical here again, cause it's an interpretive language. You don't, you don't want to waste time on going through a build step. Um, as well as the atomic classes, objects, API, like the atomic functions that you can call to do something useful, like authenticate, those things, those things become the, the base action. Um, and the AI just generates the right thing to execute against it. Um, I absolutely believe that's where things are, are, are heading. Um, because as more and more people do to the fact that the adjacent possible is going to cause people to get frustrated and abandon their projects because something came out of the blue and disrupted it. And the only way to deal with that, if you eventually realize there's no point in me starting anything, because I won't be able to finish it in time. To me, the, the only solution is, is just skip the head. Like you have to design your projects as if the entire code base is throwaway and it still has to succeed. You know what you're, I think we can both be right. I agree. That's a good way to approach, but you still have to know if the code base that you're going to throw away, you have to be, you still have to know. I mean, you know what I mean? It's like, maybe it's just a trust, but verify thing with AI generated code. You and I both know it's getting way better. It was good before it's getting, it's scary. It's scary. Good, but it's not perfect. No. And we need, we still need people who can look at it and go, yes, this is doing what I asked it to versus close enough, enter submit. Yeah. No. And here's the thing that's fun. Like when you, when you talk about code, like the, the most common hallucination I get from, from AI when I'm coding is it makes up things that don't exist, it makes up these atomic functions that don't exist, but then when I look at it, I'm like, wait, why doesn't that thing exist? Yeah. And, and actually that could be one of the fixes for your AI generated code. You should like that doesn't exist. Please go write it. The only way throwaway code is viable is if it can be generated and run and discarded in a couple of weeks, there's a step in there of making sure it does what it's expected to do. And, and I hate the metric of lines of code, but I'm going to use it for a second, bear with me. If like, if I could write a couple hundred codes, like codes, a couple hundred lines of code in a day and debug it and test it, make sure it's working, um, in the day, I felt pretty good. I felt like I cranked out a bunch of stuff. I should be able to do a couple thousand reviewing and making sure, especially with today's languages, um, that each line does as much as 10 lines of my old code did, um, or 20. But, uh, you still have to just give it a once over because of lots of reasons. And we need people that can do that very good and very quickly, even for throwaway code. And maybe by the time I will, that's no longer true because it just, it's just because the AI does that for us, but we're not there. If we have time at the end of this podcast, we don't, we're on principle number two, we do. I will. So there's intellectual, uh, there's IP there. Um, but if we have time, I'll talk to you off error and I think it will fulfill your goal. It might happen by the end of the podcast. Um, all right. All right. So yeah, I don't know how we handle theory of constraints. We don't. I think this one is, I can only get to number, at least get to number three or four before we're done. But number two is we have to use some different models to prioritize. And this goes into throwaway code. We want to prioritize. We duck. I don't know if the bottlenecks, they're still going to exist, but we're trying to optimize is, is delivery. bottlenecks are still, are you still going to exist in the system? But when we wrote this, um, testing was the bottleneck. We were thinking more well. Okay. So if we generalize this and we say bottlenecks are resources being consumed and generally like resources, we, I was, when we were doing this, I was thinking about people, but now we generalize it resources. Okay. Well, you know what? In this future world, I'm going to need compute. I'm going to need storage. I'm going to need networking. I'm going to need databases, right? Maybe, maybe that's how it extends. Let me, let me throw a thinking cap on here. Brian Finster said on our podcast, and I agree with him so much. I want to keep on repeating this is the best way to optimize your system is to try and do CD. Yeah. Cause it shows all the things like, well, we can't because we block, we'll go fix block. So I think you're thinking with the, with AI helping a mature organization to does it correctly, uh, I mean, CD of course you're doing CD, but, but is there anything else they need to do? Are there other bottlenecks to do the AI? Can the AI CD? Yeah. So I almost wish I hadn't even brought up the last topic because I'm just now going, yeah, Alan automatically on the fly generated code that's throw away. Is there a faster CD than that? There is not, it can't be. It's like, yeah, we, we, we don't compile it till it's production. It's interpretive. You know what I mean? Right. And so, all right, let's try to move on to number three. How about that? Okay. We are a forest for continuous improvement in the doubt that optimize our practices in order to succeed rather than using safety nets, sketch our failures. Obviously you're very testing there. Um, I'm gonna let you go first on this one. Cause I did the last one. Um, that obviously the language would change. I would keep that one, but I think it would need to be significantly tweaked. Yeah. Right. This is, we do still optimize our practices and actually that by the way is where I interpret systems thinking in here. Uh, but I think, I think you're right. System thinking needs to be more highlighted. Right. That's the only, if we have a whole bunch of AI agents doing suboptimal, um, optimization, Oh, our world's gonna suck. Um, because it's not the case that everything's independent, right? We're going to create a world where, where we can visibly see the butterfly effect within hours. Um, but continuous improvement. I think that's always going to be the case. Uh, adaptation, agile adaptation. Um, I think that's even more critical today than it was when we wrote this. Yeah, I think so. Both, both, both internally as a human being working on, uh, in this world, as well as externally, because again, in my worldview, disruption is going to happen all the time. Okay. And so, right. I think we're heading to a world where, you know, six kids and the, in a, working out of a garage, um, could scale something up. That could be a threat to, you know, something as big as Amazon. I don't know how they would do it, but I think that's something that is becoming more and more possible. Um, all right. How about that? Any comments? I, yeah. I got a whole bunch of reach. I read you reach you in a second, but no, I think that's kind of it. I do want to get through the rest and then I have one special bonus thing to read at the end here. Okay. Um, what about the quality culture of our team? I mean, is that, is that still a thing? I mean, we talked about, we talked about friends and I stopped caring about testing, I realized we care about quality far more than an activity. Uh, but how does AI help with the building that quality culture? And remember care and quality are two sides of the same coin. So yeah, the, um, I think that becomes a lot more critical. Tell me more. The, the, in terms of how to produce quality, because the, we enter from a world of determinism, right? What is checked in code? That's deterministic code, right? And again, going back to what might've ended up being the poison pill for the whole soul exercise, going back to that, I'm like, okay, well, if the code is throwaway, then what's the definition of quality and I still stand by it's the one we've always used, which is, um, the customer's point of view. Yeah. But that's principle number five. Right. But now this becomes more the quality culture here goes in a different way. Cause previously we were talking about how do we build quality in a, in a deterministic world? Hey, Alan, your, your if condition is, is doing greater than when it should be doing greater than equals, right? You go check it in, right? Right. It's a deterministic world. It's a lot easier to determine. I will tell you, even if developer, even if most of the code, all of the code is AI generated, uh, the team who is interacting with the AI and doing some work there, it isn't, it isn't all automated by AI. That team needs to have a quality first mindset. Yes. Yes. Absolutely. There's something still there. No. And actually this reminds me, this takes me back to my time in bank. Right. And I talked about it on the podcast. Years ago, right? One of the things that was tragic, the interesting is that bugs did not matter in bank, right? Because they have multiple different data feeds changing every single day. You have a model that's changing similarly constantly all the time. So it was a throwaway code. The experiences. So the code wasn't throwaway, but the experiences were okay. So you, you would go to Bing and you would type a query like price of Xbox. Right. And then you would, you might, you might one time notice that it average it saying, Hey, Walmart, but, but maybe one out of a hundred times you hit refresh and it says a phone number instead of Walmart, right? Um, you wouldn't report that phone number bug, even though it was a bug. What you have to report is the pattern, the observation, Hey, something is wrong in your system because the experience is non-deterministic. And so all I'm saying here in terms of the throwaway and actually given, given HTML five is so much goddamn code. Yeah, you're right. Or rather, yeah, it might be that, that we're already kind of in the throwaway code world. Yeah. Anyway. All right. Um, okay. I promise for the next of these, I am not going to use the term throwaway code. I am trying to battle the poison. We kind of already talked about five, five doesn't change. The customer is only one capable to judge and evaluate the quality of our product. Done. Number six, we use data extensively. Yeah. They have one problem with number five is who the hell is the customer. But I don't know. Keep on going. All right. Data. I think the way we use data or how data is consumed, the customer data is different. But how we have written there, I don't think changes. Yeah. I don't think it does either. The it's in matter of fact, like the second part of that principle, close the gaps between product hypothesis and business impact. I think, I think that has to go faster. I think that, yeah. Yeah. We didn't say decrease. We said close. So they're going to, that's the thing that's going to have to happen is that that has to happen faster. How about we expand abilities and know how across the team, getting the fact, this is the one that says, Hey, if you get really good at this, testers may go away. Do we now say if you get really good at this developers may go away? I do. I think I do too. Because I think, no, I think, I think the developers who hold on to white knuckles around, I'm a, I think we're going to see a world where developers begin to use the same language testers did. I'm a craftsman. They will. Yeah. And, and the people it's, and again, I'm going to go back to, I need to write. I with me leaving. Um, I haven't read any blog posts and all this one I need to write. And this topic is this Dan pink's lesser known book before drive was called the a whole new world. And it's about how right brainer we talked about last time. I'm sorry, stop it. A whole new mind, maybe whole new mind. Um, how right brainers will like people with critical thinking are going to rule the world and he's more right than he ever was. And he wrote the book almost 20 years ago. And those are the people that are going to be interacting with the Gen AI to develop to you. Was it critical or creative? Creative, creative, creative people. So let me, uh, in my spare time over here, um, I asked our friend chat GPT. I said, these are the empty principles from Alan Brent. How would we change these to reflect AI driven software release rather than the empty approach, which is mostly about continuous delivery. You can argue with that part. I want to give us some context. Um, it said, great question. Oh, by the way, uh, what is up with chat GPT? I asked it. Um, I have, I'm not going to mention anything here, but I'm going to hold on a second here. I have some rare albums and I'm not going to mention which ones they are. I have one that has a very provocative cover and I, I got, I want to sell it. I'm uncomfortable having it on my collection. Okay. But I asked it about it and he said, and chat GPT, I almost give it a, he says, it gave me a TLDR at the end. I said, yes, it's rare. Yes. It's collectible. Yes. It's controversial AF. Yeah. No, that happened to me too. Today. I don't remember the exact example. I'm like, no, no, do not turn it down a little bit. Chat GPT. No, I don't, God, I don't want these damn bots to have personalities. Okay. Let me, let me whip through this answer to this question. So, um, it's a great question. Blah, blah, blah. Our priority is delivering measurable customer and business value guided by intelligent systems. I wouldn't use those words, but it's not wrong. I like ours better. We use AI augmented models to identify, prioritize, and eliminate friction in our development delivery pipelines. I don't, I think our discussion was better, but it's not bad. Yep. We are a force for adaptive automation, continual. So you're finding our systems with feedback and loops rather than relying on manual safety nets. It's not wrong. Yeah. I didn't think about that angle. I didn't think about that angle. It's right on. We lead the organization in developing a quality mindset with AI as a co-pilot and promoting shared accountability for product excellence. Again, it's not whole. Wait, wait, wait, wait. It brings in shared accountability. Yeah. Who has shared accountability? Like last, I know LLM doesn't give a crap if you hold it. No, but no, it's the team, the peep, the humans. Okay. Okay. We coach teams on, here's a subtitle subtext. We coach teams on interpreting AI insights and building trust in autonomous or semi-autonomous release systems, which is kind of what. MT 3.0 should do. Yeah. Help people get the trust so they don't pull out of their white knuckles. They ride the wave. Right. Number five, we believe that customers and AI informed representations of them are the ultimate judges of quality. Now here's an interesting take. We believe in the customer we haven't talked about because now we know customers, we have data from them. Can we use AI to build a representation of them that can evaluate quality? That's a whole new one. That's, that's the case. Yep. Um, we use telemetry usage data and AI driven analysis to continuously close the gap between what we built and what the business needs, that's fine. Oh, it was said, we democratize AI knowledge and tools across the team, enabling everyone to participate in building smarter products and smarter systems. I get by that. These are horrible. From a, from a, a, a, I probably could have done a better prompt, but, um, not bad, right? Bad. And what we just spent the last 40 minutes on, we could have just asked GPT. I know we could have started. This is actually the way I do a lot of, um, I'm trying to form words. I'll, I'll, I'll have it give me a start. I wouldn't use these words and not quite right, but refining what's here. This is the same thing for code. I want to read this. Like again, I use my writing skills to read this, understand where it does and does not match my intent and tweak it until I like it as a reputation of me. I, we have to do the same thing with code, but what I really like, uh, is. This is kind of, it's really close to spot on. So your idea, we took your idea. We took something that could have taken weeks and months of vetting and we did some discussion, accelerated it. And we have a new place to kind of start whatever the XX principles are for. Uh, when I get back from the PCT. Right. And the world may have changed by them. That might be a great place to kick off the way, way, way then. The world will have like, again, I think the world likely will have changed multiple times. But one last thing, no matter how many times the world has changed by the time you get back, do you see any reason to believe why the modern testing motto would change? That's not modern, not about testing. Nope. Oh, accelerate the achievement of shippable quality. Yes. Yeah. That's what AI does. You're right. You're out of the money. Brit, you're a fucking profit. I mean, a freaking profit. Sorry. Sorry. Apple, if you come censor my podcast and kick us off. Yeah. I am not going to check the explicit box. Please don't listen with your kids in the car if you have a time machine. But if you do have a time machine, please contact us on the DM. Could you please come back before the 2016 election and help us with some little bit more, little bit more information. Oh, you were thinking way too small. I guess if someone's got a time machine, I have much better purposes for it. Okay. All right. All right. Biff from back to the future. We are done with episode two, 18 of the AB testing podcast, the AB testing podcast. I am Alan Abb. I am Brit Abb. See you later. 
